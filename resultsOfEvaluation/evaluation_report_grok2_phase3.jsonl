{"dataset_index": 0, "task_id": "CustomEval/graph_3", "entry_point": "has_cycle_directed", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 1, "task_id": "CustomEval/graph_4", "entry_point": "topo_sort", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 2, "task_id": "CustomEval/so_ordered_unique", "entry_point": "ordered_unique", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 3, "task_id": "CustomEval/so_merge_intervals_closed", "entry_point": "merge_intervals", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 4, "task_id": "CustomEval/so_parse_query", "entry_point": "parse_query", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 5, "task_id": "CustomEval/so_topk_words", "entry_point": "top_k_frequent", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 6, "task_id": "CustomEval/so_flatten_depth", "entry_point": "flatten_depth", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 7, "task_id": "CustomEval/so_chunk", "entry_point": "chunk", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 8, "task_id": "CustomEval/so_roman_to_int", "entry_point": "roman_to_int", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 9, "task_id": "CustomEval/so_normalize_path", "entry_point": "normalize_path", "passed": false, "runner_output": "  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp52k541kf.py\", line 40\n    assert candidate('a/b/c/../../..') == '.'}\n                                             ^\nSyntaxError: unmatched '}'\n", "test_format": "executable"}
{"dataset_index": 10, "task_id": "CustomEval/so_split_csv", "entry_point": "split_csv", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 11, "task_id": "CustomEval/so_is_balanced", "entry_point": "is_balanced", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 12, "task_id": "CustomEval/so_regex_email", "entry_point": "is_valid_email", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 13, "task_id": "CustomEval/so_json_flatten", "entry_point": "flatten_json", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 14, "task_id": "CustomEval/so_datetime_diff", "entry_point": "days_diff", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 15, "task_id": "CustomEval/so_matrix_rotate", "entry_point": "rotate_matrix", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 16, "task_id": "CustomEval/so_lru_cache", "entry_point": "LRUCache", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpkwu93907.py\", line 103, in __run_tests__\n    raise AssertionError(f\"Case {i} failed: result={result!r} expected={expected!r}\")\nAssertionError: Case 0 failed: result=<__main__.LRUCache object at 0x10e7681a0> expected='[None,None,1,None,-1]'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpkwu93907.py\", line 111, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpkwu93907.py\", line 106, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: Case 0 failed: result=<__main__.LRUCache object at 0x10e7681a0> expected='[None,None,1,None,-1]'\n", "test_format": "structured"}
{"dataset_index": 17, "task_id": "CustomEval/so_word_wrap", "entry_point": "word_wrap", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmptlp0odii.py\", line 104, in __run_tests__\n    result = fn(args)\nTypeError: word_wrap() missing 1 required positional argument: 'max_width'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmptlp0odii.py\", line 115, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmptlp0odii.py\", line 110, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: word_wrap() missing 1 required positional argument: 'max_width'\n", "test_format": "structured"}
{"dataset_index": 18, "task_id": "CustomEval/so_csv_to_dict", "entry_point": "csv_to_dict", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp3n9yrv50.py\", line 85, in __run_tests__\n    result = fn(args)\nTypeError: parse_csv_row() missing 1 required positional argument: 'row'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp3n9yrv50.py\", line 96, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp3n9yrv50.py\", line 91, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: parse_csv_row() missing 1 required positional argument: 'row'\n", "test_format": "structured"}
{"dataset_index": 19, "task_id": "CustomEval/so_pascal_triangle", "entry_point": "pascal_triangle", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpmu_slwh_.py\", line 92, in __run_tests__\n    result = fn(args)\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpmu_slwh_.py\", line 5, in pascals_triangle\n    for i in range(1, n):\n             ~~~~~^^^^^^\nTypeError: 'str' object cannot be interpreted as an integer\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpmu_slwh_.py\", line 103, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpmu_slwh_.py\", line 98, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: 'str' object cannot be interpreted as an integer\n", "test_format": "structured"}
{"dataset_index": 20, "task_id": "CustomEval/so_int_to_roman", "entry_point": "int_to_roman", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpelpqm6fj.py\", line 95, in __run_tests__\n    result = fn(args)\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpelpqm6fj.py\", line 9, in int_to_roman\n    while n >= value:\n          ^^^^^^^^^^\nTypeError: '>=' not supported between instances of 'str' and 'int'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpelpqm6fj.py\", line 106, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpelpqm6fj.py\", line 101, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: '>=' not supported between instances of 'str' and 'int'\n", "test_format": "structured"}
{"dataset_index": 21, "task_id": "CustomEval/so_prime_sieve", "entry_point": "sieve_primes", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpkc_64rl0.py\", line 92, in __run_tests__\n    result = fn(args)\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpkc_64rl0.py\", line 2, in sieve_of_eratosthenes\n    if n < 2:\n       ^^^^^\nTypeError: '<' not supported between instances of 'str' and 'int'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpkc_64rl0.py\", line 103, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpkc_64rl0.py\", line 98, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: '<' not supported between instances of 'str' and 'int'\n", "test_format": "structured"}
{"dataset_index": 22, "task_id": "CustomEval/gh_env_parse", "entry_point": "parse_env", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpfen1qdtd.py\", line 100, in __run_tests__\n    raise AssertionError(f\"Case {i} failed: result={result!r} expected={expected!r}\")\nAssertionError: Case 0 failed: result={'USER': 'alice', 'PORT': '8080', 'DEBUG': 'true', 'EMPTY': ''} expected=\"{'USER':'alice','PORT':'8080','DEBUG':'true','EMPTY':''}\"\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpfen1qdtd.py\", line 108, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpfen1qdtd.py\", line 103, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: Case 0 failed: result={'USER': 'alice', 'PORT': '8080', 'DEBUG': 'true', 'EMPTY': ''} expected=\"{'USER':'alice','PORT':'8080','DEBUG':'true','EMPTY':''}\"\n", "test_format": "structured"}
{"dataset_index": 23, "task_id": "CustomEval/gh_semver_compare", "entry_point": "semver_cmp", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpjrv12og5.py\", line 142, in __run_tests__\n    result = fn(args)\nTypeError: compare_versions() missing 1 required positional argument: 'v2'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpjrv12og5.py\", line 153, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpjrv12og5.py\", line 148, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: compare_versions() missing 1 required positional argument: 'v2'\n", "test_format": "structured"}
{"dataset_index": 24, "task_id": "CustomEval/gh_markdown_toc", "entry_point": "extract_headings", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpkjrkenxf.py\", line 96, in __run_tests__\n    raise AssertionError(f\"Case {i} failed: result={result!r} expected={expected!r}\")\nAssertionError: Case 0 failed: result=[] expected=\"[(1,'Title'),(2,'Section 1'),(3,'Sub ## part')]\"\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpkjrkenxf.py\", line 104, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpkjrkenxf.py\", line 99, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: Case 0 failed: result=[] expected=\"[(1,'Title'),(2,'Section 1'),(3,'Sub ## part')]\"\n", "test_format": "structured"}
{"dataset_index": 25, "task_id": "CustomEval/gh_gitignore_match", "entry_point": "is_ignored", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp2v4c6dns.py\", line 112, in __run_tests__\n    result = fn(args)\nTypeError: is_ignored() missing 1 required positional argument: 'patterns'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp2v4c6dns.py\", line 123, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp2v4c6dns.py\", line 118, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: is_ignored() missing 1 required positional argument: 'patterns'\n", "test_format": "structured"}
{"dataset_index": 26, "task_id": "CustomEval/gh_url_join", "entry_point": "url_join", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpvp77eduy.py\", line 87, in __run_tests__\n    result = fn(args)\nTypeError: join_url() missing 1 required positional argument: 'relative'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpvp77eduy.py\", line 98, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpvp77eduy.py\", line 93, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: join_url() missing 1 required positional argument: 'relative'\n", "test_format": "structured"}
{"dataset_index": 27, "task_id": "CustomEval/gh_json_minify", "entry_point": "json_minify", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpllefdpkv.py\", line 129, in __run_tests__\n    raise AssertionError(f\"Case {i} failed: result={result!r} expected={expected!r}\")\nAssertionError: Case 0 failed: result='\"{\\\\n  // comment\\\\n  \\\\\"a\\\\\": 1, /* block */ \\\\n  \\\\\"b\\\\\": \\\\\"/not comment/* ok */\\\\\"\\\\n}\"' expected='\"{\\\\n  \\\\n  \\\\\"a\\\\\": 1,  \\\\n  \\\\\"b\\\\\": \\\\\"/not comment/* ok */\\\\\"\\\\n}\"'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpllefdpkv.py\", line 137, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpllefdpkv.py\", line 132, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: Case 0 failed: result='\"{\\\\n  // comment\\\\n  \\\\\"a\\\\\": 1, /* block */ \\\\n  \\\\\"b\\\\\": \\\\\"/not comment/* ok */\\\\\"\\\\n}\"' expected='\"{\\\\n  \\\\n  \\\\\"a\\\\\": 1,  \\\\n  \\\\\"b\\\\\": \\\\\"/not comment/* ok */\\\\\"\\\\n}\"'\n", "test_format": "structured"}
{"dataset_index": 28, "task_id": "CustomEval/gh_dedupe_paths_ci", "entry_point": "dedupe_paths_ci", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpgxyxk3dg.py\", line 94, in __run_tests__\n    raise AssertionError(f\"Case {i} failed: result={result!r} expected={expected!r}\")\nAssertionError: Case 0 failed: result=['[', \"'\", 'R', 'e', 'a', 'd', 'm', '.', ',', 's', 'c', '/', 'p', 'y', ']'] expected=\"['Readme.md','src/app.py']\"\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpgxyxk3dg.py\", line 102, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpgxyxk3dg.py\", line 97, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: Case 0 failed: result=['[', \"'\", 'R', 'e', 'a', 'd', 'm', '.', ',', 's', 'c', '/', 'p', 'y', ']'] expected=\"['Readme.md','src/app.py']\"\n", "test_format": "structured"}
{"dataset_index": 29, "task_id": "CustomEval/gh_license_detect_simple", "entry_point": "detect_license", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp8q4it3z2.py\", line 95, in __run_tests__\n    raise AssertionError(f\"Case {i} failed: result={result!r} expected={expected!r}\")\nAssertionError: Case 0 failed: result='MIT' expected='\"MIT\"'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp8q4it3z2.py\", line 103, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp8q4it3z2.py\", line 98, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: Case 0 failed: result='MIT' expected='\"MIT\"'\n", "test_format": "structured"}
{"dataset_index": 30, "task_id": "CustomEval/gh_changelog_latest", "entry_point": "latest_changelog_version", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp4ee9bwl2.py\", line 106, in __run_tests__\n    raise AssertionError(f\"Case {i} failed: result={result!r} expected={expected!r}\")\nAssertionError: Case 0 failed: result='' expected='\"1.2.0\"'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp4ee9bwl2.py\", line 114, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp4ee9bwl2.py\", line 109, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: Case 0 failed: result='' expected='\"1.2.0\"'\n", "test_format": "structured"}
{"dataset_index": 31, "task_id": "CustomEval/gh_parse_github_slug", "entry_point": "parse_github_url", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp0i68s41n.py\", line 96, in __run_tests__\n    result = fn(args)\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp0i68s41n.py\", line 13, in parse_github_url\n    raise ValueError(\"Invalid URL format\")\nValueError: Invalid URL format\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp0i68s41n.py\", line 107, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmp0i68s41n.py\", line 102, in __run_tests__\n    raise AssertionError(f\"Case {i} failed with exception: {str(e)}\")\nAssertionError: Case 0 failed with exception: Invalid URL format\n", "test_format": "structured"}
{"dataset_index": 32, "task_id": "CustomEval/164", "entry_point": "is_valid_ipv4", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 33, "task_id": "CustomEval/166", "entry_point": "longest_common_subsequence", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 34, "task_id": "CustomEval/167", "entry_point": "edit_distance", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 35, "task_id": "CustomEval/168", "entry_point": "count_islands", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 36, "task_id": "CustomEval/170", "entry_point": "binary_search_insert", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 37, "task_id": "CustomEval/171", "entry_point": "merge_k_sorted_lists", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 38, "task_id": "CustomEval/172", "entry_point": "sliding_window_maximum", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 39, "task_id": "CustomEval/173", "entry_point": "longest_increasing_subsequence", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 40, "task_id": "CustomEval/174", "entry_point": "find_median_sorted_arrays", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 41, "task_id": "CustomEval/175", "entry_point": "regular_expression_match", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 42, "task_id": "CustomEval/164", "entry_point": "is_valid_ipv4", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 43, "task_id": "CustomEval/165", "entry_point": "knapsack_01", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 44, "task_id": "CustomEval/166", "entry_point": "longest_common_subsequence", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 45, "task_id": "CustomEval/167", "entry_point": "edit_distance", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 46, "task_id": "CustomEval/168", "entry_point": "count_islands", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 47, "task_id": "CustomEval/169", "entry_point": "valid_parentheses_stack", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 48, "task_id": "CustomEval/170", "entry_point": "binary_search_insert", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 49, "task_id": "CustomEval/171", "entry_point": "merge_k_sorted_lists", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 50, "task_id": "CustomEval/172", "entry_point": "sliding_window_maximum", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 51, "task_id": "CustomEval/173", "entry_point": "longest_increasing_subsequence", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 52, "task_id": "CustomEval/174", "entry_point": "find_median_sorted_arrays", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 53, "task_id": "CustomEval/175", "entry_point": "regular_expression_match", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 54, "task_id": "CustomEval/176", "entry_point": "serialize_deserialize_tree", "passed": false, "runner_output": "Traceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpuy0ebjuy.py\", line 59, in __run_tests__\n    check(user_function)\n    ~~~~~^^^^^^^^^^^^^^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpuy0ebjuy.py\", line 20, in check\n    root = TreeNode(1)\n           ^^^^^^^^\nNameError: name 'TreeNode' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpuy0ebjuy.py\", line 65, in <module>\n    __run_tests__()\n    ~~~~~~~~~~~~~^^\n  File \"/var/folders/52/pqfn77r906d60lf1snnwz5080000gn/T/tmpuy0ebjuy.py\", line 62, in __run_tests__\n    raise AssertionError(f\"Tests failed: {str(e)}\")\nAssertionError: Tests failed: name 'TreeNode' is not defined\n", "test_format": "executable"}
{"dataset_index": 55, "task_id": "CustomEval/177", "entry_point": "word_break", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
{"dataset_index": 56, "task_id": "CustomEval/178", "entry_point": "n_queens", "passed": true, "runner_output": "__RESULT__: ALL TESTS PASSED\n", "test_format": "executable"}
