{"timestamp_utc": "2025-09-26T10:33:03.734650", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 0, "question": "Write find_balanced_sublist(arr) that returns the longest even-length contiguous sublist where sum of first half equals sum of second half. Return empty list if none exists.\n\nReturn only the Python function code with no explanations, comments, or markdown formatting.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 29.752889156341553, "response": "def find_balanced_sublist(arr):\n    n = len(arr)\n    if n < 2:\n        return []\n\n    prefix_sums = [0] * (n + 1)\n    for k in range(n):\n        prefix_sums[k+1] = prefix_sums[k] + arr[k]\n\n    max_len = 0\n    best_i = -1\n    best_j = -1\n\n    for i in range(n):\n        for j in range(i + 1, n):\n            current_len = j - i + 1\n            if current_len % 2 == 0:\n                half_len = current_len // 2\n                \n                sum_first_half = prefix_sums[i + half_len] - prefix_sums[i]\n                sum_second_half = prefix_sums[j + 1] - prefix_sums[i + half_len]\n\n                if sum_first_half == sum_second_half:\n                    if current_len > max_len:\n                        max_len = current_len\n                        best_i = i\n                        best_j = j\n    \n    if max_len > 0:\n        return arr[best_i : best_j + 1]\n    else:\n        return []", "error": null, "raw_item": {"task_id": "custom_find_balanced_sublist", "prompt": "Write find_balanced_sublist(arr) that returns the longest even-length contiguous sublist where sum of first half equals sum of second half. Return empty list if none exists.\n\nReturn only the Python function code with no explanations, comments, or markdown formatting.", "entry_point": "find_balanced_sublist", "canonical_solution": "def find_balanced_sublist(arr: list[int]) -> list[int]:\n    n = len(arr)\n    for length in range(n, 1, -1):\n        if length % 2 != 0:\n            continue\n        for start in range(n - length + 1):\n            sub = arr[start:start+length]\n            half = length // 2\n            if sum(sub[:half]) == sum(sub[half:]):\n                return sub\n    return []", "test": [{"input": [[1, 2, 3, 3, 2, 1]], "output": [1, 2, 3, 3, 2, 1]}, {"input": [[5, 1, 2, 1, 5]], "output": []}, {"input": [[1, 1, 1, 1]], "output": [1, 1, 1, 1]}, {"input": [[1, 2, 3]], "output": []}, {"input": [[]], "output": []}, {"input": [[3, 0, 3, 0, 3]], "output": [3, 0, 3, 0]}, {"input": [[2, 1, 1, 2, 3, 4]], "output": [2, 1, 1, 2]}, {"input": [[1, 5, 3, 7]], "output": []}, {"input": [[0, 0, 0, 0]], "output": [0, 0, 0, 0]}]}}
{"timestamp_utc": "2025-09-26T10:33:23.188855", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 1, "question": "Write merge_by_priority(items_a, items_b) that merges two lists of (id, priority) pairs. Keep highest priority for each unique id. Return sorted by priority descending. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 18.452429056167603, "response": "```python\ndef merge_by_priority(items_a, items_b):\n    merged_map = {}\n    \n    for item_id, item_priority in items_a + items_b:\n        if item_id not in merged_map or item_priority > merged_map[item_id][1]:\n            merged_map[item_id] = (item_id, item_priority)\n            \n    result_list = list(merged_map.values())\n    result_list.sort(key=lambda x: x[1], reverse=True)\n    \n    return result_list\n```", "error": null, "raw_item": {"task_id": "custom_merge_by_priority", "prompt": "Write merge_by_priority(items_a, items_b) that merges two lists of (id, priority) pairs. Keep highest priority for each unique id. Return sorted by priority descending. Return only the Python function code with no explanations.", "entry_point": "merge_by_priority", "canonical_solution": "def merge_by_priority(items_a: list[tuple[str, int]], items_b: list[tuple[str, int]]) -> list[tuple[str, int]]:\n    combined = items_a + items_b\n    best = {}\n    for id, priority in combined:\n        if id not in best or priority > best[id]:\n            best[id] = priority\n    return sorted(best.items(), key=lambda x: -x[1])", "test": [{"input": [[["item1", 2], ["item2", 5]], [["item2", 3], ["item3", 4]]], "output": [["item2", 5], ["item3", 4], ["item1", 2]]}, {"input": [[], []], "output": []}, {"input": [[["a", 1]], [["a", 10]]], "output": [["a", 10]]}, {"input": [[["x", 5], ["y", 3]], [["z", 7], ["y", 6]]], "output": [["z", 7], ["y", 6], ["x", 5]]}, {"input": [[["a", 1], ["b", 2]], []], "output": [["b", 2], ["a", 1]]}]}}
{"timestamp_utc": "2025-09-26T10:33:32.626439", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 2, "question": "Write parse_env_config(lines) that parses environment variable lines into dict. Ignore lines starting with '#', lines without '=', and empty keys. Keep last occurrence of duplicate keys. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 8.436275243759155, "response": "```python\ndef parse_env_config(lines):\n    \"\"\"\n    Parses environment variable lines into a dictionary.\n\n    Args:\n        lines (list of str): A list of strings, where each string represents a line\n                             from a configuration file (e.g., .env).\n\n    Returns:\n        dict: A dictionary containing the parsed key-value pairs.\n              Keys and values are stripped of leading/trailing whitespace.\n              Comments (lines starting with '#') are ignored.\n              Lines without an '=' sign are ignored.\n              Lines with empty keys (e.g., \"=value\") are ignored.\n              For duplicate keys, the last occurrence takes precedence.\n    \"\"\"\n    config = {}\n    for line in lines:\n        stripped_line = line.strip()\n\n        if not stripped_line or stripped_line.startswith('#'):\n            continue\n\n        eq_index = stripped_line.find('=')\n        if eq_index == -1:  # No '=' found\n            continue\n\n        key = stripped_line[:eq_index].strip()\n        value = stripped_line[eq_index + 1:].strip()\n\n        if not key:  # Empty key\n            continue\n\n        config[key] = value\n    return config\n```", "error": null, "raw_item": {"task_id": "custom_parse_env_config", "prompt": "Write parse_env_config(lines) that parses environment variable lines into dict. Ignore lines starting with '#', lines without '=', and empty keys. Keep last occurrence of duplicate keys. Return only the Python function code with no explanations.", "entry_point": "parse_env_config", "canonical_solution": "def parse_env_config(lines: list[str]) -> dict[str, str]:\n    env = {}\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith(\"#\") or \"=\" not in line:\n            continue\n        key, value = line.split(\"=\", 1)\n        if key:\n            env[key] = value\n    return env", "test": [{"input": [["DB_HOST=localhost", "DB_PORT=5432", "#comment", "DB_HOST=remotehost", "=fail", "INVALID", ""]], "output": {"DB_HOST": "remotehost", "DB_PORT": "5432"}}, {"input": [["A=1", "B=2", "C=3"]], "output": {"A": "1", "B": "2", "C": "3"}}, {"input": [["# just a comment", "=", "==", "KEY_ONLY=", "NO_EQUALS"]], "output": {"KEY_ONLY": ""}}, {"input": [[]], "output": {}}, {"input": [["k1=v1", "k1=v2", "k1=v3"]], "output": {"k1": "v3"}}]}}
{"timestamp_utc": "2025-09-26T10:33:43.564363", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 3, "question": "Write minimal_partition_difference(nums) that partitions a list into two groups to minimize absolute difference of their sums. Handle empty list case explicitly. Use DP subset sum approach. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 9.936452865600586, "response": "```python\ndef minimal_partition_difference(nums):\n    if not nums:\n        return 0\n\n    total_sum = sum(nums)\n    \n    # dp[i] will be true if sum i can be formed by a subset of nums\n    dp = [False] * (total_sum + 1)\n    dp[0] = True\n\n    for num in nums:\n        # Iterate backwards to avoid using the same number multiple times in one pass\n        for i in range(total_sum, num - 1, -1):\n            if dp[i - num]:\n                dp[i] = True\n\n    min_diff = total_sum\n\n    # Find the largest possible sum_s1 <= total_sum / 2\n    # The other sum_s2 will be total_sum - sum_s1\n    # The difference will be abs(sum_s1 - (total_sum - sum_s1)) = abs(2 * sum_s1 - total_sum)\n    for s1 in range(total_sum // 2, -1, -1):\n        if dp[s1]:\n            min_diff = total_sum - 2 * s1\n            break # Found the largest s1 <= total_sum // 2, which minimizes the difference\n\n    return min_diff\n```", "error": null, "raw_item": {"task_id": "custom_minimal_partition_difference", "prompt": "Write minimal_partition_difference(nums) that partitions a list into two groups to minimize absolute difference of their sums. Handle empty list case explicitly. Use DP subset sum approach. Return only the Python function code with no explanations.", "entry_point": "minimal_partition_difference", "canonical_solution": "def minimal_partition_difference(nums: list[int]) -> int:\n    if not nums:\n        return 0\n    total = sum(nums)\n    target = total // 2\n    possible = {0}\n    for num in nums:\n        possible |= {x + num for x in possible}\n    best = max(x for x in possible if x <= target)\n    return total - 2 * best", "test": [{"input": [[1, 2, 3, 9]], "output": 3}, {"input": [[1, 2, 3, 4, 5]], "output": 1}, {"input": [[10, 10]], "output": 0}, {"input": [[7]], "output": 7}, {"input": [[]], "output": 0}, {"input": [[1, 1, 1, 1, 1, 1]], "output": 0}, {"input": [[100, 99, 98, 1]], "output": 96}]}}
{"timestamp_utc": "2025-09-26T10:33:52.979697", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 4, "question": "Write normalize_user_roles(users) where users is a dict mapping each user to a LIST of roles. Invert to map each role to list of users. Remove duplicate users per role and sort user lists alphabetically. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 8.412654161453247, "response": "```python\nfrom collections import defaultdict\n\ndef normalize_user_roles(users):\n    roles_to_users = defaultdict(list)\n\n    for user, roles in users.items():\n        for role in roles:\n            roles_to_users[role].append(user)\n\n    normalized_roles_to_users = {}\n    for role, user_list in roles_to_users.items():\n        # Remove duplicate users and sort alphabetically\n        normalized_roles_to_users[role] = sorted(list(set(user_list)))\n        \n    return normalized_roles_to_users\n```", "error": null, "raw_item": {"task_id": "custom_normalize_user_roles", "prompt": "Write normalize_user_roles(users) where users is a dict mapping each user to a LIST of roles. Invert to map each role to list of users. Remove duplicate users per role and sort user lists alphabetically. Return only the Python function code with no explanations.", "entry_point": "normalize_user_roles", "canonical_solution": "def normalize_user_roles(users: dict[str, list[str]]) -> dict[str, list[str]]:\n    role_to_users = {}\n    for user, roles in users.items():\n        for role in set(roles):  # remove duplicates\n            if role not in role_to_users:\n                role_to_users[role] = []\n            role_to_users[role].append(user)\n    for role in role_to_users:\n        role_to_users[role].sort()\n    return role_to_users", "test": [{"input": [{"alice": ["admin", "editor"], "bob": ["editor", "admin"], "charlie": ["viewer"]}], "output": {"admin": ["alice", "bob"], "editor": ["alice", "bob"], "viewer": ["charlie"]}}, {"input": [{"diana": [], "eva": ["user", "user"], "frank": ["user"]}], "output": {"user": ["eva", "frank"]}}, {"input": [{"a": ["x"], "b": ["y"], "c": ["x", "y"]}], "output": {"x": ["a", "c"], "y": ["b", "c"]}}, {"input": [{}], "output": {}}]}}
{"timestamp_utc": "2025-09-26T10:34:39.860822", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 5, "question": "Write can_form_expression(digits, target) that checks if inserting '+' or '-' operators (or nothing) between digits can reach target value. Use recursive DFS. Must handle multi-digit numbers. Return complete Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 45.87967824935913, "response": "```python\ndef can_form_expression(digits: str, target: int) -> bool:\n    n = len(digits)\n\n    def dfs(index, current_sum, last_operand):\n        if index == n:\n            return current_sum == target\n\n        for k in range(index, n):\n            num_str = digits[index : k + 1]\n            \n            if len(num_str) > 1 and num_str[0] == '0':\n                break\n\n            num = int(num_str)\n\n            if index == 0:\n                if dfs(k + 1, num, num):\n                    return True\n            else:\n                if dfs(k + 1, current_sum + num, num):\n                    return True\n\n                if dfs(k + 1, current_sum - num, -num):\n                    return True\n\n                new_last_operand = last_operand * 10 + (num if last_operand >= 0 else -num)\n                if dfs(k + 1, current_sum - last_operand + new_last_operand, new_last_operand):\n                    return True\n        \n        return False\n\n    return dfs(0, 0, 0)\n\n```", "error": null, "raw_item": {"task_id": "custom_can_form_expression", "prompt": "Write can_form_expression(digits, target) that checks if inserting '+' or '-' operators (or nothing) between digits can reach target value. Use recursive DFS. Must handle multi-digit numbers. Return complete Python function code with no explanations.", "entry_point": "can_form_expression", "canonical_solution": "def can_form_expression(digits: str, target: int) -> bool:\n    def dfs(index: int, current_value: int, expression: str) -> bool:\n        if index == len(digits):\n            return current_value == target\n        for end in range(index + 1, len(digits) + 1):\n            num_str = digits[index:end]\n            num = int(num_str)\n            if index == 0:\n                if dfs(end, num, num_str):\n                    return True\n            else:\n                if dfs(end, current_value + num, expression + '+' + num_str):\n                    return True\n                if dfs(end, current_value - num, expression + '-' + num_str):\n                    return True\n        return False\n    return dfs(0, 0, \"\")", "test": [{"input": ["123", 6], "output": true}, {"input": ["105", 5], "output": true}, {"input": ["123", 123], "output": true}, {"input": ["123", 100], "output": false}, {"input": ["000", 0], "output": true}, {"input": ["1", 1], "output": true}, {"input": ["1", 2], "output": false}]}}
{"timestamp_utc": "2025-09-26T10:34:53.970254", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 6, "question": "Write has_balanced_bits(n) that returns True if binary representation of n has equal number of 0s and 1s. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 13.10654592514038, "response": "```python\ndef has_balanced_bits(n):\n    binary_representation = bin(n)[2:]\n    count_zeros = binary_representation.count('0')\n    count_ones = binary_representation.count('1')\n    return count_zeros == count_ones\n```", "error": null, "raw_item": {"task_id": "custom_has_balanced_bits", "prompt": "Write has_balanced_bits(n) that returns True if binary representation of n has equal number of 0s and 1s. Return only the Python function code with no explanations.", "entry_point": "has_balanced_bits", "canonical_solution": "def has_balanced_bits(n: int) -> bool:\n    bits = bin(n)[2:]\n    return bits.count('0') == bits.count('1')", "test": [{"input": [10], "output": true}, {"input": [7], "output": false}, {"input": [9], "output": true}, {"input": [1], "output": false}, {"input": [51], "output": false}, {"input": [56], "output": true}, {"input": [57], "output": false}, {"input": [2], "output": true}, {"input": [15], "output": false}]}}
{"timestamp_utc": "2025-09-26T10:35:08.403098", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 7, "question": "Write remove_repeating_groups(s, k) that repeatedly removes groups of k identical adjacent characters until no more can be removed. Use stack approach. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 13.430503845214844, "response": "```python\ndef remove_repeating_groups(s, k):\n    stack = []  # Stores (character, count) tuples\n\n    for char in s:\n        if stack and stack[-1][0] == char:\n            # If current character is same as top of stack, increment its count\n            stack[-1] = (char, stack[-1][1] + 1)\n        else:\n            # Otherwise, push a new character with count 1\n            stack.append((char, 1))\n\n        # If the count of the top character reaches k, remove it (pop from stack)\n        if stack and stack[-1][1] == k:\n            stack.pop()\n\n    # Construct the result string from the remaining characters in the stack\n    result = []\n    for char, count in stack:\n        result.append(char * count)\n\n    return \"\".join(result)\n```", "error": null, "raw_item": {"task_id": "custom_remove_repeating_groups", "prompt": "Write remove_repeating_groups(s, k) that repeatedly removes groups of k identical adjacent characters until no more can be removed. Use stack approach. Return only the Python function code with no explanations.", "entry_point": "remove_repeating_groups", "canonical_solution": "def remove_repeating_groups(s: str, k: int) -> str:\n    stack = []\n    for char in s:\n        if stack and stack[-1][0] == char:\n            stack[-1][1] += 1\n            if stack[-1][1] == k:\n                stack.pop()\n        else:\n            stack.append([char, 1])\n    return ''.join(char * count for char, count in stack)", "test": [{"input": ["deeedbbcccbdaa", 3], "output": "aa"}, {"input": ["pbbcggttciiippooaais", 2], "output": "ps"}, {"input": ["abcd", 2], "output": "abcd"}, {"input": ["aaa", 3], "output": ""}, {"input": ["aaaabbbbaaaa", 4], "output": ""}, {"input": ["aabbcc", 2], "output": ""}, {"input": ["aabbccddeeedcba", 3], "output": "abc"}, {"input": ["", 3], "output": ""}]}}
{"timestamp_utc": "2025-09-26T10:35:44.829606", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 8, "question": "Write resolve_dependencies(deps) that returns valid module load order from dependency dict. Return None if cycle exists. Use DFS topological sort. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 35.42491388320923, "response": "```python\ndef resolve_dependencies(deps):\n    load_order = []\n    \n    states = {module: 'unvisited' for module in deps}\n\n    def dfs(module):\n        states[module] = 'visiting'\n\n        for dep in deps.get(module, []):\n            if dep not in states:\n                states[dep] = 'unvisited'\n\n            if states[dep] == 'visiting':\n                return False\n            if states[dep] == 'unvisited':\n                if not dfs(dep):\n                    return False\n        \n        states[module] = 'visited'\n        load_order.append(module)\n        return True\n\n    for module in deps:\n        if states[module] == 'unvisited':\n            if not dfs(module):\n                return None\n\n    return load_order[::-1]\n```", "error": null, "raw_item": {"task_id": "custom_resolve_dependencies", "prompt": "Write resolve_dependencies(deps) that returns valid module load order from dependency dict. Return None if cycle exists. Use DFS topological sort. Return only the Python function code with no explanations.", "entry_point": "resolve_dependencies", "canonical_solution": "def resolve_dependencies(deps: dict[str, list[str]]) -> list[str] | None:\n    visited = {}\n    result = []\n\n    def dfs(node):\n        if node in visited:\n            return visited[node]  # False if cycle\n        visited[node] = False  # mark as visiting\n        for neighbor in deps.get(node, []):\n            res = dfs(neighbor)\n            if res is False:\n                return False\n        visited[node] = True  # mark as visited\n        result.append(node)\n        return True\n\n    for node in deps:\n        if node not in visited:\n            if dfs(node) is False:\n                return None\n    return result[::-1]", "test": [{"input": [{"a": ["b", "c"], "b": ["c"], "c": []}], "output": ["c", "b", "a"]}, {"input": [{"x": ["y"], "y": ["z"], "z": ["x"]}], "output": null}, {"input": [{"m": ["n"], "n": [], "o": []}], "output": ["n", "m", "o"]}, {"input": [{"a": []}], "output": ["a"]}, {"input": [{}], "output": []}]}}
{"timestamp_utc": "2025-09-26T10:36:01.615408", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 9, "question": "Write clean_and_validate_urls(urls) that returns sorted list of unique valid URLs. Valid URLs start with 'http://' or 'https://' (case-insensitive) and contain no spaces. Strip whitespace and remove duplicates. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 15.784351110458374, "response": "```python\ndef clean_and_validate_urls(urls):\n    \"\"\"\n    Returns a sorted list of unique valid URLs from the input list.\n\n    A URL is considered valid if:\n    - It starts with 'http://' or 'https://' (case-insensitive).\n    - It contains no spaces.\n\n    Whitespace is stripped from each URL before validation.\n    \"\"\"\n    valid_urls_set = set()\n    for url in urls:\n        stripped_url = url.strip()\n        \n        # Check for spaces\n        if ' ' in stripped_url:\n            continue\n        \n        # Check for valid prefix (case-insensitive)\n        lower_stripped_url = stripped_url.lower()\n        if lower_stripped_url.startswith('http://') or lower_stripped_url.startswith('https://'):\n            valid_urls_set.add(stripped_url)\n            \n    sorted_unique_urls = sorted(list(valid_urls_set))\n    return sorted_unique_urls\n```", "error": null, "raw_item": {"task_id": "custom_clean_and_validate_urls", "prompt": "Write clean_and_validate_urls(urls) that returns sorted list of unique valid URLs. Valid URLs start with 'http://' or 'https://' (case-insensitive) and contain no spaces. Strip whitespace and remove duplicates. Return only the Python function code with no explanations.", "entry_point": "clean_and_validate_urls", "canonical_solution": "def clean_and_validate_urls(urls: list[str]) -> list[str]:\n    valid = set()\n    for url in urls:\n        cleaned = url.strip()\n        if cleaned.lower().startswith(\"http://\") or cleaned.lower().startswith(\"https://\"):\n            if \" \" not in cleaned:\n                valid.add(cleaned)\n    return sorted(valid)", "test": [{"input": [[" http://example.com ", "https://valid.site", "ftp://notvalid", "invalid.com", "https://valid.site"]], "output": ["http://example.com", "https://valid.site"]}, {"input": [[]], "output": []}, {"input": [["   https://a.com  ", "http://b.com", "http://b.com  "]], "output": ["http://b.com", "https://a.com"]}, {"input": [["https://with space.com", "http://ok.com"]], "output": ["http://ok.com"]}, {"input": [["HTTP://UPPERCASE.com"]], "output": ["HTTP://UPPERCASE.com"]}]}}
{"timestamp_utc": "2025-09-26T10:36:07.553848", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 10, "question": "Write normalize_filename(filename) that normalizes filenames by converting to lowercase, keeping only a-z, 0-9, underscore, and dots, removing other characters. Return 'unnamed' if result is empty. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 4.935490131378174, "response": "```python\nimport re\n\ndef normalize_filename(filename):\n    \"\"\"\n    Normalizes filenames by converting to lowercase, keeping only a-z, 0-9,\n    underscore, and dots, removing other characters.\n    Returns 'unnamed' if the result is empty.\n    \"\"\"\n    lower_filename = filename.lower()\n    normalized_filename = re.sub(r'[^a-z0-9_.]', '', lower_filename)\n    if not normalized_filename:\n        return 'unnamed'\n    return normalized_filename\n```", "error": null, "raw_item": {"task_id": "custom_normalize_filename", "prompt": "Write normalize_filename(filename) that normalizes filenames by converting to lowercase, keeping only a-z, 0-9, underscore, and dots, removing other characters. Return 'unnamed' if result is empty. Return only the Python function code with no explanations.", "entry_point": "normalize_filename", "canonical_solution": "def normalize_filename(filename: str) -> str:\n    allowed = set(\"abcdefghijklmnopqrstuvwxyz0123456789_.\")\n    result = ''.join(c.lower() for c in filename if c.lower() in allowed)\n    return result if result else \"unnamed\"", "test": [{"input": ["My Report (Final).PDF"], "output": "myreport.final.pdf"}, {"input": ["Résumé_2023!.docx"], "output": "rsum_2023.docx"}, {"input": ["  "], "output": "unnamed"}, {"input": ["file@#name!.TXT"], "output": "filename.txt"}, {"input": ["___"], "output": "___"}, {"input": ["###"], "output": "unnamed"}, {"input": ["ABC123_456.xyz"], "output": "abc123_456.xyz"}]}}
{"timestamp_utc": "2025-09-26T10:36:20.040299", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 11, "question": "Write rank_projects_by_score(projects) that ranks projects by score formula: (stars * 2) + forks - (issues * 3). Return project names sorted by score descending, then alphabetically. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 11.483891248703003, "response": "```python\ndef rank_projects_by_score(projects):\n    \"\"\"\n    Ranks projects based on a score formula and returns their names sorted.\n\n    The score formula is: (stars * 2) + forks - (issues * 3).\n    Projects are sorted by score descending, then alphabetically by name.\n\n    Args:\n        projects (list): A list of dictionaries, where each dictionary\n                         represents a project and has 'name', 'stars',\n                         'forks', and 'issues' keys.\n\n    Returns:\n        list: A list of project names sorted by the specified criteria.\n    \"\"\"\n    scored_projects = []\n    for project in projects:\n        score = (project['stars'] * 2) + project['forks'] - (project['issues'] * 3)\n        scored_projects.append({'name': project['name'], 'score': score})\n\n    # Sort by score descending, then by name alphabetically ascending\n    scored_projects.sort(key=lambda x: (-x['score'], x['name']))\n\n    return [project['name'] for project in scored_projects]\n```", "error": null, "raw_item": {"task_id": "custom_rank_projects_by_score", "prompt": "Write rank_projects_by_score(projects) that ranks projects by score formula: (stars * 2) + forks - (issues * 3). Return project names sorted by score descending, then alphabetically. Return only the Python function code with no explanations.", "entry_point": "rank_projects_by_score", "canonical_solution": "def rank_projects_by_score(projects: list[tuple[str, int, int, int]]) -> list[str]:\n    def score(proj):\n        return (proj[1] * 2) + proj[2] - (proj[3] * 3)\n    return [p[0] for p in sorted(projects, key=lambda p: (-score(p), p[0]))]", "test": [{"input": [[["ProjectA", 100, 50, 10], ["ProjectB", 80, 70, 5], ["ProjectC", 100, 50, 10]]], "output": ["ProjectA", "ProjectC", "ProjectB"]}, {"input": [[["Alpha", 10, 5, 0], ["Beta", 10, 5, 0]]], "output": ["Alpha", "Beta"]}, {"input": [[["AppX", 0, 0, 0], ["AppY", 0, 0, 1]]], "output": ["AppX", "AppY"]}, {"input": [[]], "output": []}, {"input": [[["ToolZ", 5, 5, 10], ["ToolY", 4, 4, 1]]], "output": ["ToolY", "ToolZ"]}]}}
{"timestamp_utc": "2025-09-26T10:36:33.447958", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 12, "question": "Write longest_prime_gap(nums) that finds the longest sequence of non-prime numbers between two prime numbers in the list. Return length of longest gap. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 12.40438985824585, "response": "```python\ndef longest_prime_gap(nums):\n    def is_prime(n):\n        if n < 2:\n            return False\n        for i in range(2, int(n**0.5) + 1):\n            if n % i == 0:\n                return False\n        return True\n\n    prime_indices = []\n    for i, num in enumerate(nums):\n        if is_prime(num):\n            prime_indices.append(i)\n\n    if len(prime_indices) < 2:\n        return 0\n\n    max_gap_length = 0\n    for i in range(len(prime_indices) - 1):\n        idx1 = prime_indices[i]\n        idx2 = prime_indices[i+1]\n        \n        current_gap_length = idx2 - idx1 - 1\n        if current_gap_length > max_gap_length:\n            max_gap_length = current_gap_length\n            \n    return max_gap_length\n```", "error": null, "raw_item": {"task_id": "custom_longest_prime_gap", "prompt": "Write longest_prime_gap(nums) that finds the longest sequence of non-prime numbers between two prime numbers in the list. Return length of longest gap. Return only the Python function code with no explanations.", "entry_point": "longest_prime_gap", "canonical_solution": "def longest_prime_gap(nums: list[int]) -> int:\n    def is_prime(n: int) -> bool:\n        if n < 2:\n            return False\n        for i in range(2, int(n**0.5)+1):\n            if n % i == 0:\n                return False\n        return True\n\n    indices = [i for i, val in enumerate(nums) if is_prime(val)]\n    if len(indices) < 2:\n        return 0\n\n    max_gap = 0\n    for i in range(len(indices) - 1):\n        start = indices[i]\n        end = indices[i + 1]\n        gap = end - start - 1\n        max_gap = max(max_gap, gap)\n    return max_gap", "test": [{"input": [[4, 6, 7, 8, 9, 10, 11, 4, 6, 13]], "output": 3}, {"input": [[2, 4, 6, 8, 10, 3]], "output": 4}, {"input": [[4, 6, 8, 10]], "output": 0}, {"input": [[3, 4, 5, 6, 7]], "output": 1}, {"input": [[2, 3]], "output": 0}, {"input": [[17, 4, 6, 9, 15, 19, 21, 23]], "output": 4}, {"input": [[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]], "output": 4}]}}
{"timestamp_utc": "2025-09-26T10:36:46.747864", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 13, "question": "Write categorize_commit_message(message) that categorizes commit messages. Return 'feature' for add/implement/feature/new, 'fix' for fix/bug/error/resolve, 'refactor' for refactor/cleanup/restructure, 'docs' for docs/documentation/readme, else 'other'. Case-insensitive. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 12.29857611656189, "response": "```python\ndef categorize_commit_message(message):\n    \"\"\"\n    Categorizes a commit message based on keywords.\n\n    Args:\n        message (str): The commit message to categorize.\n\n    Returns:\n        str: The category of the commit message ('feature', 'fix', 'refactor', 'docs', 'other').\n    \"\"\"\n    lower_message = message.lower()\n\n    if any(keyword in lower_message for keyword in ['add', 'implement', 'feature', 'new']):\n        return 'feature'\n    elif any(keyword in lower_message for keyword in ['fix', 'bug', 'error', 'resolve']):\n        return 'fix'\n    elif any(keyword in lower_message for keyword in ['refactor', 'cleanup', 'restructure']):\n        return 'refactor'\n    elif any(keyword in lower_message for keyword in ['docs', 'documentation', 'readme']):\n        return 'docs'\n    else:\n        return 'other'\n```", "error": null, "raw_item": {"task_id": "custom_categorize_commit_message", "prompt": "Write categorize_commit_message(message) that categorizes commit messages. Return 'feature' for add/implement/feature/new, 'fix' for fix/bug/error/resolve, 'refactor' for refactor/cleanup/restructure, 'docs' for docs/documentation/readme, else 'other'. Case-insensitive. Return only the Python function code with no explanations.", "entry_point": "categorize_commit_message", "canonical_solution": "def categorize_commit_message(message: str) -> str:\n    msg = message.lower()\n    categories = {\n        \"feature\": [\"add\", \"implement\", \"feature\", \"new\"],\n        \"fix\": [\"fix\", \"bug\", \"error\", \"resolve\"],\n        \"refactor\": [\"refactor\", \"cleanup\", \"restructure\"],\n        \"docs\": [\"docs\", \"documentation\", \"readme\"],\n    }\n    for label, keywords in categories.items():\n        if any(kw in msg for kw in keywords):\n            return label\n    return \"other\"", "test": [{"input": ["Fix bug in user login"], "output": "fix"}, {"input": ["Refactor payment module"], "output": "refactor"}, {"input": ["Updated README and docs"], "output": "docs"}, {"input": ["Initial commit"], "output": "other"}, {"input": ["Implemented new feature for signup"], "output": "feature"}, {"input": ["cleanup redundant logic"], "output": "refactor"}, {"input": ["Error handling for empty input"], "output": "fix"}, {"input": ["add configuration support"], "output": "feature"}, {"input": ["Documentation improvements"], "output": "docs"}, {"input": ["Minor UI tweaks"], "output": "other"}]}}
{"timestamp_utc": "2025-09-26T10:37:24.301967", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 14, "question": "Write max_repeated_substring(s) that returns length of longest non-overlapping repeated substring. Use sliding window with seen set. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 36.55250000953674, "response": "```python\ndef max_repeated_substring(s: str) -> int:\n    n = len(s)\n    if n < 2:\n        return 0\n\n    def check(length: int) -> bool:\n        \"\"\"\n        Checks if there exists a non-overlapping repeated substring of the given length.\n        \"\"\"\n        seen_first_occurrence = {}\n        for i in range(n - length + 1):\n            sub = s[i : i + length]\n            if sub in seen_first_occurrence:\n                first_idx = seen_first_occurrence[sub]\n                # Check for non-overlapping condition\n                if i >= first_idx + length:\n                    return True\n            else:\n                seen_first_occurrence[sub] = i\n        return False\n\n    low = 1\n    high = n // 2  # Maximum possible length for a repeated non-overlapping substring\n    ans = 0\n\n    # Binary search for the maximum length\n    while low <= high:\n        mid = (low + high) // 2\n        if check(mid):\n            ans = mid\n            low = mid + 1  # Try for a longer substring\n        else:\n            high = mid - 1 # Need a shorter substring\n\n    return ans\n```", "error": null, "raw_item": {"task_id": "custom_max_repeated_substring", "prompt": "Write max_repeated_substring(s) that returns length of longest non-overlapping repeated substring. Use sliding window with seen set. Return only the Python function code with no explanations.", "entry_point": "max_repeated_substring", "canonical_solution": "def max_repeated_substring(s: str) -> int:\n    n = len(s)\n    max_len = 0\n    for l in range(1, n // 2 + 1):\n        seen = set()\n        i = 0\n        while i + l <= n:\n            substr = s[i:i+l]\n            if substr in seen:\n                max_len = max(max_len, l)\n                i += l  # move forward non-overlapping\n            else:\n                seen.add(substr)\n                i += 1\n    return max_len", "test": [{"input": ["abababc"], "output": 2}, {"input": ["aaaa"], "output": 2}, {"input": ["abcabcabc"], "output": 3}, {"input": ["abcdef"], "output": 0}, {"input": ["ababa"], "output": 1}, {"input": [""], "output": 0}, {"input": ["a"], "output": 0}, {"input": ["abcdabcd"], "output": 4}, {"input": ["xyzxyzabcabc"], "output": 3}, {"input": ["abababab"], "output": 2}]}}
{"timestamp_utc": "2025-09-26T10:37:44.557996", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 15, "question": "Write longest_valid_bracket_substring(s) that returns length of longest valid parentheses substring. Use stack with indices. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 19.253976821899414, "response": "```python\ndef longest_valid_bracket_substring(s: str) -> int:\n    \"\"\"\n    Calculates the length of the longest valid parentheses substring using a stack with indices.\n\n    Args:\n        s: The input string containing '(' and ')'.\n\n    Returns:\n        The length of the longest valid parentheses substring.\n    \"\"\"\n    max_len = 0\n    stack = [-1]  # Initialize stack with -1 to handle edge cases like \"()\" starting at index 0\n\n    for i, char in enumerate(s):\n        if char == '(':\n            stack.append(i)\n        else:  # char == ')'\n            if stack:\n                stack.pop()\n            \n            if not stack:\n                # If stack becomes empty, it means the current ')' has no matching '('.\n                # Push current index as a new base for future calculations.\n                stack.append(i)\n            else:\n                # If stack is not empty, a match is found.\n                # Calculate length from current index to the index of the top of the stack.\n                max_len = max(max_len, i - stack[-1])\n    \n    return max_len\n\n```", "error": null, "raw_item": {"task_id": "custom_longest_valid_bracket_substring", "prompt": "Write longest_valid_bracket_substring(s) that returns length of longest valid parentheses substring. Use stack with indices. Return only the Python function code with no explanations.", "entry_point": "longest_valid_bracket_substring", "canonical_solution": "def longest_valid_bracket_substring(s: str) -> int:\n    stack = [-1]\n    max_len = 0\n\n    for i, ch in enumerate(s):\n        if ch == '(':\n            stack.append(i)\n        else:\n            stack.pop()\n            if not stack:\n                stack.append(i)\n            else:\n                max_len = max(max_len, i - stack[-1])\n\n    return max_len", "test": [{"input": ["(()"], "output": 2}, {"input": [")()())"], "output": 4}, {"input": [""], "output": 0}, {"input": ["((("], "output": 0}, {"input": ["()(()))())"], "output": 6}, {"input": ["((()))"], "output": 6}, {"input": ["()()()"], "output": 6}, {"input": [")((()))("], "output": 6}, {"input": ["(()(((()"], "output": 2}, {"input": ["())(())"], "output": 4}]}}
{"timestamp_utc": "2025-09-26T10:37:48.658487", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 16, "question": "Write summarize_category_totals(purchases) that returns list of [category, total] pairs sorted alphabetically by category. Sum amounts by category. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 3.096572160720825, "response": "```python\ndef summarize_category_totals(purchases):\n    category_totals = {}\n    for purchase in purchases:\n        category = purchase['category']\n        amount = purchase['amount']\n        category_totals[category] = category_totals.get(category, 0) + amount\n\n    result = []\n    for category, total in category_totals.items():\n        result.append([category, total])\n\n    result.sort(key=lambda x: x[0])\n    return result\n```", "error": null, "raw_item": {"task_id": "custom_summarize_category_totals", "prompt": "Write summarize_category_totals(purchases) that returns list of [category, total] pairs sorted alphabetically by category. Sum amounts by category. Return only the Python function code with no explanations.", "entry_point": "summarize_category_totals", "canonical_solution": "def summarize_category_totals(purchases: list[dict]) -> list[list]:\n    totals = {}\n    for item in purchases:\n        cat = item[\"category\"]\n        amt = item[\"amount\"]\n        totals[cat] = totals.get(cat, 0.0) + amt\n    return sorted([[cat, total] for cat, total in totals.items()])", "test": [{"input": [[{"category": "groceries", "amount": 25.5}, {"category": "electronics", "amount": 99.99}, {"category": "groceries", "amount": 13.0}, {"category": "books", "amount": 10.0}]], "output": [["books", 10.0], ["electronics", 99.99], ["groceries", 38.5]]}, {"input": [[{"category": "a", "amount": 1.0}, {"category": "b", "amount": 2.0}, {"category": "a", "amount": 3.0}, {"category": "c", "amount": 4.0}]], "output": [["a", 4.0], ["b", 2.0], ["c", 4.0]]}, {"input": [[]], "output": []}, {"input": [[{"category": "x", "amount": 0.0}, {"category": "x", "amount": 0.0}]], "output": [["x", 0.0]]}, {"input": [[{"category": "Z", "amount": 2.0}, {"category": "a", "amount": 1.0}]], "output": [["Z", 2.0], ["a", 1.0]]}]}}
{"timestamp_utc": "2025-09-26T10:37:55.203580", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 17, "question": "Write filter_unique_keywords(keywords, banned) that returns sorted unique keywords (lowercased) excluding banned words. Case-insensitive comparison. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 5.542870998382568, "response": "```python\ndef filter_unique_keywords(keywords, banned):\n    banned_lower_set = {word.lower() for word in banned}\n    \n    filtered_keywords_set = set()\n    for keyword in keywords:\n        lower_keyword = keyword.lower()\n        if lower_keyword not in banned_lower_set:\n            filtered_keywords_set.add(lower_keyword)\n            \n    return sorted(list(filtered_keywords_set))\n```", "error": null, "raw_item": {"task_id": "custom_filter_unique_keywords", "prompt": "Write filter_unique_keywords(keywords, banned) that returns sorted unique keywords (lowercased) excluding banned words. Case-insensitive comparison. Return only the Python function code with no explanations.", "entry_point": "filter_unique_keywords", "canonical_solution": "def filter_unique_keywords(keywords: list[str], banned: list[str]) -> list[str]:\n    banned_set = set(word.lower() for word in banned)\n    unique = set()\n\n    for word in keywords:\n        w = word.lower()\n        if w not in banned_set:\n            unique.add(w)\n\n    return sorted(unique)", "test": [{"input": [["Python", "code", "AI", "python", "Data", "Code"], ["ai"]], "output": ["code", "data", "python"]}, {"input": [[], ["test"]], "output": []}, {"input": [["ML", "AI", "ml", "AI"], ["ai"]], "output": ["ml"]}, {"input": [["hello", "world", "HELLO", "WORLD"], []], "output": ["hello", "world"]}, {"input": [["Data", "Science", "AI"], ["science", "ai"]], "output": ["data"]}, {"input": [["Python", "PYTHON", "python"], ["PYTHON"]], "output": []}]}}
{"timestamp_utc": "2025-09-26T10:38:24.673735", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 18, "question": "Write next_greater_circular(nums) that returns list where each position contains next greater element circularly. Use monotonic stack. O(n) time. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 28.46784210205078, "response": "```python\ndef next_greater_circular(nums: list[int]) -> list[int]:\n    n = len(nums)\n    result = [-1] * n\n    stack = []  # Stores indices of elements in nums\n\n    # Iterate twice the length of the array to handle circularity.\n    # The first 'n' iterations process the array normally.\n    # The next 'n' iterations effectively wrap around to find next greater elements\n    # for elements that didn't find one in the first pass.\n    for i in range(2 * n):\n        current_idx = i % n\n        current_val = nums[current_idx]\n\n        # While the stack is not empty and the element at the index on top of the stack\n        # is smaller than the current value, pop the index from the stack.\n        # The current value is the next greater element for the popped index.\n        while stack and nums[stack[-1]] < current_val:\n            result[stack.pop()] = current_val\n        \n        # Only push indices from the first pass (0 to n-1) onto the stack.\n        # We are only interested in finding next greater elements for the original 'n' elements.\n        # The 'current_idx' from the second pass (i >= n) is only used to process\n        # elements already in the stack, not to add new elements to be processed later.\n        if i < n:\n            stack.append(current_idx)\n    \n    return result\n\n```", "error": null, "raw_item": {"task_id": "ds_next_greater_circular", "prompt": "Write next_greater_circular(nums) that returns list where each position contains next greater element circularly. Use monotonic stack. O(n) time. Return only the Python function code with no explanations.", "entry_point": "next_greater_circular", "canonical_solution": "def next_greater_circular(nums):\n    n = len(nums)\n    res = [-1]*n\n    stack = []  # indices with decreasing stack by value\n    for i in range(2*n):\n        x = nums[i % n]\n        while stack and nums[stack[-1]] < x:\n            idx = stack.pop()\n            res[idx] = x\n        if i < n:\n            stack.append(i)\n    return res\n", "test": [{"input": [[1, 2, 1]], "output": [2, -1, 2]}, {"input": [[3, 8, 4, 1, 2]], "output": [8, -1, 8, 2, 3]}, {"input": [[5, 4, 3, 2, 1]], "output": [-1, 5, 5, 5, 5]}, {"input": [[2, 2, 2]], "output": [-1, -1, -1]}, {"input": [[]], "output": []}]}}
{"timestamp_utc": "2025-09-26T10:38:42.284952", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 19, "question": "Write normalize_product_code(s) that keeps only alphanumerics and dashes, converts to uppercase, collapses multiple dashes, trims leading/trailing dashes. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 16.608484268188477, "response": "```python\nimport re\n\ndef normalize_product_code(s: str) -> str:\n    \"\"\"\n    Normalizes a product code string by:\n    1. Keeping only alphanumeric characters and dashes.\n    2. Converting the string to uppercase.\n    3. Collapsing multiple consecutive dashes into a single dash.\n    4. Trimming any leading or trailing dashes.\n    \"\"\"\n    # Step 1: Keep only alphanumerics and dashes\n    # Remove any character that is NOT a letter, digit, or dash\n    cleaned_s = re.sub(r'[^a-zA-Z0-9-]', '', s)\n\n    # Step 2: Convert to uppercase\n    uppercased_s = cleaned_s.upper()\n\n    # Step 3: Collapse multiple dashes into a single dash\n    collapsed_dashes_s = re.sub(r'-+', '-', uppercased_s)\n\n    # Step 4: Trim leading and trailing dashes\n    trimmed_s = collapsed_dashes_s.strip('-')\n\n    return trimmed_s\n```", "error": null, "raw_item": {"task_id": "str_normalize_product_code", "prompt": "Write normalize_product_code(s) that keeps only alphanumerics and dashes, converts to uppercase, collapses multiple dashes, trims leading/trailing dashes. Return only the Python function code with no explanations.", "entry_point": "normalize_product_code", "canonical_solution": "import re\ndef normalize_product_code(s):\n    # keep alnum and dash\n    s = ''.join(ch for ch in s if ch.isalnum() or ch=='-')\n    s = s.upper()\n    s = re.sub(r'-{2,}', '-', s)\n    s = s.strip('-')\n    return s\n", "test": [{"input": [" abC--12__-xx "], "output": "ABC-12-XX"}, {"input": ["---a---b---"], "output": "A-B"}, {"input": ["***"], "output": ""}, {"input": ["proD-uct_99!!"], "output": "PROD-UCT99"}, {"input": [""], "output": ""}]}}
{"timestamp_utc": "2025-09-26T10:39:09.852706", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 20, "question": "Write single_number_triplicates(nums) that finds element appearing once while others appear thrice. Use bitwise counting without hash maps. O(n) time, O(1) space. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 26.56525492668152, "response": "```python\ndef single_number_triplicates(nums: list[int]) -> int:\n    result = 0\n    # Iterate over each bit position (0 to 31 for 32-bit integers)\n    for i in range(32):\n        bit_count = 0\n        # Count how many numbers have the i-th bit set\n        for num in nums:\n            if (num >> i) & 1:\n                bit_count += 1\n        \n        # If the count of the i-th bit is not a multiple of 3,\n        # it means the single number has this bit set.\n        if bit_count % 3 == 1:\n            # Set the i-th bit in the result\n            result |= (1 << i)\n            \n    # Python integers handle arbitrary precision, but for problems\n    # involving bit manipulation on signed integers, we often assume a\n    # fixed width (e.g., 32-bit). If the 31st bit is set, it indicates\n    # a negative number in 32-bit two's complement. We convert it back.\n    if result & (1 << 31): # Check if the 31st bit (MSB) is set\n        result -= (1 << 32) # Convert from unsigned to signed 32-bit representation\n        \n    return result\n\n```", "error": null, "raw_item": {"task_id": "bit_single_number_triplicates", "prompt": "Write single_number_triplicates(nums) that finds element appearing once while others appear thrice. Use bitwise counting without hash maps. O(n) time, O(1) space. Return only the Python function code with no explanations.", "entry_point": "single_number_triplicates", "canonical_solution": "def single_number_triplicates(nums):\n    ones = 0\n    twos = 0\n    for x in nums:\n        ones = (ones ^ x) & ~twos\n        twos = (twos ^ x) & ~ones\n    return ones\n", "test": [{"input": [[2, 2, 3, 2]], "output": 3}, {"input": [[0, 1, 0, 1, 0, 1, 99]], "output": 99}, {"input": [[-2, -2, -2, -5]], "output": -5}, {"input": [[7]], "output": 7}, {"input": [[10, 10, 10, -1]], "output": -1}]}}
{"timestamp_utc": "2025-09-26T10:39:31.909981", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 21, "question": "Write can_finish_prereqs(pairs) where pairs are (a,b) meaning 'b precedes a'. Return True if acyclic. Use topological sort without external libraries. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 21.05403208732605, "response": "```python\ndef can_finish_prereqs(pairs):\n    \"\"\"\n    Determines if a set of prerequisite pairs can be finished without cycles.\n\n    Args:\n        pairs: A list of (a, b) tuples, where 'b precedes a' (b must be taken before a).\n\n    Returns:\n        True if the prerequisites can be finished (i.e., the graph is acyclic),\n        False otherwise.\n    \"\"\"\n    \n    nodes = set()\n    for a, b in pairs:\n        nodes.add(a)\n        nodes.add(b)\n\n    graph = {node: [] for node in nodes}\n    in_degree = {node: 0 for node in nodes}\n\n    for a, b in pairs:\n        # Edge from b to a (b is a prerequisite for a)\n        graph[b].append(a)\n        in_degree[a] += 1\n\n    # Initialize queue with all nodes that have no prerequisites\n    queue = [node for node in nodes if in_degree[node] == 0]\n\n    # Counter for nodes processed in topological order\n    processed_count = 0\n\n    while queue:\n        u = queue.pop(0)  # Dequeue a node\n        processed_count += 1\n\n        # For each neighbor v of u (i.e., v is a course that u is a prerequisite for)\n        for v in graph[u]:\n            in_degree[v] -= 1  # Decrement in-degree of v\n            if in_degree[v] == 0:\n                queue.append(v)  # If v now has no prerequisites, add it to the queue\n\n    # If the number of processed nodes equals the total number of unique nodes,\n    # then there was no cycle, and a topological sort was possible.\n    return processed_count == len(nodes)\n\n```", "error": null, "raw_item": {"task_id": "graph_can_finish_prereqs", "prompt": "Write can_finish_prereqs(pairs) where pairs are (a,b) meaning 'b precedes a'. Return True if acyclic. Use topological sort without external libraries. Return only the Python function code with no explanations.", "entry_point": "can_finish_prereqs", "canonical_solution": "from collections import defaultdict, deque\ndef can_finish_prereqs(pairs):\n    adj = defaultdict(list)\n    indeg = defaultdict(int)\n    nodes = set()\n    for a,b in pairs:\n        adj[b].append(a)\n        indeg[a] += 1\n        nodes.add(a); nodes.add(b)\n        if b not in indeg: indeg[b] = indeg.get(b,0)\n    q = deque([v for v in nodes if indeg.get(v,0)==0])\n    visited = 0\n    while q:\n        v = q.popleft()\n        visited += 1\n        for w in adj[v]:\n            indeg[w] -= 1\n            if indeg[w]==0:\n                q.append(w)\n    return visited == len(nodes)\n", "test": [{"input": [[["C2", "C1"], ["C3", "C2"]]], "output": true}, {"input": [[["A", "B"], ["B", "C"], ["C", "A"]]], "output": false}, {"input": [[["A", "B"]]], "output": true}, {"input": [[["X", "Y"], ["Y", "Z"], ["Z", "X"]]], "output": false}, {"input": [[[]]], "output": true}]}}
{"timestamp_utc": "2025-09-26T10:39:52.382233", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 22, "question": "Write safe_deep_get(obj, path, default=None) that safely traverses nested dicts/lists/tuples using path keys/indices. Return default if any access fails. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 19.468177795410156, "response": "```python\ndef safe_deep_get(obj, path, default=None):\n    \"\"\"\n    Safely traverses nested dictionaries, lists, and tuples using path keys/indices.\n\n    Args:\n        obj: The object to traverse (dictionary, list, tuple, or any other type).\n        path: A sequence (e.g., list or tuple) of keys/indices representing the path\n              to the desired value.\n        default: The value to return if any part of the path cannot be traversed\n                 or if an access fails. Defaults to None.\n\n    Returns:\n        The value found at the specified path, or the default value if access fails.\n    \"\"\"\n    current_obj = obj\n    for key_or_index in path:\n        try:\n            if isinstance(current_obj, dict):\n                current_obj = current_obj[key_or_index]\n            elif isinstance(current_obj, (list, tuple)):\n                if isinstance(key_or_index, int):\n                    current_obj = current_obj[key_or_index]\n                else:\n                    return default  # Cannot use non-integer index on list/tuple\n            else:\n                return default  # current_obj is not traversable\n        except (KeyError, IndexError, TypeError):\n            # KeyError for dicts (key not found)\n            # IndexError for lists/tuples (index out of bounds)\n            # TypeError if current_obj is not subscriptable or key_or_index is invalid\n            return default\n    return current_obj\n```", "error": null, "raw_item": {"task_id": "se_safe_deep_get", "entry_point": "safe_deep_get", "prompt": "Write safe_deep_get(obj, path, default=None) that safely traverses nested dicts/lists/tuples using path keys/indices. Return default if any access fails. Return only the Python function code with no explanations.", "canonical_solution": "def safe_deep_get(obj, path, default=None):\n    cur = obj\n    for key in path:\n        if isinstance(cur, dict):\n            if key in cur:\n                cur = cur[key]\n            else:\n                return default\n        elif isinstance(cur, (list, tuple)):\n            if isinstance(key, int) and -len(cur) <= key < len(cur):\n                cur = cur[key]\n            else:\n                return default\n        else:\n            return default\n    return cur\n", "test": [{"input": [{"a": {"b": [10, 20, {"c": 42}]}}, ["a", "b", 2, "c"], null], "output": 42}, {"input": [{"a": [1, 2, 3]}, ["a", 5], "x"], "output": "x"}, {"input": [{"x": 0}, ["y"], 99], "output": 99}, {"input": [[1, 2, 3], [0], null], "output": 1}, {"input": [[1, 2, 3], ["0"], "err"], "output": "err"}]}}
{"timestamp_utc": "2025-09-26T10:40:52.242549", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 23, "question": "Write clean_and_split_sentences(text) that removes non-alphanumeric chars except .!?, normalizes whitespace, splits on sentence delimiters, returns cleaned sentence list. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 58.85599398612976, "response": "```python\nimport re\n\ndef clean_and_split_sentences(text):\n    \"\"\"\n    Removes non-alphanumeric characters (except .!?,), normalizes whitespace,\n    and splits the text into a list of cleaned sentences.\n\n    Args:\n        text (str): The input text.\n\n    Returns:\n        list: A list of cleaned sentences. Each sentence includes its\n              terminating punctuation if present.\n    \"\"\"\n    # 1. Remove non-alphanumeric chars except .!?, and preserve whitespace.\n    # The regex keeps letters (a-zA-Z), numbers (0-9), sentence delimiters (.,!,?),\n    # commas (,) and any whitespace character (\\s).\n    cleaned_text = re.sub(r'[^a-zA-Z0-9.!?,\\s]', '', text)\n\n    # 2. Normalize whitespace: replace multiple spaces with a single space,\n    # then strip leading/trailing whitespace from the whole text.\n    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n\n    # Handle empty string case after cleaning\n    if not cleaned_text:\n        return []\n\n    # 3. Split on sentence delimiters (. ! ?) while keeping the delimiters.\n    # The parentheses around [.!?] make re.split include the delimiters in the result list.\n    parts = re.split(r'([.!?])', cleaned_text)\n\n    sentences = []\n    current_sentence_builder = [] # Use a list to accumulate parts of a sentence\n\n    for part in parts:\n        if part in ['.', '!', '?']:\n            # This part is a delimiter.\n            if current_sentence_builder: # If there's content accumulated before this delimiter\n                current_sentence_builder.append(part) # Add the delimiter to the builder\n                sentence = \"\".join(current_sentence_builder).strip()\n                if sentence: # Ensure the sentence is not empty after stripping\n                    sentences.append(sentence)\n                current_sentence_builder = [] # Reset for the next sentence\n            # If current_sentence_builder is empty, it means this delimiter appeared\n            # immediately after another delimiter (e.g., \"Hello..World\") or at the very beginning.\n            # In such cases, we ignore the delimiter to avoid empty sentences or malformed ones.\n        else: # This part is sentence content or an empty string resulting from the split\n            stripped_part = part.strip()\n            if stripped_part: # Only add if there's actual content\n                # The parts from re.split are already separated by delimiters or form coherent chunks.\n                # No need to add extra spaces here, as `cleaned_text` already has normalized spaces\n                # and `stripped_part` handles leading/trailing spaces within the part itself.\n                current_sentence_builder.append(stripped_part)\n\n    # Add any remaining content that did not end with a delimiter\n    if current_sentence_builder:\n        sentences.append(\"\".join(current_sentence_builder).strip())\n\n    # Final pass to ensure no empty strings remain in the list, though the logic should prevent most.\n    return [s for s in sentences if s]\n```", "error": null, "raw_item": {"task_id": "str_clean_and_split_sentences", "entry_point": "clean_and_split_sentences", "prompt": "Write clean_and_split_sentences(text) that removes non-alphanumeric chars except .!?, normalizes whitespace, splits on sentence delimiters, returns cleaned sentence list. Return only the Python function code with no explanations.", "canonical_solution": "import re\n\ndef clean_and_split_sentences(text):\n    # Keep only letters, digits, punctuation .,!,?\n    text = re.sub(r\"[^A-Za-z0-9.!?\\s]\", \"\", text)\n    # Normalize whitespace\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    # Split on sentence delimiters\n    parts = re.split(r\"[.!?]\", text)\n    # Clean and filter\n    result = [p.strip() for p in parts if p.strip()]\n    return result\n", "test": [{"input": ["Hello!!   How are---you???   Fine."], "output": ["Hello", "How areyou", "Fine"]}, {"input": ["  multiple   spaces   and ###symbols!!"], "output": ["multiple spaces and symbols"]}, {"input": ["Nothing to clean"], "output": ["Nothing to clean"]}, {"input": ["???"], "output": []}]}}
{"timestamp_utc": "2025-09-26T10:41:06.672970", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 24, "question": "Write count_set_bits(n) that counts 1-bits in binary representation using efficient bit manipulation (Brian Kernighan's algorithm). Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 13.42683219909668, "response": "```python\ndef count_set_bits(n):\n    count = 0\n    while n > 0:\n        n &= (n - 1)\n        count += 1\n    return count\n```", "error": null, "raw_item": {"task_id": "bit_counting_set_bits", "entry_point": "count_set_bits", "prompt": "Write count_set_bits(n) that counts 1-bits in binary representation using efficient bit manipulation (Brian Kernighan's algorithm). Return only the Python function code with no explanations.", "canonical_solution": "def count_set_bits(n):\n    if n < 0:\n        raise ValueError(\"Input must be a non-negative integer.\")\n    count = 0\n    while n:\n        n &= n - 1  # Clear the least significant bit set\n        count += 1\n    return count\n", "test": [{"input": [11], "output": 3}, {"input": [0], "output": 0}, {"input": [255], "output": 8}, {"input": [1023], "output": 10}, {"input": [1], "output": 1}]}}
{"timestamp_utc": "2025-09-26T10:41:32.893806", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 25, "question": "Write filter_map_validate(records) that normalizes, validates, and filters product records, returning sorted list of valid IDs. Complex multi-step validation with price parsing, type constraints, and conditional rules. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 25.217777252197266, "response": "```python\ndef filter_map_validate(records):\n    \"\"\"\n    Normalizes, validates, and filters product records, returning a sorted list of valid IDs.\n\n    Args:\n        records (list): A list of dictionaries, where each dictionary represents a product record.\n                        Expected keys: 'id', 'name', 'price', 'category', 'stock', 'status'.\n\n    Returns:\n        list: A sorted list of IDs (strings) for records that passed all normalization and validation steps.\n    \"\"\"\n    valid_ids = []\n    \n    for record in records:\n        normalized_record = {}\n        is_valid = True\n\n        # --- 1. Normalize and Basic Type/Presence Validation ---\n        \n        # ID: Must be present, non-empty after stripping, and converted to string for consistent sorting\n        if 'id' not in record or record['id'] is None:\n            is_valid = False\n        else:\n            temp_id = str(record['id']).strip()\n            if not temp_id:\n                is_valid = False\n            else:\n                normalized_record['id'] = temp_id\n\n        # Name: Must be present, a non-empty string after stripping\n        if is_valid:\n            if 'name' not in record or not isinstance(record['name'], str) or not record['name'].strip():\n                is_valid = False\n            else:\n                normalized_record['name'] = record['name'].strip()\n\n        # Price: Must be present, parseable to a float, and positive. Handles '$' and ','\n        if is_valid:\n            if 'price' not in record or record['price'] is None:\n                is_valid = False\n            else:\n                price_str = str(record['price']).strip().replace('$', '').replace(',', '')\n                try:\n                    normalized_record['price'] = float(price_str)\n                    if normalized_record['price'] <= 0:\n                        is_valid = False\n                except ValueError:\n                    is_valid = False\n\n        # Category: Must be present, a non-empty string after stripping, converted to lowercase\n        if is_valid:\n            if 'category' not in record or not isinstance(record['category'], str) or not record['category'].strip():\n                is_valid = False\n            else:\n                normalized_record['category'] = record['category'].strip().lower()\n                # Example: Optional check for predefined categories\n                # if normalized_record['category'] not in {'electronics', 'clothing', 'accessories', 'home goods', 'books'}:\n                #     is_valid = False\n\n        # Stock: Must be present, parseable to an integer, and non-negative\n        if is_valid:\n            if 'stock' not in record or record['stock'] is None:\n                is_valid = False\n            else:\n                try:\n                    normalized_record['stock'] = int(str(record['stock']).strip())\n                    if normalized_record['stock'] < 0:\n                        is_valid = False\n                except ValueError:\n                    is_valid = False\n\n        # Status: Must be present, a non-empty string after stripping, converted to lowercase,\n        # and one of predefined values\n        if is_valid:\n            if 'status' not in record or not isinstance(record['status'], str) or not record['status'].strip():\n                is_valid = False\n            else:\n                normalized_record['status'] = record['status'].strip().lower()\n                if normalized_record['status'] not in {'active', 'inactive', 'discontinued'}:\n                    is_valid = False\n        \n        # If any basic normalization or type/presence check failed, skip this record\n        if not is_valid:\n            continue\n\n        # --- 2. Complex Conditional Validation Rules ---\n        \n        # Rule 1: If category is 'electronics', stock must be at least 10.\n        if normalized_record['category'] == 'electronics' and normalized_record['stock'] < 10:\n            is_valid = False\n\n        # Rule 2: If status is 'discontinued', stock must be 0.\n        if is_valid and normalized_record['status'] == 'discontinued' and normalized_record['stock'] != 0:\n            is_valid = False\n\n        # Rule 3: If price is greater than 1000, category cannot be 'accessories'.\n        if is_valid and normalized_record['price'] > 1000 and normalized_record['category'] == 'accessories':\n            is_valid = False\n\n        # Rule 4: If name contains \"clearance\" (case-insensitive), status must be 'discontinued'.\n        if is_valid and \"clearance\" in normalized_record['name'].lower() and normalized_record['status'] != 'discontinued':\n            is_valid = False\n        \n        # If all checks (basic and conditional) passed, add the ID to the list\n        if is_valid:\n            valid_ids.append(normalized_record['id'])\n            \n    # Sort the collected valid IDs alphabetically and return the list\n    return sorted(valid_ids)\n```", "error": null, "raw_item": {"task_id": "se_filter_map_validate_nested", "entry_point": "filter_map_validate", "prompt": "Write filter_map_validate(records) that normalizes, validates, and filters product records, returning sorted list of valid IDs. Complex multi-step validation with price parsing, type constraints, and conditional rules. Return only the Python function code with no explanations.", "canonical_solution": "import re\n\ntype_order = {\"ent\": 0, \"pro\": 1, \"std\": 2}\n\ndef _parse_price(x):\n    if isinstance(x, (int, float)):\n        return float(x) if x >= 0 else None\n    if not isinstance(x, str):\n        return None\n    s = x.strip()\n    if not s:\n        return None\n    s = re.sub(r\"[\\s$€£¥]\", \"\", s)\n    if \",\" in s and \".\" in s:\n        if s.find(\",\") < s.find(\".\"):\n            s = s.replace(\",\", \"\")\n        else:\n            s = s.replace(\".\", \"\").replace(\",\", \".\")\n    elif \",\" in s:\n        s = s.replace(\",\", \".\")\n    try:\n        v = float(s)\n        return v if v >= 0 else None\n    except Exception:\n        return None\n\ndef _to_int(x):\n    if isinstance(x, bool):\n        return None\n    if isinstance(x, int):\n        return x\n    if isinstance(x, str):\n        s = x.strip()\n        if s and s.lstrip(\"-+\").isdigit():\n            try:\n                return int(s)\n            except Exception:\n                return None\n    return None\n\ndef _to_float(x):\n    if isinstance(x, (int, float)):\n        return float(x)\n    if isinstance(x, str):\n        try:\n            return float(x.strip())\n        except Exception:\n            return None\n    return None\n\ndef _to_pct(x):\n    if x is None:\n        return None\n    if isinstance(x, (int, float)):\n        v = float(x)\n    elif isinstance(x, str):\n        try:\n            v = float(x.strip().strip('%'))\n        except Exception:\n            return None\n    else:\n        return None\n    if v < 0:\n        v = 0.0\n    if v > 100:\n        v = 100.0\n    return v\n\ndef filter_map_validate(records):\n    if not isinstance(records, list):\n        return []\n    kept = []\n    for rec in records:\n        if not isinstance(rec, dict):\n            continue\n        # --- id ---\n        rid = rec.get(\"id\")\n        rid = str(rid).strip() if rid is not None else \"\"\n        if not rid:\n            continue\n        # --- meta ---\n        meta = rec.get(\"meta\") or {}\n        if not isinstance(meta, dict):\n            meta = {}\n        rtype = str(meta.get(\"type\") or \"\").strip().lower()\n        flags = meta.get(\"flags\")\n        if isinstance(flags, list):\n            flags_norm = [str(t).strip().lower() for t in flags if isinstance(t, (str, int, float))]\n        else:\n            flags_norm = []\n        if rtype not in (\"std\",\"pro\",\"ent\"):\n            continue\n        # --- price ---\n        price = _parse_price(rec.get(\"price\"))\n        if price is None:\n            continue\n        # --- attrs ---\n        attrs = rec.get(\"attrs\") or {}\n        if not isinstance(attrs, dict):\n            attrs = {}\n        color = attrs.get(\"color\")\n        color = str(color).strip().lower() if isinstance(color, str) else None\n        size = attrs.get(\"size\")\n        if size is not None:\n            size = _to_int(size)\n        weight = attrs.get(\"weight\")\n        if weight is not None:\n            weight = _to_float(weight)\n        cond = attrs.get(\"condition\")\n        cond = str(cond).strip().upper() if isinstance(cond, str) else None\n        discount = _to_pct(attrs.get(\"discount\"))\n        # --- stock ---\n        stock = _to_int(rec.get(\"stock\"))\n        if stock is None:\n            stock = 0\n        if stock < 0:\n            stock = 0\n        # --- Validation A: color/flag gate ---\n        if not ((color in {\"red\",\"blue\",\"green\"}) or (\"eco\" in flags_norm)):\n            continue\n        # --- Validation B: price caps ---\n        if rtype in (\"std\",\"pro\") and price > 1000:\n            continue\n        if rtype == \"ent\" and price > 5000:\n            continue\n        # --- Validation C: refurb implies good condition ---\n        if \"refurb\" in flags_norm:\n            if cond not in {\"A\",\"B\"}:\n                continue\n        # --- Validation D: ent requires size>=10 and stock>=1 ---\n        if rtype == \"ent\":\n            if size is None or size < 10 or stock < 1:\n                continue\n        # --- Validation E: pro weight <= 50 if provided ---\n        if rtype == \"pro\" and weight is not None and weight > 50.0:\n            continue\n        kept.append({\n            \"id\": rid,\n            \"type\": rtype,\n            \"price\": price\n        })\n    # sort: type order (ent > pro > std) i.e., ent first, then pro, then std\n    kept.sort(key=lambda r: (type_order.get(r[\"type\"], 3), r[\"price\"], r[\"id\"].lower()))\n    return [r[\"id\"] for r in kept]\n", "test": [{"input": [[{"id": " A-1 ", "meta": {"type": "ent", "flags": ["Eco"]}, "price": "€4,999.00", "attrs": {"size": "12", "color": "Green"}, "stock": "5"}, {"id": "B-2", "meta": {"type": "pro", "flags": ["refurb"]}, "price": "$800", "attrs": {"weight": "49.5", "color": "blue", "condition": "B"}, "stock": 0}, {"id": "c-3", "meta": {"type": "std", "flags": []}, "price": "1200", "attrs": {"color": "red"}, "stock": 10}, {"id": "d-4", "meta": {"type": "ent", "flags": ["eco", "refurb"]}, "price": "5100", "attrs": {"size": 15, "color": "green", "condition": "A"}, "stock": 2}, {"id": "e-5", "meta": {"type": "pro", "flags": []}, "price": "999.99", "attrs": {"color": "yellow"}, "stock": 7}]], "output": ["A-1", "B-2"]}, {"input": [[{"id": 101, "meta": {"type": "pro", "flags": ["eco"]}, "price": "1,000.00", "attrs": {"color": "RED", "weight": "50"}, "stock": "-3"}, {"id": 102, "meta": {"type": "pro", "flags": ["eco"]}, "price": "1,000.01", "attrs": {"color": "GREEN", "weight": "10"}, "stock": "0"}, {"id": 103, "meta": {"type": "std", "flags": ["eco"]}, "price": "$0", "attrs": {"color": "green"}, "stock": "0"}]], "output": ["101", "103"]}, {"input": [[{"id": "X", "meta": {"type": "ent", "flags": ["REFURB"]}, "price": "$4500", "attrs": {"size": "9", "color": "blue", "condition": "A"}, "stock": 1}, {"id": "Y", "meta": {"type": "ent", "flags": []}, "price": "$4500", "attrs": {"size": "12", "color": "blue"}, "stock": 0}, {"id": "Z", "meta": {"type": "ent", "flags": []}, "price": "$4500", "attrs": {"size": "12", "color": "blue"}, "stock": 3}]], "output": ["Z"]}, {"input": [[{"id": "bad", "meta": {"type": "other", "flags": ["eco"]}, "price": "100", "attrs": {"color": "red"}, "stock": 1}, {"id": "ok-std", "meta": {"type": "std", "flags": ["eco"]}, "price": "1000", "attrs": {"color": "green"}, "stock": 0}]], "output": ["ok-std"]}, {"input": [[{"id": "keep-pro-over-std", "meta": {"type": "pro", "flags": ["eco"]}, "price": "500", "attrs": {"color": "blue"}}, {"id": "keep-ent-first", "meta": {"type": "ent", "flags": ["eco"]}, "price": "1200", "attrs": {"color": "green", "size": 20}, "stock": 2}, {"id": "keep-std-last", "meta": {"type": "std", "flags": ["eco"]}, "price": "100", "attrs": {"color": "red"}}]], "output": ["keep-ent-first", "keep-pro-over-std", "keep-std-last"]}]}}
{"timestamp_utc": "2025-09-26T10:42:13.695444", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 26, "question": "Write sliding_window_max(arr, k) that returns maximum element in each sliding window of size k using deque. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 39.79853320121765, "response": "```python\nimport collections\n\ndef sliding_window_max(arr, k):\n    if not arr or k <= 0:\n        return []\n    \n    n = len(arr)\n    if k > n:\n        # If k is larger than array length, no windows of size k can be formed.\n        return []\n\n    dq = collections.deque() # Stores indices of elements\n    result = []\n\n    for i in range(n):\n        # 1. Remove elements whose indices are out of the current window [i-k+1, i]\n        #    The element at dq[0] is the oldest. If its index is <= i-k, it's outside.\n        if dq and dq[0] <= i - k:\n            dq.popleft()\n        \n        # 2. Remove elements from the back of the deque that are smaller than or equal to arr[i]\n        #    These elements are no longer candidates for the maximum in future windows\n        #    because arr[i] is greater (or equal) and comes later in the window.\n        while dq and arr[dq[-1]] <= arr[i]:\n            dq.pop()\n            \n        # 3. Add current element's index to the back of the deque\n        dq.append(i)\n        \n        # 4. If we have processed at least 'k' elements (i.e., the window is fully formed),\n        #    the front of the deque (dq[0]) holds the index of the maximum element for the current window.\n        if i >= k - 1:\n            result.append(arr[dq[0]])\n            \n    return result\n\n```", "error": null, "raw_item": {"task_id": "custom_sliding_window_max", "prompt": "Write sliding_window_max(arr, k) that returns maximum element in each sliding window of size k using deque. Return only the Python function code with no explanations.", "entry_point": "sliding_window_max", "canonical_solution": "from collections import deque\n\ndef sliding_window_max(arr: list[int], k: int) -> list[int]:\n    if not arr or k == 0:\n        return []\n    \n    dq = deque()\n    result = []\n    \n    for i in range(len(arr)):\n        # Remove elements outside current window\n        while dq and dq[0] <= i - k:\n            dq.popleft()\n        \n        # Remove elements smaller than current element\n        while dq and arr[dq[-1]] <= arr[i]:\n            dq.pop()\n        \n        dq.append(i)\n        \n        # Add maximum to result if window is complete\n        if i >= k - 1:\n            result.append(arr[dq[0]])\n    \n    return result", "test": [{"input": [[1, 3, -1, -3, 5, 3, 6, 7], 3], "output": [3, 3, 5, 5, 6, 7]}, {"input": [[1, 2, 3], 1], "output": [1, 2, 3]}, {"input": [[5, 4, 3, 2, 1], 2], "output": [5, 4, 3, 2]}, {"input": [[1], 1], "output": [1]}, {"input": [[], 3], "output": []}, {"input": [[7, 2, 4], 3], "output": [7]}]}}
{"timestamp_utc": "2025-09-26T10:42:30.594877", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 27, "question": "Write rotate_matrix(matrix) that rotates n×n matrix 90 degrees clockwise in-place using transpose and reverse. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 15.895703077316284, "response": "```python\ndef rotate_matrix(matrix):\n    n = len(matrix)\n\n    # Step 1: Transpose the matrix\n    for i in range(n):\n        for j in range(i, n):\n            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n\n    # Step 2: Reverse each row\n    for i in range(n):\n        matrix[i].reverse()\n```", "error": null, "raw_item": {"task_id": "custom_rotate_matrix", "prompt": "Write rotate_matrix(matrix) that rotates n×n matrix 90 degrees clockwise in-place using transpose and reverse. Return only the Python function code with no explanations.", "entry_point": "rotate_matrix", "canonical_solution": "def rotate_matrix(matrix: list[list[int]]) -> list[list[int]]:\n    if not matrix or not matrix[0]:\n        return matrix\n    \n    n = len(matrix)\n    \n    # Transpose the matrix\n    for i in range(n):\n        for j in range(i, n):\n            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n    \n    # Reverse each row\n    for i in range(n):\n        matrix[i].reverse()\n    \n    return matrix", "test": [{"input": [[[1, 2, 3], [4, 5, 6], [7, 8, 9]]], "output": [[7, 4, 1], [8, 5, 2], [9, 6, 3]]}, {"input": [[[1, 2], [3, 4]]], "output": [[3, 1], [4, 2]]}, {"input": [[[1]]], "output": [[1]]}, {"input": [[]], "output": []}, {"input": [[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]], "output": [[13, 9, 5, 1], [14, 10, 6, 2], [15, 11, 7, 3], [16, 12, 8, 4]]}]}}
{"timestamp_utc": "2025-09-26T10:42:36.825556", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 28, "question": "Write is_arithmetic_sequence(seq) that checks if sequence forms arithmetic progression with common difference > 0. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 5.229392766952515, "response": "```python\ndef is_arithmetic_sequence(seq):\n    if len(seq) < 2:\n        return False\n\n    common_diff = seq[1] - seq[0]\n\n    if common_diff <= 0:\n        return False\n\n    for i in range(2, len(seq)):\n        if seq[i] - seq[i-1] != common_diff:\n            return False\n\n    return True\n```", "error": null, "raw_item": {"task_id": "alg_arithmetic_sequence", "entry_point": "is_arithmetic_sequence", "prompt": "Write is_arithmetic_sequence(seq) that checks if sequence forms arithmetic progression with common difference > 0. Return only the Python function code with no explanations.", "canonical_solution": "def is_arithmetic_sequence(seq):\n    if len(seq) < 2:\n        return False\n    diff = seq[1] - seq[0]\n    if diff <= 0:\n        return False\n    for i in range(2, len(seq)):\n        if seq[i] - seq[i-1] != diff:\n            return False\n    return True", "test": [{"input": [[1, 3, 5, 7, 9]], "output": true}, {"input": [[2, 4, 6, 8]], "output": true}, {"input": [[5, 5, 5]], "output": false}, {"input": [[1, 2, 4, 8]], "output": false}, {"input": [[10, 5, 0]], "output": false}]}}
{"timestamp_utc": "2025-09-26T10:42:40.204339", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 29, "question": "Write classify_severity(msg) that returns HIGH if msg contains 'error' or 'critical', MEDIUM if contains 'warning', LOW otherwise. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 2.375340223312378, "response": "```python\ndef classify_severity(msg):\n    msg_lower = msg.lower()\n    if 'error' in msg_lower or 'critical' in msg_lower:\n        return 'HIGH'\n    elif 'warning' in msg_lower:\n        return 'MEDIUM'\n    else:\n        return 'LOW'\n```", "error": null, "raw_item": {"task_id": "se_severity_classifier", "entry_point": "classify_severity", "prompt": "Write classify_severity(msg) that returns HIGH if msg contains 'error' or 'critical', MEDIUM if contains 'warning', LOW otherwise. Return only the Python function code with no explanations.", "canonical_solution": "def classify_severity(msg):\n    msg_lower = msg.lower()\n    if 'error' in msg_lower or 'critical' in msg_lower:\n        return 'HIGH'\n    elif 'warning' in msg_lower:\n        return 'MEDIUM'\n    else:\n        return 'LOW'", "test": [{"input": ["System error occurred"], "output": "HIGH"}, {"input": ["Critical failure detected"], "output": "HIGH"}, {"input": ["Warning: disk space low"], "output": "MEDIUM"}, {"input": ["Info: task completed"], "output": "LOW"}, {"input": ["ERROR in database"], "output": "HIGH"}]}}
{"timestamp_utc": "2025-09-26T10:42:48.184344", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 30, "question": "Write find_peak_index(arr) that finds index of first element that is greater than both neighbors. Return -1 if no peak exists. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 6.976016044616699, "response": "```python\ndef find_peak_index(arr):\n    n = len(arr)\n    if n < 3:\n        return -1\n\n    for i in range(1, n - 1):\n        if arr[i] > arr[i-1] and arr[i] > arr[i+1]:\n            return i\n\n    return -1\n```", "error": null, "raw_item": {"task_id": "alg_peak_finder", "entry_point": "find_peak_index", "prompt": "Write find_peak_index(arr) that finds index of first element that is greater than both neighbors. Return -1 if no peak exists. Return only the Python function code with no explanations.", "canonical_solution": "def find_peak_index(arr):\n    if len(arr) < 3:\n        return -1\n    for i in range(1, len(arr) - 1):\n        if arr[i] > arr[i-1] and arr[i] > arr[i+1]:\n            return i\n    return -1", "test": [{"input": [[1, 3, 2, 4, 1]], "output": 1}, {"input": [[1, 2, 3, 2, 1]], "output": 2}, {"input": [[1, 2, 3, 4, 5]], "output": -1}, {"input": [[5, 4, 3, 2, 1]], "output": -1}, {"input": [[1, 3, 1]], "output": 1}]}}
{"timestamp_utc": "2025-09-26T10:43:08.758746", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 31, "question": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 19.5729820728302, "response": "To group anagrams, we can leverage the property that anagrams have the same letters when sorted alphabetically. This sorted version of a word can serve as a unique key for all its anagrams.\n\nHere's the step-by-step approach:\n\n1.  **Create a mapping**: Use a dictionary (or `collections.defaultdict`) where the keys are the sorted versions of words and the values are lists of original words that correspond to that sorted key.\n\n2.  **Populate the mapping**:\n    *   Iterate through each `word` in the input `words` list.\n    *   For each `word`, sort its letters to create a canonical `key` (e.g., \"eat\", \"tea\", \"ate\" all become \"aet\").\n    *   Add the original `word` to the list associated with this `key` in the dictionary. If the `key` doesn't exist, create a new list for it.\n\n3.  **Extract groups**: Once all words have been processed, the values of the dictionary will be our groups of anagrams. Convert these values into a list of lists.\n\n4.  **Sort within groups**: As per the requirement, words within each group must be sorted alphabetically. Iterate through each group and sort its elements.\n\n5.  **Sort the groups**: Finally, the groups themselves must be sorted. The requirement is to sort them by their first word alphabetically. Python's `list.sort()` with a `key` argument is perfect for this.\n\n**Example Walkthrough:** `words = [\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"]`\n\n1.  Initialize `anagram_groups = {}` (using `defaultdict(list)` simplifies this).\n\n2.  Process words:\n    *   \"eat\" -> sorted \"aet\". `anagram_groups['aet'] = [\"eat\"]`\n    *   \"tea\" -> sorted \"aet\". `anagram_groups['aet'].append(\"tea\")` -> `[\"eat\", \"tea\"]`\n    *   \"tan\" -> sorted \"ant\". `anagram_groups['ant'] = [\"tan\"]`\n    *   \"ate\" -> sorted \"aet\". `anagram_groups['aet'].append(\"ate\")` -> `[\"eat\", \"tea\", \"ate\"]`\n    *   \"nat\" -> sorted \"ant\". `anagram_groups['ant'].append(\"nat\")` -> `[\"tan\", \"nat\"]`\n    *   \"bat\" -> sorted \"abt\". `anagram_groups['abt'] = [\"bat\"]`\n\n    After processing all words, `anagram_groups` might look like (order of keys can vary):\n    `{'aet': ['eat', 'tea', 'ate'], 'ant': ['tan', 'nat'], 'abt': ['bat']}`\n\n3.  Extract groups: `result = [['eat', 'tea', 'ate'], ['tan', 'nat'], ['bat']]`\n\n4.  Sort words within each group:\n    *   `['eat', 'tea', 'ate']` becomes `['ate', 'eat', 'tea']`\n    *   `['tan', 'nat']` becomes `['nat', 'tan']`\n    *   `['bat']` remains `['bat']`\n    `result` is now (order of inner lists still varies): `[['ate', 'eat', 'tea'], ['nat', 'tan'], ['bat']]`\n\n5.  Sort the groups by their first word:\n    *   The first words are 'ate', 'nat', 'bat'.\n    *   Sorted alphabetically: 'ate', 'bat', 'nat'.\n    *   So, the final `result` is: `[['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]`\n\n```python\nfrom collections import defaultdict\n\ndef find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n    \"\"\"\n    # Use a defaultdict to store lists of words for each sorted key.\n    # The sorted version of a word acts as a unique key for all its anagrams.\n    anagram_groups = defaultdict(list)\n\n    for word in words:\n        # Sort the letters of the current word to create a canonical key.\n        # \"\".join(sorted(word)) converts the list of sorted characters back to a string.\n        sorted_word_key = \"\".join(sorted(word))\n        \n        # Append the original word to the list associated with its sorted key.\n        anagram_groups[sorted_word_key].append(word)\n\n    # Extract all the lists of anagrams from the dictionary's values.\n    # This gives us a list of lists, where each inner list is a group of anagrams.\n    result = list(anagram_groups.values())\n\n    # Sort words within each group alphabetically, as required.\n    for group in result:\n        group.sort()\n\n    # Sort the groups themselves by their first word alphabetically, as required.\n    # The lambda function provides the sorting key (the first word of each group).\n    result.sort(key=lambda group: group[0])\n\n    return result\n\n```", "error": null, "raw_item": {"task_id": "custom_find_anagrams", "prompt": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"\n    ", "entry_point": "find_anagrams", "canonical_solution": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    from collections import defaultdict\n    \n    anagram_groups = defaultdict(list)\n    \n    for word in words:\n        # Use sorted characters as key\n        key = ''.join(sorted(word))\n        anagram_groups[key].append(word)\n    \n    result = []\n    for group in anagram_groups.values():\n        group.sort()\n        result.append(group)\n    \n    # Sort groups by their first word\n    result.sort(key=lambda x: x[0])\n    \n    return result", "test": [{"input": [["eat", "tea", "tan", "ate", "nat", "bat"]], "output": [["ate", "eat", "tea"], ["bat"], ["nat", "tan"]]}, {"input": [["hello", "world"]], "output": [["hello"], ["world"]]}, {"input": [[]], "output": []}, {"input": [["a", "aa", "aaa"]], "output": [["a"], ["aa"], ["aaa"]]}, {"input": [["abc", "bca", "cab", "xyz"]], "output": [["abc", "bca", "cab"], ["xyz"]]}]}}
{"timestamp_utc": "2025-09-26T10:43:33.110924", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 32, "question": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 23.347892999649048, "response": "To merge overlapping intervals, we can follow these steps:\n\n1.  **Sort the Intervals**: The first and most crucial step is to sort the intervals based on their start times. This ensures that when we iterate through the intervals, we are always considering them in a sequential order, making it easier to check for overlaps. If two intervals have the same start time, their order doesn't strictly matter for the merging logic, but sorting by end time as a secondary criterion can also be done (though not strictly necessary for correctness here).\n\n2.  **Initialize Merged List**: Create an empty list, say `merged`, to store the non-overlapping intervals.\n\n3.  **Iterate and Merge**:\n    *   Iterate through each interval in the sorted list.\n    *   For each `current_interval = [current_start, current_end]`:\n        *   **If `merged` is empty OR the `current_interval` does not overlap with the last interval in `merged`**:\n            *   An overlap does not exist if `current_start > last_merged_end`. In this case, simply add the `current_interval` to `merged` as a new non-overlapping interval.\n        *   **If `current_interval` *does* overlap with the last interval in `merged`**:\n            *   An overlap exists if `current_start <= last_merged_end`. In this case, merge them by updating the end time of the last interval in `merged` to be the maximum of its current end time and `current_end`. This effectively extends the last merged interval to cover the `current_interval`.\n\n4.  **Return `merged`**: After iterating through all intervals, the `merged` list will contain all non-overlapping intervals.\n\n**Example Walkthrough: `[[1, 3], [2, 6], [8, 10], [15, 18]]`**\n\n1.  **Sort**: The intervals are already sorted by start time: `[[1, 3], [2, 6], [8, 10], [15, 18]]`.\n2.  **Initialize**: `merged = []`\n\n3.  **Process `[1, 3]`**:\n    *   `merged` is empty. Add `[1, 3]`.\n    *   `merged = [[1, 3]]`\n\n4.  **Process `[2, 6]`**:\n    *   Last merged interval: `[1, 3]` (end = 3)\n    *   Current interval: `[2, 6]` (start = 2)\n    *   `2 <= 3` (overlap exists).\n    *   Merge: Update the last interval in `merged` to `[1, max(3, 6)] = [1, 6]`.\n    *   `merged = [[1, 6]]`\n\n5.  **Process `[8, 10]`**:\n    *   Last merged interval: `[1, 6]` (end = 6)\n    *   Current interval: `[8, 10]` (start = 8)\n    *   `8 > 6` (no overlap).\n    *   Add `[8, 10]` to `merged`.\n    *   `merged = [[1, 6], [8, 10]]`\n\n6.  **Process `[15, 18]`**:\n    *   Last merged interval: `[8, 10]` (end = 10)\n    *   Current interval: `[15, 18]` (start = 15)\n    *   `15 > 10` (no overlap).\n    *   Add `[15, 18]` to `merged`.\n    *   `merged = [[1, 6], [8, 10], [15, 18]]`\n\n7.  **Return**: `[[1, 6], [8, 10], [15, 18]]`\n\n**Time Complexity**:\n*   Sorting the intervals takes `O(N log N)` time, where `N` is the number of intervals.\n*   Iterating through the sorted intervals and merging takes `O(N)` time, as each interval is visited once.\n*   Therefore, the dominant factor is sorting, making the total time complexity `O(N log N)`.\n\n**Space Complexity**:\n*   The `merged` list can store up to `N` intervals in the worst case (e.g., no overlaps). This requires `O(N)` space.\n*   The `sort()` method in Python typically uses `O(log N)` or `O(N)` space depending on the implementation and data (Timsort uses `O(N)` in worst case, `O(log N)` in best case).\n*   Overall, the space complexity is `O(N)`.\n\n```python\ndef merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n    \"\"\"\n    if not intervals:\n        return []\n\n    # 1. Sort the intervals based on their start times.\n    # This is crucial for the merging logic to work correctly.\n    intervals.sort(key=lambda x: x[0])\n\n    # 2. Initialize a list to store the merged intervals.\n    merged = []\n\n    # 3. Iterate through the sorted intervals.\n    for interval in intervals:\n        # If merged is empty OR the current interval does not overlap with the last merged interval,\n        # simply add the current interval to merged.\n        # An overlap does not exist if the start of the current interval is greater than\n        # the end of the last merged interval.\n        if not merged or interval[0] > merged[-1][1]:\n            merged.append(interval)\n        # Otherwise, there is an overlap. Merge the current interval with the last merged interval.\n        # This means updating the end time of the last merged interval to be the maximum\n        # of its current end time and the current interval's end time.\n        else:\n            merged[-1][1] = max(merged[-1][1], interval[1])\n\n    return merged\n\n```", "error": null, "raw_item": {"task_id": "custom_merge_intervals", "prompt": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"\n    ", "entry_point": "merge_intervals", "canonical_solution": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    if not intervals:\n        return []\n    \n    # Sort intervals by start time\n    intervals.sort(key=lambda x: x[0])\n    \n    merged = [intervals[0]]\n    \n    for current in intervals[1:]:\n        last = merged[-1]\n        \n        # Check if current interval overlaps with last merged interval\n        if current[0] <= last[1]:\n            # Merge intervals\n            last[1] = max(last[1], current[1])\n        else:\n            # No overlap, add current interval\n            merged.append(current)\n    \n    return merged", "test": [{"input": [[[1, 3], [2, 6], [8, 10], [15, 18]]], "output": [[1, 6], [8, 10], [15, 18]]}, {"input": [[[1, 4], [4, 5]]], "output": [[1, 5]]}, {"input": [[[1, 4], [0, 2], [3, 5]]], "output": [[0, 5]]}, {"input": [[]], "output": []}, {"input": [[[1, 2]]], "output": [[1, 2]]}, {"input": [[[1, 4], [2, 3]]], "output": [[1, 4]]}]}}
{"timestamp_utc": "2025-09-26T10:43:55.726012", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 33, "question": "def binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 21.61210298538208, "response": "To find all root-to-leaf paths in a binary tree, we can use a Depth-First Search (DFS) approach. We'll traverse the tree recursively, keeping track of the path from the root to the current node. When we reach a leaf node, we convert the current path into a string and add it to our results.\n\nHere's the breakdown of the algorithm:\n\n1.  **Base Case for Empty Tree**: If the `root` is `None`, it means there's no tree, so we return an empty list.\n\n2.  **Initialize Results**: Create an empty list, `paths`, to store the final root-to-leaf path strings.\n\n3.  **DFS Helper Function**: Define a recursive helper function, `dfs(node, current_path_values)`:\n    *   `node`: The current node we are visiting.\n    *   `current_path_values`: A list of integers representing the values of nodes from the root to the *parent* of the current node.\n\n4.  **DFS Logic**:\n    *   **Handle `None` Node**: If `node` is `None`, simply return (there's nothing to process).\n    *   **Append Current Node's Value**: Add `node['val']` to `current_path_values`. This list now represents the path from the root to the `node`.\n    *   **Check for Leaf Node**: If `node['left']` is `None` AND `node['right']` is `None`, it means we've reached a leaf node.\n        *   Convert `current_path_values` (which is a list of integers) into a \"->\"-separated string using `map(str, current_path_values)` and ` \"->\".join(...)`.\n        *   Add this string to the `paths` list.\n    *   **Recursive Calls**: If it's not a leaf node:\n        *   Recursively call `dfs` for the `node['left']` child, passing the modified `current_path_values`.\n        *   Recursively call `dfs` for the `node['right']` child, passing the modified `current_path_values`.\n    *   **Backtrack**: After processing a node and its children (both recursive calls return), remove the `node['val']` from `current_path_values` using `pop()`. This is crucial for backtracking, ensuring that when the recursion unwinds, the `current_path_values` list is correctly restored for sibling branches.\n\n5.  **Initial Call**: Start the DFS by calling `dfs(root, [])`.\n\n6.  **Return Results**: After the DFS completes, `paths` will contain all the root-to-leaf path strings, so return `paths`.\n\n```python\ndef binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"\n    if root is None:\n        return []\n\n    paths = []\n\n    def dfs(node: dict | None, current_path_values: list[int]):\n        \"\"\"\n        Helper function to perform Depth-First Search.\n        Args:\n            node: The current node being visited.\n            current_path_values: A list of integer values representing the path\n                                 from the root to the current node's parent.\n        \"\"\"\n        if node is None:\n            return\n\n        # Add the current node's value to the path\n        current_path_values.append(node['val'])\n\n        # If it's a leaf node, we've found a complete path\n        if node['left'] is None and node['right'] is None:\n            paths.append(\"->\".join(map(str, current_path_values)))\n        else:\n            # Recursively call for left and right children\n            dfs(node['left'], current_path_values)\n            dfs(node['right'], current_path_values)\n        \n        # Backtrack: remove the current node's value before returning\n        # This restores current_path_values to its state before this node was added,\n        # allowing sibling branches to start from the correct parent path.\n        current_path_values.pop()\n\n    # Start the DFS from the root with an empty path list\n    dfs(root, [])\n    \n    return paths\n\n```", "error": null, "raw_item": {"task_id": "custom_binary_tree_paths", "prompt": "def binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"\n    ", "entry_point": "binary_tree_paths", "canonical_solution": "def binary_tree_paths(root: dict | None) -> list[str]:\n    if not root:\n        return []\n    \n    paths = []\n    \n    def dfs(node, path):\n        if not node:\n            return\n        \n        # Add current node to path\n        current_path = path + [str(node['val'])]\n        \n        # If leaf node, add path to result\n        if not node['left'] and not node['right']:\n            paths.append('->'.join(current_path))\n            return\n        \n        # Recurse on children\n        if node['left']:\n            dfs(node['left'], current_path)\n        if node['right']:\n            dfs(node['right'], current_path)\n    \n    dfs(root, [])\n    return paths", "test": [{"input": [{"val": 1, "left": {"val": 2, "left": null, "right": {"val": 5, "left": null, "right": null}}, "right": {"val": 3, "left": null, "right": null}}], "output": ["1->2->5", "1->3"]}, {"input": [{"val": 1, "left": null, "right": null}], "output": ["1"]}, {"input": [null], "output": []}, {"input": [{"val": 1, "left": {"val": 2, "left": null, "right": null}, "right": {"val": 3, "left": null, "right": null}}], "output": ["1->2", "1->3"]}]}}
{"timestamp_utc": "2025-09-26T10:44:49.858352", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 34, "question": "def word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 53.13092303276062, "response": "To determine if a string `s` follows a given `pattern`, we need to establish a **bijection** (a one-to-one and onto mapping) between each letter in the `pattern` and each non-empty word in `s`. This means:\n1.  Each unique letter in `pattern` must map to a unique word in `s`.\n2.  Each unique word in `s` must map to a unique letter in `pattern`.\n3.  The order of letters in `pattern` must correspond to the order of words in `s`.\n4.  The number of letters in `pattern` must be equal to the number of words in `s`.\n\nWe can achieve this by using two hash maps (dictionaries in Python) to keep track of the mappings in both directions:\n*   `char_to_word`: Maps a character from `pattern` to a word from `s`.\n*   `word_to_char`: Maps a word from `s` to a character from `pattern`.\n\nHere's the step-by-step algorithm:\n\n1.  **Split the string `s`**: First, split `s` into a list of words. Using `s.split()` (without arguments) is robust as it handles multiple spaces between words and removes empty strings, ensuring we only deal with non-empty words as per the problem statement.\n2.  **Check length consistency**: Compare the length of the `pattern` string with the number of words obtained from `s`. If they are not equal, a full match is impossible, so return `False`.\n3.  **Iterate and map**: Iterate simultaneously through `pattern` and the `words` list using an index or `zip`. For each pair `(char, word)`:\n    *   **Check `char_to_word` mapping**:\n        *   If `char` is already in `char_to_word`: This means we've seen this pattern character before. We must verify that its previously established mapping is consistent with the current `word`. If `char_to_word[char]` is not equal to `word`, then there's a contradiction (e.g., 'a' mapped to \"dog\" previously, but now 'a' needs to map to \"cat\"). In this case, return `False`.\n        *   If `char` is *not* in `char_to_word`: This is a new pattern character. Before establishing a new mapping, we must ensure that the current `word` has not already been mapped to a *different* pattern character in `word_to_char`. If `word` is already in `word_to_char` (meaning it's taken by another pattern character), then it violates the bijection rule. In this case, return `False`.\n        *   If `char` is new and `word` is not yet mapped to any pattern character, establish the new mappings: `char_to_word[char] = word` and `word_to_char[word] = char`.\n4.  **Return `True`**: If the loop completes without encountering any contradictions, it means a consistent bijection has been established for all characters and words. Return `True`.\n\n**Example Trace (`pattern = \"abba\"`, `s = \"dog cat cat dog\"`):**\n\n1.  `words = [\"dog\", \"cat\", \"cat\", \"dog\"]`\n2.  `len(pattern)` (4) == `len(words)` (4). OK.\n3.  `char_to_word = {}`, `word_to_char = {}`\n\n    *   **i = 0**: `char = 'a'`, `word = \"dog\"`\n        *   `'a'` not in `char_to_word`. `\"dog\"` not in `word_to_char`.\n        *   Map: `char_to_word['a'] = \"dog\"`, `word_to_char[\"dog\"] = 'a'`.\n        *   Maps: `{'a': 'dog'}`, `{'dog': 'a'}`\n\n    *   **i = 1**: `char = 'b'`, `word = \"cat\"`\n        *   `'b'` not in `char_to_word`. `\"cat\"` not in `word_to_char`.\n        *   Map: `char_to_word['b'] = \"cat\"`, `word_to_char[\"cat\"] = 'b'`.\n        *   Maps: `{'a': 'dog', 'b': 'cat'}`, `{'dog': 'a', 'cat': 'b'}`\n\n    *   **i = 2**: `char = 'b'`, `word = \"cat\"`\n        *   `'b'` *is* in `char_to_word`. `char_to_word['b']` is `\"cat\"`. `word` is `\"cat\"`. They match. OK.\n        *   Maps remain unchanged.\n\n    *   **i = 3**: `char = 'a'`, `word = \"dog\"`\n        *   `'a'` *is* in `char_to_word`. `char_to_word['a']` is `\"dog\"`. `word` is `\"dog\"`. They match. OK.\n        *   Maps remain unchanged.\n\n4.  Loop completes. Return `True`.\n\n```python\ndef word_pattern(pattern: str, s: str) -> bool:\n    # Split the string s into a list of words.\n    # s.split() handles multiple spaces and ensures non-empty words.\n    words = s.split()\n\n    # Step 1: Check if the number of pattern characters matches the number of words.\n    # If not, a full match is impossible.\n    if len(pattern) != len(words):\n        return False\n\n    # Step 2: Use two dictionaries to maintain the bijection.\n    # char_to_word maps a character from pattern to a word from s.\n    # word_to_char maps a word from s to a character from pattern.\n    char_to_word = {}\n    word_to_char = {}\n\n    # Step 3: Iterate through the pattern characters and words simultaneously.\n    for i in range(len(pattern)):\n        char = pattern[i]\n        word = words[i]\n\n        # Check mapping from char to word\n        if char in char_to_word:\n            # If char has been seen before, it must map to the same word.\n            if char_to_word[char] != word:\n                return False  # Contradiction: e.g., 'a' mapped to \"dog\", then 'a' mapped to \"cat\"\n        else:\n            # If char is new, ensure the word is not already mapped to a different char.\n            if word in word_to_char:\n                return False  # Contradiction: e.g., \"dog\" mapped to 'a', then \"dog\" mapped to 'b'\n            \n            # If both char and word are new to their respective mappings,\n            # establish the new bijection.\n            char_to_word[char] = word\n            word_to_char[word] = char\n\n    # Step 4: If the loop completes, it means all mappings were consistent\n    # and a bijection was maintained.\n    return True\n\n```", "error": null, "raw_item": {"task_id": "custom_word_pattern", "prompt": "def word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"\n    ", "entry_point": "word_pattern", "canonical_solution": "def word_pattern(pattern: str, s: str) -> bool:\n    words = s.split()\n    \n    if len(pattern) != len(words):\n        return False\n    \n    char_to_word = {}\n    word_to_char = {}\n    \n    for char, word in zip(pattern, words):\n        # Check char -> word mapping\n        if char in char_to_word:\n            if char_to_word[char] != word:\n                return False\n        else:\n            char_to_word[char] = word\n        \n        # Check word -> char mapping (bijection)\n        if word in word_to_char:\n            if word_to_char[word] != char:\n                return False\n        else:\n            word_to_char[word] = char\n    \n    return True", "test": [{"input": ["abba", "dog cat cat dog"], "output": true}, {"input": ["abba", "dog cat cat fish"], "output": false}, {"input": ["aaaa", "dog cat cat dog"], "output": false}, {"input": ["abba", "dog dog dog dog"], "output": false}, {"input": ["abc", "dog cat fish"], "output": true}, {"input": ["a", "dog"], "output": true}, {"input": ["ab", "dog"], "output": false}]}}
{"timestamp_utc": "2025-09-26T10:45:32.943214", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 35, "question": "class MinStack:\n    \"\"\"\n    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\n    Implement the MinStack class:\n    - MinStack() initializes the stack object.\n    - push(val) pushes the element val onto the stack.\n    - pop() removes the element on the top of the stack.\n    - top() gets the top element of the stack.\n    - get_min() retrieves the minimum element in the stack.\n\n    You must implement a solution with O(1) time complexity for each function.\n\n    Examples:\n    >>> stack = MinStack()\n    >>> stack.push(-2)\n    >>> stack.push(0)\n    >>> stack.push(-3)\n    >>> stack.get_min()\n    -3\n    >>> stack.pop()\n    >>> stack.top()\n    0\n    >>> stack.get_min()\n    -2\n    \"\"\"", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 42.08088183403015, "response": "To design a stack that supports `push`, `pop`, `top`, and `get_min` operations all in O(1) time complexity, we can augment the standard stack structure. The main challenge is `get_min()` in O(1), as a naive approach would require iterating through the stack, leading to O(N) time complexity.\n\nThe most common and effective approach involves storing not just the value, but also the minimum value encountered *up to that point* along with each element in the stack.\n\n**Approach: Store (value, current_min) pairs**\n\nWe will use a single internal list (or array) to represent our stack. Each element pushed onto this list will not just be the `val` itself, but a tuple `(val, min_so_far)`.\n\nHere's how each operation works:\n\n1.  **`MinStack()`**: Initializes an empty list to store the `(value, current_min)` tuples.\n\n2.  **`push(val)`**:\n    *   If the stack is empty, `val` is the first element, so it's also the minimum element seen so far. We push `(val, val)`.\n    *   If the stack is not empty, we look at the `min_so_far` value of the current top element (which is `self.stack[-1][1]`). The new minimum will be `min(val, self.stack[-1][1])`. We then push `(val, new_min)` onto the stack.\n\n3.  **`pop()`**: We simply remove the top tuple from our internal list using `self.stack.pop()`. This operation is O(1).\n\n4.  **`top()`**: We return the actual value of the top element. This is the first component of the top tuple: `self.stack[-1][0]`. This operation is O(1).\n\n5.  **`get_min()`**: We return the minimum value associated with the top element. This is the second component of the top tuple: `self.stack[-1][1]`. This operation is O(1).\n\n**Time Complexity:**\nAll operations (`push`, `pop`, `top`, `get_min`) involve constant-time list operations (append, pop, indexing the last element). Therefore, all operations have an O(1) time complexity.\n\n**Space Complexity:**\nIn the worst case, we store N tuples, where N is the number of elements in the stack. Each tuple stores two integers. Thus, the space complexity is O(N).\n\n**Example Walkthrough:**\n\nLet's trace the given example:\n\n1.  `stack = MinStack()`\n    *   `self.stack = []`\n\n2.  `stack.push(-2)`\n    *   `self.stack` is empty. Append `(-2, -2)`.\n    *   `self.stack = [(-2, -2)]`\n\n3.  `stack.push(0)`\n    *   `self.stack` is not empty. Current min from top is `-2`.\n    *   `new_min = min(0, -2) = -2`. Append `(0, -2)`.\n    *   `self.stack = [(-2, -2), (0, -2)]`\n\n4.  `stack.push(-3)`\n    *   `self.stack` is not empty. Current min from top is `-2`.\n    *   `new_min = min(-3, -2) = -3`. Append `(-3, -3)`.\n    *   `self.stack = [(-2, -2), (0, -2), (-3, -3)]`\n\n5.  `stack.get_min()`\n    *   Top tuple is `(-3, -3)`. Return its second element: `-3`.\n\n6.  `stack.pop()`\n    *   Remove `(-3, -3)` from `self.stack`.\n    *   `self.stack = [(-2, -2), (0, -2)]`\n\n7.  `stack.top()`\n    *   Top tuple is `(0, -2)`. Return its first element: `0`.\n\n8.  `stack.get_min()`\n    *   Top tuple is `(0, -2)`. Return its second element: `-2`.\n\nThis approach correctly implements all required functionalities within the specified time constraints.\n\n```python\nclass MinStack:\n    \"\"\"\n    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\n    Implement the MinStack class:\n    - MinStack() initializes the stack object.\n    - push(val) pushes the element val onto the stack.\n    - pop() removes the element on the top of the stack.\n    - top() gets the top element of the stack.\n    - get_min() retrieves the minimum element in the stack.\n\n    You must implement a solution with O(1) time complexity for each function.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the stack object.\n        Our stack will store tuples of (value, current_minimum_up_to_this_point).\n        \"\"\"\n        self.stack = []\n\n    def push(self, val: int) -> None:\n        \"\"\"\n        Pushes the element val onto the stack.\n        For each element, we store its value along with the minimum element\n        in the stack *at that point*.\n        \"\"\"\n        if not self.stack:\n            # If the stack is empty, the first element is also the current minimum.\n            self.stack.append((val, val))\n        else:\n            # The current minimum is the minimum of the new value and the previous minimum.\n            # The previous minimum is stored as the second element of the top tuple.\n            current_min_so_far = self.stack[-1][1]\n            new_min = min(val, current_min_so_far)\n            self.stack.append((val, new_min))\n\n    def pop(self) -> None:\n        \"\"\"\n        Removes the element on the top of the stack.\n        If the stack is empty, `list.pop()` will raise an IndexError,\n        which is standard behavior for a stack.\n        \"\"\"\n        self.stack.pop()\n\n    def top(self) -> int:\n        \"\"\"\n        Gets the top element of the stack.\n        This is the actual value, which is the first component of the top tuple.\n        If the stack is empty, `self.stack[-1]` will raise an IndexError.\n        \"\"\"\n        return self.stack[-1][0]\n\n    def get_min(self) -> int:\n        \"\"\"\n        Retrieves the minimum element in the stack.\n        This is the minimum value associated with the top element,\n        which is the second component of the top tuple.\n        If the stack is empty, `self.stack[-1]` will raise an IndexError.\n        \"\"\"\n        return self.stack[-1][1]\n\n```", "error": null, "raw_item": {"task_id": "custom_min_stack", "prompt": "class MinStack:\n    \"\"\"\n    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\n    Implement the MinStack class:\n    - MinStack() initializes the stack object.\n    - push(val) pushes the element val onto the stack.\n    - pop() removes the element on the top of the stack.\n    - top() gets the top element of the stack.\n    - get_min() retrieves the minimum element in the stack.\n\n    You must implement a solution with O(1) time complexity for each function.\n\n    Examples:\n    >>> stack = MinStack()\n    >>> stack.push(-2)\n    >>> stack.push(0)\n    >>> stack.push(-3)\n    >>> stack.get_min()\n    -3\n    >>> stack.pop()\n    >>> stack.top()\n    0\n    >>> stack.get_min()\n    -2\n    \"\"\"\n    ", "entry_point": "MinStack", "canonical_solution": "class MinStack:\n    def __init__(self):\n        self.stack = []\n        self.min_stack = []\n    \n    def push(self, val: int) -> None:\n        self.stack.append(val)\n        # Push to min_stack if it's empty or val is <= current minimum\n        if not self.min_stack or val <= self.min_stack[-1]:\n            self.min_stack.append(val)\n    \n    def pop(self) -> None:\n        if self.stack:\n            val = self.stack.pop()\n            # Pop from min_stack if the popped value was the minimum\n            if self.min_stack and val == self.min_stack[-1]:\n                self.min_stack.pop()\n    \n    def top(self) -> int:\n        return self.stack[-1] if self.stack else None\n    \n    def get_min(self) -> int:\n        return self.min_stack[-1] if self.min_stack else None", "test": [{"input": [["MinStack", "push", "push", "push", "get_min", "pop", "top", "get_min"], [[], [-2], [0], [-3], [], [], [], []]], "output": [null, null, null, null, -3, null, 0, -2]}, {"input": [["MinStack", "push", "push", "get_min", "get_min", "pop", "get_min"], [[], [1], [2], [], [], [], []]], "output": [null, null, null, 1, 1, null, 1]}, {"input": [["MinStack", "push", "get_min", "pop", "push", "get_min"], [[], [1], [], [], [2], []]], "output": [null, null, 1, null, null, 2]}]}}
{"timestamp_utc": "2025-09-26T10:46:15.556846", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 36, "question": "class LRUCache:\n    \"\"\"\n    Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.\n\n    Implement the LRUCache class:\n    - LRUCache(capacity) Initialize the LRU cache with positive size capacity.\n    - get(key) Return the value of the key if the key exists, otherwise return -1.\n    - put(key, value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache.\n      If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\n    The functions get and put must each run in O(1) average time complexity.\n\n    Examples:\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 41.61058688163757, "response": "To design an LRU Cache with O(1) average time complexity for `get` and `put` operations, we need two data structures:\n\n1.  **Hash Map (Dictionary in Python)**: To store key-value pairs and enable O(1) average time complexity for looking up a key. In our case, the value stored in the hash map will be a reference to a node in a doubly linked list.\n    `self.cache = {key: node}`\n2.  **Doubly Linked List**: To maintain the order of usage. The head of the list will represent the Most Recently Used (MRU) item, and the tail of the list will represent the Least Recently Used (LRU) item. When an item is accessed or updated, it's moved to the head of the list. When the cache exceeds its capacity, the item at the tail (LRU) is removed.\n\n### Node Structure\n\nEach node in the doubly linked list will store the `key`, `value`, and pointers to the `prev` and `next` nodes. Storing the `key` in the node is crucial because when we evict an item from the tail of the linked list, we need its key to remove it from the hash map.\n\n```python\nclass Node:\n    def __init__(self, key, value):\n        self.key = key\n        self.value = value\n        self.prev = None\n        self.next = None\n```\n\n### LRUCache Class Implementation\n\nThe `LRUCache` class will maintain:\n-   `capacity`: The maximum number of key-value pairs the cache can hold.\n-   `cache`: The hash map (Python dictionary) storing `key -> Node` mappings.\n-   `head` and `tail`: Dummy nodes for the doubly linked list. These dummy nodes simplify operations by avoiding `None` checks at the boundaries of the list. `head.next` points to the MRU node, and `tail.prev` points to the LRU node.\n\n#### Core Doubly Linked List Operations:\n\n1.  **`_remove_node(node)`**: Removes a given node from its current position in the linked list. This involves updating the `next` pointer of the previous node and the `prev` pointer of the next node.\n2.  **`_add_to_head(node)`**: Adds a given node right after the dummy `head` node, making it the new MRU item.\n\n#### `get(key)` Operation:\n\n1.  Check if the `key` exists in `self.cache`.\n2.  If not, return -1.\n3.  If yes:\n    a.  Retrieve the `node` associated with the `key` from `self.cache`.\n    b.  Since this `node` has just been accessed, it becomes the Most Recently Used. Remove it from its current position in the linked list using `_remove_node()`.\n    c.  Add it to the head of the linked list using `_add_to_head()`.\n    d.  Return the `value` stored in the node.\n\n#### `put(key, value)` Operation:\n\n1.  Check if the `key` already exists in `self.cache`.\n2.  If yes:\n    a.  Retrieve the `node` associated with the `key`.\n    b.  Update its `value` to the new `value`.\n    c.  Since this `node` has just been updated, it becomes the Most Recently Used. Remove it from its current position in the linked list using `_remove_node()`.\n    d.  Add it to the head of the linked list using `_add_to_head()`.\n3.  If no (new `key`):\n    a.  Create a new `Node(key, value)`.\n    b.  Add this new `node` to `self.cache` (`self.cache[key] = node`).\n    c.  Add this `node` to the head of the linked list using `_add_to_head()`.\n    d.  Check if the current size of the cache (`len(self.cache)`) exceeds `self.capacity`.\n        i.  If it does, the Least Recently Used item must be evicted. This item is located just before the dummy `tail` node (`self.tail.prev`).\n        ii. Get a reference to this `lru_node`.\n        iii. Remove it from the linked list using `_remove_node(lru_node)`.\n        iv. Remove it from the `self.cache` using `del self.cache[lru_node.key]`.\n\n### Time Complexity\n\nBoth `get` and `put` operations involve:\n-   Hash map operations (lookup, insertion, deletion) which are O(1) on average.\n-   Doubly linked list operations (removing a node, adding a node to the head) which are O(1) because we have direct pointers to the nodes.\n\nTherefore, the average time complexity for both `get` and `put` is O(1).\n\n### Example Walkthrough\n\nThe example provided in the problem description is correctly handled by this logic, as detailed in the thought process.\n\n```python\nclass Node:\n    def __init__(self, key, value):\n        self.key = key\n        self.value = value\n        self.prev = None\n        self.next = None\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}  # Maps key to Node\n\n        # Dummy head and tail nodes to simplify operations\n        self.head = Node(0, 0)\n        self.tail = Node(0, 0)\n        self.head.next = self.tail\n        self.tail.prev = self.head\n\n    def _remove_node(self, node):\n        \"\"\"Removes a node from the doubly linked list.\"\"\"\n        node.prev.next = node.next\n        node.next.prev = node.prev\n\n    def _add_to_head(self, node):\n        \"\"\"Adds a node right after the dummy head (MRU position).\"\"\"\n        node.prev = self.head\n        node.next = self.head.next\n        self.head.next.prev = node\n        self.head.next = node\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n\n        node = self.cache[key]\n        # Move the accessed node to the head (MRU)\n        self._remove_node(node)\n        self._add_to_head(node)\n        return node.value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            # Key exists, update value and move to head (MRU)\n            node = self.cache[key]\n            node.value = value\n            self._remove_node(node)\n            self._add_to_head(node)\n        else:\n            # New key-value pair\n            new_node = Node(key, value)\n            self.cache[key] = new_node\n            self._add_to_head(new_node)\n\n            # Check if capacity is exceeded\n            if len(self.cache) > self.capacity:\n                # Evict the Least Recently Used (LRU) item\n                lru_node = self.tail.prev # The node before the dummy tail is LRU\n                self._remove_node(lru_node)\n                del self.cache[lru_node.key]\n\n```", "error": null, "raw_item": {"task_id": "custom_lru_cache", "prompt": "class LRUCache:\n    \"\"\"\n    Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.\n\n    Implement the LRUCache class:\n    - LRUCache(capacity) Initialize the LRU cache with positive size capacity.\n    - get(key) Return the value of the key if the key exists, otherwise return -1.\n    - put(key, value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache.\n      If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\n    The functions get and put must each run in O(1) average time complexity.\n\n    Examples:\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"\n    ", "entry_point": "LRUCache", "canonical_solution": "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        # Use a list to maintain order (least recent at index 0)\n        self.order = []\n    \n    def get(self, key: int) -> int:\n        if key in self.cache:\n            # Move to end (most recently used)\n            self.order.remove(key)\n            self.order.append(key)\n            return self.cache[key]\n        return -1\n    \n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            # Update existing key\n            self.cache[key] = value\n            self.order.remove(key)\n            self.order.append(key)\n        else:\n            # Add new key\n            if len(self.cache) >= self.capacity:\n                # Remove least recently used\n                lru_key = self.order.pop(0)\n                del self.cache[lru_key]\n            \n            self.cache[key] = value\n            self.order.append(key)", "test": [{"input": [["LRUCache", "put", "put", "get", "put", "get", "put", "get", "get", "get"], [[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]], "output": [null, null, null, 1, null, -1, null, -1, 3, 4]}, {"input": [["LRUCache", "put", "get", "put", "get", "get"], [[1], [2, 1], [2], [3, 2], [2], [3]]], "output": [null, null, 1, null, -1, 2]}]}}
{"timestamp_utc": "2025-09-26T10:46:59.402895", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 37, "question": "def validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 42.84283494949341, "response": "The `validate_ip_address` function determines if a given string is a valid IPv4 address, a valid IPv6 address, or neither.\n\nThe validation process follows these steps:\n\n1.  **Distinguish between IPv4 and IPv6 candidates**:\n    *   If the input string `ip` contains a `.` (dot), it's considered a candidate for an IPv4 address.\n    *   If it contains a `:` (colon), it's considered a candidate for an IPv6 address.\n    *   If it contains neither, or both (though the problem implies they are mutually exclusive for valid IPs, and the current logic handles mixed cases by attempting IPv4 first), it's immediately \"Neither\" or will fail a specific validation.\n\n2.  **IPv4 Validation (`is_ipv4` helper function)**:\n    *   **Split by `.`**: The string is split into parts using `.` as a delimiter.\n    *   **Number of parts**: A valid IPv4 address must have exactly 4 parts. If not, it's invalid.\n    *   **Validate each part**: For each part:\n        *   **Empty part**: The part cannot be an empty string (e.g., `1.2..3` or `.1.2.3` are invalid).\n        *   **Leading zeros**: If a part has more than one digit, it cannot start with `0` (e.g., `01`, `00` are invalid, but `0` itself is valid).\n        *   **Numeric check**: All characters in the part must be digits (`0-9`).\n        *   **Range check**: After converting the part to an integer, it must be within the range `0` to `255` (inclusive).\n    *   If all parts pass these checks, it's a valid IPv4 address.\n\n3.  **IPv6 Validation (`is_ipv6` helper function)**:\n    *   **Split by `:`**: The string is split into parts using `:` as a delimiter.\n    *   **Number of parts**: A valid IPv6 address must have exactly 8 parts. If not, it's invalid.\n    *   **Validate each part**: For each part:\n        *   **Length check**: Each part must have a length between `1` and `4` characters (inclusive). This handles empty parts (e.g., `::` would produce empty strings after split) and parts that are too long.\n        *   **Hexadecimal digits check**: All characters in the part must be valid hexadecimal digits (`0-9`, `a-f`, `A-F`). Python's `string.hexdigits` can be used for this. Leading zeros are allowed in IPv6 groups.\n    *   If all parts pass these checks, it's a valid IPv6 address.\n\n4.  **Return result**:\n    *   If IPv4 validation succeeds, return \"IPv4\".\n    *   Else if IPv6 validation succeeds, return \"IPv6\".\n    *   Otherwise, return \"Neither\".\n\n```python\nimport string\n\ndef validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n    \"\"\"\n\n    def is_ipv4(s: str) -> bool:\n        parts = s.split('.')\n        # IPv4 addresses must have exactly 4 parts\n        if len(parts) != 4:\n            return False\n\n        for part in parts:\n            # 1. Check for empty parts (e.g., \"1.2..3\" or \".1.2.3\")\n            if not part: \n                return False\n            \n            # 2. Check for leading zeros (e.g., \"01\", \"00\" are invalid, but \"0\" is valid)\n            if len(part) > 1 and part[0] == '0':\n                return False\n            \n            # 3. Check if all characters are digits\n            if not part.isdigit():\n                return False\n            \n            # 4. Convert to integer and check if the number is within the valid range [0, 255]\n            num = int(part)\n            if not (0 <= num <= 255):\n                return False\n        return True\n\n    def is_ipv6(s: str) -> bool:\n        parts = s.split(':')\n        # IPv6 addresses must have exactly 8 groups\n        if len(parts) != 8:\n            return False\n\n        # string.hexdigits contains '0123456789abcdefABCDEF'\n        # We use this set to efficiently check if characters are valid hex digits.\n        # It's slightly more efficient to convert to a set if many lookups are expected,\n        # but for small strings like 4 characters, direct string lookup is fine too.\n        hex_chars = string.hexdigits \n        \n        for part in parts:\n            # 1. Check length of the group (1 to 4 characters)\n            # This handles empty parts (e.g., \"::\" results in empty strings from split) \n            # and parts that are too long (e.g., \"12345\").\n            if not (1 <= len(part) <= 4): \n                return False\n            \n            # 2. Check if all characters in the group are valid hexadecimal digits\n            for char in part:\n                if char not in hex_chars:\n                    return False\n        return True\n\n    # Determine IP type based on separators present in the string\n    if '.' in ip:\n        if is_ipv4(ip):\n            return \"IPv4\"\n    elif ':' in ip:\n        if is_ipv6(ip):\n            return \"IPv6\"\n    \n    # If neither separator found or validation failed for the identified type\n    return \"Neither\"\n\n```", "error": null, "raw_item": {"task_id": "custom_validate_ip_address", "prompt": "def validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"\n    ", "entry_point": "validate_ip_address", "canonical_solution": "def validate_ip_address(ip: str) -> str:\n    def is_valid_ipv4(ip):\n        parts = ip.split('.')\n        if len(parts) != 4:\n            return False\n        \n        for part in parts:\n            if not part or len(part) > 3:\n                return False\n            \n            # Check for leading zeros\n            if len(part) > 1 and part[0] == '0':\n                return False\n            \n            # Check if all characters are digits\n            if not part.isdigit():\n                return False\n            \n            # Check range\n            num = int(part)\n            if num < 0 or num > 255:\n                return False\n        \n        return True\n    \n    def is_valid_ipv6(ip):\n        parts = ip.split(':')\n        if len(parts) != 8:\n            return False\n        \n        for part in parts:\n            if not part or len(part) > 4:\n                return False\n            \n            # Check if all characters are valid hex\n            for char in part:\n                if char not in '0123456789abcdefABCDEF':\n                    return False\n        \n        return True\n    \n    if is_valid_ipv4(ip):\n        return \"IPv4\"\n    elif is_valid_ipv6(ip):\n        return \"IPv6\"\n    else:\n        return \"Neither\"", "test": [{"input": ["172.16.254.1"], "output": "IPv4"}, {"input": ["2001:0db8:85a3:0000:0000:8a2e:0370:7334"], "output": "IPv6"}, {"input": ["256.256.256.256"], "output": "Neither"}, {"input": ["192.168.1.1.1"], "output": "Neither"}, {"input": ["192.168.01.1"], "output": "Neither"}, {"input": ["2001:0db8:85a3::8a2e:0370:7334"], "output": "Neither"}, {"input": [""], "output": "Neither"}]}}
{"timestamp_utc": "2025-09-26T10:47:28.301977", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 38, "question": "Merge two dictionaries with integer values by keeping the maximum value for each key.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 27.894400596618652, "response": "You can achieve this by iterating through the items of the second dictionary and comparing values for common keys, while simply adding keys unique to either dictionary.\n\nHere's a Python function to do it:\n\n```python\ndef merge_dicts_max_value(d1: dict, d2: dict) -> dict:\n    \"\"\"\n    Merges two dictionaries with integer values, keeping the maximum\n    value for each common key. Keys unique to either dictionary are\n    included as-is.\n\n    Args:\n        d1: The first dictionary (keys: str, values: int).\n        d2: The second dictionary (keys: str, values: int).\n\n    Returns:\n        A new dictionary representing the merged result.\n    \"\"\"\n    # Start with a copy of d1 to avoid modifying the original d1\n    # and to include all keys from d1 initially.\n    merged_dict = d1.copy()\n\n    # Iterate through the second dictionary\n    for key, value in d2.items():\n        if key in merged_dict:\n            # If the key exists in both dictionaries,\n            # keep the maximum of the two values.\n            merged_dict[key] = max(merged_dict[key], value)\n        else:\n            # If the key exists only in d2, add it directly to the merged_dict.\n            merged_dict[key] = value\n\n    return merged_dict\n\n# --- Example Usage ---\n\ndict1 = {'a': 10, 'b': 20, 'c': 30, 'x': 5}\ndict2 = {'b': 25, 'c': 15, 'd': 40, 'y': 100}\ndict3 = {'a': 5, 'e': 50}\ndict4 = {} # An empty dictionary\n\nprint(f\"Dictionary 1: {dict1}\")\nprint(f\"Dictionary 2: {dict2}\")\n\nmerged_result1 = merge_dicts_max_value(dict1, dict2)\nprint(f\"Merged (dict1, dict2): {merged_result1}\")\n# Expected output: {'a': 10, 'b': 25, 'c': 30, 'x': 5, 'd': 40, 'y': 100}\n# 'b': max(20, 25) -> 25\n# 'c': max(30, 15) -> 30\n\nprint(\"-\" * 30)\n\nprint(f\"Dictionary 1: {dict1}\")\nprint(f\"Dictionary 3: {dict3}\")\nmerged_result2 = merge_dicts_max_value(dict1, dict3)\nprint(f\"Merged (dict1, dict3): {merged_result2}\")\n# Expected output: {'a': 10, 'b': 20, 'c': 30, 'x': 5, 'e': 50}\n# 'a': max(10, 5) -> 10\n\nprint(\"-\" * 30)\n\nprint(f\"Dictionary 1: {dict1}\")\nprint(f\"Dictionary 4 (empty): {dict4}\")\nmerged_result3 = merge_dicts_max_value(dict1, dict4)\nprint(f\"Merged (dict1, dict4): {merged_result3}\")\n# Expected output: {'a': 10, 'b': 20, 'c': 30, 'x': 5} (dict1 unchanged)\n\nprint(\"-\" * 30)\n\nprint(f\"Dictionary 4 (empty): {dict4}\")\nprint(f\"Dictionary 2: {dict2}\")\nmerged_result4 = merge_dicts_max_value(dict4, dict2)\nprint(f\"Merged (dict4, dict2): {merged_result4}\")\n# Expected output: {'b': 25, 'c': 15, 'd': 40, 'y': 100} (dict2 unchanged)\n```\n\n**Explanation:**\n\n1.  **`merged_dict = d1.copy()`**: We start by creating a copy of the first dictionary (`d1`). This ensures two things:\n    *   The original `d1` is not modified.\n    *   All keys and values from `d1` are initially present in our result.\n\n2.  **`for key, value in d2.items():`**: We then iterate through each key-value pair in the second dictionary (`d2`).\n\n3.  **`if key in merged_dict:`**: For each key from `d2`, we check if it already exists in `merged_dict` (which means it was also in `d1`).\n    *   If it does, we use `merged_dict[key] = max(merged_dict[key], value)` to assign the larger of the two values to that key in `merged_dict`.\n\n4.  **`else:`**: If the key from `d2` is *not* in `merged_dict` (meaning it's unique to `d2`), we simply add it to `merged_dict` with its corresponding value: `merged_dict[key] = value`.\n\n5.  **`return merged_dict`**: Finally, the function returns the `merged_dict` containing all keys with their maximum values.", "error": null, "raw_item": {"task_id": "MyBench/dict_merge_max", "prompt": "Merge two dictionaries with integer values by keeping the maximum value for each key.", "entry_point": "merge_max", "canonical_solution": "def merge_max(d1, d2):\n    out = dict(d1)\n    for k,v in d2.items():\n        out[k] = max(out.get(k, v), v)\n    return out", "test": [{"input": [{"a": 1, "b": 5}, {"b": 3, "c": 10}], "output": {"a": 1, "b": 5, "c": 10}}, {"input": [{}, {"x": 7}], "output": {"x": 7}}, {"input": [{"a": 5}, {"a": 5}], "output": {"a": 5}}, {"input": [{"m": -1, "n": 2}, {"m": -5, "o": 10}], "output": {"m": -1, "n": 2, "o": 10}}, {"input": [{}, {}], "output": {}}]}}
{"timestamp_utc": "2025-09-26T10:47:56.656764", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 39, "question": "Invert a dictionary where values may not be unique. Return a new dictionary mapping each value to a list of keys that had that value.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 27.352952003479004, "response": "To invert a dictionary where values may not be unique, we need to create a new dictionary where the original values become the new keys. Since multiple original keys might map to the same original value, the new value associated with each new key will be a list containing all the original keys that pointed to that value.\n\nThe `collections.defaultdict` is very useful for this task, as it automatically creates a default value (in this case, an empty list) for a key if it doesn't already exist when you try to access it.\n\nHere's the Python function to achieve this:\n\n```python\nfrom collections import defaultdict\n\ndef invert_dictionary(original_dict: dict) -> dict:\n    \"\"\"\n    Inverts a dictionary where values may not be unique.\n\n    Returns a new dictionary mapping each original value to a list of original\n    keys that had that value.\n\n    Args:\n        original_dict: The dictionary to invert. Its values must be hashable,\n                       as they will become keys in the new dictionary.\n\n    Returns:\n        A new dictionary with inverted key-value pairs. Each value from the\n        original dictionary becomes a key in the new dictionary, and its\n        corresponding value is a list of all keys from the original dictionary\n        that mapped to it.\n\n    Examples:\n        >>> invert_dictionary({'a': 1, 'b': 2, 'c': 1, 'd': 3})\n        {1: ['a', 'c'], 2: ['b'], 3: ['d']}\n\n        >>> invert_dictionary({'apple': 'fruit', 'banana': 'fruit', 'carrot': 'vegetable'})\n        {'fruit': ['apple', 'banana'], 'vegetable': ['carrot']}\n\n        >>> invert_dictionary({})\n        {}\n\n        >>> invert_dictionary({'one': 1, 'two': 2, 'three': 3})\n        {1: ['one'], 2: ['two'], 3: ['three']}\n\n        >>> invert_dictionary({10: 'A', 20: 'B', 30: 'A'})\n        {'A': [10, 30], 'B': [20]}\n    \"\"\"\n    # Initialize a defaultdict where the default factory creates an empty list\n    inverted_dict = defaultdict(list)\n\n    # Iterate through the original dictionary's key-value pairs\n    for key, value in original_dict.items():\n        # Append the current key to the list associated with the current value.\n        # If 'value' is encountered for the first time, defaultdict(list)\n        # will automatically create an empty list for it before appending.\n        inverted_dict[value].append(key)\n\n    # Convert the defaultdict to a regular dict before returning,\n    # as the problem asks for \"a new dictionary\".\n    return dict(inverted_dict)\n\n```", "error": null, "raw_item": {"task_id": "dict_invert_multival", "prompt": "Invert a dictionary where values may not be unique. Return a new dictionary mapping each value to a list of keys that had that value.", "entry_point": "invert_multival", "canonical_solution": "def invert_multival(d):\n    out={}\n    for k,v in d.items():\n        out.setdefault(v, []).append(k)\n    return out", "test": [{"input": [{"a": 1, "b": 2, "c": 1}], "output": {"1": ["a", "c"], "2": ["b"]}}, {"input": [{}], "output": {}}, {"input": [{"x": "hi", "y": "hi", "z": "bye"}], "output": {"hi": ["x", "y"], "bye": ["z"]}}, {"input": [{"p": 0, "q": 0, "r": 0}], "output": {"0": ["p", "q", "r"]}}, {"input": [{"k": 42}], "output": {"42": ["k"]}}]}}
{"timestamp_utc": "2025-09-26T10:48:29.059155", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 40, "question": "Return True if an integer has even parity (even number of 1 bits in binary), else False.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 31.39920926094055, "response": "To determine if an integer has an even parity (an even number of 1 bits in its binary representation), you can use Python's built-in `int.bit_count()` method (available from Python 3.10+).\n\n```python\ndef has_even_parity(n: int) -> bool:\n    \"\"\"\n    Checks if an integer has an even number of set (1) bits in its binary representation.\n\n    Args:\n        n: The integer to check.\n\n    Returns:\n        True if the integer has an even number of 1 bits, False otherwise.\n\n    Note:\n    - For non-negative integers, this counts the 1s in their standard binary form.\n    - For negative integers, Python's `int.bit_count()` is used. This method\n      counts the number of set bits in the *two's complement representation*.\n      Since Python integers have arbitrary precision, a negative number like -1\n      conceptually has an infinite number of leading 1s, which `bit_count()`\n      reflects as a very large number (e.g., `sys.maxsize + 1`). This large number\n      will generally result in an even parity (True) for many negative numbers.\n      If a fixed-width interpretation (e.g., 32-bit two's complement) is desired\n      for negative numbers, additional logic would be required.\n    \"\"\"\n    # int.bit_count() returns the number of set bits (1s) in the integer's binary representation.\n    num_set_bits = n.bit_count()\n\n    # Check if the count of set bits is even.\n    return num_set_bits % 2 == 0\n\n# --- Examples ---\n\n# Non-negative integers:\nprint(f\"Number: 0 (binary: 0), Parity: {has_even_parity(0)}\")          # 0 ones -> True\nprint(f\"Number: 1 (binary: 1), Parity: {has_even_parity(1)}\")          # 1 one -> False\nprint(f\"Number: 2 (binary: 10), Parity: {has_even_parity(2)}\")         # 1 one -> False\nprint(f\"Number: 3 (binary: 11), Parity: {has_even_parity(3)}\")         # 2 ones -> True\nprint(f\"Number: 4 (binary: 100), Parity: {has_even_parity(4)}\")        # 1 one -> False\nprint(f\"Number: 5 (binary: 101), Parity: {has_even_parity(5)}\")        # 2 ones -> True\nprint(f\"Number: 6 (binary: 110), Parity: {has_even_parity(6)}\")        # 2 ones -> True\nprint(f\"Number: 7 (binary: 111), Parity: {has_even_parity(7)}\")        # 3 ones -> False\nprint(f\"Number: 10 (binary: 1010), Parity: {has_even_parity(10)}\")     # 2 ones -> True\n\n# Negative integers (behavior based on Python's arbitrary-precision two's complement):\nprint(f\"Number: -1, Parity: {has_even_parity(-1)}\") # conceptually infinite 1s -> True\nprint(f\"Number: -2, Parity: {has_even_parity(-2)}\") # conceptually infinite 1s, except for one 0 -> False\nprint(f\"Number: -3, Parity: {has_even_parity(-3)}\") # conceptually infinite 1s, except for two 0s -> True\n```\n\n### Explanation:\n\n1.  **`n.bit_count()`**: This is the most straightforward and efficient way in modern Python (3.10+) to count the number of set bits (1s) in an integer's binary representation.\n2.  **`% 2 == 0`**: After getting the count of set bits, we simply check if that count is divisible by 2. If it is, the parity is even, and the function returns `True`. Otherwise, it returns `False`.\n\n### Alternative for older Python versions or without `bit_count()`:\n\nIf you're using an older Python version or want to implement it using bitwise operations directly:\n\n```python\ndef has_even_parity_bitwise(n: int) -> bool:\n    \"\"\"\n    Checks if an integer has an even number of set (1) bits using bitwise operations.\n    This version handles negative numbers by taking their absolute value, as parity\n    is most commonly discussed for non-negative numbers or fixed-width representations.\n    \"\"\"\n    # For common parity definitions, especially in contexts like data transmission,\n    # negative numbers are often treated by their absolute value, or within a\n    # fixed-width two's complement. This example uses absolute value for simplicity.\n    if n < 0:\n        n = abs(n)\n\n    count = 0\n    # Brian Kernighan's algorithm:\n    # This loop runs only as many times as there are set bits,\n    # making it very efficient.\n    while n > 0:\n        n &= (n - 1) # This operation clears the rightmost set bit\n        count += 1\n    return count % 2 == 0\n\n# --- Examples with the bitwise version ---\nprint(\"\\n--- Bitwise Version Examples ---\")\nprint(f\"Number: 0, Parity: {has_even_parity_bitwise(0)}\")\nprint(f\"Number: 3, Parity: {has_even_parity_bitwise(3)}\")\nprint(f\"Number: 7, Parity: {has_even_parity_bitwise(7)}\")\nprint(f\"Number: -3 (abs: 3), Parity: {has_even_parity_bitwise(-3)}\")\n```", "error": null, "raw_item": {"task_id": "bitwise_parity", "prompt": "Return True if an integer has even parity (even number of 1 bits in binary), else False.", "entry_point": "even_parity", "canonical_solution": "def even_parity(n):\n    c=0\n    while n:\n        n&=n-1\n        c^=1\n    return c==0", "test": [{"input": [3], "output": false}, {"input": [5], "output": true}, {"input": [0], "output": true}, {"input": [15], "output": true}, {"input": [16], "output": false}, {"input": [255], "output": true}]}}
{"timestamp_utc": "2025-09-26T10:48:42.379854", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 41, "question": "Swap two integers without using a temporary variable, using bitwise XOR. Return the swapped pair as a tuple. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 12.317669868469238, "response": "```python\ndef swap_bitwise_xor(a, b):\n    a = a ^ b\n    b = a ^ b\n    a = a ^ b\n    return (a, b)\n```", "error": null, "raw_item": {"task_id": "bitwise_swap", "prompt": "Swap two integers without using a temporary variable, using bitwise XOR. Return the swapped pair as a tuple. Return only the Python function code with no explanations.", "entry_point": "swap_xor", "canonical_solution": "def swap_xor(a,b):\n    a=a^b; b=a^b; a=a^b\n    return (a,b)", "test": [{"input": [2, 5], "output": [5, 2]}, {"input": [0, 7], "output": [7, 0]}, {"input": [-3, 9], "output": [9, -3]}, {"input": [42, 42], "output": [42, 42]}, {"input": [1000000, 123456], "output": [123456, 1000000]}]}}
{"timestamp_utc": "2025-09-26T10:48:44.626369", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 42, "question": "Compute factorial of n recursively. Assume n >= 0. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 1.2431530952453613, "response": "```python\ndef factorial_recursive(n):\n    if n == 0:\n        return 1\n    else:\n        return n * factorial_recursive(n - 1)\n```", "error": null, "raw_item": {"task_id": "recursion_factorial", "prompt": "Compute factorial of n recursively. Assume n >= 0. Return only the Python function code with no explanations.", "entry_point": "factorial", "canonical_solution": "def factorial(n):\n    return 1 if n<=1 else n*factorial(n-1)", "test": [{"input": [0], "output": 1}, {"input": [1], "output": 1}, {"input": [5], "output": 120}, {"input": [10], "output": 3628800}, {"input": [3], "output": 6}]}}
{"timestamp_utc": "2025-09-26T10:48:48.921513", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 43, "question": "Return the BFS traversal order of a graph represented as adjacency list dict, starting from given node. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 3.2938411235809326, "response": "```python\nimport collections\n\ndef bfs_traversal(graph, start_node):\n    \"\"\"\n    Performs a Breadth-First Search (BFS) traversal on a graph.\n\n    Args:\n        graph (dict): The graph represented as an adjacency list.\n                      Keys are nodes, values are lists of neighbors.\n        start_node: The starting node for the BFS traversal.\n\n    Returns:\n        list: A list of nodes in the order they were visited during BFS.\n    \"\"\"\n    if not graph or start_node not in graph:\n        return []\n\n    traversal_order = []\n    queue = collections.deque()\n    visited = set()\n\n    queue.append(start_node)\n    visited.add(start_node)\n\n    while queue:\n        current_node = queue.popleft()\n        traversal_order.append(current_node)\n\n        for neighbor in graph.get(current_node, []):\n            if neighbor not in visited:\n                visited.add(neighbor)\n                queue.append(neighbor)\n\n    return traversal_order\n```", "error": null, "raw_item": {"task_id": "graph_bfs_order", "prompt": "Return the BFS traversal order of a graph represented as adjacency list dict, starting from given node. Return only the Python function code with no explanations.", "entry_point": "bfs_order", "canonical_solution": "from collections import deque\n\ndef bfs_order(graph,start):\n    seen={start}; q=deque([start]); order=[]\n    while q:\n        u=q.popleft(); order.append(u)\n        for v in sorted(graph.get(u,[])):\n            if v not in seen:\n                seen.add(v); q.append(v)\n    return order", "test": [{"input": [{"A": ["B", "C"], "B": ["D"], "C": [], "D": []}, "A"], "output": ["A", "B", "C", "D"]}, {"input": [{"1": ["2"], "2": ["3"], "3": []}, "1"], "output": ["1", "2", "3"]}, {"input": [{"x": []}, "x"], "output": ["x"]}, {"input": [{"a": ["b"], "b": ["a"]}, "a"], "output": ["a", "b"]}, {"input": [{"m": ["n", "o"], "n": [], "o": []}, "m"], "output": ["m", "n", "o"]}]}}
{"timestamp_utc": "2025-09-26T10:48:52.390201", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 44, "question": "Given a CSV string with header 'name,value' and multiple rows, return the sum of the 'value' column as int. Assume comma-separated, no quotes. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 2.465081214904785, "response": "```python\ndef sum_value_column(csv_string: str) -> int:\n    total_sum = 0\n    lines = csv_string.strip().split('\\n')\n    # Skip header\n    for line in lines[1:]:\n        if line.strip():  # Ensure line is not empty\n            parts = line.split(',')\n            if len(parts) > 1:\n                try:\n                    total_sum += int(parts[1].strip())\n                except ValueError:\n                    # Handle cases where value might not be an integer,\n                    # though prompt implies it should be.\n                    # For this problem, we'll assume valid integers.\n                    pass\n    return total_sum\n```", "error": null, "raw_item": {"task_id": "parsing_csv_sum", "prompt": "Given a CSV string with header 'name,value' and multiple rows, return the sum of the 'value' column as int. Assume comma-separated, no quotes. Return only the Python function code with no explanations.", "entry_point": "csv_sum", "canonical_solution": "def csv_sum(text):\n    lines=text.strip().split('\\n')\n    if len(lines) <= 1:\n        return 0\n    total=0\n    for line in lines[1:]:\n        if line.strip():\n            name,val=line.split(',')\n            total+=int(val)\n    return total", "test": [{"input": ["name,value\\na,3\\nb,7\\nc,10"], "output": 20}, {"input": ["name,value\\n"], "output": 0}, {"input": ["name,value\\nfoo,0\\nbar,0"], "output": 0}, {"input": ["name,value\\nx,100"], "output": 100}, {"input": ["name,value\\na,1\\nb,2\\nc,3\\nd,4"], "output": 10}]}}
{"timestamp_utc": "2025-09-26T10:48:55.154904", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 45, "question": "Extract all sequences of digits from a string using regex and return them as a list of strings. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 1.763296127319336, "response": "```python\nimport re\n\ndef extract_digit_sequences(text):\n    \"\"\"\n    Extracts all sequences of digits from a string.\n\n    Args:\n        text (str): The input string.\n\n    Returns:\n        list: A list of strings, where each string is a sequence of digits.\n    \"\"\"\n    return re.findall(r'\\d+', text)\n```", "error": null, "raw_item": {"task_id": "parsing_regex_digits", "prompt": "Extract all sequences of digits from a string using regex and return them as a list of strings. Return only the Python function code with no explanations.", "entry_point": "extract_digits", "canonical_solution": "import re\n\ndef extract_digits(s):\n    return re.findall(r'\\d+', s)", "test": [{"input": ["abc123de45f6"], "output": ["123", "45", "6"]}, {"input": ["no digits here"], "output": []}, {"input": ["2025year"], "output": ["2025"]}, {"input": ["a1b2c3d4"], "output": ["1", "2", "3", "4"]}, {"input": ["007bond"], "output": ["007"]}]}}
{"timestamp_utc": "2025-09-26T10:48:58.766299", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 46, "question": "Return the length of the longest increasing subsequence (LIS) in a list of integers. O(n^2) solution is fine. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 2.609653949737549, "response": "```python\ndef lengthOfLIS(nums: list[int]) -> int:\n    if not nums:\n        return 0\n\n    n = len(nums)\n    dp = [1] * n  # dp[i] stores the length of the LIS ending at nums[i]\n\n    for i in range(1, n):\n        for j in range(i):\n            if nums[i] > nums[j]:\n                dp[i] = max(dp[i], dp[j] + 1)\n\n    return max(dp)\n```", "error": null, "raw_item": {"task_id": "algorithms_longest_increasing", "prompt": "Return the length of the longest increasing subsequence (LIS) in a list of integers. O(n^2) solution is fine. Return only the Python function code with no explanations.", "entry_point": "lis_length", "canonical_solution": "def lis_length(nums):\n    if not nums: return 0\n    dp=[1]*len(nums)\n    for i in range(len(nums)):\n        for j in range(i):\n            if nums[j]<nums[i]:\n                dp[i]=max(dp[i],dp[j]+1)\n    return max(dp)", "test": [{"input": [[10, 9, 2, 5, 3, 7, 101, 18]], "output": 4}, {"input": [[1, 2, 3, 4, 5]], "output": 5}, {"input": [[5, 4, 3, 2, 1]], "output": 1}, {"input": [[]], "output": 0}, {"input": [[2, 2, 2]], "output": 1}]}}
{"timestamp_utc": "2025-09-26T10:49:22.693693", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 47, "question": "0/1 Knapsack: given weights, values, and capacity W, return the maximum achievable value. Use DP. weights and values are equal length. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 22.92485809326172, "response": "```python\ndef knapsack_01(weights, values, capacity):\n    n = len(weights)\n    \n    # dp[w] will store the maximum value that can be achieved with a knapsack\n    # of capacity 'w' using the items considered so far.\n    dp = [0] * (capacity + 1)\n\n    # Iterate through each item\n    for i in range(n):\n        current_weight = weights[i]\n        current_value = values[i]\n\n        # Iterate through the knapsack capacity from right to left.\n        # This ensures that when we compute dp[w], the value dp[w - current_weight]\n        # corresponds to the state *before* the current item 'i' was considered.\n        # This prevents an item from being chosen multiple times (0/1 property).\n        for w in range(capacity, current_weight - 1, -1):\n            # Option 1: Do not include the current item.\n            # The value remains dp[w] (from the previous iteration/items).\n            \n            # Option 2: Include the current item.\n            # Value would be current_value + dp[w - current_weight].\n            # dp[w - current_weight] represents the max value for the remaining capacity\n            # after including the current item, using items *before* the current one.\n            dp[w] = max(dp[w], current_value + dp[w - current_weight])\n            \n    # The maximum value achievable with the given items and capacity W\n    return dp[capacity]\n\n```", "error": null, "raw_item": {"task_id": "algorithms_knapsack01", "prompt": "0/1 Knapsack: given weights, values, and capacity W, return the maximum achievable value. Use DP. weights and values are equal length. Return only the Python function code with no explanations.", "entry_point": "knapsack01", "canonical_solution": "def knapsack01(weights, values, W):\n    n=len(weights)\n    dp=[[0]*(W+1) for _ in range(n+1)]\n    for i in range(1,n+1):\n        for w in range(W+1):\n            dp[i][w]=dp[i-1][w]\n            if weights[i-1]<=w:\n                dp[i][w]=max(dp[i][w], values[i-1]+dp[i-1][w-weights[i-1]])\n    return dp[n][W]", "test": [{"input": [[2, 3, 4], [4, 5, 6], 5], "output": 9}, {"input": [[1, 2, 3], [6, 10, 12], 5], "output": 22}, {"input": [[5], [10], 5], "output": 10}, {"input": [[5], [10], 4], "output": 0}, {"input": [[], [], 10], "output": 0}]}}
{"timestamp_utc": "2025-09-26T10:49:35.881616", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 48, "question": "Write parse_csv_numbers(text) that parses a CSV string of integers separated by commas and newlines. Return a 2D list of integers. Ignore empty lines. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 12.184453964233398, "response": "```python\ndef parse_csv_numbers(text):\n    result = []\n    lines = text.split('\\n')\n    for line in lines:\n        stripped_line = line.strip()\n        if not stripped_line:\n            continue\n        \n        row = []\n        numbers_str = stripped_line.split(',')\n        for num_str in numbers_str:\n            row.append(int(num_str.strip()))\n        result.append(row)\n    return result\n```", "error": null, "raw_item": {"task_id": "custom_parse_csv_numbers", "prompt": "Write parse_csv_numbers(text) that parses a CSV string of integers separated by commas and newlines. Return a 2D list of integers. Ignore empty lines. Return only the Python function code with no explanations.", "entry_point": "parse_csv_numbers", "canonical_solution": "def parse_csv_numbers(text: str) -> list[list[int]]:\n    rows = []\n    for line in text.strip().splitlines():\n        if not line.strip():\n            continue\n        row = [int(x.strip()) for x in line.split(',') if x.strip()]\n        rows.append(row)\n    return rows", "test": [{"input": ["1,2,3\n4,5,6"], "output": [[1, 2, 3], [4, 5, 6]]}, {"input": ["10,20\n30\n\n40,50"], "output": [[10, 20], [30], [40, 50]]}, {"input": ["   7 , 8 ,9  "], "output": [[7, 8, 9]]}, {"input": [""], "output": []}]}}
{"timestamp_utc": "2025-09-26T10:49:41.458115", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 49, "question": "Write normalize_json_keys(obj) that recursively converts all dictionary keys in a JSON-like object to lowercase strings. Works for nested dicts and lists. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 4.574950218200684, "response": "```python\ndef normalize_json_keys(obj):\n    \"\"\"\n    Recursively converts all dictionary keys in a JSON-like object to lowercase strings.\n\n    Args:\n        obj: The JSON-like object (dict, list, string, number, boolean, None).\n\n    Returns:\n        The object with all dictionary keys normalized to lowercase.\n    \"\"\"\n    if isinstance(obj, dict):\n        return {\n            (key.lower() if isinstance(key, str) else key): normalize_json_keys(value)\n            for key, value in obj.items()\n        }\n    elif isinstance(obj, list):\n        return [normalize_json_keys(elem) for elem in obj]\n    else:\n        return obj\n```", "error": null, "raw_item": {"task_id": "custom_normalize_json_keys", "prompt": "Write normalize_json_keys(obj) that recursively converts all dictionary keys in a JSON-like object to lowercase strings. Works for nested dicts and lists. Return only the Python function code with no explanations.", "entry_point": "normalize_json_keys", "canonical_solution": "def normalize_json_keys(obj):\n    if isinstance(obj, dict):\n        return {str(k).lower(): normalize_json_keys(v) for k, v in obj.items()}\n    if isinstance(obj, list):\n        return [normalize_json_keys(x) for x in obj]\n    return obj", "test": [{"input": [{"Name": "Alice", "AGE": 30}], "output": {"name": "Alice", "age": 30}}, {"input": [[{"X": 1}, {"Y": 2}]], "output": [{"x": 1}, {"y": 2}]}, {"input": [{"Nested": {"KEY": 5}}], "output": {"nested": {"key": 5}}}, {"input": [123], "output": 123}]}}
{"timestamp_utc": "2025-09-26T10:50:03.593235", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 50, "question": "Write format_duration(seconds) that converts an integer number of seconds into a human-readable string using years, days, hours, minutes, and seconds. Skip units that are zero. Use plural form when needed. Example: 3661 → '1 hour, 1 minute, 1 second'. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 21.133970022201538, "response": "```python\ndef format_duration(seconds):\n    if seconds == 0:\n        return \"now\"\n\n    units = [\n        (31536000, \"year\"),\n        (86400, \"day\"),\n        (3600, \"hour\"),\n        (60, \"minute\"),\n        (1, \"second\")\n    ]\n\n    parts = []\n    for duration_in_seconds, unit_name in units:\n        if seconds >= duration_in_seconds:\n            value = seconds // duration_in_seconds\n            seconds %= duration_in_seconds\n            \n            s = \"\" if value == 1 else \"s\"\n            parts.append(f\"{value} {unit_name}{s}\")\n    \n    return \", \".join(parts)\n```", "error": null, "raw_item": {"task_id": "custom_format_duration", "prompt": "Write format_duration(seconds) that converts an integer number of seconds into a human-readable string using years, days, hours, minutes, and seconds. Skip units that are zero. Use plural form when needed. Example: 3661 → '1 hour, 1 minute, 1 second'. Return only the Python function code with no explanations.", "entry_point": "format_duration", "canonical_solution": "def format_duration(seconds: int) -> str:\n    units = [(\"year\", 365*24*3600), (\"day\", 24*3600), (\"hour\", 3600), (\"minute\", 60), (\"second\", 1)]\n    parts = []\n    for name, length in units:\n        if seconds >= length:\n            count, seconds = divmod(seconds, length)\n            parts.append(f\"{count} {name}{'s' if count != 1 else ''}\")\n    return \", \".join(parts) if parts else \"0 seconds\"", "test": [{"input": [0], "output": "0 seconds"}, {"input": [62], "output": "1 minute, 2 seconds"}, {"input": [3661], "output": "1 hour, 1 minute, 1 second"}, {"input": [31536000], "output": "1 year"}, {"input": [31556926], "output": "1 year, 6 hours, 9 minutes, 26 seconds"}]}}
{"timestamp_utc": "2025-09-26T10:50:23.061029", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 51, "question": "Write parse_key_value_config(text) that parses a configuration string with lines of the form 'key=value'. Ignore blank lines and lines starting with '#'. Return a dictionary with string keys and values converted to int if possible, else string. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 18.464576959609985, "response": "```python\ndef parse_key_value_config(text):\n    config = {}\n    for line in text.splitlines():\n        stripped_line = line.strip()\n        if not stripped_line or stripped_line.startswith('#'):\n            continue\n\n        if '=' in stripped_line:\n            key, value_str = stripped_line.split('=', 1)\n            key = key.strip()\n            value_str = value_str.strip()\n\n            try:\n                value = int(value_str)\n            except ValueError:\n                value = value_str\n            \n            config[key] = value\n    return config\n```", "error": null, "raw_item": {"task_id": "custom_parse_key_value_config", "prompt": "Write parse_key_value_config(text) that parses a configuration string with lines of the form 'key=value'. Ignore blank lines and lines starting with '#'. Return a dictionary with string keys and values converted to int if possible, else string. Return only the Python function code with no explanations.", "entry_point": "parse_key_value_config", "canonical_solution": "def parse_key_value_config(text: str) -> dict:\n    result = {}\n    for line in text.splitlines():\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        if '=' in line:\n            k,v = line.split('=',1)\n            v = v.strip()\n            if v.isdigit():\n                result[k.strip()] = int(v)\n            else:\n                result[k.strip()] = v\n    return result", "test": [{"input": ["a=1\nb=2\nc=hello"], "output": {"a": 1, "b": 2, "c": "hello"}}, {"input": ["#comment\nx=42\ny=text"], "output": {"x": 42, "y": "text"}}, {"input": [""], "output": {}}]}}
{"timestamp_utc": "2025-09-26T10:50:52.216081", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 52, "question": "Write pretty_print_matrix(matrix) that formats a 2D list of integers into a string where each row is space-separated and rows are separated by newlines. Columns should be aligned to the maximum width of the largest number. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 28.1513569355011, "response": "```python\ndef pretty_print_matrix(matrix):\n    if not matrix:\n        return \"\"\n\n    # Determine the number of columns.\n    # Assume all rows have the same number of columns as the first row.\n    num_cols = len(matrix[0])\n\n    # If the matrix has no columns (e.g., [[]] or [[],[]]), handle this case\n    # by letting the subsequent logic form empty strings for rows.\n    if num_cols == 0:\n        return \"\\n\".join([\"\" for _ in matrix])\n\n\n    # Calculate the maximum width needed for each column\n    max_widths = [0] * num_cols\n    for row in matrix:\n        for c_idx, element in enumerate(row):\n            max_widths[c_idx] = max(max_widths[c_idx], len(str(element)))\n\n    # Format each row\n    formatted_rows = []\n    for row in matrix:\n        formatted_row_elements = []\n        for c_idx, element in enumerate(row):\n            # Right-align each element within its determined column width\n            formatted_row_elements.append(f\"{str(element):>{max_widths[c_idx]}}\")\n        formatted_rows.append(\" \".join(formatted_row_elements))\n\n    # Join formatted rows with newlines\n    return \"\\n\".join(formatted_rows)\n```", "error": null, "raw_item": {"task_id": "custom_pretty_print_matrix", "prompt": "Write pretty_print_matrix(matrix) that formats a 2D list of integers into a string where each row is space-separated and rows are separated by newlines. Columns should be aligned to the maximum width of the largest number. Return only the Python function code with no explanations.", "entry_point": "pretty_print_matrix", "canonical_solution": "def pretty_print_matrix(matrix: list[list[int]]) -> str:\n    if not matrix:\n        return ''\n    col_widths = [max(len(str(row[i])) for row in matrix) for i in range(len(matrix[0]))]\n    lines = []\n    for row in matrix:\n        line = ' '.join(str(val).rjust(col_widths[i]) for i,val in enumerate(row))\n        lines.append(line)\n    return '\\n'.join(lines)", "test": [{"input": [[[1, 20], [300, 4]]], "output": "  1 20\n300  4"}, {"input": [[[5]]], "output": "5"}, {"input": [[]], "output": ""}]}}
{"timestamp_utc": "2025-09-26T10:51:13.689911", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 53, "question": "Write unique_permutations(s) that returns all distinct permutations of string s in lexicographic order. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 20.472209215164185, "response": "```python\nimport itertools\n\ndef unique_permutations(s: str) -> list[str]:\n    \"\"\"\n    Returns all distinct permutations of string s in lexicographic order.\n    \"\"\"\n    # Convert the string to a list of characters for itertools.permutations\n    s_chars = list(s)\n    \n    # Generate all permutations (including duplicates if s has repeating characters)\n    # and join them into strings.\n    all_perms = [\"\".join(p) for p in itertools.permutations(s_chars)]\n    \n    # Use a set to get only the distinct permutations\n    distinct_perms = set(all_perms)\n    \n    # Convert the set back to a list and sort it lexicographically\n    result = sorted(list(distinct_perms))\n    \n    return result\n```", "error": null, "raw_item": {"task_id": "custom_unique_permutations", "prompt": "Write unique_permutations(s) that returns all distinct permutations of string s in lexicographic order. Return only the Python function code with no explanations.", "entry_point": "unique_permutations", "canonical_solution": "def unique_permutations(s: str) -> list[str]:\n    from itertools import permutations\n    return sorted(set(''.join(p) for p in permutations(s)))", "test": [{"input": ["aab"], "output": ["aab", "aba", "baa"]}, {"input": ["abc"], "output": ["abc", "acb", "bac", "bca", "cab", "cba"]}, {"input": ["x"], "output": ["x"]}]}}
{"timestamp_utc": "2025-09-26T10:51:33.648264", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 54, "question": "Write format_prime_factors(n) that returns the prime factorization of integer n as a string in the form 'p1^a1 * p2^a2 ...'. If exponent is 1, omit the '^1'. Example: 60 → '2^2 * 3 * 5'. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 18.955318927764893, "response": "```python\ndef format_prime_factors(n):\n    if n == 1:\n        return ''\n\n    factors = {}\n    d = 2\n    temp_n = n\n    while d * d <= temp_n:\n        while temp_n % d == 0:\n            factors[d] = factors.get(d, 0) + 1\n            temp_n //= d\n        d += 1\n    if temp_n > 1:\n        factors[temp_n] = factors.get(temp_n, 0) + 1\n\n    parts = []\n    # Sort factors by prime number for consistent output\n    sorted_factors = sorted(factors.items())\n\n    for prime, count in sorted_factors:\n        if count == 1:\n            parts.append(str(prime))\n        else:\n            parts.append(f\"{prime}^{count}\")\n\n    return ' * '.join(parts)\n```", "error": null, "raw_item": {"task_id": "custom_format_prime_factors", "prompt": "Write format_prime_factors(n) that returns the prime factorization of integer n as a string in the form 'p1^a1 * p2^a2 ...'. If exponent is 1, omit the '^1'. Example: 60 → '2^2 * 3 * 5'. Return only the Python function code with no explanations.", "entry_point": "format_prime_factors", "canonical_solution": "def format_prime_factors(n: int) -> str:\n    factors = []\n    d = 2\n    while d*d <= n:\n        count = 0\n        while n % d == 0:\n            n //= d\n            count += 1\n        if count:\n            factors.append(f\"{d}^{count}\" if count>1 else str(d))\n        d += 1\n    if n > 1:\n        factors.append(str(n))\n    return ' * '.join(factors)", "test": [{"input": [60], "output": "2^2 * 3 * 5"}, {"input": [13], "output": "13"}, {"input": [1024], "output": "2^10"}]}}
{"timestamp_utc": "2025-09-26T10:52:28.495505", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 55, "question": "Write validate_expression(expr) that checks if a string is a valid arithmetic expression containing only digits, +, -, *, /, parentheses, and spaces. Return True if valid, else False. Parentheses must be balanced and no invalid sequences allowed (e.g. '*/', '++', empty parentheses). Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 53.84578609466553, "response": "```python\ndef validate_expression(expr):\n    # 1. Preprocessing: Remove all spaces\n    cleaned_expr = expr.replace(' ', '')\n\n    # 2. Basic checks for empty string\n    if not cleaned_expr:\n        return False\n\n    # Define allowed characters and character types for easier checks\n    allowed_chars = set(\"0123456789+-*/()\")\n    operators = set(\"+-*/\")\n    binary_operators = set(\"*/\") # Operators that are more restrictive\n    digits = set(\"0123456789\")\n\n    # 3. Character check: Ensure all characters are allowed\n    for char in cleaned_expr:\n        if char not in allowed_chars:\n            return False\n\n    # 4. Parentheses Balance and Empty Parentheses check\n    balance = 0\n    for i, char in enumerate(cleaned_expr):\n        if char == '(':\n            balance += 1\n            # Check for empty parentheses \"()\"\n            if i + 1 < len(cleaned_expr) and cleaned_expr[i+1] == ')':\n                return False\n        elif char == ')':\n            balance -= 1\n        \n        # Balance should never be negative\n        if balance < 0:\n            return False\n    \n    # Final check for balance\n    if balance != 0:\n        return False\n\n    # 5. Start/End Character checks\n    # Cannot start with '*', '/', ')'\n    if cleaned_expr[0] in binary_operators or cleaned_expr[0] == ')':\n        return False\n    # Cannot end with any operator or '('\n    if cleaned_expr[-1] in operators or cleaned_expr[-1] == '(':\n        return False\n\n    # 6.", "error": null, "raw_item": {"task_id": "custom_validate_expression", "prompt": "Write validate_expression(expr) that checks if a string is a valid arithmetic expression containing only digits, +, -, *, /, parentheses, and spaces. Return True if valid, else False. Parentheses must be balanced and no invalid sequences allowed (e.g. '*/', '++', empty parentheses). Return only the Python function code with no explanations.", "entry_point": "validate_expression", "canonical_solution": "import re\ndef validate_expression(expr: str) -> bool:\n    expr = expr.strip()\n    if not expr:\n        return False\n    # invalid sequences\n    if re.search(r'[+*/-]{2,}', expr):\n        return False\n    if re.search(r'\\(\\)', expr):\n        return False\n    # parentheses balance\n    stack = []\n    for c in expr:\n        if c == '(':\n            stack.append(c)\n        elif c == ')':\n            if not stack:\n                return False\n            stack.pop()\n    if stack:\n        return False\n    # final safety: try eval\n    try:\n        eval(expr, {\"__builtins__\":None}, {})\n    except:\n        return False\n    return True", "test": [{"input": ["1+2*(3-4)"], "output": true}, {"input": ["(5+6"], "output": false}, {"input": ["1++2"], "output": false}, {"input": ["( )"], "output": false}, {"input": ["10/2-3"], "output": true}]}}
{"timestamp_utc": "2025-09-26T10:52:42.304802", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 56, "question": "Write parse_roman(s) that converts a valid Roman numeral string into an integer. Supports numerals up to 3999 (MMMCMXCIX). Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-flash", "region": null, "success": true, "response_time": 12.806596040725708, "response": "```python\ndef parse_roman(s: str) -> int:\n    roman_map = {\n        'I': 1, 'V': 5, 'X': 10, 'L': 50,\n        'C': 100, 'D': 500, 'M': 1000\n    }\n    total = 0\n    n = len(s)\n\n    for i in range(n):\n        current_value = roman_map[s[i]]\n        if i + 1 < n and current_value < roman_map[s[i+1]]:\n            total -= current_value\n        else:\n            total += current_value\n    return total\n```", "error": null, "raw_item": {"task_id": "custom_parse_roman", "prompt": "Write parse_roman(s) that converts a valid Roman numeral string into an integer. Supports numerals up to 3999 (MMMCMXCIX). Return only the Python function code with no explanations.", "entry_point": "parse_roman", "canonical_solution": "def parse_roman(s: str) -> int:\n    values = {\"I\":1, \"V\":5, \"X\":10, \"L\":50, \"C\":100, \"D\":500, \"M\":1000}\n    total = 0\n    i = 0\n    while i < len(s):\n        if i+1 < len(s) and values[s[i]] < values[s[i+1]]:\n            total += values[s[i+1]] - values[s[i]]\n            i += 2\n        else:\n            total += values[s[i]]\n            i += 1\n    return total", "test": [{"input": ["III"], "output": 3}, {"input": ["IX"], "output": 9}, {"input": ["LVIII"], "output": 58}, {"input": ["MCMXCIV"], "output": 1994}, {"input": ["MMMCMXCIX"], "output": 3999}]}}
