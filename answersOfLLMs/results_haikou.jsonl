{"timestamp_utc": "2025-09-16T06:24:01.175735", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 0, "question": "Write find_balanced_sublist(arr) that returns the longest even-length contiguous sublist where sum of first half equals sum of second half. Return empty list if none exists.\n\nReturn only the Python function code with no explanations, comments, or markdown formatting.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 3.4850270748138428, "response": "def find_balanced_sublist(arr):\n    max_length = 0\n    result = []\n    \n    for start in range(len(arr)):\n        for end in range(start + 1, len(arr) + 1):\n            sublist = arr[start:end]\n            \n            if len(sublist) % 2 == 0:\n                mid = len(sublist) // 2\n                first_half_sum = sum(sublist[:mid])\n                second_half_sum = sum(sublist[mid:])\n                \n                if first_half_sum == second_half_sum and len(sublist) > max_length:\n                    max_length = len(sublist)\n                    result = sublist\n    \n    return result", "error": null, "raw_item": {"task_id": "custom_find_balanced_sublist", "prompt": "Write find_balanced_sublist(arr) that returns the longest even-length contiguous sublist where sum of first half equals sum of second half. Return empty list if none exists.\n\nReturn only the Python function code with no explanations, comments, or markdown formatting.", "entry_point": "find_balanced_sublist", "canonical_solution": "def find_balanced_sublist(arr: list[int]) -> list[int]:\n    n = len(arr)\n    for length in range(n, 1, -1):\n        if length % 2 != 0:\n            continue\n        for start in range(n - length + 1):\n            sub = arr[start:start+length]\n            half = length // 2\n            if sum(sub[:half]) == sum(sub[half:]):\n                return sub\n    return []", "test": [{"input": [[1, 2, 3, 3, 2, 1]], "output": [1, 2, 3, 3, 2, 1]}, {"input": [[5, 1, 2, 1, 5]], "output": []}, {"input": [[1, 1, 1, 1]], "output": [1, 1, 1, 1]}, {"input": [[1, 2, 3]], "output": []}, {"input": [[]], "output": []}, {"input": [[3, 0, 3, 0, 3]], "output": [3, 0, 3, 0]}, {"input": [[2, 1, 1, 2, 3, 4]], "output": [2, 1, 1, 2]}, {"input": [[1, 5, 3, 7]], "output": []}, {"input": [[0, 0, 0, 0]], "output": [0, 0, 0, 0]}]}}
{"timestamp_utc": "2025-09-16T06:24:04.721267", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 1, "question": "Write merge_by_priority(items_a, items_b) that merges two lists of (id, priority) pairs. Keep highest priority for each unique id. Return sorted by priority descending. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.5434176921844482, "response": "def merge_by_priority(items_a, items_b):\n    merged = {}\n    for item_id, priority in items_a + items_b:\n        if item_id not in merged or priority > merged[item_id]:\n            merged[item_id] = priority\n    \n    return sorted(merged.items(), key=lambda x: x[1], reverse=True)", "error": null, "raw_item": {"task_id": "custom_merge_by_priority", "prompt": "Write merge_by_priority(items_a, items_b) that merges two lists of (id, priority) pairs. Keep highest priority for each unique id. Return sorted by priority descending. Return only the Python function code with no explanations.", "entry_point": "merge_by_priority", "canonical_solution": "def merge_by_priority(items_a: list[tuple[str, int]], items_b: list[tuple[str, int]]) -> list[tuple[str, int]]:\n    combined = items_a + items_b\n    best = {}\n    for id, priority in combined:\n        if id not in best or priority > best[id]:\n            best[id] = priority\n    return sorted(best.items(), key=lambda x: -x[1])", "test": [{"input": [[["item1", 2], ["item2", 5]], [["item2", 3], ["item3", 4]]], "output": [["item2", 5], ["item3", 4], ["item1", 2]]}, {"input": [[], []], "output": []}, {"input": [[["a", 1]], [["a", 10]]], "output": [["a", 10]]}, {"input": [[["x", 5], ["y", 3]], [["z", 7], ["y", 6]]], "output": [["z", 7], ["y", 6], ["x", 5]]}, {"input": [[["a", 1], ["b", 2]], []], "output": [["b", 2], ["a", 1]]}]}}
{"timestamp_utc": "2025-09-16T06:24:09.032036", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 2, "question": "Write parse_env_config(lines) that parses environment variable lines into dict. Ignore lines starting with '#', lines without '=', and empty keys. Keep last occurrence of duplicate keys. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 3.3082528114318848, "response": "Here's the implementation:\n\n```python\ndef parse_env_config(lines):\n    config = {}\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        parts = line.split('=', 1)\n        if len(parts) == 2:\n            key, value = parts[0].strip(), parts[1].strip()\n            if key:\n                config[key] = value\n    return config\n```", "error": null, "raw_item": {"task_id": "custom_parse_env_config", "prompt": "Write parse_env_config(lines) that parses environment variable lines into dict. Ignore lines starting with '#', lines without '=', and empty keys. Keep last occurrence of duplicate keys. Return only the Python function code with no explanations.", "entry_point": "parse_env_config", "canonical_solution": "def parse_env_config(lines: list[str]) -> dict[str, str]:\n    env = {}\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith(\"#\") or \"=\" not in line:\n            continue\n        key, value = line.split(\"=\", 1)\n        if key:\n            env[key] = value\n    return env", "test": [{"input": [["DB_HOST=localhost", "DB_PORT=5432", "#comment", "DB_HOST=remotehost", "=fail", "INVALID", ""]], "output": {"DB_HOST": "remotehost", "DB_PORT": "5432"}}, {"input": [["A=1", "B=2", "C=3"]], "output": {"A": "1", "B": "2", "C": "3"}}, {"input": [["# just a comment", "=", "==", "KEY_ONLY=", "NO_EQUALS"]], "output": {"KEY_ONLY": ""}}, {"input": [[]], "output": {}}, {"input": [["k1=v1", "k1=v2", "k1=v3"]], "output": {"k1": "v3"}}]}}
{"timestamp_utc": "2025-09-16T06:24:15.604632", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 3, "question": "Write minimal_partition_difference(nums) that partitions a list into two groups to minimize absolute difference of their sums. Handle empty list case explicitly. Use DP subset sum approach. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 5.568002223968506, "response": "def minimal_partition_difference(nums):\n    if not nums:\n        return 0\n    \n    total_sum = sum(nums)\n    target = total_sum // 2\n    n = len(nums)\n    \n    # Create DP table\n    dp = [[False] * (target + 1) for _ in range(n + 1)]\n    \n    # Initialize first column as True (zero sum always possible)\n    for i in range(n + 1):\n        dp[i][0] = True\n    \n    # Fill DP table\n    for i in range(1, n + 1):\n        for j in range(1, target + 1):\n            if nums[i-1] <= j:\n                dp[i][j] = dp[i-1][j] or dp[i-1][j-nums[i-1]]\n            else:\n                dp[i][j] = dp[i-1][j]\n    \n    # Find largest subset sum <= target\n    for j in range(target, -1, -1):\n        if dp[n][j]:\n            return abs(total_sum - 2 * j)", "error": null, "raw_item": {"task_id": "custom_minimal_partition_difference", "prompt": "Write minimal_partition_difference(nums) that partitions a list into two groups to minimize absolute difference of their sums. Handle empty list case explicitly. Use DP subset sum approach. Return only the Python function code with no explanations.", "entry_point": "minimal_partition_difference", "canonical_solution": "def minimal_partition_difference(nums: list[int]) -> int:\n    if not nums:\n        return 0\n    total = sum(nums)\n    target = total // 2\n    possible = {0}\n    for num in nums:\n        possible |= {x + num for x in possible}\n    best = max(x for x in possible if x <= target)\n    return total - 2 * best", "test": [{"input": [[1, 2, 3, 9]], "output": 3}, {"input": [[1, 2, 3, 4, 5]], "output": 1}, {"input": [[10, 10]], "output": 0}, {"input": [[7]], "output": 7}, {"input": [[]], "output": 0}, {"input": [[1, 1, 1, 1, 1, 1]], "output": 0}, {"input": [[100, 99, 98, 1]], "output": 96}]}}
{"timestamp_utc": "2025-09-16T06:24:19.389366", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 4, "question": "Write normalize_user_roles(users) where users is a dict mapping each user to a LIST of roles. Invert to map each role to list of users. Remove duplicate users per role and sort user lists alphabetically. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.782499074935913, "response": "```python\ndef normalize_user_roles(users):\n    roles = {}\n    for user, user_roles in users.items():\n        for role in user_roles:\n            if role not in roles:\n                roles[role] = []\n            if user not in roles[role]:\n                roles[role].append(user)\n    \n    for role in roles:\n        roles[role] = sorted(roles[role])\n    \n    return roles\n```", "error": null, "raw_item": {"task_id": "custom_normalize_user_roles", "prompt": "Write normalize_user_roles(users) where users is a dict mapping each user to a LIST of roles. Invert to map each role to list of users. Remove duplicate users per role and sort user lists alphabetically. Return only the Python function code with no explanations.", "entry_point": "normalize_user_roles", "canonical_solution": "def normalize_user_roles(users: dict[str, list[str]]) -> dict[str, list[str]]:\n    role_to_users = {}\n    for user, roles in users.items():\n        for role in set(roles):  # remove duplicates\n            if role not in role_to_users:\n                role_to_users[role] = []\n            role_to_users[role].append(user)\n    for role in role_to_users:\n        role_to_users[role].sort()\n    return role_to_users", "test": [{"input": [{"alice": ["admin", "editor"], "bob": ["editor", "admin"], "charlie": ["viewer"]}], "output": {"admin": ["alice", "bob"], "editor": ["alice", "bob"], "viewer": ["charlie"]}}, {"input": [{"diana": [], "eva": ["user", "user"], "frank": ["user"]}], "output": {"user": ["eva", "frank"]}}, {"input": [{"a": ["x"], "b": ["y"], "c": ["x", "y"]}], "output": {"x": ["a", "c"], "y": ["b", "c"]}}, {"input": [{}], "output": {}}]}}
{"timestamp_utc": "2025-09-16T06:24:26.757143", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 5, "question": "Write can_form_expression(digits, target) that checks if inserting '+' or '-' operators (or nothing) between digits can reach target value. Use recursive DFS. Must handle multi-digit numbers. Return complete Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 6.365559101104736, "response": "Here's the solution:\n\n```python\ndef can_form_expression(digits, target):\n    def dfs(index, current_value, expression):\n        # Base case: reached end of digits\n        if index == len(digits):\n            return current_value == target\n        \n        # Try all possible ways to form next number\n        for j in range(index, len(digits)):\n            # Extract current number (handling multi-digit case)\n            current_number = int(''.join(digits[index:j+1]))\n            \n            # First number or no operator case\n            if index == 0:\n                if dfs(j+1, current_number, str(current_number)):\n                    return True\n            \n            # Try adding current number\n            if dfs(j+1, current_value + current_number, expression + '+' + str(current_number)):\n                return True\n            \n            # Try subtracting current number\n            if dfs(j+1, current_value - current_number, expression + '-' + str(current_number)):\n                return True\n        \n        return False\n\n    return dfs(0, 0, '')\n```", "error": null, "raw_item": {"task_id": "custom_can_form_expression", "prompt": "Write can_form_expression(digits, target) that checks if inserting '+' or '-' operators (or nothing) between digits can reach target value. Use recursive DFS. Must handle multi-digit numbers. Return complete Python function code with no explanations.", "entry_point": "can_form_expression", "canonical_solution": "def can_form_expression(digits: str, target: int) -> bool:\n    def dfs(index: int, current_value: int, expression: str) -> bool:\n        if index == len(digits):\n            return current_value == target\n        for end in range(index + 1, len(digits) + 1):\n            num_str = digits[index:end]\n            num = int(num_str)\n            if index == 0:\n                if dfs(end, num, num_str):\n                    return True\n            else:\n                if dfs(end, current_value + num, expression + '+' + num_str):\n                    return True\n                if dfs(end, current_value - num, expression + '-' + num_str):\n                    return True\n        return False\n    return dfs(0, 0, \"\")", "test": [{"input": ["123", 6], "output": true}, {"input": ["105", 5], "output": true}, {"input": ["123", 123], "output": true}, {"input": ["123", 100], "output": false}, {"input": ["000", 0], "output": true}, {"input": ["1", 1], "output": true}, {"input": ["1", 2], "output": false}]}}
{"timestamp_utc": "2025-09-16T06:24:29.671895", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 6, "question": "Write has_balanced_bits(n) that returns True if binary representation of n has equal number of 0s and 1s. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 1.91261887550354, "response": "def has_balanced_bits(n):\n    binary = bin(n)[2:]\n    return binary.count('0') == binary.count('1')", "error": null, "raw_item": {"task_id": "custom_has_balanced_bits", "prompt": "Write has_balanced_bits(n) that returns True if binary representation of n has equal number of 0s and 1s. Return only the Python function code with no explanations.", "entry_point": "has_balanced_bits", "canonical_solution": "def has_balanced_bits(n: int) -> bool:\n    bits = bin(n)[2:]\n    return bits.count('0') == bits.count('1')", "test": [{"input": [10], "output": true}, {"input": [7], "output": false}, {"input": [9], "output": true}, {"input": [1], "output": false}, {"input": [51], "output": false}, {"input": [56], "output": true}, {"input": [57], "output": false}, {"input": [2], "output": true}, {"input": [15], "output": false}]}}
{"timestamp_utc": "2025-09-16T06:24:34.029286", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 7, "question": "Write remove_repeating_groups(s, k) that repeatedly removes groups of k identical adjacent characters until no more can be removed. Use stack approach. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 3.3558571338653564, "response": "def remove_repeating_groups(s, k):\n    stack = []\n    \n    for char in s:\n        if stack and stack[-1][0] == char:\n            stack[-1][1] += 1\n        else:\n            stack.append([char, 1])\n        \n        if stack[-1][1] == k:\n            stack.pop()\n    \n    result = []\n    for char, count in stack:\n        result.extend([char] * count)\n    \n    return ''.join(result)", "error": null, "raw_item": {"task_id": "custom_remove_repeating_groups", "prompt": "Write remove_repeating_groups(s, k) that repeatedly removes groups of k identical adjacent characters until no more can be removed. Use stack approach. Return only the Python function code with no explanations.", "entry_point": "remove_repeating_groups", "canonical_solution": "def remove_repeating_groups(s: str, k: int) -> str:\n    stack = []\n    for char in s:\n        if stack and stack[-1][0] == char:\n            stack[-1][1] += 1\n            if stack[-1][1] == k:\n                stack.pop()\n        else:\n            stack.append([char, 1])\n    return ''.join(char * count for char, count in stack)", "test": [{"input": ["deeedbbcccbdaa", 3], "output": "aa"}, {"input": ["pbbcggttciiippooaais", 2], "output": "ps"}, {"input": ["abcd", 2], "output": "abcd"}, {"input": ["aaa", 3], "output": ""}, {"input": ["aaaabbbbaaaa", 4], "output": ""}, {"input": ["aabbcc", 2], "output": ""}, {"input": ["aabbccddeeedcba", 3], "output": "abc"}, {"input": ["", 3], "output": ""}]}}
{"timestamp_utc": "2025-09-16T06:24:39.101509", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 8, "question": "Write resolve_dependencies(deps) that returns valid module load order from dependency dict. Return None if cycle exists. Use DFS topological sort. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 4.071078777313232, "response": "def resolve_dependencies(deps):\n    def dfs(node, visited, rec_stack, order):\n        visited.add(node)\n        rec_stack.add(node)\n        \n        for neighbor in deps.get(node, []):\n            if neighbor in rec_stack:\n                return None\n            if neighbor not in visited:\n                result = dfs(neighbor, visited, rec_stack, order)\n                if result is None:\n                    return None\n        \n        rec_stack.remove(node)\n        order.append(node)\n        return order\n    \n    visited = set()\n    order = []\n    \n    for module in list(deps.keys()):\n        if module not in visited:\n            result = dfs(module, visited, set(), order)\n            if result is None:\n                return None\n    \n    return list(reversed(order))", "error": null, "raw_item": {"task_id": "custom_resolve_dependencies", "prompt": "Write resolve_dependencies(deps) that returns valid module load order from dependency dict. Return None if cycle exists. Use DFS topological sort. Return only the Python function code with no explanations.", "entry_point": "resolve_dependencies", "canonical_solution": "def resolve_dependencies(deps: dict[str, list[str]]) -> list[str] | None:\n    visited = {}\n    result = []\n\n    def dfs(node):\n        if node in visited:\n            return visited[node]  # False if cycle\n        visited[node] = False  # mark as visiting\n        for neighbor in deps.get(node, []):\n            res = dfs(neighbor)\n            if res is False:\n                return False\n        visited[node] = True  # mark as visited\n        result.append(node)\n        return True\n\n    for node in deps:\n        if node not in visited:\n            if dfs(node) is False:\n                return None\n    return result[::-1]", "test": [{"input": [{"a": ["b", "c"], "b": ["c"], "c": []}], "output": ["c", "b", "a"]}, {"input": [{"x": ["y"], "y": ["z"], "z": ["x"]}], "output": null}, {"input": [{"m": ["n"], "n": [], "o": []}], "output": ["n", "m", "o"]}, {"input": [{"a": []}], "output": ["a"]}, {"input": [{}], "output": []}]}}
{"timestamp_utc": "2025-09-16T06:24:42.489468", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 9, "question": "Write clean_and_validate_urls(urls) that returns sorted list of unique valid URLs. Valid URLs start with 'http://' or 'https://' (case-insensitive) and contain no spaces. Strip whitespace and remove duplicates. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.385990858078003, "response": "def clean_and_validate_urls(urls):\n    valid_urls = set()\n    for url in urls:\n        url = url.strip()\n        if url.lower().startswith(('http://', 'https://')) and ' ' not in url:\n            valid_urls.add(url)\n    return sorted(valid_urls)", "error": null, "raw_item": {"task_id": "custom_clean_and_validate_urls", "prompt": "Write clean_and_validate_urls(urls) that returns sorted list of unique valid URLs. Valid URLs start with 'http://' or 'https://' (case-insensitive) and contain no spaces. Strip whitespace and remove duplicates. Return only the Python function code with no explanations.", "entry_point": "clean_and_validate_urls", "canonical_solution": "def clean_and_validate_urls(urls: list[str]) -> list[str]:\n    valid = set()\n    for url in urls:\n        cleaned = url.strip()\n        if cleaned.lower().startswith(\"http://\") or cleaned.lower().startswith(\"https://\"):\n            if \" \" not in cleaned:\n                valid.add(cleaned)\n    return sorted(valid)", "test": [{"input": [[" http://example.com ", "https://valid.site", "ftp://notvalid", "invalid.com", "https://valid.site"]], "output": ["http://example.com", "https://valid.site"]}, {"input": [[]], "output": []}, {"input": [["   https://a.com  ", "http://b.com", "http://b.com  "]], "output": ["http://b.com", "https://a.com"]}, {"input": [["https://with space.com", "http://ok.com"]], "output": ["http://ok.com"]}, {"input": [["HTTP://UPPERCASE.com"]], "output": ["HTTP://UPPERCASE.com"]}]}}
{"timestamp_utc": "2025-09-16T06:24:45.673664", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 10, "question": "Write normalize_filename(filename) that normalizes filenames by converting to lowercase, keeping only a-z, 0-9, underscore, and dots, removing other characters. Return 'unnamed' if result is empty. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.1819310188293457, "response": "def normalize_filename(filename):\n    normalized = ''.join(c.lower() for c in filename if c.isalnum() or c in '._')\n    return normalized if normalized else 'unnamed'", "error": null, "raw_item": {"task_id": "custom_normalize_filename", "prompt": "Write normalize_filename(filename) that normalizes filenames by converting to lowercase, keeping only a-z, 0-9, underscore, and dots, removing other characters. Return 'unnamed' if result is empty. Return only the Python function code with no explanations.", "entry_point": "normalize_filename", "canonical_solution": "def normalize_filename(filename: str) -> str:\n    allowed = set(\"abcdefghijklmnopqrstuvwxyz0123456789_.\")\n    result = ''.join(c.lower() for c in filename if c.lower() in allowed)\n    return result if result else \"unnamed\"", "test": [{"input": ["My Report (Final).PDF"], "output": "myreport.final.pdf"}, {"input": ["Résumé_2023!.docx"], "output": "rsum_2023.docx"}, {"input": ["  "], "output": "unnamed"}, {"input": ["file@#name!.TXT"], "output": "filename.txt"}, {"input": ["___"], "output": "___"}, {"input": ["###"], "output": "unnamed"}, {"input": ["ABC123_456.xyz"], "output": "abc123_456.xyz"}]}}
{"timestamp_utc": "2025-09-16T06:24:49.034654", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 11, "question": "Write rank_projects_by_score(projects) that ranks projects by score formula: (stars * 2) + forks - (issues * 3). Return project names sorted by score descending, then alphabetically. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.3583691120147705, "response": "def rank_projects_by_score(projects):\n    def score_project(project):\n        return (project['stars'] * 2) + project['forks'] - (project['issues'] * 3)\n    \n    return sorted(projects, key=lambda p: (-score_project(p), p['name']))", "error": null, "raw_item": {"task_id": "custom_rank_projects_by_score", "prompt": "Write rank_projects_by_score(projects) that ranks projects by score formula: (stars * 2) + forks - (issues * 3). Return project names sorted by score descending, then alphabetically. Return only the Python function code with no explanations.", "entry_point": "rank_projects_by_score", "canonical_solution": "def rank_projects_by_score(projects: list[tuple[str, int, int, int]]) -> list[str]:\n    def score(proj):\n        return (proj[1] * 2) + proj[2] - (proj[3] * 3)\n    return [p[0] for p in sorted(projects, key=lambda p: (-score(p), p[0]))]", "test": [{"input": [[["ProjectA", 100, 50, 10], ["ProjectB", 80, 70, 5], ["ProjectC", 100, 50, 10]]], "output": ["ProjectA", "ProjectC", "ProjectB"]}, {"input": [[["Alpha", 10, 5, 0], ["Beta", 10, 5, 0]]], "output": ["Alpha", "Beta"]}, {"input": [[["AppX", 0, 0, 0], ["AppY", 0, 0, 1]]], "output": ["AppX", "AppY"]}, {"input": [[]], "output": []}, {"input": [[["ToolZ", 5, 5, 10], ["ToolY", 4, 4, 1]]], "output": ["ToolY", "ToolZ"]}]}}
{"timestamp_utc": "2025-09-16T06:24:54.708800", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 12, "question": "Write longest_prime_gap(nums) that finds the longest sequence of non-prime numbers between two prime numbers in the list. Return length of longest gap. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 4.671741008758545, "response": "def longest_prime_gap(nums):\n    def is_prime(n):\n        if n < 2:\n            return False\n        for i in range(2, int(n**0.5) + 1):\n            if n % i == 0:\n                return False\n        return True\n    \n    primes = [num for num in nums if is_prime(num)]\n    \n    if len(primes) < 2:\n        return 0\n    \n    max_gap = 0\n    \n    for i in range(len(primes) - 1):\n        current_gap = 0\n        for num in nums:\n            if primes[i] < num < primes[i+1]:\n                if not is_prime(num):\n                    current_gap += 1\n        max_gap = max(max_gap, current_gap)\n    \n    return max_gap", "error": null, "raw_item": {"task_id": "custom_longest_prime_gap", "prompt": "Write longest_prime_gap(nums) that finds the longest sequence of non-prime numbers between two prime numbers in the list. Return length of longest gap. Return only the Python function code with no explanations.", "entry_point": "longest_prime_gap", "canonical_solution": "def longest_prime_gap(nums: list[int]) -> int:\n    def is_prime(n: int) -> bool:\n        if n < 2:\n            return False\n        for i in range(2, int(n**0.5)+1):\n            if n % i == 0:\n                return False\n        return True\n\n    indices = [i for i, val in enumerate(nums) if is_prime(val)]\n    if len(indices) < 2:\n        return 0\n\n    max_gap = 0\n    for i in range(len(indices) - 1):\n        start = indices[i]\n        end = indices[i + 1]\n        gap = end - start - 1\n        max_gap = max(max_gap, gap)\n    return max_gap", "test": [{"input": [[4, 6, 7, 8, 9, 10, 11, 4, 6, 13]], "output": 3}, {"input": [[2, 4, 6, 8, 10, 3]], "output": 4}, {"input": [[4, 6, 8, 10]], "output": 0}, {"input": [[3, 4, 5, 6, 7]], "output": 1}, {"input": [[2, 3]], "output": 0}, {"input": [[17, 4, 6, 9, 15, 19, 21, 23]], "output": 4}, {"input": [[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]], "output": 4}]}}
{"timestamp_utc": "2025-09-16T06:24:59.202923", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 13, "question": "Write categorize_commit_message(message) that categorizes commit messages. Return 'feature' for add/implement/feature/new, 'fix' for fix/bug/error/resolve, 'refactor' for refactor/cleanup/restructure, 'docs' for docs/documentation/readme, else 'other'. Case-insensitive. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 3.491811990737915, "response": "def categorize_commit_message(message):\n    message = message.lower()\n    if any(keyword in message for keyword in ['add', 'implement', 'feature', 'new']):\n        return 'feature'\n    elif any(keyword in message for keyword in ['fix', 'bug', 'error', 'resolve']):\n        return 'fix'\n    elif any(keyword in message for keyword in ['refactor', 'cleanup', 'restructure']):\n        return 'refactor'\n    elif any(keyword in message for keyword in ['docs', 'documentation', 'readme']):\n        return 'docs'\n    else:\n        return 'other'", "error": null, "raw_item": {"task_id": "custom_categorize_commit_message", "prompt": "Write categorize_commit_message(message) that categorizes commit messages. Return 'feature' for add/implement/feature/new, 'fix' for fix/bug/error/resolve, 'refactor' for refactor/cleanup/restructure, 'docs' for docs/documentation/readme, else 'other'. Case-insensitive. Return only the Python function code with no explanations.", "entry_point": "categorize_commit_message", "canonical_solution": "def categorize_commit_message(message: str) -> str:\n    msg = message.lower()\n    categories = {\n        \"feature\": [\"add\", \"implement\", \"feature\", \"new\"],\n        \"fix\": [\"fix\", \"bug\", \"error\", \"resolve\"],\n        \"refactor\": [\"refactor\", \"cleanup\", \"restructure\"],\n        \"docs\": [\"docs\", \"documentation\", \"readme\"],\n    }\n    for label, keywords in categories.items():\n        if any(kw in msg for kw in keywords):\n            return label\n    return \"other\"", "test": [{"input": ["Fix bug in user login"], "output": "fix"}, {"input": ["Refactor payment module"], "output": "refactor"}, {"input": ["Updated README and docs"], "output": "docs"}, {"input": ["Initial commit"], "output": "other"}, {"input": ["Implemented new feature for signup"], "output": "feature"}, {"input": ["cleanup redundant logic"], "output": "refactor"}, {"input": ["Error handling for empty input"], "output": "fix"}, {"input": ["add configuration support"], "output": "feature"}, {"input": ["Documentation improvements"], "output": "docs"}, {"input": ["Minor UI tweaks"], "output": "other"}]}}
{"timestamp_utc": "2025-09-16T06:25:03.799621", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 14, "question": "Write max_repeated_substring(s) that returns length of longest non-overlapping repeated substring. Use sliding window with seen set. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 3.594144821166992, "response": "def max_repeated_substring(s):\n    n = len(s)\n    max_length = 0\n    \n    for length in range(1, n // 2 + 1):\n        seen = set()\n        for start in range(n - 2 * length + 1):\n            substring = s[start:start + length]\n            if substring in seen:\n                max_length = max(max_length, length)\n                break\n            seen.add(substring)\n    \n    return max_length", "error": null, "raw_item": {"task_id": "custom_max_repeated_substring", "prompt": "Write max_repeated_substring(s) that returns length of longest non-overlapping repeated substring. Use sliding window with seen set. Return only the Python function code with no explanations.", "entry_point": "max_repeated_substring", "canonical_solution": "def max_repeated_substring(s: str) -> int:\n    n = len(s)\n    max_len = 0\n    for l in range(1, n // 2 + 1):\n        seen = set()\n        i = 0\n        while i + l <= n:\n            substr = s[i:i+l]\n            if substr in seen:\n                max_len = max(max_len, l)\n                i += l  # move forward non-overlapping\n            else:\n                seen.add(substr)\n                i += 1\n    return max_len", "test": [{"input": ["abababc"], "output": 2}, {"input": ["aaaa"], "output": 2}, {"input": ["abcabcabc"], "output": 3}, {"input": ["abcdef"], "output": 0}, {"input": ["ababa"], "output": 1}, {"input": [""], "output": 0}, {"input": ["a"], "output": 0}, {"input": ["abcdabcd"], "output": 4}, {"input": ["xyzxyzabcabc"], "output": 3}, {"input": ["abababab"], "output": 2}]}}
{"timestamp_utc": "2025-09-16T06:25:07.887215", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 15, "question": "Write longest_valid_bracket_substring(s) that returns length of longest valid parentheses substring. Use stack with indices. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 3.0843358039855957, "response": "def longest_valid_bracket_substring(s):\n    stack = [-1]\n    max_length = 0\n    \n    for i in range(len(s)):\n        if s[i] == '(':\n            stack.append(i)\n        else:\n            stack.pop()\n            \n            if not stack:\n                stack.append(i)\n            else:\n                current_length = i - stack[-1]\n                max_length = max(max_length, current_length)\n    \n    return max_length", "error": null, "raw_item": {"task_id": "custom_longest_valid_bracket_substring", "prompt": "Write longest_valid_bracket_substring(s) that returns length of longest valid parentheses substring. Use stack with indices. Return only the Python function code with no explanations.", "entry_point": "longest_valid_bracket_substring", "canonical_solution": "def longest_valid_bracket_substring(s: str) -> int:\n    stack = [-1]\n    max_len = 0\n\n    for i, ch in enumerate(s):\n        if ch == '(':\n            stack.append(i)\n        else:\n            stack.pop()\n            if not stack:\n                stack.append(i)\n            else:\n                max_len = max(max_len, i - stack[-1])\n\n    return max_len", "test": [{"input": ["(()"], "output": 2}, {"input": [")()())"], "output": 4}, {"input": [""], "output": 0}, {"input": ["((("], "output": 0}, {"input": ["()(()))())"], "output": 6}, {"input": ["((()))"], "output": 6}, {"input": ["()()()"], "output": 6}, {"input": [")((()))("], "output": 6}, {"input": ["(()(((()"], "output": 2}, {"input": ["())(())"], "output": 4}]}}
{"timestamp_utc": "2025-09-16T06:25:11.671894", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 16, "question": "Write summarize_category_totals(purchases) that returns list of [category, total] pairs sorted alphabetically by category. Sum amounts by category. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.7834889888763428, "response": "def summarize_category_totals(purchases):\n    category_totals = {}\n    for purchase in purchases:\n        category = purchase[1]\n        amount = purchase[2]\n        category_totals[category] = category_totals.get(category, 0) + amount\n    \n    return sorted(category_totals.items())", "error": null, "raw_item": {"task_id": "custom_summarize_category_totals", "prompt": "Write summarize_category_totals(purchases) that returns list of [category, total] pairs sorted alphabetically by category. Sum amounts by category. Return only the Python function code with no explanations.", "entry_point": "summarize_category_totals", "canonical_solution": "def summarize_category_totals(purchases: list[dict]) -> list[list]:\n    totals = {}\n    for item in purchases:\n        cat = item[\"category\"]\n        amt = item[\"amount\"]\n        totals[cat] = totals.get(cat, 0.0) + amt\n    return sorted([[cat, total] for cat, total in totals.items()])", "test": [{"input": [[{"category": "groceries", "amount": 25.5}, {"category": "electronics", "amount": 99.99}, {"category": "groceries", "amount": 13.0}, {"category": "books", "amount": 10.0}]], "output": [["books", 10.0], ["electronics", 99.99], ["groceries", 38.5]]}, {"input": [[{"category": "a", "amount": 1.0}, {"category": "b", "amount": 2.0}, {"category": "a", "amount": 3.0}, {"category": "c", "amount": 4.0}]], "output": [["a", 4.0], ["b", 2.0], ["c", 4.0]]}, {"input": [[]], "output": []}, {"input": [[{"category": "x", "amount": 0.0}, {"category": "x", "amount": 0.0}]], "output": [["x", 0.0]]}, {"input": [[{"category": "Z", "amount": 2.0}, {"category": "a", "amount": 1.0}]], "output": [["Z", 2.0], ["a", 1.0]]}]}}
{"timestamp_utc": "2025-09-16T06:25:14.727663", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 17, "question": "Write filter_unique_keywords(keywords, banned) that returns sorted unique keywords (lowercased) excluding banned words. Case-insensitive comparison. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.0545461177825928, "response": "def filter_unique_keywords(keywords, banned):\n    return sorted(set(keyword.lower() for keyword in keywords if keyword.lower() not in set(word.lower() for word in banned)))", "error": null, "raw_item": {"task_id": "custom_filter_unique_keywords", "prompt": "Write filter_unique_keywords(keywords, banned) that returns sorted unique keywords (lowercased) excluding banned words. Case-insensitive comparison. Return only the Python function code with no explanations.", "entry_point": "filter_unique_keywords", "canonical_solution": "def filter_unique_keywords(keywords: list[str], banned: list[str]) -> list[str]:\n    banned_set = set(word.lower() for word in banned)\n    unique = set()\n\n    for word in keywords:\n        w = word.lower()\n        if w not in banned_set:\n            unique.add(w)\n\n    return sorted(unique)", "test": [{"input": [["Python", "code", "AI", "python", "Data", "Code"], ["ai"]], "output": ["code", "data", "python"]}, {"input": [[], ["test"]], "output": []}, {"input": [["ML", "AI", "ml", "AI"], ["ai"]], "output": ["ml"]}, {"input": [["hello", "world", "HELLO", "WORLD"], []], "output": ["hello", "world"]}, {"input": [["Data", "Science", "AI"], ["science", "ai"]], "output": ["data"]}, {"input": [["Python", "PYTHON", "python"], ["PYTHON"]], "output": []}]}}
{"timestamp_utc": "2025-09-16T06:25:18.670960", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 18, "question": "Write next_greater_circular(nums) that returns list where each position contains next greater element circularly. Use monotonic stack. O(n) time. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.941377878189087, "response": "def next_greater_circular(nums):\n    n = len(nums)\n    result = [-1] * n\n    stack = []\n    \n    for i in range(2 * n):\n        while stack and nums[stack[-1]] < nums[i % n]:\n            result[stack.pop()] = nums[i % n]\n        \n        if i < n:\n            stack.append(i)\n    \n    return result", "error": null, "raw_item": {"task_id": "ds_next_greater_circular", "prompt": "Write next_greater_circular(nums) that returns list where each position contains next greater element circularly. Use monotonic stack. O(n) time. Return only the Python function code with no explanations.", "entry_point": "next_greater_circular", "canonical_solution": "def next_greater_circular(nums):\n    n = len(nums)\n    res = [-1]*n\n    stack = []  # indices with decreasing stack by value\n    for i in range(2*n):\n        x = nums[i % n]\n        while stack and nums[stack[-1]] < x:\n            idx = stack.pop()\n            res[idx] = x\n        if i < n:\n            stack.append(i)\n    return res\n", "test": [{"input": [[1, 2, 1]], "output": [2, -1, 2]}, {"input": [[3, 8, 4, 1, 2]], "output": [8, -1, 8, 2, 3]}, {"input": [[5, 4, 3, 2, 1]], "output": [-1, 5, 5, 5, 5]}, {"input": [[2, 2, 2]], "output": [-1, -1, -1]}, {"input": [[]], "output": []}]}}
{"timestamp_utc": "2025-09-16T06:25:22.425327", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 19, "question": "Write normalize_product_code(s) that keeps only alphanumerics and dashes, converts to uppercase, collapses multiple dashes, trims leading/trailing dashes. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.7521378993988037, "response": "def normalize_product_code(s):\n    import re\n    return re.sub(r'^-+|-+$', '', re.sub(r'-+', '-', re.sub(r'[^a-zA-Z0-9-]', '', s.upper())))", "error": null, "raw_item": {"task_id": "str_normalize_product_code", "prompt": "Write normalize_product_code(s) that keeps only alphanumerics and dashes, converts to uppercase, collapses multiple dashes, trims leading/trailing dashes. Return only the Python function code with no explanations.", "entry_point": "normalize_product_code", "canonical_solution": "import re\ndef normalize_product_code(s):\n    # keep alnum and dash\n    s = ''.join(ch for ch in s if ch.isalnum() or ch=='-')\n    s = s.upper()\n    s = re.sub(r'-{2,}', '-', s)\n    s = s.strip('-')\n    return s\n", "test": [{"input": [" abC--12__-xx "], "output": "ABC-12-XX"}, {"input": ["---a---b---"], "output": "A-B"}, {"input": ["***"], "output": ""}, {"input": ["proD-uct_99!!"], "output": "PROD-UCT99"}, {"input": [""], "output": ""}]}}
{"timestamp_utc": "2025-09-16T06:25:25.947432", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 20, "question": "Write single_number_triplicates(nums) that finds element appearing once while others appear thrice. Use bitwise counting without hash maps. O(n) time, O(1) space. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.519062042236328, "response": "Here's the implementation:\n\n```python\ndef single_number_triplicates(nums):\n    ones = 0\n    twos = 0\n    \n    for num in nums:\n        ones = (ones ^ num) & ~twos\n        twos = (twos ^ num) & ~ones\n    \n    return ones\n```", "error": null, "raw_item": {"task_id": "bit_single_number_triplicates", "prompt": "Write single_number_triplicates(nums) that finds element appearing once while others appear thrice. Use bitwise counting without hash maps. O(n) time, O(1) space. Return only the Python function code with no explanations.", "entry_point": "single_number_triplicates", "canonical_solution": "def single_number_triplicates(nums):\n    ones = 0\n    twos = 0\n    for x in nums:\n        ones = (ones ^ x) & ~twos\n        twos = (twos ^ x) & ~ones\n    return ones\n", "test": [{"input": [[2, 2, 3, 2]], "output": 3}, {"input": [[0, 1, 0, 1, 0, 1, 99]], "output": 99}, {"input": [[-2, -2, -2, -5]], "output": -5}, {"input": [[7]], "output": 7}, {"input": [[10, 10, 10, -1]], "output": -1}]}}
{"timestamp_utc": "2025-09-16T06:25:31.844417", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 21, "question": "Write can_finish_prereqs(pairs) where pairs are (a,b) meaning 'b precedes a'. Return True if acyclic. Use topological sort without external libraries. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 4.895289659500122, "response": "def can_finish_prereqs(pairs):\n    graph = {}\n    for a, b in pairs:\n        if a not in graph:\n            graph[a] = set()\n        if b not in graph:\n            graph[b] = set()\n        graph[a].add(b)\n    \n    def dfs(node, path):\n        if node in path:\n            return False\n        if node in visited:\n            return True\n        \n        path.add(node)\n        for neighbor in graph[node]:\n            if not dfs(neighbor, path):\n                return False\n        path.remove(node)\n        \n        visited.add(node)\n        return True\n    \n    visited = set()\n    for node in graph:\n        if node not in visited:\n            if not dfs(node, set()):\n                return False\n    \n    return True", "error": null, "raw_item": {"task_id": "graph_can_finish_prereqs", "prompt": "Write can_finish_prereqs(pairs) where pairs are (a,b) meaning 'b precedes a'. Return True if acyclic. Use topological sort without external libraries. Return only the Python function code with no explanations.", "entry_point": "can_finish_prereqs", "canonical_solution": "from collections import defaultdict, deque\ndef can_finish_prereqs(pairs):\n    adj = defaultdict(list)\n    indeg = defaultdict(int)\n    nodes = set()\n    for a,b in pairs:\n        adj[b].append(a)\n        indeg[a] += 1\n        nodes.add(a); nodes.add(b)\n        if b not in indeg: indeg[b] = indeg.get(b,0)\n    q = deque([v for v in nodes if indeg.get(v,0)==0])\n    visited = 0\n    while q:\n        v = q.popleft()\n        visited += 1\n        for w in adj[v]:\n            indeg[w] -= 1\n            if indeg[w]==0:\n                q.append(w)\n    return visited == len(nodes)\n", "test": [{"input": [[["C2", "C1"], ["C3", "C2"]]], "output": true}, {"input": [[["A", "B"], ["B", "C"], ["C", "A"]]], "output": false}, {"input": [[["A", "B"]]], "output": true}, {"input": [[["X", "Y"], ["Y", "Z"], ["Z", "X"]]], "output": false}, {"input": [[[]]], "output": true}]}}
{"timestamp_utc": "2025-09-16T06:25:35.931238", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 22, "question": "Write safe_deep_get(obj, path, default=None) that safely traverses nested dicts/lists/tuples using path keys/indices. Return default if any access fails. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 3.0847690105438232, "response": "def safe_deep_get(obj, path, default=None):\n    try:\n        for key in path.split('.') if isinstance(path, str) else path:\n            if isinstance(obj, (dict, list, tuple)):\n                obj = obj[key] if isinstance(key, (int, str)) else obj[int(key)]\n            else:\n                return default\n        return obj\n    except (KeyError, IndexError, TypeError, ValueError):\n        return default", "error": null, "raw_item": {"task_id": "se_safe_deep_get", "entry_point": "safe_deep_get", "prompt": "Write safe_deep_get(obj, path, default=None) that safely traverses nested dicts/lists/tuples using path keys/indices. Return default if any access fails. Return only the Python function code with no explanations.", "canonical_solution": "def safe_deep_get(obj, path, default=None):\n    cur = obj\n    for key in path:\n        if isinstance(cur, dict):\n            if key in cur:\n                cur = cur[key]\n            else:\n                return default\n        elif isinstance(cur, (list, tuple)):\n            if isinstance(key, int) and -len(cur) <= key < len(cur):\n                cur = cur[key]\n            else:\n                return default\n        else:\n            return default\n    return cur\n", "test": [{"input": [{"a": {"b": [10, 20, {"c": 42}]}}, ["a", "b", 2, "c"], null], "output": 42}, {"input": [{"a": [1, 2, 3]}, ["a", 5], "x"], "output": "x"}, {"input": [{"x": 0}, ["y"], 99], "output": 99}, {"input": [[1, 2, 3], [0], null], "output": 1}, {"input": [[1, 2, 3], ["0"], "err"], "output": "err"}]}}
{"timestamp_utc": "2025-09-16T06:25:40.339334", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 23, "question": "Write clean_and_split_sentences(text) that removes non-alphanumeric chars except .!?, normalizes whitespace, splits on sentence delimiters, returns cleaned sentence list. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 3.4060919284820557, "response": "def clean_and_split_sentences(text):\n    import re\n    \n    # Remove non-alphanumeric chars except .!? and normalize whitespace\n    cleaned_text = re.sub(r'[^\\w\\s.!?]', '', text)\n    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n    \n    # Split on sentence delimiters\n    sentences = re.split(r'(?<=[.!?])\\s+', cleaned_text)\n    \n    # Remove any empty sentences\n    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n    \n    return sentences", "error": null, "raw_item": {"task_id": "str_clean_and_split_sentences", "entry_point": "clean_and_split_sentences", "prompt": "Write clean_and_split_sentences(text) that removes non-alphanumeric chars except .!?, normalizes whitespace, splits on sentence delimiters, returns cleaned sentence list. Return only the Python function code with no explanations.", "canonical_solution": "import re\n\ndef clean_and_split_sentences(text):\n    # Keep only letters, digits, punctuation .,!,?\n    text = re.sub(r\"[^A-Za-z0-9.!?\\s]\", \"\", text)\n    # Normalize whitespace\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    # Split on sentence delimiters\n    parts = re.split(r\"[.!?]\", text)\n    # Clean and filter\n    result = [p.strip() for p in parts if p.strip()]\n    return result\n", "test": [{"input": ["Hello!!   How are---you???   Fine."], "output": ["Hello", "How areyou", "Fine"]}, {"input": ["  multiple   spaces   and ###symbols!!"], "output": ["multiple spaces and symbols"]}, {"input": ["Nothing to clean"], "output": ["Nothing to clean"]}, {"input": ["???"], "output": []}]}}
{"timestamp_utc": "2025-09-16T06:25:43.719123", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 24, "question": "Write count_set_bits(n) that counts 1-bits in binary representation using efficient bit manipulation (Brian Kernighan's algorithm). Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.3781111240386963, "response": "def count_set_bits(n):\n    count = 0\n    while n:\n        n &= (n - 1)\n        count += 1\n    return count", "error": null, "raw_item": {"task_id": "bit_counting_set_bits", "entry_point": "count_set_bits", "prompt": "Write count_set_bits(n) that counts 1-bits in binary representation using efficient bit manipulation (Brian Kernighan's algorithm). Return only the Python function code with no explanations.", "canonical_solution": "def count_set_bits(n):\n    if n < 0:\n        raise ValueError(\"Input must be a non-negative integer.\")\n    count = 0\n    while n:\n        n &= n - 1  # Clear the least significant bit set\n        count += 1\n    return count\n", "test": [{"input": [11], "output": 3}, {"input": [0], "output": 0}, {"input": [255], "output": 8}, {"input": [1023], "output": 10}, {"input": [1], "output": 1}]}}
{"timestamp_utc": "2025-09-16T06:25:51.802418", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 25, "question": "Write filter_map_validate(records) that normalizes, validates, and filters product records, returning sorted list of valid IDs. Complex multi-step validation with price parsing, type constraints, and conditional rules. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 7.080995082855225, "response": "def filter_map_validate(records):\n    def is_valid_product(record):\n        try:\n            name = record.get('name', '').strip()\n            price_str = record.get('price', '')\n            category = record.get('category', '')\n            \n            # Basic validation checks\n            if not name or len(name) < 3:\n                return None\n            \n            # Parse and validate price\n            try:\n                price = float(price_str.replace('$', '').replace(',', ''))\n                if price <= 0 or price > 10000:\n                    return None\n            except (ValueError, TypeError):\n                return None\n            \n            # Category constraints\n            valid_categories = ['Electronics', 'Clothing', 'Home', 'Books']\n            if category not in valid_categories:\n                return None\n            \n            # Additional complex validation rules\n            if category == 'Electronics' and price < 50:\n                return None\n            \n            if category == 'Clothing' and not (10 <= price <= 500):\n                return None\n            \n            # Normalize record\n            normalized_record = {\n                'id': record.get('id'),\n                'name': name.title(),\n                'price': round(price, 2),\n                'category': category\n            }\n            \n            return normalized_record\n        \n        except Exception:\n            return None\n    \n    # Filter, map, and validate records\n    valid_records = [\n        record['id'] for record in \n        filter(None, map(is_valid_product, records))\n    ]\n    \n    # Return sorted list of valid IDs\n    return sorted(valid_records)", "error": null, "raw_item": {"task_id": "se_filter_map_validate_nested", "entry_point": "filter_map_validate", "prompt": "Write filter_map_validate(records) that normalizes, validates, and filters product records, returning sorted list of valid IDs. Complex multi-step validation with price parsing, type constraints, and conditional rules. Return only the Python function code with no explanations.", "canonical_solution": "import re\n\ntype_order = {\"ent\": 0, \"pro\": 1, \"std\": 2}\n\ndef _parse_price(x):\n    if isinstance(x, (int, float)):\n        return float(x) if x >= 0 else None\n    if not isinstance(x, str):\n        return None\n    s = x.strip()\n    if not s:\n        return None\n    s = re.sub(r\"[\\s$€£¥]\", \"\", s)\n    if \",\" in s and \".\" in s:\n        if s.find(\",\") < s.find(\".\"):\n            s = s.replace(\",\", \"\")\n        else:\n            s = s.replace(\".\", \"\").replace(\",\", \".\")\n    elif \",\" in s:\n        s = s.replace(\",\", \".\")\n    try:\n        v = float(s)\n        return v if v >= 0 else None\n    except Exception:\n        return None\n\ndef _to_int(x):\n    if isinstance(x, bool):\n        return None\n    if isinstance(x, int):\n        return x\n    if isinstance(x, str):\n        s = x.strip()\n        if s and s.lstrip(\"-+\").isdigit():\n            try:\n                return int(s)\n            except Exception:\n                return None\n    return None\n\ndef _to_float(x):\n    if isinstance(x, (int, float)):\n        return float(x)\n    if isinstance(x, str):\n        try:\n            return float(x.strip())\n        except Exception:\n            return None\n    return None\n\ndef _to_pct(x):\n    if x is None:\n        return None\n    if isinstance(x, (int, float)):\n        v = float(x)\n    elif isinstance(x, str):\n        try:\n            v = float(x.strip().strip('%'))\n        except Exception:\n            return None\n    else:\n        return None\n    if v < 0:\n        v = 0.0\n    if v > 100:\n        v = 100.0\n    return v\n\ndef filter_map_validate(records):\n    if not isinstance(records, list):\n        return []\n    kept = []\n    for rec in records:\n        if not isinstance(rec, dict):\n            continue\n        # --- id ---\n        rid = rec.get(\"id\")\n        rid = str(rid).strip() if rid is not None else \"\"\n        if not rid:\n            continue\n        # --- meta ---\n        meta = rec.get(\"meta\") or {}\n        if not isinstance(meta, dict):\n            meta = {}\n        rtype = str(meta.get(\"type\") or \"\").strip().lower()\n        flags = meta.get(\"flags\")\n        if isinstance(flags, list):\n            flags_norm = [str(t).strip().lower() for t in flags if isinstance(t, (str, int, float))]\n        else:\n            flags_norm = []\n        if rtype not in (\"std\",\"pro\",\"ent\"):\n            continue\n        # --- price ---\n        price = _parse_price(rec.get(\"price\"))\n        if price is None:\n            continue\n        # --- attrs ---\n        attrs = rec.get(\"attrs\") or {}\n        if not isinstance(attrs, dict):\n            attrs = {}\n        color = attrs.get(\"color\")\n        color = str(color).strip().lower() if isinstance(color, str) else None\n        size = attrs.get(\"size\")\n        if size is not None:\n            size = _to_int(size)\n        weight = attrs.get(\"weight\")\n        if weight is not None:\n            weight = _to_float(weight)\n        cond = attrs.get(\"condition\")\n        cond = str(cond).strip().upper() if isinstance(cond, str) else None\n        discount = _to_pct(attrs.get(\"discount\"))\n        # --- stock ---\n        stock = _to_int(rec.get(\"stock\"))\n        if stock is None:\n            stock = 0\n        if stock < 0:\n            stock = 0\n        # --- Validation A: color/flag gate ---\n        if not ((color in {\"red\",\"blue\",\"green\"}) or (\"eco\" in flags_norm)):\n            continue\n        # --- Validation B: price caps ---\n        if rtype in (\"std\",\"pro\") and price > 1000:\n            continue\n        if rtype == \"ent\" and price > 5000:\n            continue\n        # --- Validation C: refurb implies good condition ---\n        if \"refurb\" in flags_norm:\n            if cond not in {\"A\",\"B\"}:\n                continue\n        # --- Validation D: ent requires size>=10 and stock>=1 ---\n        if rtype == \"ent\":\n            if size is None or size < 10 or stock < 1:\n                continue\n        # --- Validation E: pro weight <= 50 if provided ---\n        if rtype == \"pro\" and weight is not None and weight > 50.0:\n            continue\n        kept.append({\n            \"id\": rid,\n            \"type\": rtype,\n            \"price\": price\n        })\n    # sort: type order (ent > pro > std) i.e., ent first, then pro, then std\n    kept.sort(key=lambda r: (type_order.get(r[\"type\"], 3), r[\"price\"], r[\"id\"].lower()))\n    return [r[\"id\"] for r in kept]\n", "test": [{"input": [[{"id": " A-1 ", "meta": {"type": "ent", "flags": ["Eco"]}, "price": "€4,999.00", "attrs": {"size": "12", "color": "Green"}, "stock": "5"}, {"id": "B-2", "meta": {"type": "pro", "flags": ["refurb"]}, "price": "$800", "attrs": {"weight": "49.5", "color": "blue", "condition": "B"}, "stock": 0}, {"id": "c-3", "meta": {"type": "std", "flags": []}, "price": "1200", "attrs": {"color": "red"}, "stock": 10}, {"id": "d-4", "meta": {"type": "ent", "flags": ["eco", "refurb"]}, "price": "5100", "attrs": {"size": 15, "color": "green", "condition": "A"}, "stock": 2}, {"id": "e-5", "meta": {"type": "pro", "flags": []}, "price": "999.99", "attrs": {"color": "yellow"}, "stock": 7}]], "output": ["A-1", "B-2"]}, {"input": [[{"id": 101, "meta": {"type": "pro", "flags": ["eco"]}, "price": "1,000.00", "attrs": {"color": "RED", "weight": "50"}, "stock": "-3"}, {"id": 102, "meta": {"type": "pro", "flags": ["eco"]}, "price": "1,000.01", "attrs": {"color": "GREEN", "weight": "10"}, "stock": "0"}, {"id": 103, "meta": {"type": "std", "flags": ["eco"]}, "price": "$0", "attrs": {"color": "green"}, "stock": "0"}]], "output": ["101", "103"]}, {"input": [[{"id": "X", "meta": {"type": "ent", "flags": ["REFURB"]}, "price": "$4500", "attrs": {"size": "9", "color": "blue", "condition": "A"}, "stock": 1}, {"id": "Y", "meta": {"type": "ent", "flags": []}, "price": "$4500", "attrs": {"size": "12", "color": "blue"}, "stock": 0}, {"id": "Z", "meta": {"type": "ent", "flags": []}, "price": "$4500", "attrs": {"size": "12", "color": "blue"}, "stock": 3}]], "output": ["Z"]}, {"input": [[{"id": "bad", "meta": {"type": "other", "flags": ["eco"]}, "price": "100", "attrs": {"color": "red"}, "stock": 1}, {"id": "ok-std", "meta": {"type": "std", "flags": ["eco"]}, "price": "1000", "attrs": {"color": "green"}, "stock": 0}]], "output": ["ok-std"]}, {"input": [[{"id": "keep-pro-over-std", "meta": {"type": "pro", "flags": ["eco"]}, "price": "500", "attrs": {"color": "blue"}}, {"id": "keep-ent-first", "meta": {"type": "ent", "flags": ["eco"]}, "price": "1200", "attrs": {"color": "green", "size": 20}, "stock": 2}, {"id": "keep-std-last", "meta": {"type": "std", "flags": ["eco"]}, "price": "100", "attrs": {"color": "red"}}]], "output": ["keep-ent-first", "keep-pro-over-std", "keep-std-last"]}]}}
{"timestamp_utc": "2025-09-16T06:25:57.126960", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 26, "question": "Write sliding_window_max(arr, k) that returns maximum element in each sliding window of size k using deque. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 4.32216477394104, "response": "Here's the implementation of sliding_window_max using a deque:\n\n```python\nfrom collections import deque\n\ndef sliding_window_max(arr, k):\n    if not arr or k <= 0:\n        return []\n    \n    result = []\n    window = deque()\n    \n    for i in range(len(arr)):\n        # Remove indices outside current window\n        while window and window[0] <= i - k:\n            window.popleft()\n        \n        # Remove smaller elements from back of deque\n        while window and arr[window[-1]] < arr[i]:\n            window.pop()\n        \n        window.append(i)\n        \n        # Start adding to result once first window is formed\n        if i >= k - 1:\n            result.append(arr[window[0]])\n    \n    return result\n```", "error": null, "raw_item": {"task_id": "custom_sliding_window_max", "prompt": "Write sliding_window_max(arr, k) that returns maximum element in each sliding window of size k using deque. Return only the Python function code with no explanations.", "entry_point": "sliding_window_max", "canonical_solution": "from collections import deque\n\ndef sliding_window_max(arr: list[int], k: int) -> list[int]:\n    if not arr or k == 0:\n        return []\n    \n    dq = deque()\n    result = []\n    \n    for i in range(len(arr)):\n        # Remove elements outside current window\n        while dq and dq[0] <= i - k:\n            dq.popleft()\n        \n        # Remove elements smaller than current element\n        while dq and arr[dq[-1]] <= arr[i]:\n            dq.pop()\n        \n        dq.append(i)\n        \n        # Add maximum to result if window is complete\n        if i >= k - 1:\n            result.append(arr[dq[0]])\n    \n    return result", "test": [{"input": [[1, 3, -1, -3, 5, 3, 6, 7], 3], "output": [3, 3, 5, 5, 6, 7]}, {"input": [[1, 2, 3], 1], "output": [1, 2, 3]}, {"input": [[5, 4, 3, 2, 1], 2], "output": [5, 4, 3, 2]}, {"input": [[1], 1], "output": [1]}, {"input": [[], 3], "output": []}, {"input": [[7, 2, 4], 3], "output": [7]}]}}
{"timestamp_utc": "2025-09-16T06:26:01.221733", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 27, "question": "Write rotate_matrix(matrix) that rotates n×n matrix 90 degrees clockwise in-place using transpose and reverse. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 3.0930399894714355, "response": "def rotate_matrix(matrix):\n    n = len(matrix)\n    \n    # Transpose the matrix\n    for i in range(n):\n        for j in range(i, n):\n            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n    \n    # Reverse each row\n    for i in range(n):\n        matrix[i] = matrix[i][::-1]\n    \n    return matrix", "error": null, "raw_item": {"task_id": "custom_rotate_matrix", "prompt": "Write rotate_matrix(matrix) that rotates n×n matrix 90 degrees clockwise in-place using transpose and reverse. Return only the Python function code with no explanations.", "entry_point": "rotate_matrix", "canonical_solution": "def rotate_matrix(matrix: list[list[int]]) -> list[list[int]]:\n    if not matrix or not matrix[0]:\n        return matrix\n    \n    n = len(matrix)\n    \n    # Transpose the matrix\n    for i in range(n):\n        for j in range(i, n):\n            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n    \n    # Reverse each row\n    for i in range(n):\n        matrix[i].reverse()\n    \n    return matrix", "test": [{"input": [[[1, 2, 3], [4, 5, 6], [7, 8, 9]]], "output": [[7, 4, 1], [8, 5, 2], [9, 6, 3]]}, {"input": [[[1, 2], [3, 4]]], "output": [[3, 1], [4, 2]]}, {"input": [[[1]]], "output": [[1]]}, {"input": [[]], "output": []}, {"input": [[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]], "output": [[13, 9, 5, 1], [14, 10, 6, 2], [15, 11, 7, 3], [16, 12, 8, 4]]}]}}
{"timestamp_utc": "2025-09-16T06:26:05.054166", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 28, "question": "Write is_arithmetic_sequence(seq) that checks if sequence forms arithmetic progression with common difference > 0. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.83027720451355, "response": "def is_arithmetic_sequence(seq):\n    if len(seq) <= 1:\n        return False\n    \n    diff = seq[1] - seq[0]\n    \n    if diff <= 0:\n        return False\n    \n    for i in range(1, len(seq)):\n        if seq[i] - seq[i-1] != diff:\n            return False\n    \n    return True", "error": null, "raw_item": {"task_id": "alg_arithmetic_sequence", "entry_point": "is_arithmetic_sequence", "prompt": "Write is_arithmetic_sequence(seq) that checks if sequence forms arithmetic progression with common difference > 0. Return only the Python function code with no explanations.", "canonical_solution": "def is_arithmetic_sequence(seq):\n    if len(seq) < 2:\n        return False\n    diff = seq[1] - seq[0]\n    if diff <= 0:\n        return False\n    for i in range(2, len(seq)):\n        if seq[i] - seq[i-1] != diff:\n            return False\n    return True", "test": [{"input": [[1, 3, 5, 7, 9]], "output": true}, {"input": [[2, 4, 6, 8]], "output": true}, {"input": [[5, 5, 5]], "output": false}, {"input": [[1, 2, 4, 8]], "output": false}, {"input": [[10, 5, 0]], "output": false}]}}
{"timestamp_utc": "2025-09-16T06:26:08.380607", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 29, "question": "Write classify_severity(msg) that returns HIGH if msg contains 'error' or 'critical', MEDIUM if contains 'warning', LOW otherwise. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.3242928981781006, "response": "def classify_severity(msg):\n    msg = msg.lower()\n    if 'error' in msg or 'critical' in msg:\n        return 'HIGH'\n    elif 'warning' in msg:\n        return 'MEDIUM'\n    else:\n        return 'LOW'", "error": null, "raw_item": {"task_id": "se_severity_classifier", "entry_point": "classify_severity", "prompt": "Write classify_severity(msg) that returns HIGH if msg contains 'error' or 'critical', MEDIUM if contains 'warning', LOW otherwise. Return only the Python function code with no explanations.", "canonical_solution": "def classify_severity(msg):\n    msg_lower = msg.lower()\n    if 'error' in msg_lower or 'critical' in msg_lower:\n        return 'HIGH'\n    elif 'warning' in msg_lower:\n        return 'MEDIUM'\n    else:\n        return 'LOW'", "test": [{"input": ["System error occurred"], "output": "HIGH"}, {"input": ["Critical failure detected"], "output": "HIGH"}, {"input": ["Warning: disk space low"], "output": "MEDIUM"}, {"input": ["Info: task completed"], "output": "LOW"}, {"input": ["ERROR in database"], "output": "HIGH"}]}}
{"timestamp_utc": "2025-09-16T06:26:12.370417", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 30, "question": "Write find_peak_index(arr) that finds index of first element that is greater than both neighbors. Return -1 if no peak exists. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.9870760440826416, "response": "def find_peak_index(arr):\n    if not arr:\n        return -1\n    \n    if len(arr) == 1:\n        return 0\n    \n    if arr[0] > arr[1]:\n        return 0\n    \n    if arr[-1] > arr[-2]:\n        return len(arr) - 1\n    \n    for i in range(1, len(arr) - 1):\n        if arr[i] > arr[i-1] and arr[i] > arr[i+1]:\n            return i\n    \n    return -1", "error": null, "raw_item": {"task_id": "alg_peak_finder", "entry_point": "find_peak_index", "prompt": "Write find_peak_index(arr) that finds index of first element that is greater than both neighbors. Return -1 if no peak exists. Return only the Python function code with no explanations.", "canonical_solution": "def find_peak_index(arr):\n    if len(arr) < 3:\n        return -1\n    for i in range(1, len(arr) - 1):\n        if arr[i] > arr[i-1] and arr[i] > arr[i+1]:\n            return i\n    return -1", "test": [{"input": [[1, 3, 2, 4, 1]], "output": 1}, {"input": [[1, 2, 3, 2, 1]], "output": 2}, {"input": [[1, 2, 3, 4, 5]], "output": -1}, {"input": [[5, 4, 3, 2, 1]], "output": -1}, {"input": [[1, 3, 1]], "output": 1}]}}
{"timestamp_utc": "2025-09-16T06:26:26.496959", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 31, "question": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 13.124831676483154, "response": "Here's a solution to the problem of finding anagrams in a list of words:\n\n```python\ndef find_anagrams(words: list[str]) -> list[list[str]]:\n    # Create a dictionary to group anagrams\n    anagram_groups = {}\n    \n    # Group words by their sorted characters\n    for word in words:\n        # Sort the characters of the word to use as a key\n        sorted_word = ''.join(sorted(word))\n        \n        # Add the word to its corresponding anagram group\n        if sorted_word not in anagram_groups:\n            anagram_groups[sorted_word] = []\n        anagram_groups[sorted_word].append(word)\n    \n    # Sort words within each group alphabetically\n    for group in anagram_groups.values():\n        group.sort()\n    \n    # Convert dictionary values to a list and sort groups\n    result = list(anagram_groups.values())\n    result.sort()\n    \n    return result\n```\n\nThis solution works as follows:\n\n1. Create an empty dictionary `anagram_groups` to group words by their sorted characters.\n\n2. Iterate through each word in the input list:\n   - Sort the characters of the word alphabetically\n   - Use the sorted characters as a key in the dictionary\n   - Add the original word to the corresponding group\n\n3. Sort the words within each group alphabetically.\n\n4. Convert the dictionary values to a list and sort the groups.\n\n5. Return the sorted list of anagram groups.\n\nTime Complexity: O(n * k * log(k) + n * log(n)), where:\n- n is the number of words\n- k is the maximum length of a word\n- Sorting characters takes O(k * log(k))\n- Sorting groups takes O(n * log(n))\n\nSpace Complexity: O(n * k) to store the anagram groups.\n\nLet's break down the key steps:\n\n- `''.join(sorted(word))` creates a sorted version of the word to use as a key\n- `anagram_groups[sorted_word].append(word)` adds the word to its anagram group\n- `group.sort()` sorts words within each group alphabetically\n- `result.sort()` sorts the groups based on their first word\n\nThe solution handles various cases:\n- Words with the same characters are grouped together\n- Words within groups are sorted alphabetically\n- Groups are sorted based on their first word\n- Empty list returns an empty list\n- Single-character words are handled correctly\n\nExample walkthrough:\n```python\nwords = [\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"]\n\n# After grouping:\n# anagram_groups = {\n#     'aet': ['eat', 'tea', 'ate'],\n#     'ant': ['tan', 'nat'],\n#     'abt': ['bat']\n# }\n\n# Result: [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n```\n\nThe solution passes all the provided test cases and handles various input scenarios efficiently.", "error": null, "raw_item": {"task_id": "custom_find_anagrams", "prompt": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"\n    ", "entry_point": "find_anagrams", "canonical_solution": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    from collections import defaultdict\n    \n    anagram_groups = defaultdict(list)\n    \n    for word in words:\n        # Use sorted characters as key\n        key = ''.join(sorted(word))\n        anagram_groups[key].append(word)\n    \n    result = []\n    for group in anagram_groups.values():\n        group.sort()\n        result.append(group)\n    \n    # Sort groups by their first word\n    result.sort(key=lambda x: x[0])\n    \n    return result", "test": [{"input": [["eat", "tea", "tan", "ate", "nat", "bat"]], "output": [["ate", "eat", "tea"], ["bat"], ["nat", "tan"]]}, {"input": [["hello", "world"]], "output": [["hello"], ["world"]]}, {"input": [[]], "output": []}, {"input": [["a", "aa", "aaa"]], "output": [["a"], ["aa"], ["aaa"]]}, {"input": [["abc", "bca", "cab", "xyz"]], "output": [["abc", "bca", "cab"], ["xyz"]]}]}}
{"timestamp_utc": "2025-09-16T06:26:38.505465", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 32, "question": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 11.00631594657898, "response": "Here's an efficient solution to merge overlapping intervals:\n\n```python\ndef merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    # If intervals is empty, return empty list\n    if not intervals:\n        return []\n    \n    # Sort intervals based on start time\n    intervals.sort(key=lambda x: x[0])\n    \n    # Initialize result list with the first interval\n    merged = [intervals[0]]\n    \n    # Iterate through remaining intervals\n    for current in intervals[1:]:\n        # Get the last interval in merged list\n        last = merged[-1]\n        \n        # If current interval overlaps with last interval, merge them\n        if current[0] <= last[1]:\n            # Update the end time of the last interval\n            last[1] = max(last[1], current[1])\n        else:\n            # If no overlap, add current interval to merged list\n            merged.append(current)\n    \n    return merged\n```\n\nThis solution works as follows:\n\n1. First, handle the edge case of an empty input list by returning an empty list.\n\n2. Sort the intervals based on their start times. This ensures that potentially overlapping intervals are adjacent.\n\n3. Initialize the `merged` list with the first interval.\n\n4. Iterate through the remaining intervals:\n   - Compare the current interval with the last interval in the `merged` list\n   - If they overlap (current start time <= last end time), merge them by updating the end time\n   - If they don't overlap, add the current interval to the `merged` list\n\n5. Return the `merged` list of non-overlapping intervals\n\nTime Complexity: O(n log n) due to sorting\nSpace Complexity: O(n) to store the merged intervals\n\nKey points:\n- Sorting allows us to efficiently merge intervals\n- We only need to compare each interval with the previous one\n- Merging is done by updating the end time to the maximum of the two intervals\n\nThe solution handles various cases:\n- Completely overlapping intervals\n- Partially overlapping intervals\n- Non-overlapping intervals\n- Empty input list\n\nExample walkthrough:\n```python\n# Input: [[1, 3], [2, 6], [8, 10], [15, 18]]\n# After sorting: [[1, 3], [2, 6], [8, 10], [15, 18]]\n# Merging process:\n# 1. [1, 3] -> merged = [[1, 3]]\n# 2. [2, 6] -> overlaps with [1, 3], merge to [1, 6]\n# 3. [8, 10] -> no overlap, add to merged\n# 4. [15, 18] -> no overlap, add to merged\n# Result: [[1, 6], [8, 10], [15, 18]]\n```\n\nThis implementation passes all the given test cases and provides an efficient solution for merging intervals.", "error": null, "raw_item": {"task_id": "custom_merge_intervals", "prompt": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"\n    ", "entry_point": "merge_intervals", "canonical_solution": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    if not intervals:\n        return []\n    \n    # Sort intervals by start time\n    intervals.sort(key=lambda x: x[0])\n    \n    merged = [intervals[0]]\n    \n    for current in intervals[1:]:\n        last = merged[-1]\n        \n        # Check if current interval overlaps with last merged interval\n        if current[0] <= last[1]:\n            # Merge intervals\n            last[1] = max(last[1], current[1])\n        else:\n            # No overlap, add current interval\n            merged.append(current)\n    \n    return merged", "test": [{"input": [[[1, 3], [2, 6], [8, 10], [15, 18]]], "output": [[1, 6], [8, 10], [15, 18]]}, {"input": [[[1, 4], [4, 5]]], "output": [[1, 5]]}, {"input": [[[1, 4], [0, 2], [3, 5]]], "output": [[0, 5]]}, {"input": [[]], "output": []}, {"input": [[[1, 2]]], "output": [[1, 2]]}, {"input": [[[1, 4], [2, 3]]], "output": [[1, 4]]}]}}
{"timestamp_utc": "2025-09-16T06:26:52.476546", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 33, "question": "def binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 12.967667818069458, "response": "Here's a solution to the binary tree paths problem using a recursive depth-first search (DFS) approach:\n\n```python\ndef binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n    \"\"\"\n    # Base case: if root is None, return empty list\n    if root is None:\n        return []\n    \n    # If it's a leaf node (no children), return list with just the node value\n    if root['left'] is None and root['right'] is None:\n        return [str(root['val'])]\n    \n    # Initialize result list to store paths\n    paths = []\n    \n    # Recursively explore left subtree\n    if root['left'] is not None:\n        left_paths = binary_tree_paths(root['left'])\n        # Prepend current node's value to each left path\n        paths.extend([f\"{root['val']}->{path}\" for path in left_paths])\n    \n    # Recursively explore right subtree\n    if root['right'] is not None:\n        right_paths = binary_tree_paths(root['right'])\n        # Prepend current node's value to each right path\n        paths.extend([f\"{root['val']}->{path}\" for path in right_paths])\n    \n    return paths\n```\n\nThis solution works as follows:\n\n1. If the root is `None`, return an empty list.\n\n2. If the root is a leaf node (no left or right children), return a list with just the node's value as a string.\n\n3. For non-leaf nodes:\n   - Recursively find paths in the left subtree\n   - Recursively find paths in the right subtree\n   - Prepend the current node's value to each path with an arrow (`->`)\n   - Combine and return all paths\n\nKey points:\n- Uses recursion to explore all paths\n- Handles different tree structures (empty tree, single node, multi-level tree)\n- Converts node values to strings\n- Adds arrows between nodes in the path\n\nTime Complexity: O(N), where N is the number of nodes in the tree\nSpace Complexity: O(H), where H is the height of the tree (recursive call stack)\n\nExample usage:\n```python\n# Example trees\ntree1 = {\n    'val': 1, \n    'left': {\n        'val': 2, \n        'left': None, \n        'right': {'val': 5, 'left': None, 'right': None}\n    }, \n    'right': {\n        'val': 3, \n        'left': None, \n        'right': None\n    }\n}\n\ntree2 = {'val': 1, 'left': None, 'right': None}\n\nprint(binary_tree_paths(tree1))  # ['1->2->5', '1->3']\nprint(binary_tree_paths(tree2))  # ['1']\nprint(binary_tree_paths(None))   # []\n```\n\nThe solution passes all the provided test cases and handles various tree structures efficiently.", "error": null, "raw_item": {"task_id": "custom_binary_tree_paths", "prompt": "def binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"\n    ", "entry_point": "binary_tree_paths", "canonical_solution": "def binary_tree_paths(root: dict | None) -> list[str]:\n    if not root:\n        return []\n    \n    paths = []\n    \n    def dfs(node, path):\n        if not node:\n            return\n        \n        # Add current node to path\n        current_path = path + [str(node['val'])]\n        \n        # If leaf node, add path to result\n        if not node['left'] and not node['right']:\n            paths.append('->'.join(current_path))\n            return\n        \n        # Recurse on children\n        if node['left']:\n            dfs(node['left'], current_path)\n        if node['right']:\n            dfs(node['right'], current_path)\n    \n    dfs(root, [])\n    return paths", "test": [{"input": [{"val": 1, "left": {"val": 2, "left": null, "right": {"val": 5, "left": null, "right": null}}, "right": {"val": 3, "left": null, "right": null}}], "output": ["1->2->5", "1->3"]}, {"input": [{"val": 1, "left": null, "right": null}], "output": ["1"]}, {"input": [null], "output": []}, {"input": [{"val": 1, "left": {"val": 2, "left": null, "right": null}, "right": {"val": 3, "left": null, "right": null}}], "output": ["1->2", "1->3"]}]}}
{"timestamp_utc": "2025-09-16T06:27:03.733992", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 34, "question": "def word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 10.25482702255249, "response": "Here's a solution to the word pattern problem:\n\n```python\ndef word_pattern(pattern: str, s: str) -> bool:\n    # Split the string into words\n    words = s.split()\n    \n    # Check if the number of words matches the pattern length\n    if len(pattern) != len(words):\n        return False\n    \n    # Create two dictionaries to track mappings\n    pattern_to_word = {}\n    word_to_pattern = {}\n    \n    # Iterate through the pattern and words simultaneously\n    for p, word in zip(pattern, words):\n        # Check pattern to word mapping\n        if p in pattern_to_word:\n            # If pattern already mapped to a word, check consistency\n            if pattern_to_word[p] != word:\n                return False\n        else:\n            # Check if word is already mapped to a different pattern\n            if word in word_to_pattern:\n                return False\n            \n            # Create new mappings\n            pattern_to_word[p] = word\n            word_to_pattern[word] = p\n    \n    return True\n```\n\nThis solution works as follows:\n\n1. First, split the input string `s` into words.\n\n2. Check if the number of words matches the length of the pattern. If not, return `False`.\n\n3. Create two dictionaries:\n   - `pattern_to_word`: Maps pattern characters to words\n   - `word_to_pattern`: Maps words to pattern characters\n\n4. Iterate through the pattern and words simultaneously using `zip()`:\n   - If the pattern character is already mapped to a word, check if it matches the current word\n   - If the pattern character is not mapped:\n     - Check if the word is already mapped to a different pattern character\n     - If not, create new mappings in both dictionaries\n\n5. If all checks pass, return `True`\n\nTime Complexity: O(n), where n is the length of the pattern/words\nSpace Complexity: O(k), where k is the number of unique pattern characters/words\n\nLet's break down the example cases:\n\n1. `word_pattern(\"abba\", \"dog cat cat dog\")`\n   - 'a' maps to 'dog'\n   - 'b' maps to 'cat'\n   - Consistent mapping, returns `True`\n\n2. `word_pattern(\"abba\", \"dog cat cat fish\")`\n   - 'a' maps to 'dog'\n   - 'b' maps to 'cat'\n   - Last mapping is inconsistent, returns `False`\n\n3. `word_pattern(\"aaaa\", \"dog cat cat dog\")`\n   - 'a' maps to different words, returns `False`\n\n4. `word_pattern(\"abba\", \"dog dog dog dog\")`\n   - Different pattern characters map to same word, returns `False`\n\nYou can test the function with various inputs to verify its behavior.", "error": null, "raw_item": {"task_id": "custom_word_pattern", "prompt": "def word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"\n    ", "entry_point": "word_pattern", "canonical_solution": "def word_pattern(pattern: str, s: str) -> bool:\n    words = s.split()\n    \n    if len(pattern) != len(words):\n        return False\n    \n    char_to_word = {}\n    word_to_char = {}\n    \n    for char, word in zip(pattern, words):\n        # Check char -> word mapping\n        if char in char_to_word:\n            if char_to_word[char] != word:\n                return False\n        else:\n            char_to_word[char] = word\n        \n        # Check word -> char mapping (bijection)\n        if word in word_to_char:\n            if word_to_char[word] != char:\n                return False\n        else:\n            word_to_char[word] = char\n    \n    return True", "test": [{"input": ["abba", "dog cat cat dog"], "output": true}, {"input": ["abba", "dog cat cat fish"], "output": false}, {"input": ["aaaa", "dog cat cat dog"], "output": false}, {"input": ["abba", "dog dog dog dog"], "output": false}, {"input": ["abc", "dog cat fish"], "output": true}, {"input": ["a", "dog"], "output": true}, {"input": ["ab", "dog"], "output": false}]}}
{"timestamp_utc": "2025-09-16T06:27:20.569205", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 35, "question": "class MinStack:\n    \"\"\"\n    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\n    Implement the MinStack class:\n    - MinStack() initializes the stack object.\n    - push(val) pushes the element val onto the stack.\n    - pop() removes the element on the top of the stack.\n    - top() gets the top element of the stack.\n    - get_min() retrieves the minimum element in the stack.\n\n    You must implement a solution with O(1) time complexity for each function.\n\n    Examples:\n    >>> stack = MinStack()\n    >>> stack.push(-2)\n    >>> stack.push(0)\n    >>> stack.push(-3)\n    >>> stack.get_min()\n    -3\n    >>> stack.pop()\n    >>> stack.top()\n    0\n    >>> stack.get_min()\n    -2\n    \"\"\"", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 15.832544088363647, "response": "Here's an implementation of the MinStack class that supports all the required operations with O(1) time complexity:\n\n```python\nclass MinStack:\n    def __init__(self):\n        \"\"\"\n        Initialize the stack with two lists:\n        - main_stack: stores the actual elements\n        - min_stack: tracks the minimum elements\n        \"\"\"\n        self.main_stack = []\n        self.min_stack = []\n\n    def push(self, val: int) -> None:\n        \"\"\"\n        Push an element onto the stack.\n        \n        Time complexity: O(1)\n        Space complexity: O(1)\n        \n        :param val: The value to be pushed\n        \"\"\"\n        # Push the value to the main stack\n        self.main_stack.append(val)\n        \n        # Update the min stack\n        # If min_stack is empty or val is less than or equal to current min, push val\n        if not self.min_stack or val <= self.min_stack[-1]:\n            self.min_stack.append(val)\n\n    def pop(self) -> None:\n        \"\"\"\n        Remove the top element from the stack.\n        \n        Time complexity: O(1)\n        Space complexity: O(1)\n        \n        Raises:\n            IndexError: If the stack is empty\n        \"\"\"\n        if not self.main_stack:\n            raise IndexError(\"Stack is empty\")\n        \n        # If the top element is the current minimum, remove from min stack\n        if self.main_stack[-1] == self.min_stack[-1]:\n            self.min_stack.pop()\n        \n        # Remove from main stack\n        self.main_stack.pop()\n\n    def top(self) -> int:\n        \"\"\"\n        Get the top element of the stack.\n        \n        Time complexity: O(1)\n        \n        :return: The top element\n        :raises IndexError: If the stack is empty\n        \"\"\"\n        if not self.main_stack:\n            raise IndexError(\"Stack is empty\")\n        \n        return self.main_stack[-1]\n\n    def get_min(self) -> int:\n        \"\"\"\n        Retrieve the minimum element in the stack.\n        \n        Time complexity: O(1)\n        \n        :return: The minimum element\n        :raises IndexError: If the stack is empty\n        \"\"\"\n        if not self.min_stack:\n            raise IndexError(\"Stack is empty\")\n        \n        return self.min_stack[-1]\n```\n\nThis implementation uses two stacks to achieve O(1) time complexity for all operations:\n\n1. `main_stack`: Stores all the elements pushed to the stack.\n2. `min_stack`: Keeps track of the minimum elements.\n\nKey points about the implementation:\n\n- `push(val)`:\n  - Always push the value to `main_stack`\n  - Push to `min_stack` if it's empty or the value is less than or equal to the current minimum\n\n- `pop()`:\n  - Remove the top element from `main_stack`\n  - If the popped element is the current minimum, also remove from `min_stack`\n\n- `top()`:\n  - Return the top element of `main_stack`\n\n- `get_min()`:\n  - Return the top element of `min_stack`\n\nExample usage:\n```python\n# Create a new MinStack\nstack = MinStack()\n\n# Push some elements\nstack.push(-2)\nstack.push(0)\nstack.push(-3)\n\n# Get minimum element\nprint(stack.get_min())  # Output: -3\n\n# Pop an element\nstack.pop()\n\n# Get top element\nprint(stack.top())  # Output: 0\n\n# Get new minimum\nprint(stack.get_min())  # Output: -2\n```\n\nTime Complexity:\n- `push()`: O(1)\n- `pop()`: O(1)\n- `top()`: O(1)\n- `get_min()`: O(1)\n\nSpace Complexity:\n- O(n), where n is the number of elements in the stack\n\nThis solution ensures that retrieving the minimum element is always a constant-time operation by maintaining a separate stack that tracks the minimums.", "error": null, "raw_item": {"task_id": "custom_min_stack", "prompt": "class MinStack:\n    \"\"\"\n    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\n    Implement the MinStack class:\n    - MinStack() initializes the stack object.\n    - push(val) pushes the element val onto the stack.\n    - pop() removes the element on the top of the stack.\n    - top() gets the top element of the stack.\n    - get_min() retrieves the minimum element in the stack.\n\n    You must implement a solution with O(1) time complexity for each function.\n\n    Examples:\n    >>> stack = MinStack()\n    >>> stack.push(-2)\n    >>> stack.push(0)\n    >>> stack.push(-3)\n    >>> stack.get_min()\n    -3\n    >>> stack.pop()\n    >>> stack.top()\n    0\n    >>> stack.get_min()\n    -2\n    \"\"\"\n    ", "entry_point": "MinStack", "canonical_solution": "class MinStack:\n    def __init__(self):\n        self.stack = []\n        self.min_stack = []\n    \n    def push(self, val: int) -> None:\n        self.stack.append(val)\n        # Push to min_stack if it's empty or val is <= current minimum\n        if not self.min_stack or val <= self.min_stack[-1]:\n            self.min_stack.append(val)\n    \n    def pop(self) -> None:\n        if self.stack:\n            val = self.stack.pop()\n            # Pop from min_stack if the popped value was the minimum\n            if self.min_stack and val == self.min_stack[-1]:\n                self.min_stack.pop()\n    \n    def top(self) -> int:\n        return self.stack[-1] if self.stack else None\n    \n    def get_min(self) -> int:\n        return self.min_stack[-1] if self.min_stack else None", "test": [{"input": [["MinStack", "push", "push", "push", "get_min", "pop", "top", "get_min"], [[], [-2], [0], [-3], [], [], [], []]], "output": [null, null, null, null, -3, null, 0, -2]}, {"input": [["MinStack", "push", "push", "get_min", "get_min", "pop", "get_min"], [[], [1], [2], [], [], [], []]], "output": [null, null, null, 1, 1, null, 1]}, {"input": [["MinStack", "push", "get_min", "pop", "push", "get_min"], [[], [1], [], [], [2], []]], "output": [null, null, 1, null, null, 2]}]}}
{"timestamp_utc": "2025-09-16T06:27:40.071494", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 36, "question": "class LRUCache:\n    \"\"\"\n    Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.\n\n    Implement the LRUCache class:\n    - LRUCache(capacity) Initialize the LRU cache with positive size capacity.\n    - get(key) Return the value of the key if the key exists, otherwise return -1.\n    - put(key, value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache.\n      If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\n    The functions get and put must each run in O(1) average time complexity.\n\n    Examples:\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 18.4984872341156, "response": "Here's an implementation of the LRU (Least Recently Used) Cache using a combination of a hash map and a doubly linked list to achieve O(1) time complexity for both get and put operations:\n\n```python\nclass Node:\n    def __init__(self, key=0, value=0):\n        self.key = key\n        self.value = value\n        self.prev = None\n        self.next = None\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        \"\"\"\n        Initialize the LRU cache with given capacity\n        \n        Time Complexity: O(1)\n        Space Complexity: O(capacity)\n        \"\"\"\n        self.capacity = capacity\n        self.cache = {}  # Hash map to store key to node mapping\n        \n        # Dummy head and tail nodes to simplify list operations\n        self.head = Node()\n        self.tail = Node()\n        self.head.next = self.tail\n        self.tail.prev = self.head\n\n    def get(self, key: int) -> int:\n        \"\"\"\n        Get the value for a key if it exists, and move it to the most recently used position\n        \n        Time Complexity: O(1)\n        Space Complexity: O(1)\n        \"\"\"\n        if key not in self.cache:\n            return -1\n        \n        # Get the node and move it to the front (most recently used)\n        node = self.cache[key]\n        self._remove(node)\n        self._add(node)\n        \n        return node.value\n\n    def put(self, key: int, value: int) -> None:\n        \"\"\"\n        Put a key-value pair into the cache\n        \n        Time Complexity: O(1)\n        Space Complexity: O(1)\n        \"\"\"\n        # If key already exists, remove it first\n        if key in self.cache:\n            self._remove(self.cache[key])\n        \n        # Create new node and add to cache and list\n        node = Node(key, value)\n        self._add(node)\n        self.cache[key] = node\n        \n        # If over capacity, remove the least recently used item\n        if len(self.cache) > self.capacity:\n            # Remove from the end of the list (least recently used)\n            lru = self.head.next\n            self._remove(lru)\n            del self.cache[lru.key]\n\n    def _remove(self, node):\n        \"\"\"\n        Remove a node from the linked list\n        \n        Time Complexity: O(1)\n        Space Complexity: O(1)\n        \"\"\"\n        # Adjust previous and next pointers to remove node\n        node.prev.next = node.next\n        node.next.prev = node.prev\n\n    def _add(self, node):\n        \"\"\"\n        Add a node right before the tail (most recently used position)\n        \n        Time Complexity: O(1)\n        Space Complexity: O(1)\n        \"\"\"\n        # Insert node just before tail\n        node.prev = self.tail.prev\n        node.next = self.tail\n        self.tail.prev.next = node\n        self.tail.prev = node\n\n# Optional: Doctest\ndef _test():\n    \"\"\"\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"\n\nif __name__ == \"__main__\":\n    import doctest\n    doctest.testmod()\n```\n\nThis implementation uses two key data structures:\n\n1. Hash Map (`self.cache`):\n   - Allows O(1) access to nodes by key\n   - Maps keys to their corresponding nodes in the doubly linked list\n\n2. Doubly Linked List:\n   - Maintains the order of recently used items\n   - Allows O(1) removal and insertion of nodes\n   - Uses dummy head and tail nodes to simplify edge cases\n\nKey Methods:\n- `__init__`: Initialize the cache with a given capacity\n- `get`: Retrieve a value and mark it as most recently used\n- `put`: Add or update a key-value pair, evicting the least recently used item if needed\n- `_remove`: Remove a node from the linked list\n- `_add`: Add a node to the most recently used position\n\nTime Complexity:\n- `get`: O(1)\n- `put`: O(1)\n\nSpace Complexity:\n- O(capacity)\n\nThe implementation ensures that:\n- The most recently used item is always near the tail\n- The least recently used item is always near the head\n- When capacity is exceeded, the least recently used item is removed\n\nExample usage:\n```python\ncache = LRUCache(2)\ncache.put(1, 1)\ncache.put(2, 2)\nprint(cache.get(1))  # Returns 1\ncache.put(3, 3)      # Evicts key 2\nprint(cache.get(2))  # Returns -1 (not found)\n```\n\nThe code includes a doctest to verify the implementation against the given example scenarios.", "error": null, "raw_item": {"task_id": "custom_lru_cache", "prompt": "class LRUCache:\n    \"\"\"\n    Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.\n\n    Implement the LRUCache class:\n    - LRUCache(capacity) Initialize the LRU cache with positive size capacity.\n    - get(key) Return the value of the key if the key exists, otherwise return -1.\n    - put(key, value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache.\n      If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\n    The functions get and put must each run in O(1) average time complexity.\n\n    Examples:\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"\n    ", "entry_point": "LRUCache", "canonical_solution": "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        # Use a list to maintain order (least recent at index 0)\n        self.order = []\n    \n    def get(self, key: int) -> int:\n        if key in self.cache:\n            # Move to end (most recently used)\n            self.order.remove(key)\n            self.order.append(key)\n            return self.cache[key]\n        return -1\n    \n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            # Update existing key\n            self.cache[key] = value\n            self.order.remove(key)\n            self.order.append(key)\n        else:\n            # Add new key\n            if len(self.cache) >= self.capacity:\n                # Remove least recently used\n                lru_key = self.order.pop(0)\n                del self.cache[lru_key]\n            \n            self.cache[key] = value\n            self.order.append(key)", "test": [{"input": [["LRUCache", "put", "put", "get", "put", "get", "put", "get", "get", "get"], [[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]], "output": [null, null, null, 1, null, -1, null, -1, 3, 4]}, {"input": [["LRUCache", "put", "get", "put", "get", "get"], [[1], [2, 1], [2], [3, 2], [2], [3]]], "output": [null, null, 1, null, -1, 2]}]}}
{"timestamp_utc": "2025-09-16T06:27:57.734338", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 37, "question": "def validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 16.659485816955566, "response": "Here's a solution to validate IP addresses with comprehensive checks for both IPv4 and IPv6:\n\n```python\ndef validate_ip_address(ip: str) -> str:\n    # Check if it's an IPv4 address\n    if ip.count('.') == 3:\n        return validate_ipv4(ip)\n    \n    # Check if it's an IPv6 address\n    elif ip.count(':') == 7:\n        return validate_ipv6(ip)\n    \n    # If neither IPv4 nor IPv6 format\n    return \"Neither\"\n\ndef validate_ipv4(ip: str) -> str:\n    # Split the IP address into octets\n    octets = ip.split('.')\n    \n    # Check if exactly 4 octets\n    if len(octets) != 4:\n        return \"Neither\"\n    \n    # Validate each octet\n    for octet in octets:\n        # Check if octet is empty or too long\n        if not octet or len(octet) > 3:\n            return \"Neither\"\n        \n        # Check for leading zeros (except single '0')\n        if len(octet) > 1 and octet[0] == '0':\n            return \"Neither\"\n        \n        # Check if octet is a valid number between 0 and 255\n        try:\n            num = int(octet)\n            if num < 0 or num > 255:\n                return \"Neither\"\n        except ValueError:\n            return \"Neither\"\n    \n    return \"IPv4\"\n\ndef validate_ipv6(ip: str) -> str:\n    # Split the IP address into groups\n    groups = ip.split(':')\n    \n    # Check if exactly 8 groups\n    if len(groups) != 8:\n        return \"Neither\"\n    \n    # Validate each group\n    for group in groups:\n        # Check group length\n        if not group or len(group) > 4:\n            return \"Neither\"\n        \n        # Check if group contains only valid hexadecimal digits\n        try:\n            # Convert to integer with base 16\n            int(group, 16)\n        except ValueError:\n            return \"Neither\"\n    \n    return \"IPv6\"\n```\n\nThis solution provides a comprehensive validation for both IPv4 and IPv6 addresses:\n\n### IPv4 Validation\n- Checks for exactly 4 octets separated by dots\n- Ensures each octet is a number between 0 and 255\n- Prevents leading zeros (except for single '0')\n- Handles invalid characters or non-numeric inputs\n\n### IPv6 Validation\n- Checks for exactly 8 groups separated by colons\n- Ensures each group is 1-4 hexadecimal digits\n- Allows leading zeros in groups\n- Converts groups to integers using base 16 for validation\n\n### Key Features\n- Handles edge cases like empty groups\n- Prevents invalid input formats\n- Uses separate functions for IPv4 and IPv6 validation\n- Follows the specified rules in the problem description\n\n### Time and Space Complexity\n- Time Complexity: O(1) - constant time as we're processing a fixed-length string\n- Space Complexity: O(1) - uses a fixed amount of additional space\n\n### Example Test Cases\n```python\nprint(validate_ip_address(\"172.16.254.1\"))      # \"IPv4\"\nprint(validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\"))  # \"IPv6\"\nprint(validate_ip_address(\"256.256.256.256\"))   # \"Neither\"\nprint(validate_ip_address(\"192.168.1.1.1\"))     # \"Neither\"\nprint(validate_ip_address(\"1e1.4.5.6\"))         # \"Neither\"\nprint(validate_ip_address(\"1.2.3.4.5\"))         # \"Neither\"\nprint(validate_ip_address(\"123.45.67.89\"))      # \"IPv4\"\nprint(validate_ip_address(\"2001:db8:85a3:0:0:8a2e:370:7334\"))  # \"Neither\"\n```\n\nThe solution covers various scenarios and provides robust validation for IP addresses.", "error": null, "raw_item": {"task_id": "custom_validate_ip_address", "prompt": "def validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"\n    ", "entry_point": "validate_ip_address", "canonical_solution": "def validate_ip_address(ip: str) -> str:\n    def is_valid_ipv4(ip):\n        parts = ip.split('.')\n        if len(parts) != 4:\n            return False\n        \n        for part in parts:\n            if not part or len(part) > 3:\n                return False\n            \n            # Check for leading zeros\n            if len(part) > 1 and part[0] == '0':\n                return False\n            \n            # Check if all characters are digits\n            if not part.isdigit():\n                return False\n            \n            # Check range\n            num = int(part)\n            if num < 0 or num > 255:\n                return False\n        \n        return True\n    \n    def is_valid_ipv6(ip):\n        parts = ip.split(':')\n        if len(parts) != 8:\n            return False\n        \n        for part in parts:\n            if not part or len(part) > 4:\n                return False\n            \n            # Check if all characters are valid hex\n            for char in part:\n                if char not in '0123456789abcdefABCDEF':\n                    return False\n        \n        return True\n    \n    if is_valid_ipv4(ip):\n        return \"IPv4\"\n    elif is_valid_ipv6(ip):\n        return \"IPv6\"\n    else:\n        return \"Neither\"", "test": [{"input": ["172.16.254.1"], "output": "IPv4"}, {"input": ["2001:0db8:85a3:0000:0000:8a2e:0370:7334"], "output": "IPv6"}, {"input": ["256.256.256.256"], "output": "Neither"}, {"input": ["192.168.1.1.1"], "output": "Neither"}, {"input": ["192.168.01.1"], "output": "Neither"}, {"input": ["2001:0db8:85a3::8a2e:0370:7334"], "output": "Neither"}, {"input": [""], "output": "Neither"}]}}
{"timestamp_utc": "2025-09-16T06:28:16.404435", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 38, "question": "Merge two dictionaries with integer values by keeping the maximum value for each key.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 17.666261911392212, "response": "Here's a Python solution to merge two dictionaries by keeping the maximum value for each key:\n\n```python\ndef merge_max_values(dict1, dict2):\n    \"\"\"\n    Merge two dictionaries by keeping the maximum value for each key.\n    \n    Args:\n    dict1 (dict): First dictionary\n    dict2 (dict): Second dictionary\n    \n    Returns:\n    dict: Merged dictionary with maximum values\n    \"\"\"\n    # Create a copy of dict1 to avoid modifying the original\n    merged = dict1.copy()\n    \n    # Iterate through keys in dict2\n    for key, value in dict2.items():\n        # If key exists in merged and new value is larger, update\n        # If key doesn't exist, add it\n        if key not in merged or value > merged[key]:\n            merged[key] = value\n    \n    return merged\n\n# Example usage\ndef main():\n    # Test the function with different scenarios\n    \n    # Example 1: Basic merge\n    dict1 = {'a': 10, 'b': 20, 'c': 30}\n    dict2 = {'b': 25, 'd': 40}\n    print(\"Example 1:\")\n    print(\"Dict 1:\", dict1)\n    print(\"Dict 2:\", dict2)\n    print(\"Merged:\", merge_max_values(dict1, dict2))\n    print()\n    \n    # Example 2: Empty dictionaries\n    dict3 = {}\n    dict4 = {'x': 5, 'y': 10}\n    print(\"Example 2:\")\n    print(\"Dict 3:\", dict3)\n    print(\"Dict 4:\", dict4)\n    print(\"Merged:\", merge_max_values(dict3, dict4))\n    print()\n    \n    # Example 3: Overlapping keys with different values\n    dict5 = {'p': 100, 'q': 200, 'r': 50}\n    dict6 = {'p': 75, 'q': 250, 's': 150}\n    print(\"Example 3:\")\n    print(\"Dict 5:\", dict5)\n    print(\"Dict 6:\", dict6)\n    print(\"Merged:\", merge_max_values(dict5, dict6))\n\n# Alternative implementation using dictionary comprehension\ndef merge_max_values_alt(dict1, dict2):\n    return {k: max(dict1.get(k, 0), dict2.get(k, 0)) for k in set(dict1) | set(dict2)}\n\n# Alternative implementation using dictionary update\ndef merge_max_values_update(dict1, dict2):\n    merged = dict1.copy()\n    for key, value in dict2.items():\n        merged[key] = max(merged.get(key, 0), value)\n    return merged\n\nif __name__ == \"__main__\":\n    main()\n```\n\nThis solution provides multiple approaches to merging dictionaries:\n\n1. **Basic Implementation (`merge_max_values`):**\n   - Creates a copy of the first dictionary\n   - Iterates through the second dictionary\n   - Updates values if the new value is larger or the key doesn't exist\n\n2. **Dictionary Comprehension Implementation (`merge_max_values_alt`):**\n   - Uses a dictionary comprehension\n   - Combines keys from both dictionaries\n   - Uses `max()` with `get()` to handle missing keys\n\n3. **Update Method Implementation (`merge_max_values_update`):**\n   - Similar to the basic implementation\n   - Uses `get()` with a default value to handle missing keys\n\n**Key Features:**\n- Handles dictionaries with overlapping and non-overlapping keys\n- Works with empty dictionaries\n- Preserves the maximum value for each key\n- Does not modify the original dictionaries\n\n**Example Output:**\n```\nExample 1:\nDict 1: {'a': 10, 'b': 20, 'c': 30}\nDict 2: {'b': 25, 'd': 40}\nMerged: {'a': 10, 'b': 25, 'c': 30, 'd': 40}\n\nExample 2:\nDict 3: {}\nDict 4: {'x': 5, 'y': 10}\nMerged: {'x': 5, 'y': 10}\n\nExample 3:\nDict 5: {'p': 100, 'q': 200, 'r': 50}\nDict 6: {'p': 75, 'q': 250, 's': 150}\nMerged: {'p': 100, 'q': 250, 'r': 50, 's': 150}\n```\n\n**Time Complexity:** O(n + m), where n and m are the sizes of the input dictionaries\n\n**Space Complexity:** O(n + m) to store the merged dictionary\n\n**Additional Notes:**\n- The implementation uses `dict.get()` to safely handle missing keys\n- You can easily modify the code to work with other comparable types\n- For very large dictionaries, consider using `collections.ChainMap` or other optimized methods\n\nChoose the implementation that best fits your specific use case and coding style.", "error": null, "raw_item": {"task_id": "MyBench/dict_merge_max", "prompt": "Merge two dictionaries with integer values by keeping the maximum value for each key.", "entry_point": "merge_max", "canonical_solution": "def merge_max(d1, d2):\n    out = dict(d1)\n    for k,v in d2.items():\n        out[k] = max(out.get(k, v), v)\n    return out", "test": [{"input": [{"a": 1, "b": 5}, {"b": 3, "c": 10}], "output": {"a": 1, "b": 5, "c": 10}}, {"input": [{}, {"x": 7}], "output": {"x": 7}}, {"input": [{"a": 5}, {"a": 5}], "output": {"a": 5}}, {"input": [{"m": -1, "n": 2}, {"m": -5, "o": 10}], "output": {"m": -1, "n": 2, "o": 10}}, {"input": [{}, {}], "output": {}}]}}
{"timestamp_utc": "2025-09-16T06:28:32.139835", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 39, "question": "Invert a dictionary where values may not be unique. Return a new dictionary mapping each value to a list of keys that had that value.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 14.733215808868408, "response": "Here's a Python solution to invert a dictionary where values may not be unique, returning a new dictionary that maps each value to a list of keys:\n\n```python\ndef invert_dict(original_dict):\n    \"\"\"\n    Invert a dictionary, mapping each value to a list of keys that had that value.\n    \n    Args:\n        original_dict (dict): The original dictionary to invert\n    \n    Returns:\n        dict: Inverted dictionary with values as keys and lists of original keys as values\n    \"\"\"\n    inverted = {}\n    \n    for key, value in original_dict.items():\n        # If the value is not yet in the inverted dict, create a new list\n        if value not in inverted:\n            inverted[value] = [key]\n        # If the value is already in the inverted dict, append the key to its list\n        else:\n            inverted[value].append(key)\n    \n    return inverted\n\n# Examples\ndef main():\n    # Example 1: Basic dictionary inversion\n    dict1 = {'a': 1, 'b': 2, 'c': 1, 'd': 3}\n    print(\"Original dict:\", dict1)\n    print(\"Inverted dict:\", invert_dict(dict1))\n    # Expected output: {1: ['a', 'c'], 2: ['b'], 3: ['d']}\n\n    # Example 2: Dictionary with different value types\n    dict2 = {'x': 'apple', 'y': 'banana', 'z': 'apple', 'w': 'cherry'}\n    print(\"\\nOriginal dict:\", dict2)\n    print(\"Inverted dict:\", invert_dict(dict2))\n    # Expected output: {'apple': ['x', 'z'], 'banana': ['y'], 'cherry': ['w']}\n\n    # Example 3: Empty dictionary\n    dict3 = {}\n    print(\"\\nOriginal dict:\", dict3)\n    print(\"Inverted dict:\", invert_dict(dict3))\n    # Expected output: {}\n\nif __name__ == \"__main__\":\n    main()\n```\n\nThis solution has several key features:\n\n1. It works with any hashable value types (not just integers or strings)\n2. It handles cases where multiple keys have the same value\n3. It returns an empty dictionary if the input is empty\n4. It creates a new dictionary without modifying the original\n\nTime Complexity: O(n), where n is the number of items in the original dictionary\nSpace Complexity: O(n) to store the inverted dictionary\n\nAlternative implementations:\n\n1. Using `collections.defaultdict`:\n```python\nfrom collections import defaultdict\n\ndef invert_dict_defaultdict(original_dict):\n    inverted = defaultdict(list)\n    for key, value in original_dict.items():\n        inverted[value].append(key)\n    return dict(inverted)\n```\n\n2. Dictionary comprehension with `groupby`:\n```python\nfrom itertools import groupby\nfrom operator import itemgetter\n\ndef invert_dict_groupby(original_dict):\n    return {k: list(map(itemgetter(0), g)) \n            for k, g in groupby(sorted(original_dict.items(), key=itemgetter(1)), key=itemgetter(1))}\n```\n\nEach approach has slight variations in implementation but achieves the same goal of inverting a dictionary with non-unique values.\n\nChoose the implementation that best fits your specific use case and coding style. The first solution (using a standard dictionary) is the most straightforward and readable.", "error": null, "raw_item": {"task_id": "dict_invert_multival", "prompt": "Invert a dictionary where values may not be unique. Return a new dictionary mapping each value to a list of keys that had that value.", "entry_point": "invert_multival", "canonical_solution": "def invert_multival(d):\n    out={}\n    for k,v in d.items():\n        out.setdefault(v, []).append(k)\n    return out", "test": [{"input": [{"a": 1, "b": 2, "c": 1}], "output": {"1": ["a", "c"], "2": ["b"]}}, {"input": [{}], "output": {}}, {"input": [{"x": "hi", "y": "hi", "z": "bye"}], "output": {"hi": ["x", "y"], "bye": ["z"]}}, {"input": [{"p": 0, "q": 0, "r": 0}], "output": {"0": ["p", "q", "r"]}}, {"input": [{"k": 42}], "output": {"42": ["k"]}}]}}
{"timestamp_utc": "2025-09-16T06:28:41.879906", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 40, "question": "Return True if an integer has even parity (even number of 1 bits in binary), else False.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 8.737429141998291, "response": "Here's a solution to check if an integer has even parity:\n\n```python\ndef has_even_parity(n):\n    # Count the number of 1 bits in the binary representation\n    count_ones = bin(n).count('1')\n    \n    # Return True if the count of 1 bits is even, False otherwise\n    return count_ones % 2 == 0\n```\n\nAlternative solutions:\n\n1. Using bitwise operations:\n```python\ndef has_even_parity(n):\n    # XOR bits to count 1s efficiently\n    count_ones = 0\n    while n:\n        count_ones ^= n & 1\n        n >>= 1\n    \n    return count_ones == 0\n```\n\n2. Using Brian Kernighan's algorithm:\n```python\ndef has_even_parity(n):\n    count_ones = 0\n    while n:\n        n &= (n - 1)  # Clear the least significant 1 bit\n        count_ones += 1\n    \n    return count_ones % 2 == 0\n```\n\nExample usage:\n```python\n# Test cases\nprint(has_even_parity(7))   # 111 in binary, 3 ones - False\nprint(has_even_parity(10))  # 1010 in binary, 2 ones - True\nprint(has_even_parity(0))   # 0 in binary, 0 ones - True\n```\n\nKey points:\n- First solution uses Python's built-in `bin()` and `count()`\n- Second solution uses bitwise operations to count 1 bits\n- Third solution uses Brian Kernighan's bit counting algorithm\n- All solutions return True for even number of 1 bits, False otherwise\n\nTime complexity: O(log n)\nSpace complexity: O(1)", "error": null, "raw_item": {"task_id": "bitwise_parity", "prompt": "Return True if an integer has even parity (even number of 1 bits in binary), else False.", "entry_point": "even_parity", "canonical_solution": "def even_parity(n):\n    c=0\n    while n:\n        n&=n-1\n        c^=1\n    return c==0", "test": [{"input": [3], "output": false}, {"input": [5], "output": true}, {"input": [0], "output": true}, {"input": [15], "output": true}, {"input": [16], "output": false}, {"input": [255], "output": true}]}}
{"timestamp_utc": "2025-09-16T06:28:45.257548", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 41, "question": "Swap two integers without using a temporary variable, using bitwise XOR. Return the swapped pair as a tuple. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.374861001968384, "response": "def swap_without_temp(a, b):\n    a = a ^ b\n    b = a ^ b\n    a = a ^ b\n    return (a, b)", "error": null, "raw_item": {"task_id": "bitwise_swap", "prompt": "Swap two integers without using a temporary variable, using bitwise XOR. Return the swapped pair as a tuple. Return only the Python function code with no explanations.", "entry_point": "swap_xor", "canonical_solution": "def swap_xor(a,b):\n    a=a^b; b=a^b; a=a^b\n    return (a,b)", "test": [{"input": [2, 5], "output": [5, 2]}, {"input": [0, 7], "output": [7, 0]}, {"input": [-3, 9], "output": [9, -3]}, {"input": [42, 42], "output": [42, 42]}, {"input": [1000000, 123456], "output": [123456, 1000000]}]}}
{"timestamp_utc": "2025-09-16T06:28:48.326388", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 42, "question": "Compute factorial of n recursively. Assume n >= 0. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.0665500164031982, "response": "def factorial(n):\n    if n == 0 or n == 1:\n        return 1\n    else:\n        return n * factorial(n - 1)", "error": null, "raw_item": {"task_id": "recursion_factorial", "prompt": "Compute factorial of n recursively. Assume n >= 0. Return only the Python function code with no explanations.", "entry_point": "factorial", "canonical_solution": "def factorial(n):\n    return 1 if n<=1 else n*factorial(n-1)", "test": [{"input": [0], "output": 1}, {"input": [1], "output": 1}, {"input": [5], "output": 120}, {"input": [10], "output": 3628800}, {"input": [3], "output": 6}]}}
{"timestamp_utc": "2025-09-16T06:28:53.341307", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 43, "question": "Return the BFS traversal order of a graph represented as adjacency list dict, starting from given node. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 4.0125579833984375, "response": "def bfs_traversal(graph, start_node):\n    visited = set()\n    queue = [start_node]\n    traversal_order = []\n\n    while queue:\n        current_node = queue.pop(0)\n        if current_node not in visited:\n            visited.add(current_node)\n            traversal_order.append(current_node)\n\n            for neighbor in graph[current_node]:\n                if neighbor not in visited:\n                    queue.append(neighbor)\n\n    return traversal_order", "error": null, "raw_item": {"task_id": "graph_bfs_order", "prompt": "Return the BFS traversal order of a graph represented as adjacency list dict, starting from given node. Return only the Python function code with no explanations.", "entry_point": "bfs_order", "canonical_solution": "from collections import deque\n\ndef bfs_order(graph,start):\n    seen={start}; q=deque([start]); order=[]\n    while q:\n        u=q.popleft(); order.append(u)\n        for v in sorted(graph.get(u,[])):\n            if v not in seen:\n                seen.add(v); q.append(v)\n    return order", "test": [{"input": [{"A": ["B", "C"], "B": ["D"], "C": [], "D": []}, "A"], "output": ["A", "B", "C", "D"]}, {"input": [{"1": ["2"], "2": ["3"], "3": []}, "1"], "output": ["1", "2", "3"]}, {"input": [{"x": []}, "x"], "output": ["x"]}, {"input": [{"a": ["b"], "b": ["a"]}, "a"], "output": ["a", "b"]}, {"input": [{"m": ["n", "o"], "n": [], "o": []}, "m"], "output": ["m", "n", "o"]}]}}
{"timestamp_utc": "2025-09-16T06:28:56.818370", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 44, "question": "Given a CSV string with header 'name,value' and multiple rows, return the sum of the 'value' column as int. Assume comma-separated, no quotes. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.473928928375244, "response": "def sum_values(csv_string):\n    lines = csv_string.strip().split('\\n')\n    return sum(int(line.split(',')[1]) for line in lines[1:])", "error": null, "raw_item": {"task_id": "parsing_csv_sum", "prompt": "Given a CSV string with header 'name,value' and multiple rows, return the sum of the 'value' column as int. Assume comma-separated, no quotes. Return only the Python function code with no explanations.", "entry_point": "csv_sum", "canonical_solution": "def csv_sum(text):\n    lines=text.strip().split('\\n')\n    if len(lines) <= 1:\n        return 0\n    total=0\n    for line in lines[1:]:\n        if line.strip():\n            name,val=line.split(',')\n            total+=int(val)\n    return total", "test": [{"input": ["name,value\\na,3\\nb,7\\nc,10"], "output": 20}, {"input": ["name,value\\n"], "output": 0}, {"input": ["name,value\\nfoo,0\\nbar,0"], "output": 0}, {"input": ["name,value\\nx,100"], "output": 100}, {"input": ["name,value\\na,1\\nb,2\\nc,3\\nd,4"], "output": 10}]}}
{"timestamp_utc": "2025-09-16T06:29:00.102267", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 45, "question": "Extract all sequences of digits from a string using regex and return them as a list of strings. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.280893325805664, "response": "```python\nimport re\n\ndef extract_digits(text):\n    return re.findall(r'\\d+', text)\n```", "error": null, "raw_item": {"task_id": "parsing_regex_digits", "prompt": "Extract all sequences of digits from a string using regex and return them as a list of strings. Return only the Python function code with no explanations.", "entry_point": "extract_digits", "canonical_solution": "import re\n\ndef extract_digits(s):\n    return re.findall(r'\\d+', s)", "test": [{"input": ["abc123de45f6"], "output": ["123", "45", "6"]}, {"input": ["no digits here"], "output": []}, {"input": ["2025year"], "output": ["2025"]}, {"input": ["a1b2c3d4"], "output": ["1", "2", "3", "4"]}, {"input": ["007bond"], "output": ["007"]}]}}
{"timestamp_utc": "2025-09-16T06:29:03.534005", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 46, "question": "Return the length of the longest increasing subsequence (LIS) in a list of integers. O(n^2) solution is fine. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.429208755493164, "response": "def lengthOfLIS(nums):\n    if not nums:\n        return 0\n    \n    n = len(nums)\n    dp = [1] * n\n    \n    for i in range(1, n):\n        for j in range(i):\n            if nums[i] > nums[j]:\n                dp[i] = max(dp[i], dp[j] + 1)\n    \n    return max(dp)", "error": null, "raw_item": {"task_id": "algorithms_longest_increasing", "prompt": "Return the length of the longest increasing subsequence (LIS) in a list of integers. O(n^2) solution is fine. Return only the Python function code with no explanations.", "entry_point": "lis_length", "canonical_solution": "def lis_length(nums):\n    if not nums: return 0\n    dp=[1]*len(nums)\n    for i in range(len(nums)):\n        for j in range(i):\n            if nums[j]<nums[i]:\n                dp[i]=max(dp[i],dp[j]+1)\n    return max(dp)", "test": [{"input": [[10, 9, 2, 5, 3, 7, 101, 18]], "output": 4}, {"input": [[1, 2, 3, 4, 5]], "output": 5}, {"input": [[5, 4, 3, 2, 1]], "output": 1}, {"input": [[]], "output": 0}, {"input": [[2, 2, 2]], "output": 1}]}}
{"timestamp_utc": "2025-09-16T06:29:08.278697", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 47, "question": "0/1 Knapsack: given weights, values, and capacity W, return the maximum achievable value. Use DP. weights and values are equal length. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 3.74261474609375, "response": "def knapsack(weights, values, W):\n    n = len(weights)\n    dp = [[0] * (W + 1) for _ in range(n + 1)]\n    \n    for i in range(1, n + 1):\n        for w in range(1, W + 1):\n            if weights[i-1] <= w:\n                dp[i][w] = max(values[i-1] + dp[i-1][w-weights[i-1]], dp[i-1][w])\n            else:\n                dp[i][w] = dp[i-1][w]\n    \n    return dp[n][W]", "error": null, "raw_item": {"task_id": "algorithms_knapsack01", "prompt": "0/1 Knapsack: given weights, values, and capacity W, return the maximum achievable value. Use DP. weights and values are equal length. Return only the Python function code with no explanations.", "entry_point": "knapsack01", "canonical_solution": "def knapsack01(weights, values, W):\n    n=len(weights)\n    dp=[[0]*(W+1) for _ in range(n+1)]\n    for i in range(1,n+1):\n        for w in range(W+1):\n            dp[i][w]=dp[i-1][w]\n            if weights[i-1]<=w:\n                dp[i][w]=max(dp[i][w], values[i-1]+dp[i-1][w-weights[i-1]])\n    return dp[n][W]", "test": [{"input": [[2, 3, 4], [4, 5, 6], 5], "output": 9}, {"input": [[1, 2, 3], [6, 10, 12], 5], "output": 22}, {"input": [[5], [10], 5], "output": 10}, {"input": [[5], [10], 4], "output": 0}, {"input": [[], [], 10], "output": 0}]}}
{"timestamp_utc": "2025-09-16T06:29:11.866359", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 48, "question": "Write parse_csv_numbers(text) that parses a CSV string of integers separated by commas and newlines. Return a 2D list of integers. Ignore empty lines. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.582493305206299, "response": "def parse_csv_numbers(text):\n    result = []\n    for line in text.strip().split('\\n'):\n        if line.strip():\n            result.append([int(num) for num in line.split(',')])\n    return result", "error": null, "raw_item": {"task_id": "custom_parse_csv_numbers", "prompt": "Write parse_csv_numbers(text) that parses a CSV string of integers separated by commas and newlines. Return a 2D list of integers. Ignore empty lines. Return only the Python function code with no explanations.", "entry_point": "parse_csv_numbers", "canonical_solution": "def parse_csv_numbers(text: str) -> list[list[int]]:\n    rows = []\n    for line in text.strip().splitlines():\n        if not line.strip():\n            continue\n        row = [int(x.strip()) for x in line.split(',') if x.strip()]\n        rows.append(row)\n    return rows", "test": [{"input": ["1,2,3\n4,5,6"], "output": [[1, 2, 3], [4, 5, 6]]}, {"input": ["10,20\n30\n\n40,50"], "output": [[10, 20], [30], [40, 50]]}, {"input": ["   7 , 8 ,9  "], "output": [[7, 8, 9]]}, {"input": [""], "output": []}]}}
{"timestamp_utc": "2025-09-16T06:29:15.154867", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 49, "question": "Write normalize_json_keys(obj) that recursively converts all dictionary keys in a JSON-like object to lowercase strings. Works for nested dicts and lists. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 2.28507399559021, "response": "def normalize_json_keys(obj):\n    if isinstance(obj, dict):\n        return {key.lower(): normalize_json_keys(value) for key, value in obj.items()}\n    elif isinstance(obj, list):\n        return [normalize_json_keys(item) for item in obj]\n    else:\n        return obj", "error": null, "raw_item": {"task_id": "custom_normalize_json_keys", "prompt": "Write normalize_json_keys(obj) that recursively converts all dictionary keys in a JSON-like object to lowercase strings. Works for nested dicts and lists. Return only the Python function code with no explanations.", "entry_point": "normalize_json_keys", "canonical_solution": "def normalize_json_keys(obj):\n    if isinstance(obj, dict):\n        return {str(k).lower(): normalize_json_keys(v) for k, v in obj.items()}\n    if isinstance(obj, list):\n        return [normalize_json_keys(x) for x in obj]\n    return obj", "test": [{"input": [{"Name": "Alice", "AGE": 30}], "output": {"name": "Alice", "age": 30}}, {"input": [[{"X": 1}, {"Y": 2}]], "output": [{"x": 1}, {"y": 2}]}, {"input": [{"Nested": {"KEY": 5}}], "output": {"nested": {"key": 5}}}, {"input": [123], "output": 123}]}}
{"timestamp_utc": "2025-09-16T06:29:21.804678", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 50, "question": "Write format_duration(seconds) that converts an integer number of seconds into a human-readable string using years, days, hours, minutes, and seconds. Skip units that are zero. Use plural form when needed. Example: 3661 → '1 hour, 1 minute, 1 second'. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 5.648035764694214, "response": "def format_duration(seconds):\n    if seconds == 0:\n        return \"now\"\n    \n    units = [\n        (31536000, \"year\"),\n        (86400, \"day\"),\n        (3600, \"hour\"),\n        (60, \"minute\"),\n        (1, \"second\")\n    ]\n    \n    result = []\n    for divisor, unit in units:\n        value = seconds // divisor\n        if value > 0:\n            if value == 1:\n                result.append(f\"{value} {unit}\")\n            else:\n                result.append(f\"{value} {unit}s\")\n            seconds %= divisor\n    \n    if len(result) > 1:\n        return \", \".join(result[:-1]) + \" and \" + result[-1]\n    return result[0]", "error": null, "raw_item": {"task_id": "custom_format_duration", "prompt": "Write format_duration(seconds) that converts an integer number of seconds into a human-readable string using years, days, hours, minutes, and seconds. Skip units that are zero. Use plural form when needed. Example: 3661 → '1 hour, 1 minute, 1 second'. Return only the Python function code with no explanations.", "entry_point": "format_duration", "canonical_solution": "def format_duration(seconds: int) -> str:\n    units = [(\"year\", 365*24*3600), (\"day\", 24*3600), (\"hour\", 3600), (\"minute\", 60), (\"second\", 1)]\n    parts = []\n    for name, length in units:\n        if seconds >= length:\n            count, seconds = divmod(seconds, length)\n            parts.append(f\"{count} {name}{'s' if count != 1 else ''}\")\n    return \", \".join(parts) if parts else \"0 seconds\"", "test": [{"input": [0], "output": "0 seconds"}, {"input": [62], "output": "1 minute, 2 seconds"}, {"input": [3661], "output": "1 hour, 1 minute, 1 second"}, {"input": [31536000], "output": "1 year"}, {"input": [31556926], "output": "1 year, 6 hours, 9 minutes, 26 seconds"}]}}
{"timestamp_utc": "2025-09-16T06:29:26.415701", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 51, "question": "Write parse_key_value_config(text) that parses a configuration string with lines of the form 'key=value'. Ignore blank lines and lines starting with '#'. Return a dictionary with string keys and values converted to int if possible, else string. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 3.6077980995178223, "response": "```python\ndef parse_key_value_config(text):\n    config = {}\n    for line in text.split('\\n'):\n        line = line.strip()\n        if line and not line.startswith('#'):\n            key, value = line.split('=', 1)\n            key = key.strip()\n            value = value.strip()\n            try:\n                value = int(value)\n            except ValueError:\n                pass\n            config[key] = value\n    return config\n```", "error": null, "raw_item": {"task_id": "custom_parse_key_value_config", "prompt": "Write parse_key_value_config(text) that parses a configuration string with lines of the form 'key=value'. Ignore blank lines and lines starting with '#'. Return a dictionary with string keys and values converted to int if possible, else string. Return only the Python function code with no explanations.", "entry_point": "parse_key_value_config", "canonical_solution": "def parse_key_value_config(text: str) -> dict:\n    result = {}\n    for line in text.splitlines():\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        if '=' in line:\n            k,v = line.split('=',1)\n            v = v.strip()\n            if v.isdigit():\n                result[k.strip()] = int(v)\n            else:\n                result[k.strip()] = v\n    return result", "test": [{"input": ["a=1\nb=2\nc=hello"], "output": {"a": 1, "b": 2, "c": "hello"}}, {"input": ["#comment\nx=42\ny=text"], "output": {"x": 42, "y": "text"}}, {"input": [""], "output": {}}]}}
{"timestamp_utc": "2025-09-16T06:29:31.424617", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 52, "question": "Write pretty_print_matrix(matrix) that formats a 2D list of integers into a string where each row is space-separated and rows are separated by newlines. Columns should be aligned to the maximum width of the largest number. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 4.006435871124268, "response": "def pretty_print_matrix(matrix):\n    if not matrix:\n        return \"\"\n    \n    # Find max width of any number in matrix\n    max_width = max(len(str(num)) for row in matrix for num in row)\n    \n    # Format each row with right-aligned numbers\n    formatted_rows = [\n        ' '.join(f'{num:>{max_width}}' for num in row)\n        for row in matrix\n    ]\n    \n    # Join rows with newlines\n    return '\\n'.join(formatted_rows)", "error": null, "raw_item": {"task_id": "custom_pretty_print_matrix", "prompt": "Write pretty_print_matrix(matrix) that formats a 2D list of integers into a string where each row is space-separated and rows are separated by newlines. Columns should be aligned to the maximum width of the largest number. Return only the Python function code with no explanations.", "entry_point": "pretty_print_matrix", "canonical_solution": "def pretty_print_matrix(matrix: list[list[int]]) -> str:\n    if not matrix:\n        return ''\n    col_widths = [max(len(str(row[i])) for row in matrix) for i in range(len(matrix[0]))]\n    lines = []\n    for row in matrix:\n        line = ' '.join(str(val).rjust(col_widths[i]) for i,val in enumerate(row))\n        lines.append(line)\n    return '\\n'.join(lines)", "test": [{"input": [[[1, 20], [300, 4]]], "output": "  1 20\n300  4"}, {"input": [[[5]]], "output": "5"}, {"input": [[]], "output": ""}]}}
{"timestamp_utc": "2025-09-16T06:29:36.121059", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 53, "question": "Write unique_permutations(s) that returns all distinct permutations of string s in lexicographic order. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 3.6942849159240723, "response": "def unique_permutations(s):\n    def backtrack(current, remaining):\n        if not remaining:\n            result.append(current)\n            return\n        \n        used = set()\n        for i in range(len(remaining)):\n            if remaining[i] not in used:\n                used.add(remaining[i])\n                backtrack(current + remaining[i], remaining[:i] + remaining[i+1:])\n    \n    result = []\n    backtrack('', ''.join(sorted(s)))\n    return result", "error": null, "raw_item": {"task_id": "custom_unique_permutations", "prompt": "Write unique_permutations(s) that returns all distinct permutations of string s in lexicographic order. Return only the Python function code with no explanations.", "entry_point": "unique_permutations", "canonical_solution": "def unique_permutations(s: str) -> list[str]:\n    from itertools import permutations\n    return sorted(set(''.join(p) for p in permutations(s)))", "test": [{"input": ["aab"], "output": ["aab", "aba", "baa"]}, {"input": ["abc"], "output": ["abc", "acb", "bac", "bca", "cab", "cba"]}, {"input": ["x"], "output": ["x"]}]}}
{"timestamp_utc": "2025-09-16T06:29:42.357193", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 54, "question": "Write format_prime_factors(n) that returns the prime factorization of integer n as a string in the form 'p1^a1 * p2^a2 ...'. If exponent is 1, omit the '^1'. Example: 60 → '2^2 * 3 * 5'. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 5.233917236328125, "response": "def format_prime_factors(n):\n    if n <= 1:\n        return str(n)\n    \n    factors = []\n    d = 2\n    while d * d <= n:\n        count = 0\n        while n % d == 0:\n            n //= d\n            count += 1\n        if count > 0:\n            factors.append((d, count))\n        d += 1\n    \n    if n > 1:\n        factors.append((n, 1))\n    \n    result = []\n    for prime, exp in factors:\n        if exp == 1:\n            result.append(str(prime))\n        else:\n            result.append(f\"{prime}^{exp}\")\n    \n    return ' * '.join(result)", "error": null, "raw_item": {"task_id": "custom_format_prime_factors", "prompt": "Write format_prime_factors(n) that returns the prime factorization of integer n as a string in the form 'p1^a1 * p2^a2 ...'. If exponent is 1, omit the '^1'. Example: 60 → '2^2 * 3 * 5'. Return only the Python function code with no explanations.", "entry_point": "format_prime_factors", "canonical_solution": "def format_prime_factors(n: int) -> str:\n    factors = []\n    d = 2\n    while d*d <= n:\n        count = 0\n        while n % d == 0:\n            n //= d\n            count += 1\n        if count:\n            factors.append(f\"{d}^{count}\" if count>1 else str(d))\n        d += 1\n    if n > 1:\n        factors.append(str(n))\n    return ' * '.join(factors)", "test": [{"input": [60], "output": "2^2 * 3 * 5"}, {"input": [13], "output": "13"}, {"input": [1024], "output": "2^10"}]}}
{"timestamp_utc": "2025-09-16T06:29:48.500365", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 55, "question": "Write validate_expression(expr) that checks if a string is a valid arithmetic expression containing only digits, +, -, *, /, parentheses, and spaces. Return True if valid, else False. Parentheses must be balanced and no invalid sequences allowed (e.g. '*/', '++', empty parentheses). Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 5.1402130126953125, "response": "def validate_expression(expr):\n    expr = expr.replace(' ', '')\n    if not expr:\n        return False\n    \n    operators = set('+-*/')\n    stack = []\n    prev_char = None\n    \n    for char in expr:\n        if char.isdigit():\n            prev_char = char\n        elif char in operators:\n            if not prev_char or prev_char in operators or prev_char == '(':\n                return False\n            prev_char = char\n        elif char == '(':\n            if prev_char and (prev_char.isdigit() or prev_char == ')'):\n                return False\n            stack.append(char)\n            prev_char = char\n        elif char == ')':\n            if not stack or prev_char in operators or prev_char == '(':\n                return False\n            stack.pop()\n            prev_char = char\n        else:\n            return False\n    \n    return len(stack) == 0 and prev_char and prev_char not in operators", "error": null, "raw_item": {"task_id": "custom_validate_expression", "prompt": "Write validate_expression(expr) that checks if a string is a valid arithmetic expression containing only digits, +, -, *, /, parentheses, and spaces. Return True if valid, else False. Parentheses must be balanced and no invalid sequences allowed (e.g. '*/', '++', empty parentheses). Return only the Python function code with no explanations.", "entry_point": "validate_expression", "canonical_solution": "import re\ndef validate_expression(expr: str) -> bool:\n    expr = expr.strip()\n    if not expr:\n        return False\n    # invalid sequences\n    if re.search(r'[+*/-]{2,}', expr):\n        return False\n    if re.search(r'\\(\\)', expr):\n        return False\n    # parentheses balance\n    stack = []\n    for c in expr:\n        if c == '(':\n            stack.append(c)\n        elif c == ')':\n            if not stack:\n                return False\n            stack.pop()\n    if stack:\n        return False\n    # final safety: try eval\n    try:\n        eval(expr, {\"__builtins__\":None}, {})\n    except:\n        return False\n    return True", "test": [{"input": ["1+2*(3-4)"], "output": true}, {"input": ["(5+6"], "output": false}, {"input": ["1++2"], "output": false}, {"input": ["( )"], "output": false}, {"input": ["10/2-3"], "output": true}]}}
{"timestamp_utc": "2025-09-16T06:29:54.024993", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 56, "question": "Write parse_roman(s) that converts a valid Roman numeral string into an integer. Supports numerals up to 3999 (MMMCMXCIX). Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0", "region": "us-east-1", "success": true, "response_time": 4.522033214569092, "response": "def parse_roman(s):\n    roman_values = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000\n    }\n    \n    total = 0\n    prev_value = 0\n    \n    for char in reversed(s):\n        current_value = roman_values[char]\n        \n        if current_value >= prev_value:\n            total += current_value\n        else:\n            total -= current_value\n        \n        prev_value = current_value\n    \n    return total", "error": null, "raw_item": {"task_id": "custom_parse_roman", "prompt": "Write parse_roman(s) that converts a valid Roman numeral string into an integer. Supports numerals up to 3999 (MMMCMXCIX). Return only the Python function code with no explanations.", "entry_point": "parse_roman", "canonical_solution": "def parse_roman(s: str) -> int:\n    values = {\"I\":1, \"V\":5, \"X\":10, \"L\":50, \"C\":100, \"D\":500, \"M\":1000}\n    total = 0\n    i = 0\n    while i < len(s):\n        if i+1 < len(s) and values[s[i]] < values[s[i+1]]:\n            total += values[s[i+1]] - values[s[i]]\n            i += 2\n        else:\n            total += values[s[i]]\n            i += 1\n    return total", "test": [{"input": ["III"], "output": 3}, {"input": ["IX"], "output": 9}, {"input": ["LVIII"], "output": 58}, {"input": ["MCMXCIV"], "output": 1994}, {"input": ["MMMCMXCIX"], "output": 3999}]}}
