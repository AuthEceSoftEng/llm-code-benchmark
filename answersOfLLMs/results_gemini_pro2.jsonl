{"timestamp_utc": "2025-09-26T09:40:04.500940", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 0, "question": "Write find_balanced_sublist(arr) that returns the longest even-length contiguous sublist where sum of first half equals sum of second half. Return empty list if none exists.\n\nReturn only the Python function code with no explanations, comments, or markdown formatting.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 96.37188625335693, "response": "```python\ndef find_balanced_sublist(arr):\n    n = len(arr)\n    max_len = 0\n    result = []\n\n    if n < 2:\n        return []\n\n    prefix_sum = [0] * (n + 1)\n    for i in range(n):\n        prefix_sum[i + 1] = prefix_sum[i] + arr[i]\n\n    for i in range(n):\n        for j in range(i + 1, n):\n            sub_len = j - i + 1\n            if sub_len % 2 == 0:\n                mid_point = i + sub_len // 2\n                \n                sum1 = prefix_sum[mid_point] - prefix_sum[i]\n                sum2 = prefix_sum[j + 1] - prefix_sum[mid_point]\n                \n                if sum1 == sum2:\n                    if sub_len > max_len:\n                        max_len = sub_len\n                        result = arr[i : j + 1]\n    \n    return result\n```", "error": null, "raw_item": {"task_id": "custom_find_balanced_sublist", "prompt": "Write find_balanced_sublist(arr) that returns the longest even-length contiguous sublist where sum of first half equals sum of second half. Return empty list if none exists.\n\nReturn only the Python function code with no explanations, comments, or markdown formatting.", "entry_point": "find_balanced_sublist", "canonical_solution": "def find_balanced_sublist(arr: list[int]) -> list[int]:\n    n = len(arr)\n    for length in range(n, 1, -1):\n        if length % 2 != 0:\n            continue\n        for start in range(n - length + 1):\n            sub = arr[start:start+length]\n            half = length // 2\n            if sum(sub[:half]) == sum(sub[half:]):\n                return sub\n    return []", "test": [{"input": [[1, 2, 3, 3, 2, 1]], "output": [1, 2, 3, 3, 2, 1]}, {"input": [[5, 1, 2, 1, 5]], "output": []}, {"input": [[1, 1, 1, 1]], "output": [1, 1, 1, 1]}, {"input": [[1, 2, 3]], "output": []}, {"input": [[]], "output": []}, {"input": [[3, 0, 3, 0, 3]], "output": [3, 0, 3, 0]}, {"input": [[2, 1, 1, 2, 3, 4]], "output": [2, 1, 1, 2]}, {"input": [[1, 5, 3, 7]], "output": []}, {"input": [[0, 0, 0, 0]], "output": [0, 0, 0, 0]}]}}
{"timestamp_utc": "2025-09-26T09:40:32.808655", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 1, "question": "Write merge_by_priority(items_a, items_b) that merges two lists of (id, priority) pairs. Keep highest priority for each unique id. Return sorted by priority descending. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 27.30575704574585, "response": "```python\ndef merge_by_priority(items_a, items_b):\n    \"\"\"\n    Merges two lists of (id, priority) pairs, keeping the highest priority for\n    each unique id, and returns the result sorted by priority descending.\n    \"\"\"\n    merged_dict = {}\n    all_items = items_a + items_b\n\n    for item_id, priority in all_items:\n        if item_id not in merged_dict or priority > merged_dict[item_id]:\n            merged_dict[item_id] = priority\n\n    # Convert dictionary to a list of tuples and sort by priority (the second element)\n    sorted_items = sorted(merged_dict.items(), key=lambda item: item[1], reverse=True)\n\n    return sorted_items\n```", "error": null, "raw_item": {"task_id": "custom_merge_by_priority", "prompt": "Write merge_by_priority(items_a, items_b) that merges two lists of (id, priority) pairs. Keep highest priority for each unique id. Return sorted by priority descending. Return only the Python function code with no explanations.", "entry_point": "merge_by_priority", "canonical_solution": "def merge_by_priority(items_a: list[tuple[str, int]], items_b: list[tuple[str, int]]) -> list[tuple[str, int]]:\n    combined = items_a + items_b\n    best = {}\n    for id, priority in combined:\n        if id not in best or priority > best[id]:\n            best[id] = priority\n    return sorted(best.items(), key=lambda x: -x[1])", "test": [{"input": [[["item1", 2], ["item2", 5]], [["item2", 3], ["item3", 4]]], "output": [["item2", 5], ["item3", 4], ["item1", 2]]}, {"input": [[], []], "output": []}, {"input": [[["a", 1]], [["a", 10]]], "output": [["a", 10]]}, {"input": [[["x", 5], ["y", 3]], [["z", 7], ["y", 6]]], "output": [["z", 7], ["y", 6], ["x", 5]]}, {"input": [[["a", 1], ["b", 2]], []], "output": [["b", 2], ["a", 1]]}]}}
{"timestamp_utc": "2025-09-26T09:41:02.621388", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 2, "question": "Write parse_env_config(lines) that parses environment variable lines into dict. Ignore lines starting with '#', lines without '=', and empty keys. Keep last occurrence of duplicate keys. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 28.810227394104004, "response": "```python\ndef parse_env_config(lines):\n    \"\"\"\n    Parses environment variable lines into a dictionary.\n\n    Args:\n        lines: A list of strings, where each string is a line from an\n               environment configuration file.\n\n    Returns:\n        A dictionary of the parsed key-value pairs.\n    \"\"\"\n    config = {}\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith('#') or '=' not in line:\n            continue\n\n        key, value = line.split('=', 1)\n        key = key.strip()\n\n        if not key:\n            continue\n\n        config[key] = value.strip()\n    return config\n```", "error": null, "raw_item": {"task_id": "custom_parse_env_config", "prompt": "Write parse_env_config(lines) that parses environment variable lines into dict. Ignore lines starting with '#', lines without '=', and empty keys. Keep last occurrence of duplicate keys. Return only the Python function code with no explanations.", "entry_point": "parse_env_config", "canonical_solution": "def parse_env_config(lines: list[str]) -> dict[str, str]:\n    env = {}\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith(\"#\") or \"=\" not in line:\n            continue\n        key, value = line.split(\"=\", 1)\n        if key:\n            env[key] = value\n    return env", "test": [{"input": [["DB_HOST=localhost", "DB_PORT=5432", "#comment", "DB_HOST=remotehost", "=fail", "INVALID", ""]], "output": {"DB_HOST": "remotehost", "DB_PORT": "5432"}}, {"input": [["A=1", "B=2", "C=3"]], "output": {"A": "1", "B": "2", "C": "3"}}, {"input": [["# just a comment", "=", "==", "KEY_ONLY=", "NO_EQUALS"]], "output": {"KEY_ONLY": ""}}, {"input": [[]], "output": {}}, {"input": [["k1=v1", "k1=v2", "k1=v3"]], "output": {"k1": "v3"}}]}}
{"timestamp_utc": "2025-09-26T09:41:41.268753", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 3, "question": "Write minimal_partition_difference(nums) that partitions a list into two groups to minimize absolute difference of their sums. Handle empty list case explicitly. Use DP subset sum approach. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 37.644721031188965, "response": "```python\ndef minimal_partition_difference(nums):\n    \"\"\"\n    Partitions a list into two groups to minimize the absolute difference of their sums.\n    Uses a Dynamic Programming subset sum approach.\n    \"\"\"\n    # Handle the empty list case explicitly.\n    if not nums:\n        return 0\n\n    total_sum = sum(nums)\n    \n    # Use a set to store all possible subset sums that can be formed.\n    # This is the core of the DP subset sum approach.\n    # Initialize with 0 for the empty subset.\n    possible_sums = {0}\n    \n    # Iterate through each number in the input list.\n    for num in nums:\n        # For each number, create new possible sums by adding the current number\n        # to all previously found possible sums.\n        # A new set is created in each iteration to avoid modifying the set while iterating.\n        new_sums = set()\n        for s in possible_sums:\n            new_sums.add(s + num)\n        possible_sums.update(new_sums)\n\n    # The goal is to find a partition sum 's1' that is as close as possible to total_sum / 2.\n    # The difference between the two partitions will be |s1 - s2|.\n    # Since s1 + s2 = total_sum, we have s2 = total_sum - s1.\n    # The difference is |s1 - (total_sum - s1)| = |2*s1 - total_sum|.\n    # We need to find the minimum of this value over all possible sums 's1'.\n    \n    min_diff = float('inf')\n    \n    for s in possible_sums:\n        diff = abs(total_sum - 2 * s)\n        if diff < min_diff:\n            min_diff = diff\n            \n    return min_diff\n```", "error": null, "raw_item": {"task_id": "custom_minimal_partition_difference", "prompt": "Write minimal_partition_difference(nums) that partitions a list into two groups to minimize absolute difference of their sums. Handle empty list case explicitly. Use DP subset sum approach. Return only the Python function code with no explanations.", "entry_point": "minimal_partition_difference", "canonical_solution": "def minimal_partition_difference(nums: list[int]) -> int:\n    if not nums:\n        return 0\n    total = sum(nums)\n    target = total // 2\n    possible = {0}\n    for num in nums:\n        possible |= {x + num for x in possible}\n    best = max(x for x in possible if x <= target)\n    return total - 2 * best", "test": [{"input": [[1, 2, 3, 9]], "output": 3}, {"input": [[1, 2, 3, 4, 5]], "output": 1}, {"input": [[10, 10]], "output": 0}, {"input": [[7]], "output": 7}, {"input": [[]], "output": 0}, {"input": [[1, 1, 1, 1, 1, 1]], "output": 0}, {"input": [[100, 99, 98, 1]], "output": 96}]}}
{"timestamp_utc": "2025-09-26T09:42:16.987789", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 4, "question": "Write normalize_user_roles(users) where users is a dict mapping each user to a LIST of roles. Invert to map each role to list of users. Remove duplicate users per role and sort user lists alphabetically. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 34.71631097793579, "response": "```python\ndef normalize_user_roles(users):\n    \"\"\"\n    Inverts a user-to-roles dictionary to a role-to-users dictionary.\n\n    Args:\n        users (dict): A dictionary mapping each username to a list of roles.\n                      Example: {'user1': ['admin', 'editor'], 'user2': ['editor']}\n\n    Returns:\n        dict: A dictionary mapping each role to a sorted list of unique users\n              who have that role.\n              Example: {'admin': ['user1'], 'editor': ['user1', 'user2']}\n    \"\"\"\n    roles_to_users = {}\n    for user, roles in users.items():\n        for role in roles:\n            roles_to_users.setdefault(role, []).append(user)\n\n    # Sort and remove duplicates from user lists\n    for role, user_list in roles_to_users.items():\n        roles_to_users[role] = sorted(list(set(user_list)))\n\n    return roles_to_users\n```", "error": null, "raw_item": {"task_id": "custom_normalize_user_roles", "prompt": "Write normalize_user_roles(users) where users is a dict mapping each user to a LIST of roles. Invert to map each role to list of users. Remove duplicate users per role and sort user lists alphabetically. Return only the Python function code with no explanations.", "entry_point": "normalize_user_roles", "canonical_solution": "def normalize_user_roles(users: dict[str, list[str]]) -> dict[str, list[str]]:\n    role_to_users = {}\n    for user, roles in users.items():\n        for role in set(roles):  # remove duplicates\n            if role not in role_to_users:\n                role_to_users[role] = []\n            role_to_users[role].append(user)\n    for role in role_to_users:\n        role_to_users[role].sort()\n    return role_to_users", "test": [{"input": [{"alice": ["admin", "editor"], "bob": ["editor", "admin"], "charlie": ["viewer"]}], "output": {"admin": ["alice", "bob"], "editor": ["alice", "bob"], "viewer": ["charlie"]}}, {"input": [{"diana": [], "eva": ["user", "user"], "frank": ["user"]}], "output": {"user": ["eva", "frank"]}}, {"input": [{"a": ["x"], "b": ["y"], "c": ["x", "y"]}], "output": {"x": ["a", "c"], "y": ["b", "c"]}}, {"input": [{}], "output": {}}]}}
{"timestamp_utc": "2025-09-26T09:43:30.922473", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 5, "question": "Write can_form_expression(digits, target) that checks if inserting '+' or '-' operators (or nothing) between digits can reach target value. Use recursive DFS. Must handle multi-digit numbers. Return complete Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 72.93262481689453, "response": "```python\ndef can_form_expression(digits, target):\n    \"\"\"\n    Checks if inserting '+' or '-' operators (or nothing for concatenation) \n    between the digits of a given string can result in a target value.\n\n    This implementation uses a recursive Depth-First Search (DFS) approach.\n    \"\"\"\n    \n    # A nested helper function to implement the recursive DFS.\n    def dfs(index, current_val):\n        \"\"\"\n        Recursively explores expression possibilities.\n\n        :param index: The starting index in the 'digits' string for the next number.\n        :param current_val: The evaluated value of the expression so far.\n        \"\"\"\n        # Base case: If we have processed all digits.\n        if index == len(digits):\n            # Return True if the final value matches the target, False otherwise.\n            return current_val == target\n\n        # Recursive step:\n        # Iterate from the current index to the end of the string to form\n        # all possible subsequent numbers (e.g., from \"123\", form \"1\", \"12\", \"123\").\n        for i in range(index, len(digits)):\n            s_num = digits[index : i + 1]\n            num = int(s_num)\n            next_index = i + 1\n\n            # For the very first number in the expression (when index is 0),\n            # there is no preceding operator. We just start the evaluation\n            # with its value.\n            if index == 0:\n                if dfs(next_index, num):\n                    return True\n            else:\n                # For all subsequent numbers, we can either add or subtract them\n                # from the value of the expression evaluated so far.\n\n                # Branch 1: Try adding the current number.\n                if dfs(next_index, current_val + num):\n                    return True\n                \n                # Branch 2: Try subtracting the current number.\n                if dfs(next_index, current_val - num):\n                    return True\n        \n        # If no path from the current state (index, current_val) leads to the target,\n        # backtrack by returning False.\n        return False\n\n    # Handle the edge case of an empty input string.\n    if not digits:\n        return False\n        \n    # Start the initial DFS call. The index is 0, and the initial value is 0.\n    # The special handling for index == 0 inside the DFS function will correctly\n    # process the first number of the expression.\n    return dfs(0, 0)\n```", "error": null, "raw_item": {"task_id": "custom_can_form_expression", "prompt": "Write can_form_expression(digits, target) that checks if inserting '+' or '-' operators (or nothing) between digits can reach target value. Use recursive DFS. Must handle multi-digit numbers. Return complete Python function code with no explanations.", "entry_point": "can_form_expression", "canonical_solution": "def can_form_expression(digits: str, target: int) -> bool:\n    def dfs(index: int, current_value: int, expression: str) -> bool:\n        if index == len(digits):\n            return current_value == target\n        for end in range(index + 1, len(digits) + 1):\n            num_str = digits[index:end]\n            num = int(num_str)\n            if index == 0:\n                if dfs(end, num, num_str):\n                    return True\n            else:\n                if dfs(end, current_value + num, expression + '+' + num_str):\n                    return True\n                if dfs(end, current_value - num, expression + '-' + num_str):\n                    return True\n        return False\n    return dfs(0, 0, \"\")", "test": [{"input": ["123", 6], "output": true}, {"input": ["105", 5], "output": true}, {"input": ["123", 123], "output": true}, {"input": ["123", 100], "output": false}, {"input": ["000", 0], "output": true}, {"input": ["1", 1], "output": true}, {"input": ["1", 2], "output": false}]}}
{"timestamp_utc": "2025-09-26T09:43:53.185064", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 6, "question": "Write has_balanced_bits(n) that returns True if binary representation of n has equal number of 0s and 1s. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 21.259496927261353, "response": "```python\ndef has_balanced_bits(n):\n    \"\"\"\n    Returns True if the binary representation of n has an equal number of 0s and 1s.\n    \"\"\"\n    if n < 0:\n        return False  # Or handle as per specific requirements for negative numbers\n    binary_str = bin(n)[2:]\n    return binary_str.count('0') == binary_str.count('1')\n```", "error": null, "raw_item": {"task_id": "custom_has_balanced_bits", "prompt": "Write has_balanced_bits(n) that returns True if binary representation of n has equal number of 0s and 1s. Return only the Python function code with no explanations.", "entry_point": "has_balanced_bits", "canonical_solution": "def has_balanced_bits(n: int) -> bool:\n    bits = bin(n)[2:]\n    return bits.count('0') == bits.count('1')", "test": [{"input": [10], "output": true}, {"input": [7], "output": false}, {"input": [9], "output": true}, {"input": [1], "output": false}, {"input": [51], "output": false}, {"input": [56], "output": true}, {"input": [57], "output": false}, {"input": [2], "output": true}, {"input": [15], "output": false}]}}
{"timestamp_utc": "2025-09-26T09:44:15.016055", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 7, "question": "Write remove_repeating_groups(s, k) that repeatedly removes groups of k identical adjacent characters until no more can be removed. Use stack approach. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 20.828913927078247, "response": "```python\ndef remove_repeating_groups(s, k):\n    \"\"\"\n    Repeatedly removes groups of k identical adjacent characters\n    until no more can be removed, using a stack approach.\n\n    Args:\n        s (str): The input string.\n        k (int): The size of the group of identical adjacent characters to remove.\n\n    Returns:\n        str: The string after all possible removals.\n    \"\"\"\n    stack = []  # Will store pairs of [character, count]\n\n    for char in s:\n        # If the stack is not empty and the current character matches the top of the stack\n        if stack and stack[-1][0] == char:\n            stack[-1][1] += 1\n        else:\n            # Push a new character with a count of 1\n            stack.append([char, 1])\n\n        # If the count of the character at the top of the stack reaches k\n        if stack[-1][1] == k:\n            stack.pop()\n\n    # Reconstruct the string from the characters remaining in the stack\n    return \"\".join(char * count for char, count in stack)\n```", "error": null, "raw_item": {"task_id": "custom_remove_repeating_groups", "prompt": "Write remove_repeating_groups(s, k) that repeatedly removes groups of k identical adjacent characters until no more can be removed. Use stack approach. Return only the Python function code with no explanations.", "entry_point": "remove_repeating_groups", "canonical_solution": "def remove_repeating_groups(s: str, k: int) -> str:\n    stack = []\n    for char in s:\n        if stack and stack[-1][0] == char:\n            stack[-1][1] += 1\n            if stack[-1][1] == k:\n                stack.pop()\n        else:\n            stack.append([char, 1])\n    return ''.join(char * count for char, count in stack)", "test": [{"input": ["deeedbbcccbdaa", 3], "output": "aa"}, {"input": ["pbbcggttciiippooaais", 2], "output": "ps"}, {"input": ["abcd", 2], "output": "abcd"}, {"input": ["aaa", 3], "output": ""}, {"input": ["aaaabbbbaaaa", 4], "output": ""}, {"input": ["aabbcc", 2], "output": ""}, {"input": ["aabbccddeeedcba", 3], "output": "abc"}, {"input": ["", 3], "output": ""}]}}
{"timestamp_utc": "2025-09-26T09:44:49.765015", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 8, "question": "Write resolve_dependencies(deps) that returns valid module load order from dependency dict. Return None if cycle exists. Use DFS topological sort. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 33.74588418006897, "response": "```python\ndef resolve_dependencies(deps):\n    \"\"\"\n    Returns a valid module load order from a dependency dictionary.\n    Uses DFS-based topological sort.\n    Returns None if a cycle is detected.\n    \"\"\"\n    result = []\n    # States: 0 = unvisited, 1 = visiting, 2 = visited\n    # Using sets for faster lookups\n    visiting = set()  # Corresponds to state 1\n    visited = set()   # Corresponds to state 2\n\n    # Get all unique modules from both keys and dependency lists\n    all_modules = set(deps.keys())\n    for dependencies in deps.values():\n        all_modules.update(dependencies)\n\n    def dfs(module):\n        \"\"\"\n        Performs Depth First Search. Returns False if a cycle is detected.\n        \"\"\"\n        visiting.add(module)\n\n        for dependency in deps.get(module, []):\n            if dependency in visiting:\n                # Cycle detected: found a node that is currently in the recursion stack\n                return False\n            if dependency not in visited:\n                if not dfs(dependency):\n                    # Propagate the cycle detection result\n                    return False\n\n        # All dependencies of 'module' are resolved.\n        # Move from 'visiting' to 'visited' and add to the result.\n        visiting.remove(module)\n        visited.add(module)\n        result.append(module)\n        return True\n\n    # We need to iterate over all modules to handle disconnected graphs.\n    # Sorting ensures a deterministic output order for the same input.\n    for module in sorted(list(all_modules)):\n        if module not in visited:\n            if not dfs(module):\n                # A cycle was detected, so no valid load order exists.\n                return None\n\n    return result\n```", "error": null, "raw_item": {"task_id": "custom_resolve_dependencies", "prompt": "Write resolve_dependencies(deps) that returns valid module load order from dependency dict. Return None if cycle exists. Use DFS topological sort. Return only the Python function code with no explanations.", "entry_point": "resolve_dependencies", "canonical_solution": "def resolve_dependencies(deps: dict[str, list[str]]) -> list[str] | None:\n    visited = {}\n    result = []\n\n    def dfs(node):\n        if node in visited:\n            return visited[node]  # False if cycle\n        visited[node] = False  # mark as visiting\n        for neighbor in deps.get(node, []):\n            res = dfs(neighbor)\n            if res is False:\n                return False\n        visited[node] = True  # mark as visited\n        result.append(node)\n        return True\n\n    for node in deps:\n        if node not in visited:\n            if dfs(node) is False:\n                return None\n    return result[::-1]", "test": [{"input": [{"a": ["b", "c"], "b": ["c"], "c": []}], "output": ["c", "b", "a"]}, {"input": [{"x": ["y"], "y": ["z"], "z": ["x"]}], "output": null}, {"input": [{"m": ["n"], "n": [], "o": []}], "output": ["n", "m", "o"]}, {"input": [{"a": []}], "output": ["a"]}, {"input": [{}], "output": []}]}}
{"timestamp_utc": "2025-09-26T09:45:10.228463", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 9, "question": "Write clean_and_validate_urls(urls) that returns sorted list of unique valid URLs. Valid URLs start with 'http://' or 'https://' (case-insensitive) and contain no spaces. Strip whitespace and remove duplicates. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 19.460455894470215, "response": "```python\ndef clean_and_validate_urls(urls):\n    \"\"\"\n    Cleans, validates, and returns a sorted list of unique URL strings.\n\n    Args:\n        urls: A list of strings, where each string is a potential URL.\n\n    Returns:\n        A sorted list of unique, valid URL strings. A valid URL starts\n        with 'http://' or 'https://' (case-insensitive) and contains no spaces.\n    \"\"\"\n    valid_urls = set()\n    for url in urls:\n        cleaned_url = url.strip()\n        if ' ' not in cleaned_url and (\n            cleaned_url.lower().startswith('http://') or\n            cleaned_url.lower().startswith('https://')\n        ):\n            valid_urls.add(cleaned_url)\n    return sorted(list(valid_urls))\n```", "error": null, "raw_item": {"task_id": "custom_clean_and_validate_urls", "prompt": "Write clean_and_validate_urls(urls) that returns sorted list of unique valid URLs. Valid URLs start with 'http://' or 'https://' (case-insensitive) and contain no spaces. Strip whitespace and remove duplicates. Return only the Python function code with no explanations.", "entry_point": "clean_and_validate_urls", "canonical_solution": "def clean_and_validate_urls(urls: list[str]) -> list[str]:\n    valid = set()\n    for url in urls:\n        cleaned = url.strip()\n        if cleaned.lower().startswith(\"http://\") or cleaned.lower().startswith(\"https://\"):\n            if \" \" not in cleaned:\n                valid.add(cleaned)\n    return sorted(valid)", "test": [{"input": [[" http://example.com ", "https://valid.site", "ftp://notvalid", "invalid.com", "https://valid.site"]], "output": ["http://example.com", "https://valid.site"]}, {"input": [[]], "output": []}, {"input": [["   https://a.com  ", "http://b.com", "http://b.com  "]], "output": ["http://b.com", "https://a.com"]}, {"input": [["https://with space.com", "http://ok.com"]], "output": ["http://ok.com"]}, {"input": [["HTTP://UPPERCASE.com"]], "output": ["HTTP://UPPERCASE.com"]}]}}
{"timestamp_utc": "2025-09-26T09:45:28.545006", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 10, "question": "Write normalize_filename(filename) that normalizes filenames by converting to lowercase, keeping only a-z, 0-9, underscore, and dots, removing other characters. Return 'unnamed' if result is empty. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 17.313212871551514, "response": "```python\nimport re\n\ndef normalize_filename(filename):\n    \"\"\"\n    Normalizes a filename by converting it to lowercase, removing all characters\n    except for letters (a-z), numbers (0-9), underscores, and dots.\n\n    If the resulting filename is empty, it returns 'unnamed'.\n    \"\"\"\n    # Convert to lowercase\n    s = filename.lower()\n    # Remove all characters that are not a-z, 0-9, underscore, or dot\n    s = re.sub(r'[^a-z0-9_.]', '', s)\n    # If the resulting string is empty, return 'unnamed'\n    return s if s else 'unnamed'\n\n```", "error": null, "raw_item": {"task_id": "custom_normalize_filename", "prompt": "Write normalize_filename(filename) that normalizes filenames by converting to lowercase, keeping only a-z, 0-9, underscore, and dots, removing other characters. Return 'unnamed' if result is empty. Return only the Python function code with no explanations.", "entry_point": "normalize_filename", "canonical_solution": "def normalize_filename(filename: str) -> str:\n    allowed = set(\"abcdefghijklmnopqrstuvwxyz0123456789_.\")\n    result = ''.join(c.lower() for c in filename if c.lower() in allowed)\n    return result if result else \"unnamed\"", "test": [{"input": ["My Report (Final).PDF"], "output": "myreport.final.pdf"}, {"input": ["Résumé_2023!.docx"], "output": "rsum_2023.docx"}, {"input": ["  "], "output": "unnamed"}, {"input": ["file@#name!.TXT"], "output": "filename.txt"}, {"input": ["___"], "output": "___"}, {"input": ["###"], "output": "unnamed"}, {"input": ["ABC123_456.xyz"], "output": "abc123_456.xyz"}]}}
{"timestamp_utc": "2025-09-26T09:45:55.871279", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 11, "question": "Write rank_projects_by_score(projects) that ranks projects by score formula: (stars * 2) + forks - (issues * 3). Return project names sorted by score descending, then alphabetically. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 26.317185878753662, "response": "```python\ndef rank_projects_by_score(projects):\n    \"\"\"\n    Ranks projects based on a score and returns their names sorted.\n\n    The score is calculated as: (stars * 2) + forks - (issues * 3).\n    Projects are sorted by score in descending order. Ties are broken\n    by sorting project names alphabetically in ascending order.\n    \"\"\"\n    sorted_projects = sorted(\n        projects,\n        key=lambda p: (\n            -((p['stars'] * 2) + p['forks'] - (p['issues'] * 3)),\n            p['name']\n        )\n    )\n    return [p['name'] for p in sorted_projects]\n```", "error": null, "raw_item": {"task_id": "custom_rank_projects_by_score", "prompt": "Write rank_projects_by_score(projects) that ranks projects by score formula: (stars * 2) + forks - (issues * 3). Return project names sorted by score descending, then alphabetically. Return only the Python function code with no explanations.", "entry_point": "rank_projects_by_score", "canonical_solution": "def rank_projects_by_score(projects: list[tuple[str, int, int, int]]) -> list[str]:\n    def score(proj):\n        return (proj[1] * 2) + proj[2] - (proj[3] * 3)\n    return [p[0] for p in sorted(projects, key=lambda p: (-score(p), p[0]))]", "test": [{"input": [[["ProjectA", 100, 50, 10], ["ProjectB", 80, 70, 5], ["ProjectC", 100, 50, 10]]], "output": ["ProjectA", "ProjectC", "ProjectB"]}, {"input": [[["Alpha", 10, 5, 0], ["Beta", 10, 5, 0]]], "output": ["Alpha", "Beta"]}, {"input": [[["AppX", 0, 0, 0], ["AppY", 0, 0, 1]]], "output": ["AppX", "AppY"]}, {"input": [[]], "output": []}, {"input": [[["ToolZ", 5, 5, 10], ["ToolY", 4, 4, 1]]], "output": ["ToolY", "ToolZ"]}]}}
{"timestamp_utc": "2025-09-26T09:46:33.323718", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 12, "question": "Write longest_prime_gap(nums) that finds the longest sequence of non-prime numbers between two prime numbers in the list. Return length of longest gap. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 36.4497389793396, "response": "```python\ndef longest_prime_gap(nums):\n    \"\"\"\n    Finds the longest sequence of non-prime numbers between two prime numbers in a list.\n    \"\"\"\n    \n    def is_prime(n):\n        if n <= 1:\n            return False\n        if n <= 3:\n            return True\n        if n % 2 == 0 or n % 3 == 0:\n            return False\n        i = 5\n        while i * i <= n:\n            if n % i == 0 or n % (i + 2) == 0:\n                return False\n            i += 6\n        return True\n\n    max_gap = 0\n    current_gap = 0\n    found_first_prime = False\n\n    for num in nums:\n        if is_prime(num):\n            if found_first_prime:\n                if current_gap > max_gap:\n                    max_gap = current_gap\n                current_gap = 0\n            else:\n                found_first_prime = True\n        elif found_first_prime:\n            current_gap += 1\n            \n    return max_gap\n```", "error": null, "raw_item": {"task_id": "custom_longest_prime_gap", "prompt": "Write longest_prime_gap(nums) that finds the longest sequence of non-prime numbers between two prime numbers in the list. Return length of longest gap. Return only the Python function code with no explanations.", "entry_point": "longest_prime_gap", "canonical_solution": "def longest_prime_gap(nums: list[int]) -> int:\n    def is_prime(n: int) -> bool:\n        if n < 2:\n            return False\n        for i in range(2, int(n**0.5)+1):\n            if n % i == 0:\n                return False\n        return True\n\n    indices = [i for i, val in enumerate(nums) if is_prime(val)]\n    if len(indices) < 2:\n        return 0\n\n    max_gap = 0\n    for i in range(len(indices) - 1):\n        start = indices[i]\n        end = indices[i + 1]\n        gap = end - start - 1\n        max_gap = max(max_gap, gap)\n    return max_gap", "test": [{"input": [[4, 6, 7, 8, 9, 10, 11, 4, 6, 13]], "output": 3}, {"input": [[2, 4, 6, 8, 10, 3]], "output": 4}, {"input": [[4, 6, 8, 10]], "output": 0}, {"input": [[3, 4, 5, 6, 7]], "output": 1}, {"input": [[2, 3]], "output": 0}, {"input": [[17, 4, 6, 9, 15, 19, 21, 23]], "output": 4}, {"input": [[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]], "output": 4}]}}
{"timestamp_utc": "2025-09-26T09:47:02.197546", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 13, "question": "Write categorize_commit_message(message) that categorizes commit messages. Return 'feature' for add/implement/feature/new, 'fix' for fix/bug/error/resolve, 'refactor' for refactor/cleanup/restructure, 'docs' for docs/documentation/readme, else 'other'. Case-insensitive. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 27.870131969451904, "response": "```python\ndef categorize_commit_message(message):\n    lower_message = message.lower()\n\n    feature_keywords = ['add', 'implement', 'feature', 'new']\n    if any(keyword in lower_message for keyword in feature_keywords):\n        return 'feature'\n\n    fix_keywords = ['fix', 'bug', 'error', 'resolve']\n    if any(keyword in lower_message for keyword in fix_keywords):\n        return 'fix'\n\n    refactor_keywords = ['refactor', 'cleanup', 'restructure']\n    if any(keyword in lower_message for keyword in refactor_keywords):\n        return 'refactor'\n\n    docs_keywords = ['docs', 'documentation', 'readme']\n    if any(keyword in lower_message for keyword in docs_keywords):\n        return 'docs'\n\n    return 'other'\n```", "error": null, "raw_item": {"task_id": "custom_categorize_commit_message", "prompt": "Write categorize_commit_message(message) that categorizes commit messages. Return 'feature' for add/implement/feature/new, 'fix' for fix/bug/error/resolve, 'refactor' for refactor/cleanup/restructure, 'docs' for docs/documentation/readme, else 'other'. Case-insensitive. Return only the Python function code with no explanations.", "entry_point": "categorize_commit_message", "canonical_solution": "def categorize_commit_message(message: str) -> str:\n    msg = message.lower()\n    categories = {\n        \"feature\": [\"add\", \"implement\", \"feature\", \"new\"],\n        \"fix\": [\"fix\", \"bug\", \"error\", \"resolve\"],\n        \"refactor\": [\"refactor\", \"cleanup\", \"restructure\"],\n        \"docs\": [\"docs\", \"documentation\", \"readme\"],\n    }\n    for label, keywords in categories.items():\n        if any(kw in msg for kw in keywords):\n            return label\n    return \"other\"", "test": [{"input": ["Fix bug in user login"], "output": "fix"}, {"input": ["Refactor payment module"], "output": "refactor"}, {"input": ["Updated README and docs"], "output": "docs"}, {"input": ["Initial commit"], "output": "other"}, {"input": ["Implemented new feature for signup"], "output": "feature"}, {"input": ["cleanup redundant logic"], "output": "refactor"}, {"input": ["Error handling for empty input"], "output": "fix"}, {"input": ["add configuration support"], "output": "feature"}, {"input": ["Documentation improvements"], "output": "docs"}, {"input": ["Minor UI tweaks"], "output": "other"}]}}
{"timestamp_utc": "2025-09-26T09:48:07.782195", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 14, "question": "Write max_repeated_substring(s) that returns length of longest non-overlapping repeated substring. Use sliding window with seen set. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 64.58252501487732, "response": "```python\ndef max_repeated_substring(s):\n    n = len(s)\n\n    def check(length):\n        seen = {}\n        for i in range(n - length + 1):\n            substring = s[i : i + length]\n            if substring in seen:\n                if i >= seen[substring] + length:\n                    return True\n            else:\n                seen[substring] = i\n        return False\n\n    ans = 0\n    low, high = 1, n\n\n    while low <= high:\n        mid = (low + high) // 2\n        if check(mid):\n            ans = mid\n            low = mid + 1\n        else:\n            high = mid - 1\n            \n    return ans\n```", "error": null, "raw_item": {"task_id": "custom_max_repeated_substring", "prompt": "Write max_repeated_substring(s) that returns length of longest non-overlapping repeated substring. Use sliding window with seen set. Return only the Python function code with no explanations.", "entry_point": "max_repeated_substring", "canonical_solution": "def max_repeated_substring(s: str) -> int:\n    n = len(s)\n    max_len = 0\n    for l in range(1, n // 2 + 1):\n        seen = set()\n        i = 0\n        while i + l <= n:\n            substr = s[i:i+l]\n            if substr in seen:\n                max_len = max(max_len, l)\n                i += l  # move forward non-overlapping\n            else:\n                seen.add(substr)\n                i += 1\n    return max_len", "test": [{"input": ["abababc"], "output": 2}, {"input": ["aaaa"], "output": 2}, {"input": ["abcabcabc"], "output": 3}, {"input": ["abcdef"], "output": 0}, {"input": ["ababa"], "output": 1}, {"input": [""], "output": 0}, {"input": ["a"], "output": 0}, {"input": ["abcdabcd"], "output": 4}, {"input": ["xyzxyzabcabc"], "output": 3}, {"input": ["abababab"], "output": 2}]}}
{"timestamp_utc": "2025-09-26T09:48:38.888163", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 15, "question": "Write longest_valid_bracket_substring(s) that returns length of longest valid parentheses substring. Use stack with indices. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 30.10421085357666, "response": "```python\ndef longest_valid_bracket_substring(s):\n    \"\"\"\n    Calculates the length of the longest valid parentheses substring.\n\n    This function uses a stack to keep track of the indices of open parentheses.\n    - A stack is initialized with -1 to handle edge cases where a valid\n      substring starts from the beginning of the string.\n    - When an open parenthesis '(' is encountered, its index is pushed onto the stack.\n    - When a closing parenthesis ')' is encountered, an index is popped from the stack.\n    - If the stack becomes empty after popping, it means the current ')' is unmatched.\n      Its index is then pushed to serve as a new base for future valid substrings.\n    - If the stack is not empty after popping, a valid pair is found. The length of\n      the current valid substring is calculated as the difference between the current\n      index and the index at the top of the stack. The maximum length found so far\n      is updated.\n\n    Args:\n        s: The input string consisting of '(' and ')' characters.\n\n    Returns:\n        The length of the longest valid parentheses substring.\n    \"\"\"\n    max_len = 0\n    stack = [-1]\n\n    for i, char in enumerate(s):\n        if char == '(':\n            stack.append(i)\n        else:\n            stack.pop()\n            if not stack:\n                stack.append(i)\n            else:\n                current_len = i - stack[-1]\n                if current_len > max_len:\n                    max_len = current_len\n    return max_len\n```", "error": null, "raw_item": {"task_id": "custom_longest_valid_bracket_substring", "prompt": "Write longest_valid_bracket_substring(s) that returns length of longest valid parentheses substring. Use stack with indices. Return only the Python function code with no explanations.", "entry_point": "longest_valid_bracket_substring", "canonical_solution": "def longest_valid_bracket_substring(s: str) -> int:\n    stack = [-1]\n    max_len = 0\n\n    for i, ch in enumerate(s):\n        if ch == '(':\n            stack.append(i)\n        else:\n            stack.pop()\n            if not stack:\n                stack.append(i)\n            else:\n                max_len = max(max_len, i - stack[-1])\n\n    return max_len", "test": [{"input": ["(()"], "output": 2}, {"input": [")()())"], "output": 4}, {"input": [""], "output": 0}, {"input": ["((("], "output": 0}, {"input": ["()(()))())"], "output": 6}, {"input": ["((()))"], "output": 6}, {"input": ["()()()"], "output": 6}, {"input": [")((()))("], "output": 6}, {"input": ["(()(((()"], "output": 2}, {"input": ["())(())"], "output": 4}]}}
{"timestamp_utc": "2025-09-26T09:49:16.952646", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 16, "question": "Write summarize_category_totals(purchases) that returns list of [category, total] pairs sorted alphabetically by category. Sum amounts by category. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 37.0581579208374, "response": "```python\ndef summarize_category_totals(purchases):\n    \"\"\"\n    Summarizes purchase amounts by category and returns a sorted list of totals.\n\n    Args:\n        purchases: A list of dictionaries, where each dictionary represents a\n                   purchase and must contain 'category' and 'amount' keys.\n\n    Returns:\n        A list of [category, total] pairs, sorted alphabetically by category.\n    \"\"\"\n    totals = {}\n    for purchase in purchases:\n        category = purchase['category']\n        amount = purchase['amount']\n        totals[category] = totals.get(category, 0) + amount\n\n    # Create a list of [category, total] pairs and sort it by category.\n    # sorted() on a dictionary's .items() view sorts by key (the category) by default.\n    # The result is a list of tuples, which we convert to a list of lists.\n    return [list(item) for item in sorted(totals.items())]\n```", "error": null, "raw_item": {"task_id": "custom_summarize_category_totals", "prompt": "Write summarize_category_totals(purchases) that returns list of [category, total] pairs sorted alphabetically by category. Sum amounts by category. Return only the Python function code with no explanations.", "entry_point": "summarize_category_totals", "canonical_solution": "def summarize_category_totals(purchases: list[dict]) -> list[list]:\n    totals = {}\n    for item in purchases:\n        cat = item[\"category\"]\n        amt = item[\"amount\"]\n        totals[cat] = totals.get(cat, 0.0) + amt\n    return sorted([[cat, total] for cat, total in totals.items()])", "test": [{"input": [[{"category": "groceries", "amount": 25.5}, {"category": "electronics", "amount": 99.99}, {"category": "groceries", "amount": 13.0}, {"category": "books", "amount": 10.0}]], "output": [["books", 10.0], ["electronics", 99.99], ["groceries", 38.5]]}, {"input": [[{"category": "a", "amount": 1.0}, {"category": "b", "amount": 2.0}, {"category": "a", "amount": 3.0}, {"category": "c", "amount": 4.0}]], "output": [["a", 4.0], ["b", 2.0], ["c", 4.0]]}, {"input": [[]], "output": []}, {"input": [[{"category": "x", "amount": 0.0}, {"category": "x", "amount": 0.0}]], "output": [["x", 0.0]]}, {"input": [[{"category": "Z", "amount": 2.0}, {"category": "a", "amount": 1.0}]], "output": [["Z", 2.0], ["a", 1.0]]}]}}
{"timestamp_utc": "2025-09-26T09:49:42.438434", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 17, "question": "Write filter_unique_keywords(keywords, banned) that returns sorted unique keywords (lowercased) excluding banned words. Case-insensitive comparison. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 24.481307983398438, "response": "```python\ndef filter_unique_keywords(keywords, banned):\n    \"\"\"\n    Returns a sorted list of unique, lowercased keywords,\n    excluding any words present in the banned list.\n    Comparison is case-insensitive.\n\n    Args:\n        keywords (list[str]): A list of keyword strings.\n        banned (list[str]): A list of banned word strings.\n\n    Returns:\n        list[str]: A sorted list of unique, filtered, and lowercased keywords.\n    \"\"\"\n    banned_lower = {word.lower() for word in banned}\n    unique_keywords = {word.lower() for word in keywords}\n    filtered = unique_keywords - banned_lower\n    return sorted(list(filtered))\n```", "error": null, "raw_item": {"task_id": "custom_filter_unique_keywords", "prompt": "Write filter_unique_keywords(keywords, banned) that returns sorted unique keywords (lowercased) excluding banned words. Case-insensitive comparison. Return only the Python function code with no explanations.", "entry_point": "filter_unique_keywords", "canonical_solution": "def filter_unique_keywords(keywords: list[str], banned: list[str]) -> list[str]:\n    banned_set = set(word.lower() for word in banned)\n    unique = set()\n\n    for word in keywords:\n        w = word.lower()\n        if w not in banned_set:\n            unique.add(w)\n\n    return sorted(unique)", "test": [{"input": [["Python", "code", "AI", "python", "Data", "Code"], ["ai"]], "output": ["code", "data", "python"]}, {"input": [[], ["test"]], "output": []}, {"input": [["ML", "AI", "ml", "AI"], ["ai"]], "output": ["ml"]}, {"input": [["hello", "world", "HELLO", "WORLD"], []], "output": ["hello", "world"]}, {"input": [["Data", "Science", "AI"], ["science", "ai"]], "output": ["data"]}, {"input": [["Python", "PYTHON", "python"], ["PYTHON"]], "output": []}]}}
{"timestamp_utc": "2025-09-26T09:50:19.571537", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 18, "question": "Write next_greater_circular(nums) that returns list where each position contains next greater element circularly. Use monotonic stack. O(n) time. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 36.129826068878174, "response": "```python\ndef next_greater_circular(nums):\n    \"\"\"\n    For a circular array, finds the next greater number for every element.\n    Uses a monotonic stack for O(n) time complexity.\n    \"\"\"\n    n = len(nums)\n    result = [-1] * n\n    stack = []  # Stack stores indices\n\n    # Iterate twice through the array to handle circularity\n    for i in range(2 * n - 1, -1, -1):\n        current_index = i % n\n        \n        # While stack is not empty and the element at the top of the stack\n        # is less than or equal to the current element, pop from the stack.\n        while stack and nums[stack[-1]] <= nums[current_index]:\n            stack.pop()\n\n        # If the stack is not empty, the element at the top is the next greater element.\n        # Otherwise, no greater element exists in the circular traversal.\n        if stack:\n            result[current_index] = nums[stack[-1]]\n            \n        # Push the current index onto the stack for future comparisons.\n        stack.append(current_index)\n        \n    return result\n```", "error": null, "raw_item": {"task_id": "ds_next_greater_circular", "prompt": "Write next_greater_circular(nums) that returns list where each position contains next greater element circularly. Use monotonic stack. O(n) time. Return only the Python function code with no explanations.", "entry_point": "next_greater_circular", "canonical_solution": "def next_greater_circular(nums):\n    n = len(nums)\n    res = [-1]*n\n    stack = []  # indices with decreasing stack by value\n    for i in range(2*n):\n        x = nums[i % n]\n        while stack and nums[stack[-1]] < x:\n            idx = stack.pop()\n            res[idx] = x\n        if i < n:\n            stack.append(i)\n    return res\n", "test": [{"input": [[1, 2, 1]], "output": [2, -1, 2]}, {"input": [[3, 8, 4, 1, 2]], "output": [8, -1, 8, 2, 3]}, {"input": [[5, 4, 3, 2, 1]], "output": [-1, 5, 5, 5, 5]}, {"input": [[2, 2, 2]], "output": [-1, -1, -1]}, {"input": [[]], "output": []}]}}
{"timestamp_utc": "2025-09-26T09:51:01.026755", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 19, "question": "Write normalize_product_code(s) that keeps only alphanumerics and dashes, converts to uppercase, collapses multiple dashes, trims leading/trailing dashes. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 40.4519419670105, "response": "```python\ndef normalize_product_code(s):\n    \"\"\"\n    Normalizes a product code by keeping only alphanumerics and dashes,\n    converting to uppercase, collapsing multiple dashes, and trimming\n    leading/trailing dashes.\n    \"\"\"\n    if not isinstance(s, str):\n        return \"\"\n\n    # Keep only alphanumerics and dashes, and convert to uppercase\n    normalized = \"\".join(char for char in s.upper() if char.isalnum() or char == '-')\n\n    # Collapse consecutive dashes into a single dash\n    while '--' in normalized:\n        normalized = normalized.replace('--', '-')\n\n    # Trim leading and trailing dashes\n    return normalized.strip('-')\n\n```", "error": null, "raw_item": {"task_id": "str_normalize_product_code", "prompt": "Write normalize_product_code(s) that keeps only alphanumerics and dashes, converts to uppercase, collapses multiple dashes, trims leading/trailing dashes. Return only the Python function code with no explanations.", "entry_point": "normalize_product_code", "canonical_solution": "import re\ndef normalize_product_code(s):\n    # keep alnum and dash\n    s = ''.join(ch for ch in s if ch.isalnum() or ch=='-')\n    s = s.upper()\n    s = re.sub(r'-{2,}', '-', s)\n    s = s.strip('-')\n    return s\n", "test": [{"input": [" abC--12__-xx "], "output": "ABC-12-XX"}, {"input": ["---a---b---"], "output": "A-B"}, {"input": ["***"], "output": ""}, {"input": ["proD-uct_99!!"], "output": "PROD-UCT99"}, {"input": [""], "output": ""}]}}
{"timestamp_utc": "2025-09-26T09:52:19.409807", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 20, "question": "Write single_number_triplicates(nums) that finds element appearing once while others appear thrice. Use bitwise counting without hash maps. O(n) time, O(1) space. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 77.37925505638123, "response": "```python\ndef single_number_triplicates(nums):\n    ones = 0\n    twos = 0\n    for num in nums:\n        ones = (ones ^ num) & ~twos\n        twos = (twos ^ num) & ~ones\n    return ones\n```", "error": null, "raw_item": {"task_id": "bit_single_number_triplicates", "prompt": "Write single_number_triplicates(nums) that finds element appearing once while others appear thrice. Use bitwise counting without hash maps. O(n) time, O(1) space. Return only the Python function code with no explanations.", "entry_point": "single_number_triplicates", "canonical_solution": "def single_number_triplicates(nums):\n    ones = 0\n    twos = 0\n    for x in nums:\n        ones = (ones ^ x) & ~twos\n        twos = (twos ^ x) & ~ones\n    return ones\n", "test": [{"input": [[2, 2, 3, 2]], "output": 3}, {"input": [[0, 1, 0, 1, 0, 1, 99]], "output": 99}, {"input": [[-2, -2, -2, -5]], "output": -5}, {"input": [[7]], "output": 7}, {"input": [[10, 10, 10, -1]], "output": -1}]}}
{"timestamp_utc": "2025-09-26T09:53:34.013185", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 21, "question": "Write can_finish_prereqs(pairs) where pairs are (a,b) meaning 'b precedes a'. Return True if acyclic. Use topological sort without external libraries. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 73.59948801994324, "response": "```python\ndef can_finish_prereqs(pairs):\n    \"\"\"\n    Determines if a set of prerequisites is possible to complete.\n\n    Args:\n        pairs: A list of tuples (a, b), where b must be completed before a.\n\n    Returns:\n        True if the prerequisite graph is acyclic, False otherwise.\n    \"\"\"\n    nodes = set()\n    for a, b in pairs:\n        nodes.add(a)\n        nodes.add(b)\n\n    adj_list = {node: [] for node in nodes}\n    in_degree = {node: 0 for node in nodes}\n\n    # A pair (a, b) means b precedes a, so there's a directed edge b -> a.\n    for a, b in pairs:\n        adj_list[b].append(a)\n        in_degree[a] += 1\n\n    # Initialize a queue with all nodes that have an in-degree of 0.\n    # These are the starting points with no prerequisites.\n    queue = [node for node in nodes if in_degree[node] == 0]\n\n    processed_count = 0\n    while queue:\n        # Dequeue a node and consider it \"completed\".\n        node = queue.pop(0)\n        processed_count += 1\n\n        # For each neighbor of the completed node, reduce its in-degree.\n        for neighbor in adj_list[node]:\n            in_degree[neighbor] -= 1\n            # If a neighbor's in-degree becomes 0, it's now ready to be processed.\n            if in_degree[neighbor] == 0:\n                queue.append(neighbor)\n\n    # If the number of processed nodes equals the total number of unique nodes,\n    # then a valid topological sort was possible, and the graph is acyclic.\n    return processed_count == len(nodes)\n```", "error": null, "raw_item": {"task_id": "graph_can_finish_prereqs", "prompt": "Write can_finish_prereqs(pairs) where pairs are (a,b) meaning 'b precedes a'. Return True if acyclic. Use topological sort without external libraries. Return only the Python function code with no explanations.", "entry_point": "can_finish_prereqs", "canonical_solution": "from collections import defaultdict, deque\ndef can_finish_prereqs(pairs):\n    adj = defaultdict(list)\n    indeg = defaultdict(int)\n    nodes = set()\n    for a,b in pairs:\n        adj[b].append(a)\n        indeg[a] += 1\n        nodes.add(a); nodes.add(b)\n        if b not in indeg: indeg[b] = indeg.get(b,0)\n    q = deque([v for v in nodes if indeg.get(v,0)==0])\n    visited = 0\n    while q:\n        v = q.popleft()\n        visited += 1\n        for w in adj[v]:\n            indeg[w] -= 1\n            if indeg[w]==0:\n                q.append(w)\n    return visited == len(nodes)\n", "test": [{"input": [[["C2", "C1"], ["C3", "C2"]]], "output": true}, {"input": [[["A", "B"], ["B", "C"], ["C", "A"]]], "output": false}, {"input": [[["A", "B"]]], "output": true}, {"input": [[["X", "Y"], ["Y", "Z"], ["Z", "X"]]], "output": false}, {"input": [[[]]], "output": true}]}}
{"timestamp_utc": "2025-09-26T09:54:02.977749", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 22, "question": "Write safe_deep_get(obj, path, default=None) that safely traverses nested dicts/lists/tuples using path keys/indices. Return default if any access fails. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 27.961117267608643, "response": "```python\ndef safe_deep_get(obj, path, default=None):\n    \"\"\"\n    Safely traverses nested dictionaries, lists, or tuples using a path of keys/indices.\n\n    Args:\n        obj (dict, list, tuple): The object to traverse.\n        path (iterable): A list or tuple of keys and/or indices representing the path.\n        default (any, optional): The value to return if the path is not found or\n                                 an error occurs during traversal. Defaults to None.\n\n    Returns:\n        any: The value at the specified path, or the default value if access fails.\n    \"\"\"\n    current_level = obj\n    try:\n        for key in path:\n            current_level = current_level[key]\n        return current_level\n    except (KeyError, IndexError, TypeError):\n        return default\n```", "error": null, "raw_item": {"task_id": "se_safe_deep_get", "entry_point": "safe_deep_get", "prompt": "Write safe_deep_get(obj, path, default=None) that safely traverses nested dicts/lists/tuples using path keys/indices. Return default if any access fails. Return only the Python function code with no explanations.", "canonical_solution": "def safe_deep_get(obj, path, default=None):\n    cur = obj\n    for key in path:\n        if isinstance(cur, dict):\n            if key in cur:\n                cur = cur[key]\n            else:\n                return default\n        elif isinstance(cur, (list, tuple)):\n            if isinstance(key, int) and -len(cur) <= key < len(cur):\n                cur = cur[key]\n            else:\n                return default\n        else:\n            return default\n    return cur\n", "test": [{"input": [{"a": {"b": [10, 20, {"c": 42}]}}, ["a", "b", 2, "c"], null], "output": 42}, {"input": [{"a": [1, 2, 3]}, ["a", 5], "x"], "output": "x"}, {"input": [{"x": 0}, ["y"], 99], "output": 99}, {"input": [[1, 2, 3], [0], null], "output": 1}, {"input": [[1, 2, 3], ["0"], "err"], "output": "err"}]}}
{"timestamp_utc": "2025-09-26T09:54:50.106978", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 23, "question": "Write clean_and_split_sentences(text) that removes non-alphanumeric chars except .!?, normalizes whitespace, splits on sentence delimiters, returns cleaned sentence list. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 46.12639093399048, "response": "```python\nimport re\n\ndef clean_and_split_sentences(text):\n    \"\"\"\n    Removes non-alphanumeric characters (except .!?), normalizes whitespace,\n    and splits the text into a list of sentences.\n\n    Args:\n        text: The input string to process.\n\n    Returns:\n        A list of cleaned sentences.\n    \"\"\"\n    # Remove any character that is not a letter, number, whitespace, or sentence delimiter\n    cleaned_text = re.sub(r'[^a-zA-Z0-9.!?\\s]', '', text)\n\n    # Normalize whitespace: replace multiple spaces/newlines/tabs with a single space\n    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n\n    if not cleaned_text:\n        return []\n\n    # Split the text on sentence delimiters (.!?) followed by a space.\n    # The lookbehind `(?<=[.!?])` ensures the delimiters are kept with their sentences.\n    sentences = re.split(r'(?<=[.!?])\\s+', cleaned_text)\n\n    # Filter out any potential empty strings from the list\n    return [s for s in sentences if s]\n```", "error": null, "raw_item": {"task_id": "str_clean_and_split_sentences", "entry_point": "clean_and_split_sentences", "prompt": "Write clean_and_split_sentences(text) that removes non-alphanumeric chars except .!?, normalizes whitespace, splits on sentence delimiters, returns cleaned sentence list. Return only the Python function code with no explanations.", "canonical_solution": "import re\n\ndef clean_and_split_sentences(text):\n    # Keep only letters, digits, punctuation .,!,?\n    text = re.sub(r\"[^A-Za-z0-9.!?\\s]\", \"\", text)\n    # Normalize whitespace\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    # Split on sentence delimiters\n    parts = re.split(r\"[.!?]\", text)\n    # Clean and filter\n    result = [p.strip() for p in parts if p.strip()]\n    return result\n", "test": [{"input": ["Hello!!   How are---you???   Fine."], "output": ["Hello", "How areyou", "Fine"]}, {"input": ["  multiple   spaces   and ###symbols!!"], "output": ["multiple spaces and symbols"]}, {"input": ["Nothing to clean"], "output": ["Nothing to clean"]}, {"input": ["???"], "output": []}]}}
{"timestamp_utc": "2025-09-26T09:55:14.212219", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 24, "question": "Write count_set_bits(n) that counts 1-bits in binary representation using efficient bit manipulation (Brian Kernighan's algorithm). Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 23.103620767593384, "response": "```python\ndef count_set_bits(n):\n    \"\"\"\n    Counts the number of set bits (1s) in the binary representation of an integer n\n    using Brian Kernighan's algorithm.\n    \"\"\"\n    count = 0\n    while n > 0:\n        # This operation clears the rightmost set bit\n        n &= (n - 1)\n        count += 1\n    return count\n```", "error": null, "raw_item": {"task_id": "bit_counting_set_bits", "entry_point": "count_set_bits", "prompt": "Write count_set_bits(n) that counts 1-bits in binary representation using efficient bit manipulation (Brian Kernighan's algorithm). Return only the Python function code with no explanations.", "canonical_solution": "def count_set_bits(n):\n    if n < 0:\n        raise ValueError(\"Input must be a non-negative integer.\")\n    count = 0\n    while n:\n        n &= n - 1  # Clear the least significant bit set\n        count += 1\n    return count\n", "test": [{"input": [11], "output": 3}, {"input": [0], "output": 0}, {"input": [255], "output": 8}, {"input": [1023], "output": 10}, {"input": [1], "output": 1}]}}
{"timestamp_utc": "2025-09-26T09:56:16.820046", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 25, "question": "Write filter_map_validate(records) that normalizes, validates, and filters product records, returning sorted list of valid IDs. Complex multi-step validation with price parsing, type constraints, and conditional rules. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 61.60589909553528, "response": "```python\nimport re\n\ndef filter_map_validate(records):\n    \"\"\"\n    Normalizes, validates, and filters a list of product records.\n\n    The function performs the following steps for each record:\n    1.  Normalization: Converts keys to lowercase and strips whitespace from strings.\n    2.  Validation:\n        -   Checks for the presence and correct data types of required fields\n            (id, name, price, type, stock).\n        -   Parses a numerical price from a string value (e.g., \"$19.99\").\n        -   Applies conditional validation rules based on the product type:\n            -   'book': Must have a valid 10 or 13-digit ISBN.\n            -   'electronics': If price > 1000, must have a positive 'warranty_years'.\n                             If price < 20, must have 'on_sale' as True.\n            -   'clothing': Must have a valid 'size'.\n        -   A record with 'stock' of 0 is only valid if its 'status' is 'pre-order'.\n    3.  Filtering & Mapping: Collects the 'id' of each record that passes all validation checks.\n\n    Args:\n        records (list): A list of dictionaries, where each dictionary is a product record.\n\n    Returns:\n        list: A sorted list of integer IDs of the valid product records.\n    \"\"\"\n    valid_ids = []\n    VALID_TYPES = {'book', 'electronics', 'clothing'}\n    VALID_SIZES = {'xs', 's', 'm', 'l', 'xl', 'xxl'}\n\n    if not isinstance(records, list):\n        return []\n\n    for record in records:\n        try:\n            if not isinstance(record, dict):\n                continue\n\n            # 1. Normalization\n            norm_rec = {str(k).lower(): v for k, v in record.items()}\n\n            # 2. Core Field Validation\n            rec_id = norm_rec['id']\n            if not isinstance(rec_id, int) or rec_id <= 0:\n                continue\n\n            name = norm_rec['name']\n            if not isinstance(name, str):\n                continue\n            name = name.strip()\n            if not name or len(name) > 50:\n                continue\n\n            stock = norm_rec['stock']\n            if not isinstance(stock, int) or stock < 0:\n                continue\n\n            if stock == 0:\n                status = norm_rec.get('status', '')\n                if not isinstance(status, str) or status.strip().lower() != 'pre-order':\n                    continue\n\n            rec_type = norm_rec['type']\n            if not isinstance(rec_type, str):\n                continue\n            rec_type = rec_type.strip().lower()\n            if rec_type not in VALID_TYPES:\n                continue\n\n            # 3. Price Parsing and Validation\n            price_str = norm_rec['price']\n            if not isinstance(price_str, str):\n                continue\n            price_match = re.search(r'(\\d+\\.?\\d*|\\.\\d+)', price_str)\n            if not price_match:\n                continue\n            price = float(price_match.group(1))\n            if price < 0:\n                continue\n\n            # 4. Conditional Validation by Type\n            if rec_type == 'book':\n                isbn = norm_rec.get('isbn')\n                if not isinstance(isbn, str):\n                    continue\n                cleaned_isbn = re.sub(r'[^0-9]', '', isbn)\n                if len(cleaned_isbn) not in [10, 13]:\n                    continue\n\n            elif rec_type == 'electronics':\n                on_sale = norm_rec.get('on_sale', False)\n                if not isinstance(on_sale, bool):\n                    continue\n                if price < 20.00 and not on_sale:\n                    continue\n                if price > 1000.00:\n                    warranty = norm_rec.get('warranty_years')\n                    if not isinstance(warranty, int) or warranty <= 0:\n                        continue\n\n            elif rec_type == 'clothing':\n                size = norm_rec.get('size')\n                if not isinstance(size, str) or size.strip().lower() not in VALID_SIZES:\n                    continue\n\n            # If all checks passed, the record is valid\n            valid_ids.append(rec_id)\n\n        except (KeyError, TypeError, ValueError):\n            # Skip record if any essential key is missing or a value has the wrong type\n            continue\n\n    return sorted(valid_ids)\n```", "error": null, "raw_item": {"task_id": "se_filter_map_validate_nested", "entry_point": "filter_map_validate", "prompt": "Write filter_map_validate(records) that normalizes, validates, and filters product records, returning sorted list of valid IDs. Complex multi-step validation with price parsing, type constraints, and conditional rules. Return only the Python function code with no explanations.", "canonical_solution": "import re\n\ntype_order = {\"ent\": 0, \"pro\": 1, \"std\": 2}\n\ndef _parse_price(x):\n    if isinstance(x, (int, float)):\n        return float(x) if x >= 0 else None\n    if not isinstance(x, str):\n        return None\n    s = x.strip()\n    if not s:\n        return None\n    s = re.sub(r\"[\\s$€£¥]\", \"\", s)\n    if \",\" in s and \".\" in s:\n        if s.find(\",\") < s.find(\".\"):\n            s = s.replace(\",\", \"\")\n        else:\n            s = s.replace(\".\", \"\").replace(\",\", \".\")\n    elif \",\" in s:\n        s = s.replace(\",\", \".\")\n    try:\n        v = float(s)\n        return v if v >= 0 else None\n    except Exception:\n        return None\n\ndef _to_int(x):\n    if isinstance(x, bool):\n        return None\n    if isinstance(x, int):\n        return x\n    if isinstance(x, str):\n        s = x.strip()\n        if s and s.lstrip(\"-+\").isdigit():\n            try:\n                return int(s)\n            except Exception:\n                return None\n    return None\n\ndef _to_float(x):\n    if isinstance(x, (int, float)):\n        return float(x)\n    if isinstance(x, str):\n        try:\n            return float(x.strip())\n        except Exception:\n            return None\n    return None\n\ndef _to_pct(x):\n    if x is None:\n        return None\n    if isinstance(x, (int, float)):\n        v = float(x)\n    elif isinstance(x, str):\n        try:\n            v = float(x.strip().strip('%'))\n        except Exception:\n            return None\n    else:\n        return None\n    if v < 0:\n        v = 0.0\n    if v > 100:\n        v = 100.0\n    return v\n\ndef filter_map_validate(records):\n    if not isinstance(records, list):\n        return []\n    kept = []\n    for rec in records:\n        if not isinstance(rec, dict):\n            continue\n        # --- id ---\n        rid = rec.get(\"id\")\n        rid = str(rid).strip() if rid is not None else \"\"\n        if not rid:\n            continue\n        # --- meta ---\n        meta = rec.get(\"meta\") or {}\n        if not isinstance(meta, dict):\n            meta = {}\n        rtype = str(meta.get(\"type\") or \"\").strip().lower()\n        flags = meta.get(\"flags\")\n        if isinstance(flags, list):\n            flags_norm = [str(t).strip().lower() for t in flags if isinstance(t, (str, int, float))]\n        else:\n            flags_norm = []\n        if rtype not in (\"std\",\"pro\",\"ent\"):\n            continue\n        # --- price ---\n        price = _parse_price(rec.get(\"price\"))\n        if price is None:\n            continue\n        # --- attrs ---\n        attrs = rec.get(\"attrs\") or {}\n        if not isinstance(attrs, dict):\n            attrs = {}\n        color = attrs.get(\"color\")\n        color = str(color).strip().lower() if isinstance(color, str) else None\n        size = attrs.get(\"size\")\n        if size is not None:\n            size = _to_int(size)\n        weight = attrs.get(\"weight\")\n        if weight is not None:\n            weight = _to_float(weight)\n        cond = attrs.get(\"condition\")\n        cond = str(cond).strip().upper() if isinstance(cond, str) else None\n        discount = _to_pct(attrs.get(\"discount\"))\n        # --- stock ---\n        stock = _to_int(rec.get(\"stock\"))\n        if stock is None:\n            stock = 0\n        if stock < 0:\n            stock = 0\n        # --- Validation A: color/flag gate ---\n        if not ((color in {\"red\",\"blue\",\"green\"}) or (\"eco\" in flags_norm)):\n            continue\n        # --- Validation B: price caps ---\n        if rtype in (\"std\",\"pro\") and price > 1000:\n            continue\n        if rtype == \"ent\" and price > 5000:\n            continue\n        # --- Validation C: refurb implies good condition ---\n        if \"refurb\" in flags_norm:\n            if cond not in {\"A\",\"B\"}:\n                continue\n        # --- Validation D: ent requires size>=10 and stock>=1 ---\n        if rtype == \"ent\":\n            if size is None or size < 10 or stock < 1:\n                continue\n        # --- Validation E: pro weight <= 50 if provided ---\n        if rtype == \"pro\" and weight is not None and weight > 50.0:\n            continue\n        kept.append({\n            \"id\": rid,\n            \"type\": rtype,\n            \"price\": price\n        })\n    # sort: type order (ent > pro > std) i.e., ent first, then pro, then std\n    kept.sort(key=lambda r: (type_order.get(r[\"type\"], 3), r[\"price\"], r[\"id\"].lower()))\n    return [r[\"id\"] for r in kept]\n", "test": [{"input": [[{"id": " A-1 ", "meta": {"type": "ent", "flags": ["Eco"]}, "price": "€4,999.00", "attrs": {"size": "12", "color": "Green"}, "stock": "5"}, {"id": "B-2", "meta": {"type": "pro", "flags": ["refurb"]}, "price": "$800", "attrs": {"weight": "49.5", "color": "blue", "condition": "B"}, "stock": 0}, {"id": "c-3", "meta": {"type": "std", "flags": []}, "price": "1200", "attrs": {"color": "red"}, "stock": 10}, {"id": "d-4", "meta": {"type": "ent", "flags": ["eco", "refurb"]}, "price": "5100", "attrs": {"size": 15, "color": "green", "condition": "A"}, "stock": 2}, {"id": "e-5", "meta": {"type": "pro", "flags": []}, "price": "999.99", "attrs": {"color": "yellow"}, "stock": 7}]], "output": ["A-1", "B-2"]}, {"input": [[{"id": 101, "meta": {"type": "pro", "flags": ["eco"]}, "price": "1,000.00", "attrs": {"color": "RED", "weight": "50"}, "stock": "-3"}, {"id": 102, "meta": {"type": "pro", "flags": ["eco"]}, "price": "1,000.01", "attrs": {"color": "GREEN", "weight": "10"}, "stock": "0"}, {"id": 103, "meta": {"type": "std", "flags": ["eco"]}, "price": "$0", "attrs": {"color": "green"}, "stock": "0"}]], "output": ["101", "103"]}, {"input": [[{"id": "X", "meta": {"type": "ent", "flags": ["REFURB"]}, "price": "$4500", "attrs": {"size": "9", "color": "blue", "condition": "A"}, "stock": 1}, {"id": "Y", "meta": {"type": "ent", "flags": []}, "price": "$4500", "attrs": {"size": "12", "color": "blue"}, "stock": 0}, {"id": "Z", "meta": {"type": "ent", "flags": []}, "price": "$4500", "attrs": {"size": "12", "color": "blue"}, "stock": 3}]], "output": ["Z"]}, {"input": [[{"id": "bad", "meta": {"type": "other", "flags": ["eco"]}, "price": "100", "attrs": {"color": "red"}, "stock": 1}, {"id": "ok-std", "meta": {"type": "std", "flags": ["eco"]}, "price": "1000", "attrs": {"color": "green"}, "stock": 0}]], "output": ["ok-std"]}, {"input": [[{"id": "keep-pro-over-std", "meta": {"type": "pro", "flags": ["eco"]}, "price": "500", "attrs": {"color": "blue"}}, {"id": "keep-ent-first", "meta": {"type": "ent", "flags": ["eco"]}, "price": "1200", "attrs": {"color": "green", "size": 20}, "stock": 2}, {"id": "keep-std-last", "meta": {"type": "std", "flags": ["eco"]}, "price": "100", "attrs": {"color": "red"}}]], "output": ["keep-ent-first", "keep-pro-over-std", "keep-std-last"]}]}}
{"timestamp_utc": "2025-09-26T09:56:49.359751", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 26, "question": "Write sliding_window_max(arr, k) that returns maximum element in each sliding window of size k using deque. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 31.536192893981934, "response": "```python\nimport collections\n\ndef sliding_window_max(arr, k):\n    \"\"\"\n    Finds the maximum element in each sliding window of size k using a deque.\n\n    Args:\n        arr: A list of numbers.\n        k: The size of the sliding window.\n\n    Returns:\n        A list containing the maximum element for each window.\n    \"\"\"\n    if not arr or k == 0 or k > len(arr):\n        return []\n\n    output = []\n    # The deque will store indices of elements in arr\n    dq = collections.deque()\n\n    for i, val in enumerate(arr):\n        # 1. Remove indices from the left that are out of the current window\n        if dq and dq[0] <= i - k:\n            dq.popleft()\n\n        # 2. Maintain a decreasing order of values in the deque from front to back\n        #    Remove indices from the right whose corresponding values are smaller\n        #    than the current value, as they can never be the maximum.\n        while dq and arr[dq[-1]] < val:\n            dq.pop()\n\n        # 3. Add the current index to the deque\n        dq.append(i)\n\n        # 4. The front of the deque is the index of the maximum element for the\n        #    current window. Append it to the output once we have a full window.\n        if i >= k - 1:\n            output.append(arr[dq[0]])\n            \n    return output\n```", "error": null, "raw_item": {"task_id": "custom_sliding_window_max", "prompt": "Write sliding_window_max(arr, k) that returns maximum element in each sliding window of size k using deque. Return only the Python function code with no explanations.", "entry_point": "sliding_window_max", "canonical_solution": "from collections import deque\n\ndef sliding_window_max(arr: list[int], k: int) -> list[int]:\n    if not arr or k == 0:\n        return []\n    \n    dq = deque()\n    result = []\n    \n    for i in range(len(arr)):\n        # Remove elements outside current window\n        while dq and dq[0] <= i - k:\n            dq.popleft()\n        \n        # Remove elements smaller than current element\n        while dq and arr[dq[-1]] <= arr[i]:\n            dq.pop()\n        \n        dq.append(i)\n        \n        # Add maximum to result if window is complete\n        if i >= k - 1:\n            result.append(arr[dq[0]])\n    \n    return result", "test": [{"input": [[1, 3, -1, -3, 5, 3, 6, 7], 3], "output": [3, 3, 5, 5, 6, 7]}, {"input": [[1, 2, 3], 1], "output": [1, 2, 3]}, {"input": [[5, 4, 3, 2, 1], 2], "output": [5, 4, 3, 2]}, {"input": [[1], 1], "output": [1]}, {"input": [[], 3], "output": []}, {"input": [[7, 2, 4], 3], "output": [7]}]}}
{"timestamp_utc": "2025-09-26T09:57:17.296902", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 27, "question": "Write rotate_matrix(matrix) that rotates n×n matrix 90 degrees clockwise in-place using transpose and reverse. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 26.934314012527466, "response": "```python\ndef rotate_matrix(matrix):\n    \"\"\"\n    Rotates an n x n matrix 90 degrees clockwise in-place.\n    \"\"\"\n    n = len(matrix)\n\n    # Transpose the matrix\n    for i in range(n):\n        for j in range(i, n):\n            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n\n    # Reverse each row\n    for i in range(n):\n        matrix[i].reverse()\n```", "error": null, "raw_item": {"task_id": "custom_rotate_matrix", "prompt": "Write rotate_matrix(matrix) that rotates n×n matrix 90 degrees clockwise in-place using transpose and reverse. Return only the Python function code with no explanations.", "entry_point": "rotate_matrix", "canonical_solution": "def rotate_matrix(matrix: list[list[int]]) -> list[list[int]]:\n    if not matrix or not matrix[0]:\n        return matrix\n    \n    n = len(matrix)\n    \n    # Transpose the matrix\n    for i in range(n):\n        for j in range(i, n):\n            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n    \n    # Reverse each row\n    for i in range(n):\n        matrix[i].reverse()\n    \n    return matrix", "test": [{"input": [[[1, 2, 3], [4, 5, 6], [7, 8, 9]]], "output": [[7, 4, 1], [8, 5, 2], [9, 6, 3]]}, {"input": [[[1, 2], [3, 4]]], "output": [[3, 1], [4, 2]]}, {"input": [[[1]]], "output": [[1]]}, {"input": [[]], "output": []}, {"input": [[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]], "output": [[13, 9, 5, 1], [14, 10, 6, 2], [15, 11, 7, 3], [16, 12, 8, 4]]}]}}
{"timestamp_utc": "2025-09-26T09:57:39.912561", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 28, "question": "Write is_arithmetic_sequence(seq) that checks if sequence forms arithmetic progression with common difference > 0. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 21.611976861953735, "response": "```python\ndef is_arithmetic_sequence(seq):\n    if len(seq) < 2:\n        return False\n\n    difference = seq[1] - seq[0]\n\n    if difference <= 0:\n        return False\n\n    for i in range(2, len(seq)):\n        if seq[i] - seq[i-1] != difference:\n            return False\n            \n    return True\n```", "error": null, "raw_item": {"task_id": "alg_arithmetic_sequence", "entry_point": "is_arithmetic_sequence", "prompt": "Write is_arithmetic_sequence(seq) that checks if sequence forms arithmetic progression with common difference > 0. Return only the Python function code with no explanations.", "canonical_solution": "def is_arithmetic_sequence(seq):\n    if len(seq) < 2:\n        return False\n    diff = seq[1] - seq[0]\n    if diff <= 0:\n        return False\n    for i in range(2, len(seq)):\n        if seq[i] - seq[i-1] != diff:\n            return False\n    return True", "test": [{"input": [[1, 3, 5, 7, 9]], "output": true}, {"input": [[2, 4, 6, 8]], "output": true}, {"input": [[5, 5, 5]], "output": false}, {"input": [[1, 2, 4, 8]], "output": false}, {"input": [[10, 5, 0]], "output": false}]}}
{"timestamp_utc": "2025-09-26T09:57:59.464971", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 29, "question": "Write classify_severity(msg) that returns HIGH if msg contains 'error' or 'critical', MEDIUM if contains 'warning', LOW otherwise. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 18.55056405067444, "response": "```python\ndef classify_severity(msg):\n    if 'error' in msg or 'critical' in msg:\n        return 'HIGH'\n    elif 'warning' in msg:\n        return 'MEDIUM'\n    else:\n        return 'LOW'\n```", "error": null, "raw_item": {"task_id": "se_severity_classifier", "entry_point": "classify_severity", "prompt": "Write classify_severity(msg) that returns HIGH if msg contains 'error' or 'critical', MEDIUM if contains 'warning', LOW otherwise. Return only the Python function code with no explanations.", "canonical_solution": "def classify_severity(msg):\n    msg_lower = msg.lower()\n    if 'error' in msg_lower or 'critical' in msg_lower:\n        return 'HIGH'\n    elif 'warning' in msg_lower:\n        return 'MEDIUM'\n    else:\n        return 'LOW'", "test": [{"input": ["System error occurred"], "output": "HIGH"}, {"input": ["Critical failure detected"], "output": "HIGH"}, {"input": ["Warning: disk space low"], "output": "MEDIUM"}, {"input": ["Info: task completed"], "output": "LOW"}, {"input": ["ERROR in database"], "output": "HIGH"}]}}
{"timestamp_utc": "2025-09-26T09:58:15.944899", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 30, "question": "Write find_peak_index(arr) that finds index of first element that is greater than both neighbors. Return -1 if no peak exists. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 15.477341175079346, "response": "```python\ndef find_peak_index(arr):\n    \"\"\"\n    Finds the index of the first element in an array that is strictly greater than both of its neighbors.\n    \n    Args:\n        arr: A list of numbers.\n        \n    Returns:\n        The index of the first peak element.\n        Returns -1 if no such peak exists or the array is too short to have a peak.\n    \"\"\"\n    # A peak must have two neighbors, so we check from the second to the second-to-last element.\n    for i in range(1, len(arr) - 1):\n        # Check if the current element is greater than its left and right neighbors\n        if arr[i] > arr[i-1] and arr[i] > arr[i+1]:\n            return i  # Found the first peak, return its index\n            \n    return -1  # No peak was found\n```", "error": null, "raw_item": {"task_id": "alg_peak_finder", "entry_point": "find_peak_index", "prompt": "Write find_peak_index(arr) that finds index of first element that is greater than both neighbors. Return -1 if no peak exists. Return only the Python function code with no explanations.", "canonical_solution": "def find_peak_index(arr):\n    if len(arr) < 3:\n        return -1\n    for i in range(1, len(arr) - 1):\n        if arr[i] > arr[i-1] and arr[i] > arr[i+1]:\n            return i\n    return -1", "test": [{"input": [[1, 3, 2, 4, 1]], "output": 1}, {"input": [[1, 2, 3, 2, 1]], "output": 2}, {"input": [[1, 2, 3, 4, 5]], "output": -1}, {"input": [[5, 4, 3, 2, 1]], "output": -1}, {"input": [[1, 3, 1]], "output": 1}]}}
{"timestamp_utc": "2025-09-26T09:58:55.478304", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 31, "question": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 38.53017807006836, "response": "An elegant way to solve this is to use a dictionary to group the anagrams. The key for each group can be the \"canonical\" representation of an anagram, which is simply the word with its characters sorted. For example, \"eat\", \"tea\", and \"ate\" all become \"aet\" when their characters are sorted.\n\nHere's the step-by-step logic:\n1.  Initialize an empty dictionary to store the groups. A `collections.defaultdict(list)` is perfect for this, as it simplifies appending to lists.\n2.  Iterate through each `word` in the input list.\n3.  For each `word`, create a key by sorting its characters and joining them back into a string (e.g., `''.join(sorted(word))`).\n4.  Use this key to append the original `word` to the corresponding list in the dictionary.\n5.  After iterating through all words, the dictionary's values will be the unsorted groups of anagrams.\n6.  Create a new list from these dictionary values.\n7.  Sort the words alphabetically *within* each group.\n8.  Finally, sort the list of groups themselves. Python's default list sorting will sort them based on their first element, which satisfies the requirement.\n\n```python\nfrom collections import defaultdict\n\ndef find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"\n    # Use a defaultdict to automatically handle the creation of new group lists.\n    anagram_groups = defaultdict(list)\n\n    # Group words by their sorted character representation.\n    for word in words:\n        # The key is the sorted version of the word, e.g., \"aet\" for \"eat\".\n        key = \"\".join(sorted(word))\n        anagram_groups[key].append(word)\n\n    # Get the lists of anagrams from the dictionary's values.\n    # Sort the words within each group alphabetically.\n    result = [sorted(group) for group in anagram_groups.values()]\n    \n    # Sort the groups themselves based on their first word.\n    # Python's default list sort works perfectly for this.\n    result.sort()\n\n    return result\n\n```", "error": null, "raw_item": {"task_id": "custom_find_anagrams", "prompt": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"\n    ", "entry_point": "find_anagrams", "canonical_solution": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    from collections import defaultdict\n    \n    anagram_groups = defaultdict(list)\n    \n    for word in words:\n        # Use sorted characters as key\n        key = ''.join(sorted(word))\n        anagram_groups[key].append(word)\n    \n    result = []\n    for group in anagram_groups.values():\n        group.sort()\n        result.append(group)\n    \n    # Sort groups by their first word\n    result.sort(key=lambda x: x[0])\n    \n    return result", "test": [{"input": [["eat", "tea", "tan", "ate", "nat", "bat"]], "output": [["ate", "eat", "tea"], ["bat"], ["nat", "tan"]]}, {"input": [["hello", "world"]], "output": [["hello"], ["world"]]}, {"input": [[]], "output": []}, {"input": [["a", "aa", "aaa"]], "output": [["a"], ["aa"], ["aaa"]]}, {"input": [["abc", "bca", "cab", "xyz"]], "output": [["abc", "bca", "cab"], ["xyz"]]}]}}
{"timestamp_utc": "2025-09-26T09:59:33.499483", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 32, "question": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 37.01832389831543, "response": "```python\nimport collections\n\ndef merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    The core idea is to first sort the intervals by their starting points.\n    Then, we iterate through the sorted intervals and decide whether to merge\n    the current interval with the previous one or to add it as a new interval.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n\n    >>> merge_intervals([[1, 5]])\n    [[1, 5]]\n    \"\"\"\n    # 1. Handle the edge case of an empty list.\n    if not intervals:\n        return []\n\n    # 2. Sort the intervals based on their starting point.\n    # This is the crucial step that allows us to process intervals in order.\n    intervals.sort(key=lambda x: x[0])\n\n    # 3. Initialize a 'merged' list with the first interval.\n    # We will compare subsequent intervals to the last one in this list.\n    merged = [intervals[0]]\n\n    # 4. Iterate through the rest of the intervals (from the second one).\n    for i in range(1, len(intervals)):\n        current_start, current_end = intervals[i]\n        last_merged_start, last_merged_end = merged[-1]\n\n        # 5. Check for an overlap.\n        # An overlap occurs if the current interval's start is less than or\n        # equal to the end of the last merged interval.\n        if current_start <= last_merged_end:\n            # If they overlap, merge them by updating the end of the last\n            # interval in 'merged' to be the maximum of the two ends.\n            merged[-1][1] = max(last_merged_end, current_end)\n        else:\n            # If there's no overlap, the current interval is a new,\n            # non-overlapping interval, so we append it to our 'merged' list.\n            merged.append([current_start, current_end])\n\n    return merged\n```", "error": null, "raw_item": {"task_id": "custom_merge_intervals", "prompt": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"\n    ", "entry_point": "merge_intervals", "canonical_solution": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    if not intervals:\n        return []\n    \n    # Sort intervals by start time\n    intervals.sort(key=lambda x: x[0])\n    \n    merged = [intervals[0]]\n    \n    for current in intervals[1:]:\n        last = merged[-1]\n        \n        # Check if current interval overlaps with last merged interval\n        if current[0] <= last[1]:\n            # Merge intervals\n            last[1] = max(last[1], current[1])\n        else:\n            # No overlap, add current interval\n            merged.append(current)\n    \n    return merged", "test": [{"input": [[[1, 3], [2, 6], [8, 10], [15, 18]]], "output": [[1, 6], [8, 10], [15, 18]]}, {"input": [[[1, 4], [4, 5]]], "output": [[1, 5]]}, {"input": [[[1, 4], [0, 2], [3, 5]]], "output": [[0, 5]]}, {"input": [[]], "output": []}, {"input": [[[1, 2]]], "output": [[1, 2]]}, {"input": [[[1, 4], [2, 3]]], "output": [[1, 4]]}]}}
{"timestamp_utc": "2025-09-26T10:00:21.040088", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 33, "question": "def binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 46.53684210777283, "response": "This problem is a classic tree traversal exercise, perfectly suited for a recursive Depth-First Search (DFS) approach. We need to explore each path from the root down to a leaf, building a string representation of the path as we go.\n\nHere's a step-by-step breakdown of the logic:\n\n1.  **Main Function (`binary_tree_paths`):**\n    *   This function will be the public interface. Its main job is to handle the initial setup.\n    *   **Edge Case:** If the input `root` is `None`, the tree is empty, so we should return an empty list `[]` as per the requirements.\n    *   It will initialize an empty list, let's call it `result_paths`, to store the final path strings.\n    *   It will then kick off the recursive process using a helper function.\n\n2.  **Recursive Helper Function (e.g., `dfs`):**\n    *   This function will do the heavy lifting of traversing the tree.\n    *   It needs to know two things at each step:\n        1.  The `node` it's currently visiting.\n        2.  The `current_path` string built so far to reach this `node`.\n    *   **Action:** When the helper is called on a `node`, it first appends that `node`'s value to the `current_path`.\n    *   **Base Case (Leaf Node):** The recursion stops when we reach a leaf. A node is a leaf if both its `left` and `right` children are `None`. When this happens, we have found a complete root-to-leaf path. We add the fully constructed `current_path` string to our `result_paths` list and stop going down this branch.\n    *   **Recursive Step (Internal Node):** If the current node is not a leaf, we need to continue exploring.\n        *   If the `left` child exists, we recursively call the helper function on the `left` child, passing along the updated `current_path`.\n        *   If the `right` child exists, we do the same for the `right` child.\n\nLet's trace the first example: `{'val': 1, 'left': {'val': 2, ...}, 'right': {'val': 3, ...}}`\n\n1.  `binary_tree_paths(root)` is called. `root` is not `None`.\n2.  `result_paths` = `[]`.\n3.  Call `dfs(node=1, current_path=\"\")`.\n4.  Inside `dfs(node=1, current_path=\"\")`:\n    *   `new_path` becomes `\"1\"`.\n    *   Node 1 is not a leaf.\n    *   Call `dfs(node=2, current_path=\"1->\")`.\n5.  Inside `dfs(node=2, current_path=\"1->\")`:\n    *   `new_path` becomes `\"1->2\"`.\n    *   Node 2 is not a leaf.\n    *   Left child is `None`.\n    *   Call `dfs(node=5, current_path=\"1->2->\")`.\n6.  Inside `dfs(node=5, current_path=\"1->2->\")`:\n    *   `new_path` becomes `\"1->2->5\"`.\n    *   Node 5 **is a leaf** (left and right are `None`).\n    *   Add `\"1->2->5\"` to `result_paths`. `result_paths` is now `['1->2->5']`.\n    *   Return from this call.\n7.  Back in `dfs(node=2, ...)`: The call for the right child (node 5) is finished. The function for node 2 finishes and returns.\n8.  Back in `dfs(node=1, ...)`: The call for the left child (node 2) is finished.\n    *   Now, call `dfs(node=3, current_path=\"1->\")`.\n9.  Inside `dfs(node=3, current_path=\"1->\")`:\n    *   `new_path` becomes `\"1->3\"`.\n    *   Node 3 **is a leaf**.\n    *   Add `\"1->3\"` to `result_paths`. `result_paths` is now `['1->2->5', '1->3']`.\n    *   Return from this call.\n10. Back in `dfs(node=1, ...)`: The call for the right child (node 3) is finished. The function for node 1 finishes.\n11. The initial `binary_tree_paths` function returns `result_paths`, which is `['1->2->5', '1->3']`.\n\nThis logic correctly finds all paths.\n\n```python\ndef binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"\n    # Handle the edge case of an empty tree\n    if not root:\n        return []\n\n    # This list will be populated by the recursive helper function\n    paths = []\n\n    def find_paths_recursive(node: dict, current_path: str):\n        \"\"\"A helper function to perform DFS and build path strings.\"\"\"\n        \n        # Append the current node's value to the path string\n        # If the path is empty (root node), just use the value. Otherwise, add an arrow.\n        if not current_path:\n            path_so_far = str(node['val'])\n        else:\n            path_so_far = current_path + \"->\" + str(node['val'])\n\n        # Base case: If it's a leaf node, we've found a complete path.\n        is_leaf = not node['left'] and not node['right']\n        if is_leaf:\n            paths.append(path_so_far)\n            return\n\n        # Recursive step: Continue down the left and/or right children.\n        if node['left']:\n            find_paths_recursive(node['left'], path_so_far)\n        \n        if node['right']:\n            find_paths_recursive(node['right'], path_so_far)\n\n    # Start the recursion from the root with an empty path\n    find_paths_recursive(root, \"\")\n    \n    return paths\n\n```", "error": null, "raw_item": {"task_id": "custom_binary_tree_paths", "prompt": "def binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"\n    ", "entry_point": "binary_tree_paths", "canonical_solution": "def binary_tree_paths(root: dict | None) -> list[str]:\n    if not root:\n        return []\n    \n    paths = []\n    \n    def dfs(node, path):\n        if not node:\n            return\n        \n        # Add current node to path\n        current_path = path + [str(node['val'])]\n        \n        # If leaf node, add path to result\n        if not node['left'] and not node['right']:\n            paths.append('->'.join(current_path))\n            return\n        \n        # Recurse on children\n        if node['left']:\n            dfs(node['left'], current_path)\n        if node['right']:\n            dfs(node['right'], current_path)\n    \n    dfs(root, [])\n    return paths", "test": [{"input": [{"val": 1, "left": {"val": 2, "left": null, "right": {"val": 5, "left": null, "right": null}}, "right": {"val": 3, "left": null, "right": null}}], "output": ["1->2->5", "1->3"]}, {"input": [{"val": 1, "left": null, "right": null}], "output": ["1"]}, {"input": [null], "output": []}, {"input": [{"val": 1, "left": {"val": 2, "left": null, "right": null}, "right": {"val": 3, "left": null, "right": null}}], "output": ["1->2", "1->3"]}]}}
{"timestamp_utc": "2025-09-26T10:01:11.642659", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 34, "question": "def word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 49.598358154296875, "response": "```python\ndef word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"\n    words = s.split()\n\n    # If the number of characters in the pattern and the number of words\n    # are different, they can't possibly match.\n    if len(pattern) != len(words):\n        return False\n\n    # To check for a bijection, we need to ensure two things:\n    # 1. Each character in the pattern maps to exactly one word.\n    # 2. Each word is mapped to by exactly one character.\n    # We can use two dictionaries (hash maps) to track these mappings.\n\n    char_to_word = {}\n    word_to_char = {}\n\n    for char, word in zip(pattern, words):\n        # Check the forward mapping (char -> word)\n        if char in char_to_word:\n            # If the char is already mapped, it must map to the current word.\n            if char_to_word[char] != word:\n                return False\n        # If the char is not yet mapped, we also need to check the reverse mapping.\n        else:\n            # Check the reverse mapping (word -> char)\n            # If the word is already mapped to a different character, it's a violation.\n            if word in word_to_char:\n                return False\n            \n            # If no conflicts, establish the new bidirectional mapping.\n            char_to_word[char] = word\n            word_to_char[word] = char\n            \n    # If the loop completes without returning False, the pattern is valid.\n    return True\n\n```", "error": null, "raw_item": {"task_id": "custom_word_pattern", "prompt": "def word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"\n    ", "entry_point": "word_pattern", "canonical_solution": "def word_pattern(pattern: str, s: str) -> bool:\n    words = s.split()\n    \n    if len(pattern) != len(words):\n        return False\n    \n    char_to_word = {}\n    word_to_char = {}\n    \n    for char, word in zip(pattern, words):\n        # Check char -> word mapping\n        if char in char_to_word:\n            if char_to_word[char] != word:\n                return False\n        else:\n            char_to_word[char] = word\n        \n        # Check word -> char mapping (bijection)\n        if word in word_to_char:\n            if word_to_char[word] != char:\n                return False\n        else:\n            word_to_char[word] = char\n    \n    return True", "test": [{"input": ["abba", "dog cat cat dog"], "output": true}, {"input": ["abba", "dog cat cat fish"], "output": false}, {"input": ["aaaa", "dog cat cat dog"], "output": false}, {"input": ["abba", "dog dog dog dog"], "output": false}, {"input": ["abc", "dog cat fish"], "output": true}, {"input": ["a", "dog"], "output": true}, {"input": ["ab", "dog"], "output": false}]}}
{"timestamp_utc": "2025-09-26T10:02:03.494551", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 35, "question": "class MinStack:\n    \"\"\"\n    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\n    Implement the MinStack class:\n    - MinStack() initializes the stack object.\n    - push(val) pushes the element val onto the stack.\n    - pop() removes the element on the top of the stack.\n    - top() gets the top element of the stack.\n    - get_min() retrieves the minimum element in the stack.\n\n    You must implement a solution with O(1) time complexity for each function.\n\n    Examples:\n    >>> stack = MinStack()\n    >>> stack.push(-2)\n    >>> stack.push(0)\n    >>> stack.push(-3)\n    >>> stack.get_min()\n    -3\n    >>> stack.pop()\n    >>> stack.top()\n    0\n    >>> stack.get_min()\n    -2\n    \"\"\"", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 50.76901817321777, "response": "An elegant and common way to solve this problem is by using two stacks.\n\n1.  **`self.stack`**: This will be a normal stack that holds all the values pushed into it.\n2.  **`self.min_stack`**: This second stack will track the minimum value at each stage. The top of `self.min_stack` will always be the minimum value of the entire `self.stack`.\n\nHere's how the logic works for each function:\n\n*   **`push(val)`**:\n    1.  Push the `val` onto the main `self.stack`.\n    2.  Check the `self.min_stack`.\n        *   If `self.min_stack` is empty, or if `val` is less than or equal to the current minimum (which is `self.min_stack[-1]`), then push `val` onto `self.min_stack` as well. This new value is the new minimum.\n        *   A simpler, though slightly less space-efficient, approach is to always push a value onto `min_stack`. We push `min(val, current_min)`, where `current_min` is the top of `min_stack` (or infinity if the stack is empty). This keeps the two stacks synchronized in size, simplifying the `pop` operation.\n\n*   **`pop()`**:\n    1.  Pop the value from the main `self.stack`.\n    2.  If using the simplified `push` logic, we simply pop from `self.min_stack` as well. Since the stacks are always the same size, the minimum corresponding to the popped element is also removed, revealing the previous minimum.\n\n*   **`top()`**:\n    *   Return the top element of `self.stack`.\n\n*   **`get_min()`**:\n    *   Return the top element of `self.min_stack`.\n\nBecause all stack operations (append, pop, and accessing the last element) are O(1), all four required functions will also have a time complexity of O(1).\n\n### Python Implementation\n\n```python\nclass MinStack:\n    \"\"\"\n    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\n    Implement the MinStack class:\n    - MinStack() initializes the stack object.\n    - push(val) pushes the element val onto the stack.\n    - pop() removes the element on the top of the stack.\n    - top() gets the top element of the stack.\n    - get_min() retrieves the minimum element in the stack.\n\n    You must implement a solution with O(1) time complexity for each function.\n\n    Examples:\n    >>> stack = MinStack()\n    >>> stack.push(-2)\n    >>> stack.push(0)\n    >>> stack.push(-3)\n    >>> stack.get_min()\n    -3\n    >>> stack.pop()\n    >>> stack.top()\n    0\n    >>> stack.get_min()\n    -2\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the MinStack object with two lists acting as stacks.\n        self.stack stores all elements.\n        self.min_stack stores the minimum value at each level of the stack.\n        \"\"\"\n        self.stack = []\n        self.min_stack = []\n\n    def push(self, val: int) -> None:\n        \"\"\"\n        Pushes an element onto the stack and updates the minimum stack.\n        \"\"\"\n        self.stack.append(val)\n        \n        # Determine the new minimum. It's either the new value or the existing minimum.\n        if not self.min_stack:\n            # If min_stack is empty, the new value is the first and only minimum.\n            current_min = val\n        else:\n            # Compare the new value with the current minimum.\n            current_min = min(val, self.min_stack[-1])\n            \n        self.min_stack.append(current_min)\n\n    def pop(self) -> None:\n        \"\"\"\n        Removes the top element from both stacks to keep them in sync.\n        This ensures that get_min() always returns the minimum of the remaining elements.\n        \"\"\"\n        if self.stack:\n            self.stack.pop()\n            self.min_stack.pop()\n\n    def top(self) -> int:\n        \"\"\"\n        Returns the top element of the main stack.\n        \"\"\"\n        if self.stack:\n            return self.stack[-1]\n        return None  # Or raise an exception for an empty stack\n\n    def get_min(self) -> int:\n        \"\"\"\n        Returns the current minimum element, which is the top of the min_stack.\n        \"\"\"\n        if self.min_stack:\n            return self.min_stack[-1]\n        return None # Or raise an exception for an empty stack\n\n```", "error": null, "raw_item": {"task_id": "custom_min_stack", "prompt": "class MinStack:\n    \"\"\"\n    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\n    Implement the MinStack class:\n    - MinStack() initializes the stack object.\n    - push(val) pushes the element val onto the stack.\n    - pop() removes the element on the top of the stack.\n    - top() gets the top element of the stack.\n    - get_min() retrieves the minimum element in the stack.\n\n    You must implement a solution with O(1) time complexity for each function.\n\n    Examples:\n    >>> stack = MinStack()\n    >>> stack.push(-2)\n    >>> stack.push(0)\n    >>> stack.push(-3)\n    >>> stack.get_min()\n    -3\n    >>> stack.pop()\n    >>> stack.top()\n    0\n    >>> stack.get_min()\n    -2\n    \"\"\"\n    ", "entry_point": "MinStack", "canonical_solution": "class MinStack:\n    def __init__(self):\n        self.stack = []\n        self.min_stack = []\n    \n    def push(self, val: int) -> None:\n        self.stack.append(val)\n        # Push to min_stack if it's empty or val is <= current minimum\n        if not self.min_stack or val <= self.min_stack[-1]:\n            self.min_stack.append(val)\n    \n    def pop(self) -> None:\n        if self.stack:\n            val = self.stack.pop()\n            # Pop from min_stack if the popped value was the minimum\n            if self.min_stack and val == self.min_stack[-1]:\n                self.min_stack.pop()\n    \n    def top(self) -> int:\n        return self.stack[-1] if self.stack else None\n    \n    def get_min(self) -> int:\n        return self.min_stack[-1] if self.min_stack else None", "test": [{"input": [["MinStack", "push", "push", "push", "get_min", "pop", "top", "get_min"], [[], [-2], [0], [-3], [], [], [], []]], "output": [null, null, null, null, -3, null, 0, -2]}, {"input": [["MinStack", "push", "push", "get_min", "get_min", "pop", "get_min"], [[], [1], [2], [], [], [], []]], "output": [null, null, null, 1, 1, null, 1]}, {"input": [["MinStack", "push", "get_min", "pop", "push", "get_min"], [[], [1], [], [], [2], []]], "output": [null, null, 1, null, null, 2]}]}}
{"timestamp_utc": "2025-09-26T10:02:57.116207", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 36, "question": "class LRUCache:\n    \"\"\"\n    Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.\n\n    Implement the LRUCache class:\n    - LRUCache(capacity) Initialize the LRU cache with positive size capacity.\n    - get(key) Return the value of the key if the key exists, otherwise return -1.\n    - put(key, value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache.\n      If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\n    The functions get and put must each run in O(1) average time complexity.\n\n    Examples:\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 52.61176419258118, "response": "An elegant and efficient solution to this problem uses a combination of two data structures:\n\n1.  A **Hash Map (Dictionary in Python)**: This provides O(1) average time complexity for accessing elements by their key. We will use it to store the key and a reference (pointer) to a node in a doubly linked list. `map: key -> Node`\n\n2.  A **Doubly Linked List**: This data structure allows for O(1) time complexity for adding or removing nodes from either end, or from the middle if we have a direct reference to the node. We will use this list to maintain the order of \"recency.\" The most recently used item will be at one end (e.g., the tail), and the least recently used item will be at the other end (the head).\n\n### How It Works:\n\n*   **`__init__(capacity)`**:\n    *   Initialize a dictionary `self.cache` to store `key -> Node` mappings.\n    *   Initialize a `self.capacity` variable.\n    *   Create a doubly linked list. To simplify edge cases (like an empty list or removing the last element), we use two \"sentinel\" or \"dummy\" nodes: `self.head` and `self.tail`. The actual cached items will always be between these two nodes.\n    *   `self.head` points to the least recently used (LRU) side, and `self.tail` points to the most recently used (MRU) side.\n\n*   **`get(key)`**:\n    1.  Look up the `key` in the `self.cache` dictionary.\n    2.  If the key is not found, return -1.\n    3.  If the key is found, we have its corresponding `Node`. This access makes the item the most recently used. Therefore, we must move its node to the tail (MRU end) of our doubly linked list.\n    4.  Return the value from the node.\n\n*   **`put(key, value)`**:\n    1.  Check if the `key` already exists in `self.cache`.\n    2.  **If it exists**: Update the value in its corresponding node and move that node to the tail (MRU end) of the list.\n    3.  **If it's a new key**:\n        a. Create a new `Node` with the key and value.\n        b. Add the new node to the tail (MRU end) of the list.\n        c. Add the new `key -> Node` mapping to the `self.cache` dictionary.\n        d. Check if the cache size (`len(self.cache)`) now exceeds `self.capacity`.\n        e. If it does, we must evict the least recently used item. This is the node right after our dummy `self.head`. Remove it from both the linked list and the `self.cache` dictionary.\n\nBy combining these two structures, all operations (`get` and `put`) achieve an average time complexity of O(1).\n\n### Implementation\n\n```python\nclass Node:\n    \"\"\"A node in a doubly linked list.\"\"\"\n    def __init__(self, key, val):\n        self.key = key\n        self.val = val\n        self.prev = None\n        self.next = None\n\nclass LRUCache:\n    \"\"\"\n    Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.\n\n    Implement the LRUCache class:\n    - LRUCache(capacity) Initialize the LRU cache with positive size capacity.\n    - get(key) Return the value of the key if the key exists, otherwise return -1.\n    - put(key, value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache.\n      If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\n    The functions get and put must each run in O(1) average time complexity.\n\n    Examples:\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        # Hash map: key -> Node\n        self.cache = {}\n        \n        # Dummy head and tail for the doubly linked list\n        # head <-> ...nodes... <-> tail\n        # head.next is the LRU, tail.prev is the MRU\n        self.head = Node(0, 0)\n        self.tail = Node(0, 0)\n        self.head.next = self.tail\n        self.tail.prev = self.head\n\n    # --- Internal Helper Methods for Linked List ---\n\n    def _remove(self, node: Node):\n        \"\"\"Removes a node from the doubly linked list.\"\"\"\n        prev_node = node.prev\n        next_node = node.next\n        prev_node.next = next_node\n        next_node.prev = prev_node\n\n    def _add_to_tail(self, node: Node):\n        \"\"\"Adds a node right before the tail (making it the most recent).\"\"\"\n        prev_tail = self.tail.prev\n        prev_tail.next = node\n        node.prev = prev_tail\n        node.next = self.tail\n        self.tail.prev = node\n\n    # --- Public API ---\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n\n        node = self.cache[key]\n        # Move the accessed node to the tail (most recently used)\n        self._remove(node)\n        self._add_to_tail(node)\n        \n        return node.val\n\n    def put(self, key: int, value: int) -> None:\n        # If key exists, update its value and move it to the tail\n        if key in self.cache:\n            node = self.cache[key]\n            node.val = value\n            self._remove(node)\n            self._add_to_tail(node)\n            return\n\n        # If the cache is at full capacity, evict the least recently used item\n        if len(self.cache) == self.capacity:\n            # The LRU node is the one right after the dummy head\n            lru_node = self.head.next\n            self._remove(lru_node)\n            del self.cache[lru_node.key]\n\n        # Add the new key-value pair\n        new_node = Node(key, value)\n        self.cache[key] = new_node\n        self._add_to_tail(new_node)\n```", "error": null, "raw_item": {"task_id": "custom_lru_cache", "prompt": "class LRUCache:\n    \"\"\"\n    Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.\n\n    Implement the LRUCache class:\n    - LRUCache(capacity) Initialize the LRU cache with positive size capacity.\n    - get(key) Return the value of the key if the key exists, otherwise return -1.\n    - put(key, value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache.\n      If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\n    The functions get and put must each run in O(1) average time complexity.\n\n    Examples:\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"\n    ", "entry_point": "LRUCache", "canonical_solution": "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        # Use a list to maintain order (least recent at index 0)\n        self.order = []\n    \n    def get(self, key: int) -> int:\n        if key in self.cache:\n            # Move to end (most recently used)\n            self.order.remove(key)\n            self.order.append(key)\n            return self.cache[key]\n        return -1\n    \n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            # Update existing key\n            self.cache[key] = value\n            self.order.remove(key)\n            self.order.append(key)\n        else:\n            # Add new key\n            if len(self.cache) >= self.capacity:\n                # Remove least recently used\n                lru_key = self.order.pop(0)\n                del self.cache[lru_key]\n            \n            self.cache[key] = value\n            self.order.append(key)", "test": [{"input": [["LRUCache", "put", "put", "get", "put", "get", "put", "get", "get", "get"], [[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]], "output": [null, null, null, 1, null, -1, null, -1, 3, 4]}, {"input": [["LRUCache", "put", "get", "put", "get", "get"], [[1], [2, 1], [2], [3, 2], [2], [3]]], "output": [null, null, 1, null, -1, 2]}]}}
{"timestamp_utc": "2025-09-26T10:03:50.736978", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 37, "question": "def validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 52.61818337440491, "response": "An excellent way to solve this is to create two helper functions, one for each IP version, and then call them from the main function. This keeps the logic clean and separated.\n\n### 1. IPv4 Validation Logic\n\n1.  **Split the string:** Use `ip.split('.')`. A valid IPv4 address must have exactly 4 parts.\n2.  **Check each part:**\n    *   It must be a numeric string (`.isdigit()`).\n    *   It cannot have leading zeros unless the part is just \"0\". A simple check for this is `len(part) > 1 and part.startswith('0')`.\n    *   When converted to an integer, its value must be between 0 and 255.\n\n### 2. IPv6 Validation Logic\n\n1.  **Split the string:** Use `ip.split(':')`. A valid IPv6 address must have exactly 8 parts.\n2.  **Check each part:**\n    *   Its length must be between 1 and 4 characters.\n    *   Each character must be a valid hexadecimal digit (0-9, a-f, A-F). A clean, Pythonic way to check this is to try converting the part to an integer from base 16. If it fails, it contains invalid characters.\n\n### 3. Main Function Logic\n\n1.  First, try to validate the string as an IPv4 address. If it succeeds, return \"IPv4\".\n2.  If it's not a valid IPv4, try to validate it as an IPv6 address. If it succeeds, return \"IPv6\".\n3.  If both validations fail, return \"Neither\".\n\n```python\ndef validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"\n\n    def is_ipv4(s: str) -> bool:\n        \"\"\"Helper function to validate an IPv4 address.\"\"\"\n        try:\n            parts = s.split('.')\n            # Must have four parts\n            if len(parts) != 4:\n                return False\n            for part in parts:\n                # Each part must not have leading zeros (unless it's \"0\")\n                if len(part) > 1 and part.startswith('0'):\n                    return False\n                # Each part must be a number in the 0-255 range\n                # isdigit() check also handles empty parts from \"1..2.3.4\"\n                if not part.isdigit() or not (0 <= int(part) <= 255):\n                    return False\n            return True\n        except (ValueError, AttributeError):\n            # Catches errors from int() conversion or split() on non-strings\n            return False\n\n    def is_ipv6(s: str) -> bool:\n        \"\"\"Helper function to validate an IPv6 address.\"\"\"\n        try:\n            parts = s.split(':')\n            # Must have eight parts\n            if len(parts) != 8:\n                return False\n            for part in parts:\n                # Each part must be 1-4 hex digits long\n                if not (1 <= len(part) <= 4):\n                    return False\n                # Each part must be a valid hexadecimal number.\n                # int(part, 16) will raise a ValueError if not.\n                int(part, 16)\n            return True\n        except (ValueError, AttributeError):\n            # Catches errors from int(part, 16) or split()\n            return False\n\n    if is_ipv4(ip):\n        return \"IPv4\"\n    elif is_ipv6(ip):\n        return \"IPv6\"\n    else:\n        return \"Neither\"\n\n```", "error": null, "raw_item": {"task_id": "custom_validate_ip_address", "prompt": "def validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"\n    ", "entry_point": "validate_ip_address", "canonical_solution": "def validate_ip_address(ip: str) -> str:\n    def is_valid_ipv4(ip):\n        parts = ip.split('.')\n        if len(parts) != 4:\n            return False\n        \n        for part in parts:\n            if not part or len(part) > 3:\n                return False\n            \n            # Check for leading zeros\n            if len(part) > 1 and part[0] == '0':\n                return False\n            \n            # Check if all characters are digits\n            if not part.isdigit():\n                return False\n            \n            # Check range\n            num = int(part)\n            if num < 0 or num > 255:\n                return False\n        \n        return True\n    \n    def is_valid_ipv6(ip):\n        parts = ip.split(':')\n        if len(parts) != 8:\n            return False\n        \n        for part in parts:\n            if not part or len(part) > 4:\n                return False\n            \n            # Check if all characters are valid hex\n            for char in part:\n                if char not in '0123456789abcdefABCDEF':\n                    return False\n        \n        return True\n    \n    if is_valid_ipv4(ip):\n        return \"IPv4\"\n    elif is_valid_ipv6(ip):\n        return \"IPv6\"\n    else:\n        return \"Neither\"", "test": [{"input": ["172.16.254.1"], "output": "IPv4"}, {"input": ["2001:0db8:85a3:0000:0000:8a2e:0370:7334"], "output": "IPv6"}, {"input": ["256.256.256.256"], "output": "Neither"}, {"input": ["192.168.1.1.1"], "output": "Neither"}, {"input": ["192.168.01.1"], "output": "Neither"}, {"input": ["2001:0db8:85a3::8a2e:0370:7334"], "output": "Neither"}, {"input": [""], "output": "Neither"}]}}
{"timestamp_utc": "2025-09-26T10:04:54.599493", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 38, "question": "Merge two dictionaries with integer values by keeping the maximum value for each key.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 62.85909605026245, "response": "Of course! Here are a few ways to merge two dictionaries by keeping the maximum value for common keys, ranging from the most common and Pythonic to other alternatives.\n\nLet's use these two dictionaries as an example:\n\n```python\nd1 = {'a': 100, 'b': 200, 'c': 300}\nd2 = {'a': 150, 'b': 180, 'd': 400}\n```\n\nThe desired result is `{'a': 150, 'b': 200, 'c': 300, 'd': 400}`.\n\n---\n\n### Method 1: Using a Dictionary Comprehension (Most Pythonic)\n\nThis is a concise and highly readable one-liner. It works by first creating a set of all unique keys from both dictionaries and then iterating over them to build the new dictionary.\n\n```python\nd1 = {'a': 100, 'b': 200, 'c': 300}\nd2 = {'a': 150, 'b': 180, 'd': 400}\n\n# Get all unique keys from both dictionaries using set union |\nall_keys = d1.keys() | d2.keys()\n\n# Use float('-inf') as a default for keys that don't exist in one of the dicts\nmerged_dict = {\n    key: max(d1.get(key, float('-inf')), d2.get(key, float('-inf')))\n    for key in all_keys\n}\n\nprint(merged_dict)\n# Output: {'c': 300, 'd': 400, 'b': 200, 'a': 150}\n# Note: Dictionary order may vary in older Python versions.\n```\n\n**How it works:**\n1.  `d1.keys() | d2.keys()` creates a set of all unique keys from `d1` and `d2` (`{'a', 'b', 'c', 'd'}`).\n2.  The comprehension iterates through each `key` in this set.\n3.  `d1.get(key, float('-inf'))` safely gets the value for the key from `d1`. If the key doesn't exist, it returns negative infinity (`-inf`), which will lose any `max()` comparison against an actual integer.\n4.  `max()` then finds the maximum value between the two dictionaries for that key.\n\n---\n\n### Method 2: Using a Simple Loop (Easy to Understand)\n\nThis approach is more verbose but can be easier for beginners to follow. It involves creating a copy of the first dictionary and then updating it by iterating through the second.\n\n```python\nd1 = {'a': 100, 'b': 200, 'c': 300}\nd2 = {'a': 150, 'b': 180, 'd': 400}\n\n# Start with a copy of the first dictionary\nmerged_dict = d1.copy()\n\nfor key, value in d2.items():\n    # If key exists in the merged_dict, update with the max value.\n    # Otherwise, set it to the new value.\n    # The .get() method handles both cases elegantly.\n    merged_dict[key] = max(merged_dict.get(key, value), value)\n\nprint(merged_dict)\n# Output: {'a': 150, 'b': 200, 'c': 300, 'd': 400}\n```\n\n**How it works:**\n1.  `merged_dict = d1.copy()` creates a new dictionary so we don't modify the original `d1`.\n2.  We loop through each `key` and `value` in the second dictionary (`d2`).\n3.  `merged_dict.get(key, value)` tries to get the current value for the `key` from our `merged_dict`. If the key isn't there (e.g., for key `'d'`), it defaults to the `value` from `d2`.\n4.  `max()` compares this existing value with the new `value` from `d2` and the result is stored.\n\n---\n\n### Method 3: Using `collections.Counter` (Elegant but Specific)\n\nThe `collections.Counter` object is a specialized dictionary subclass. Its union operator (`|`) is implemented to do exactly what you want: take the maximum of values for common keys.\n\nThis is very concise but might be less obvious to readers unfamiliar with `Counter`'s behavior.\n\n```python\nfrom collections import Counter\n\nd1 = {'a': 100, 'b': 200, 'c': 300}\nd2 = {'a': 150, 'b': 180, 'd': 400}\n\n# Convert dictionaries to Counter objects\ncounter1 = Counter(d1)\ncounter2 = Counter(d2)\n\n# The union operator | for Counters keeps the maximum value\nmerged_counter = counter1 | counter2\n\n# Convert the result back to a standard dictionary\nmerged_dict = dict(merged_counter)\n\nprint(merged_dict)\n# Output: {'a': 150, 'b': 200, 'c': 300, 'd': 400}\n```\n\n### Summary: Which to Choose?\n\n| Method | Pros | Cons | Best for... |\n| :--- | :--- | :--- | :--- |\n| **Dict Comprehension** | Pythonic, concise, efficient. | Can be dense for absolute beginners. | **Most general-purpose situations.** This is the idiomatic solution. |\n| **Simple Loop** | Very clear, easy to read and debug. | More verbose than other methods. | Beginners, or when the merging logic is more complex than a simple `max()`. |\n| **`collections.Counter`**| Extremely concise and expressive. | Requires an import; might be less intuitive if you're not familiar with `Counter`. | When your data semantically represents counts or when you need other `Counter` features. |", "error": null, "raw_item": {"task_id": "MyBench/dict_merge_max", "prompt": "Merge two dictionaries with integer values by keeping the maximum value for each key.", "entry_point": "merge_max", "canonical_solution": "def merge_max(d1, d2):\n    out = dict(d1)\n    for k,v in d2.items():\n        out[k] = max(out.get(k, v), v)\n    return out", "test": [{"input": [{"a": 1, "b": 5}, {"b": 3, "c": 10}], "output": {"a": 1, "b": 5, "c": 10}}, {"input": [{}, {"x": 7}], "output": {"x": 7}}, {"input": [{"a": 5}, {"a": 5}], "output": {"a": 5}}, {"input": [{"m": -1, "n": 2}, {"m": -5, "o": 10}], "output": {"m": -1, "n": 2, "o": 10}}, {"input": [{}, {}], "output": {}}]}}
{"timestamp_utc": "2025-09-26T10:05:42.793222", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 39, "question": "Invert a dictionary where values may not be unique. Return a new dictionary mapping each value to a list of keys that had that value.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 47.19040608406067, "response": "Of course. Here are a few ways to solve this problem in Python, from the most common and \"Pythonic\" to a more basic approach.\n\n### The Problem\n\nGiven a dictionary like `{'a': 1, 'b': 2, 'c': 1}`, you want to produce a new dictionary where the keys are the *values* from the original, and the values are *lists of keys* that shared that value.\n\nFor the example above, the desired output would be `{1: ['a', 'c'], 2: ['b']}`.\n\n---\n\n### Solution 1: Using `collections.defaultdict` (Recommended)\n\nThis is the most idiomatic and efficient way to handle this task. A `defaultdict` is a specialized dictionary that automatically creates a default value (e.g., an empty list) for a key if it doesn't exist.\n\n```python\nfrom collections import defaultdict\n\ndef invert_dict_non_unique(original_dict: dict) -> dict:\n    \"\"\"\n    Inverts a dictionary where values may not be unique.\n\n    Args:\n        original_dict: The dictionary to invert.\n\n    Returns:\n        A new dictionary where each key is a value from the original\n        dictionary and each value is a list of keys that had that value.\n    \"\"\"\n    inverted_dict = defaultdict(list)\n    for key, value in original_dict.items():\n        inverted_dict[value].append(key)\n    \n    # A defaultdict is a subclass of dict. If you need a regular dict,\n    # you can convert it at the end.\n    return dict(inverted_dict)\n\n# --- Example Usage ---\nstudent_grades = {\n    'Alice': 'A',\n    'Bob': 'B',\n    'Charlie': 'A',\n    'David': 'C',\n    'Eve': 'B'\n}\n\ngrades_to_students = invert_dict_non_unique(student_grades)\n\nprint(f\"Original dictionary: {student_grades}\")\nprint(f\"Inverted dictionary: {grades_to_students}\")\n# Expected Output:\n# Original dictionary: {'Alice': 'A', 'Bob': 'B', 'Charlie': 'A', 'David': 'C', 'Eve': 'B'}\n# Inverted dictionary: {'A': ['Alice', 'Charlie'], 'B': ['Bob', 'Eve'], 'C': ['David']}\n```\n\n**How it works:**\n1. We initialize a `defaultdict(list)`. This tells the dictionary: \"If a key is accessed for the first time, create an empty list `[]` for it.\"\n2. We loop through each `(key, value)` pair of the original dictionary.\n3. For each pair, we use the `value` as the key for our new dictionary and `append` the `key` to its list.\n4. The `defaultdict` handles the logic for us:\n   - If `value` is a new key (e.g., 'A' the first time), it creates `inverted_dict['A'] = []` and then appends 'Alice'.\n   - If `value` is an existing key (e.g., 'A' the second time), it simply appends 'Charlie' to the existing list.\n\n---\n\n### Solution 2: Using `dict.setdefault()`\n\nThis method uses a standard dictionary and its `setdefault` method, which achieves a similar result without needing to import `collections`.\n\n```python\ndef invert_dict_setdefault(original_dict: dict) -> dict:\n    \"\"\"\n    Inverts a dictionary using the setdefault method.\n    \"\"\"\n    inverted_dict = {}\n    for key, value in original_dict.items():\n        # setdefault(key, default) returns the value for the key.\n        # If the key doesn't exist, it inserts the key with the default\n        # value and then returns the default value.\n        inverted_dict.setdefault(value, []).append(key)\n    return inverted_dict\n\n# --- Example Usage ---\nfile_extensions = {\n    'image.jpg': 'image',\n    'photo.png': 'image',\n    'document.pdf': 'document',\n    'archive.zip': 'archive',\n    'report.pdf': 'document'\n}\n\ntype_to_files = invert_dict_setdefault(file_extensions)\nprint(f\"\\nOriginal dictionary: {file_extensions}\")\nprint(f\"Inverted dictionary: {type_to_files}\")\n# Expected Output:\n# Original dictionary: {'image.jpg': 'image', 'photo.png': 'image', 'document.pdf': 'document', 'archive.zip': 'archive', 'report.pdf': 'document'}\n# Inverted dictionary: {'image': ['image.jpg', 'photo.png'], 'document': ['document.pdf', 'report.pdf'], 'archive': ['archive.zip']}\n```\n\n**How it works:**\nThe line `inverted_dict.setdefault(value, []).append(key)` is very concise:\n1. `setdefault(value, [])` looks for `value` in `inverted_dict`.\n2. If `value` is found, `setdefault` returns the list associated with it.\n3. If `value` is *not* found, `setdefault` first sets `inverted_dict[value] = []` and *then* returns the newly created empty list.\n4. In either case, the method returns a list to which we can immediately `.append(key)`.\n\n---\n\n### Solution 3: Using a Standard `for` Loop and `if/else`\n\nThis is the most explicit approach and is great for understanding the underlying logic without any special methods or imports.\n\n```python\ndef invert_dict_basic_loop(original_dict: dict) -> dict:\n    \"\"\"\n    Inverts a dictionary using a basic for loop and an if/else check.\n    \"\"\"\n    inverted_dict = {}\n    for key, value in original_dict.items():\n        if value in inverted_dict:\n            # If the value already exists as a key, append the new original key\n            inverted_dict[value].append(key)\n        else:\n            # If this is the first time we see this value, create a new list\n            inverted_dict[value] = [key]\n    return inverted_dict\n\n# --- Example Usage ---\nstudent_grades = {\n    'Alice': 'A',\n    'Bob': 'B',\n    'Charlie': 'A',\n}\n\ngrades_to_students = invert_dict_basic_loop(student_grades)\nprint(f\"\\nOriginal dictionary: {student_grades}\")\nprint(f\"Inverted dictionary: {grades_to_students}\")\n# Expected Output:\n# Original dictionary: {'Alice': 'A', 'Bob': 'B', 'Charlie': 'A'}\n# Inverted dictionary: {'A': ['Alice', 'Charlie'], 'B': ['Bob']}\n```\n\n### Which Method Should You Choose?\n\n- **`defaultdict`:** Generally the preferred method. It's clean, highly readable, and performant. It clearly states the intent of the code.\n- **`setdefault`:** A great one-liner alternative if you prefer not to use an import. It's just as effective but can be slightly less readable to those unfamiliar with the method.\n- **Basic `for` loop:** The most verbose, but also the most explicit. It's perfect for learning the logic from scratch.", "error": null, "raw_item": {"task_id": "dict_invert_multival", "prompt": "Invert a dictionary where values may not be unique. Return a new dictionary mapping each value to a list of keys that had that value.", "entry_point": "invert_multival", "canonical_solution": "def invert_multival(d):\n    out={}\n    for k,v in d.items():\n        out.setdefault(v, []).append(k)\n    return out", "test": [{"input": [{"a": 1, "b": 2, "c": 1}], "output": {"1": ["a", "c"], "2": ["b"]}}, {"input": [{}], "output": {}}, {"input": [{"x": "hi", "y": "hi", "z": "bye"}], "output": {"hi": ["x", "y"], "bye": ["z"]}}, {"input": [{"p": 0, "q": 0, "r": 0}], "output": {"0": ["p", "q", "r"]}}, {"input": [{"k": 42}], "output": {"42": ["k"]}}]}}
{"timestamp_utc": "2025-09-26T10:06:24.441612", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 40, "question": "Return True if an integer has even parity (even number of 1 bits in binary), else False.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 40.64526128768921, "response": "Of course. Here are a few ways to solve this, from the most straightforward to the most performant.\n\n### 1. Simple & Readable Solution (Recommended)\n\nThis approach converts the integer to its binary string representation and counts the number of `'1'` characters. It's the most \"Pythonic\" and easiest to understand.\n\n```python\ndef has_even_parity(n: int) -> bool:\n    \"\"\"\n    Checks if an integer has an even number of 1s in its binary representation.\n\n    Args:\n        n: The integer to check.\n\n    Returns:\n        True if the number of 1-bits is even, False otherwise.\n    \"\"\"\n    # For negative numbers, Python's bin() adds a '-', e.g., bin(-10) is '-0b1010'.\n    # The count('1') method still works correctly.\n    one_count = bin(n).count('1')\n    \n    # Return True if the count is even (count % 2 == 0)\n    return one a % 2 == 0\n\n# --- Examples ---\nprint(f\"10 (binary 1010) -> {has_even_parity(10)}\")   # Two 1s -> True\nprint(f\"13 (binary 1101) -> {has_even_parity(13)}\")   # Three 1s -> False\nprint(f\"0 (binary 0) -> {has_even_parity(0)}\")       # Zero 1s -> True\nprint(f\"1 (binary 1) -> {has_even_parity(1)}\")       # One 1 -> False\nprint(f\"7 (binary 111) -> {has_evenparity(7)}\")     # Three 1s -> False\nprint(f\"-10 (binary -1010) -> {has_even_parity(-10)}\") # Two 1s -> True\n```\n\n**Output:**\n```\n10 (binary 1010) -> True\n13 (binary 1101) -> False\n0 (binary 0) -> True\n1 (binary 1) -> False\n7 (binary 111) -> False\n-10 (binary -1010) -> True\n```\n\n---\n\n### 2. Performant Bitwise Solution\n\nThis method uses bitwise operations, which are generally faster than string conversions, especially in performance-critical code. This loop runs only as many times as there are `1` bits in the number.\n\nThe trick is that `n & (n - 1)` always clears the least significant '1' bit.\n\n```python\ndef has_even_parity_bitwise(n: int) -> bool:\n    \"\"\"\n    Checks for even parity using an efficient bitwise operation.\n    This function is not intended for negative numbers and will return True.\n    \"\"\"\n    # Start with an assumption of even parity (0 ones found so far)\n    parity_is_even = True\n    \n    # We only care about the bits of positive numbers\n    if n < 0:\n        n = abs(n)\n\n    while n > 0:\n        # Each time we find a '1' bit, we flip the parity\n        parity_is_even = not parity_is_even\n        \n        # This clever trick clears the least significant '1' bit\n        n = n & (n - 1)\n        \n    return parity_is_even\n\n# --- Examples ---\nprint(\"\\n--- Bitwise Method ---\")\nprint(f\"10 (binary 1010) -> {has_even_parity_bitwise(10)}\")   # Flips twice -> True\nprint(f\"13 (binary 1101) -> {has_even_parity_bitwise(13)}\")   # Flips three times -> False\nprint(f\"0 (binary 0) -> {has_even_parity_bitwise(0)}\")       # Loop doesn't run -> True\nprint(f\"7 (binary 111) -> {has_even_parity_bitwise(7)}\")     # Flips three times -> False\n```\n\n**Output:**\n```\n--- Bitwise Method ---\n10 (binary 1010) -> True\n13 (binary 1101) -> False\n0 (binary 0) -> True\n7 (binary 111) -> False\n```\n\n### Summary\n\n| Method | Pros | Cons |\n| :--- | :--- | :--- |\n| **Simple (bin().count())** | Very readable, easy to understand, correctly handles negative numbers. | Can be slower due to string conversion overhead. |\n| **Bitwise** | Very fast, especially for sparse numbers (few '1's). | Less intuitive, requires understanding bitwise operations. |\n\nFor most applications, the **simple and readable solution is the best choice**. Use the bitwise method only if you have identified this calculation as a performance bottleneck in your program.", "error": null, "raw_item": {"task_id": "bitwise_parity", "prompt": "Return True if an integer has even parity (even number of 1 bits in binary), else False.", "entry_point": "even_parity", "canonical_solution": "def even_parity(n):\n    c=0\n    while n:\n        n&=n-1\n        c^=1\n    return c==0", "test": [{"input": [3], "output": false}, {"input": [5], "output": true}, {"input": [0], "output": true}, {"input": [15], "output": true}, {"input": [16], "output": false}, {"input": [255], "output": true}]}}
{"timestamp_utc": "2025-09-26T10:06:48.998397", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 41, "question": "Swap two integers without using a temporary variable, using bitwise XOR. Return the swapped pair as a tuple. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 23.554286241531372, "response": "```python\ndef xor_swap(a: int, b: int) -> tuple[int, int]:\n    \"\"\"\n    Swaps two integers using bitwise XOR without a temporary variable.\n    \n    Args:\n        a: The first integer.\n        b: The second integer.\n        \n    Returns:\n        A tuple containing the swapped integers (b, a).\n    \"\"\"\n    a = a ^ b\n    b = a ^ b\n    a = a ^ b\n    return (a, b)\n```", "error": null, "raw_item": {"task_id": "bitwise_swap", "prompt": "Swap two integers without using a temporary variable, using bitwise XOR. Return the swapped pair as a tuple. Return only the Python function code with no explanations.", "entry_point": "swap_xor", "canonical_solution": "def swap_xor(a,b):\n    a=a^b; b=a^b; a=a^b\n    return (a,b)", "test": [{"input": [2, 5], "output": [5, 2]}, {"input": [0, 7], "output": [7, 0]}, {"input": [-3, 9], "output": [9, -3]}, {"input": [42, 42], "output": [42, 42]}, {"input": [1000000, 123456], "output": [123456, 1000000]}]}}
{"timestamp_utc": "2025-09-26T10:07:09.568330", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 42, "question": "Compute factorial of n recursively. Assume n >= 0. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 19.568835020065308, "response": "```python\ndef factorial(n):\n    if n == 0:\n        return 1\n    else:\n        return n * factorial(n - 1)\n```", "error": null, "raw_item": {"task_id": "recursion_factorial", "prompt": "Compute factorial of n recursively. Assume n >= 0. Return only the Python function code with no explanations.", "entry_point": "factorial", "canonical_solution": "def factorial(n):\n    return 1 if n<=1 else n*factorial(n-1)", "test": [{"input": [0], "output": 1}, {"input": [1], "output": 1}, {"input": [5], "output": 120}, {"input": [10], "output": 3628800}, {"input": [3], "output": 6}]}}
{"timestamp_utc": "2025-09-26T10:08:22.181054", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 43, "question": "Return the BFS traversal order of a graph represented as adjacency list dict, starting from given node. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 71.61048603057861, "response": "```python\nimport collections\n\ndef bfs(graph, start_node):\n    \"\"\"\n    Performs a Breadth-First Search on a graph represented by an adjacency list.\n\n    Args:\n        graph (dict): The graph as an adjacency list dictionary where keys are\n                      nodes and values are lists of their adjacent nodes.\n        start_node: The node from which the BFS traversal begins.\n\n    Returns:\n        list: A list of nodes in the order of the BFS traversal. Returns an\n              empty list if the start_node is not in the graph.\n    \"\"\"\n    if start_node not in graph:\n        return []\n\n    visited = {start_node}\n    queue = collections.deque([start_node])\n    traversal_order = []\n\n    while queue:\n        node = queue.popleft()\n        traversal_order.append(node)\n\n        for neighbor in graph.get(node, []):\n            if neighbor not in visited:\n                visited.add(neighbor)\n                queue.append(neighbor)\n\n    return traversal_order\n```", "error": null, "raw_item": {"task_id": "graph_bfs_order", "prompt": "Return the BFS traversal order of a graph represented as adjacency list dict, starting from given node. Return only the Python function code with no explanations.", "entry_point": "bfs_order", "canonical_solution": "from collections import deque\n\ndef bfs_order(graph,start):\n    seen={start}; q=deque([start]); order=[]\n    while q:\n        u=q.popleft(); order.append(u)\n        for v in sorted(graph.get(u,[])):\n            if v not in seen:\n                seen.add(v); q.append(v)\n    return order", "test": [{"input": [{"A": ["B", "C"], "B": ["D"], "C": [], "D": []}, "A"], "output": ["A", "B", "C", "D"]}, {"input": [{"1": ["2"], "2": ["3"], "3": []}, "1"], "output": ["1", "2", "3"]}, {"input": [{"x": []}, "x"], "output": ["x"]}, {"input": [{"a": ["b"], "b": ["a"]}, "a"], "output": ["a", "b"]}, {"input": [{"m": ["n", "o"], "n": [], "o": []}, "m"], "output": ["m", "n", "o"]}]}}
{"timestamp_utc": "2025-09-26T10:08:51.290007", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 44, "question": "Given a CSV string with header 'name,value' and multiple rows, return the sum of the 'value' column as int. Assume comma-separated, no quotes. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 28.10698699951172, "response": "```python\ndef sum_csv_values(csv_string: str) -> int:\n    \"\"\"\n    Given a CSV string with a header 'name,value', returns the sum of the 'value' column.\n    Assumes comma-separated data with no quotes.\n    \"\"\"\n    lines = csv_string.strip().split('\\n')\n    # Skip the header, filter out empty lines, and sum the second column\n    return sum(int(line.split(',')[1]) for line in lines[1:] if line)\n```", "error": null, "raw_item": {"task_id": "parsing_csv_sum", "prompt": "Given a CSV string with header 'name,value' and multiple rows, return the sum of the 'value' column as int. Assume comma-separated, no quotes. Return only the Python function code with no explanations.", "entry_point": "csv_sum", "canonical_solution": "def csv_sum(text):\n    lines=text.strip().split('\\n')\n    if len(lines) <= 1:\n        return 0\n    total=0\n    for line in lines[1:]:\n        if line.strip():\n            name,val=line.split(',')\n            total+=int(val)\n    return total", "test": [{"input": ["name,value\\na,3\\nb,7\\nc,10"], "output": 20}, {"input": ["name,value\\n"], "output": 0}, {"input": ["name,value\\nfoo,0\\nbar,0"], "output": 0}, {"input": ["name,value\\nx,100"], "output": 100}, {"input": ["name,value\\na,1\\nb,2\\nc,3\\nd,4"], "output": 10}]}}
{"timestamp_utc": "2025-09-26T10:09:05.705639", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 45, "question": "Extract all sequences of digits from a string using regex and return them as a list of strings. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 13.412079811096191, "response": "```python\nimport re\nfrom typing import List\n\ndef extract_digits(text: str) -> List[str]:\n    \"\"\"\n    Extracts all sequences of digits from a string using regex\n    and returns them as a list of strings.\n    \"\"\"\n    return re.findall(r'\\d+', text)\n```", "error": null, "raw_item": {"task_id": "parsing_regex_digits", "prompt": "Extract all sequences of digits from a string using regex and return them as a list of strings. Return only the Python function code with no explanations.", "entry_point": "extract_digits", "canonical_solution": "import re\n\ndef extract_digits(s):\n    return re.findall(r'\\d+', s)", "test": [{"input": ["abc123de45f6"], "output": ["123", "45", "6"]}, {"input": ["no digits here"], "output": []}, {"input": ["2025year"], "output": ["2025"]}, {"input": ["a1b2c3d4"], "output": ["1", "2", "3", "4"]}, {"input": ["007bond"], "output": ["007"]}]}}
{"timestamp_utc": "2025-09-26T10:09:38.771323", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 46, "question": "Return the length of the longest increasing subsequence (LIS) in a list of integers. O(n^2) solution is fine. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 32.06204080581665, "response": "```python\ndef length_of_lis(nums: list[int]) -> int:\n    \"\"\"\n    Calculates the length of the Longest Increasing Subsequence using O(n^2) dynamic programming.\n    \"\"\"\n    if not nums:\n        return 0\n\n    n = len(nums)\n    # dp[i] will be the length of the LIS ending at index i\n    dp = [1] * n\n\n    for i in range(1, n):\n        for j in range(i):\n            if nums[i] > nums[j]:\n                dp[i] = max(dp[i], dp[j] + 1)\n\n    return max(dp)\n```", "error": null, "raw_item": {"task_id": "algorithms_longest_increasing", "prompt": "Return the length of the longest increasing subsequence (LIS) in a list of integers. O(n^2) solution is fine. Return only the Python function code with no explanations.", "entry_point": "lis_length", "canonical_solution": "def lis_length(nums):\n    if not nums: return 0\n    dp=[1]*len(nums)\n    for i in range(len(nums)):\n        for j in range(i):\n            if nums[j]<nums[i]:\n                dp[i]=max(dp[i],dp[j]+1)\n    return max(dp)", "test": [{"input": [[10, 9, 2, 5, 3, 7, 101, 18]], "output": 4}, {"input": [[1, 2, 3, 4, 5]], "output": 5}, {"input": [[5, 4, 3, 2, 1]], "output": 1}, {"input": [[]], "output": 0}, {"input": [[2, 2, 2]], "output": 1}]}}
{"timestamp_utc": "2025-09-26T10:10:21.445204", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 47, "question": "0/1 Knapsack: given weights, values, and capacity W, return the maximum achievable value. Use DP. weights and values are equal length. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 41.670329093933105, "response": "```python\ndef knapsack(weights, values, W):\n    \"\"\"\n    Solves the 0/1 knapsack problem using dynamic programming (space-optimized).\n\n    Args:\n        weights: A list of integers representing the weights of the items.\n        values: A list of integers representing the values of the items.\n        W: An integer representing the maximum capacity of the knapsack.\n\n    Returns:\n        The maximum achievable value.\n    \"\"\"\n    n = len(weights)\n    # dp[w] will store the maximum value that can be obtained with a knapsack capacity of w.\n    dp = [0] * (W + 1)\n\n    # Iterate through each item\n    for i in range(n):\n        # Iterate backwards through the capacities from W down to the weight of the current item.\n        # This ensures that we use each item at most once (0/1 property).\n        for w in range(W, weights[i] - 1, -1):\n            # For each capacity w, we have two choices:\n            # 1. Don't include the current item i: The value remains dp[w].\n            # 2. Include the current item i: The value is values[i] + dp[w - weights[i]].\n            # We take the maximum of these two choices.\n            dp[w] = max(dp[w], values[i] + dp[w - weights[i]])\n\n    # The final answer is the maximum value achievable with the full capacity W.\n    return dp[W]\n```", "error": null, "raw_item": {"task_id": "algorithms_knapsack01", "prompt": "0/1 Knapsack: given weights, values, and capacity W, return the maximum achievable value. Use DP. weights and values are equal length. Return only the Python function code with no explanations.", "entry_point": "knapsack01", "canonical_solution": "def knapsack01(weights, values, W):\n    n=len(weights)\n    dp=[[0]*(W+1) for _ in range(n+1)]\n    for i in range(1,n+1):\n        for w in range(W+1):\n            dp[i][w]=dp[i-1][w]\n            if weights[i-1]<=w:\n                dp[i][w]=max(dp[i][w], values[i-1]+dp[i-1][w-weights[i-1]])\n    return dp[n][W]", "test": [{"input": [[2, 3, 4], [4, 5, 6], 5], "output": 9}, {"input": [[1, 2, 3], [6, 10, 12], 5], "output": 22}, {"input": [[5], [10], 5], "output": 10}, {"input": [[5], [10], 4], "output": 0}, {"input": [[], [], 10], "output": 0}]}}
{"timestamp_utc": "2025-09-26T10:10:53.397239", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 48, "question": "Write parse_csv_numbers(text) that parses a CSV string of integers separated by commas and newlines. Return a 2D list of integers. Ignore empty lines. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 30.948877096176147, "response": "```python\ndef parse_csv_numbers(text):\n    \"\"\"\n    Parses a CSV string of integers separated by commas and newlines.\n\n    Args:\n        text: A string containing numbers in CSV format.\n\n    Returns:\n        A 2D list of integers. Empty lines in the input are ignored.\n    \"\"\"\n    return [\n        [int(num.strip()) for num in line.split(',')]\n        for line in text.splitlines()\n        if line.strip()\n    ]\n```", "error": null, "raw_item": {"task_id": "custom_parse_csv_numbers", "prompt": "Write parse_csv_numbers(text) that parses a CSV string of integers separated by commas and newlines. Return a 2D list of integers. Ignore empty lines. Return only the Python function code with no explanations.", "entry_point": "parse_csv_numbers", "canonical_solution": "def parse_csv_numbers(text: str) -> list[list[int]]:\n    rows = []\n    for line in text.strip().splitlines():\n        if not line.strip():\n            continue\n        row = [int(x.strip()) for x in line.split(',') if x.strip()]\n        rows.append(row)\n    return rows", "test": [{"input": ["1,2,3\n4,5,6"], "output": [[1, 2, 3], [4, 5, 6]]}, {"input": ["10,20\n30\n\n40,50"], "output": [[10, 20], [30], [40, 50]]}, {"input": ["   7 , 8 ,9  "], "output": [[7, 8, 9]]}, {"input": [""], "output": []}]}}
{"timestamp_utc": "2025-09-26T10:11:18.852621", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 49, "question": "Write normalize_json_keys(obj) that recursively converts all dictionary keys in a JSON-like object to lowercase strings. Works for nested dicts and lists. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 24.451364994049072, "response": "```python\ndef normalize_json_keys(obj):\n    \"\"\"\n    Recursively converts all dictionary keys in a JSON-like object to\n    lowercase strings. Works for nested dicts and lists.\n    \"\"\"\n    if isinstance(obj, dict):\n        return {str(k).lower(): normalize_json_keys(v) for k, v in obj.items()}\n    if isinstance(obj, list):\n        return [normalize_json_keys(elem) for elem in obj]\n    return obj\n```", "error": null, "raw_item": {"task_id": "custom_normalize_json_keys", "prompt": "Write normalize_json_keys(obj) that recursively converts all dictionary keys in a JSON-like object to lowercase strings. Works for nested dicts and lists. Return only the Python function code with no explanations.", "entry_point": "normalize_json_keys", "canonical_solution": "def normalize_json_keys(obj):\n    if isinstance(obj, dict):\n        return {str(k).lower(): normalize_json_keys(v) for k, v in obj.items()}\n    if isinstance(obj, list):\n        return [normalize_json_keys(x) for x in obj]\n    return obj", "test": [{"input": [{"Name": "Alice", "AGE": 30}], "output": {"name": "Alice", "age": 30}}, {"input": [[{"X": 1}, {"Y": 2}]], "output": [{"x": 1}, {"y": 2}]}, {"input": [{"Nested": {"KEY": 5}}], "output": {"nested": {"key": 5}}}, {"input": [123], "output": 123}]}}
{"timestamp_utc": "2025-09-26T10:12:14.626182", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 50, "question": "Write format_duration(seconds) that converts an integer number of seconds into a human-readable string using years, days, hours, minutes, and seconds. Skip units that are zero. Use plural form when needed. Example: 3661 → '1 hour, 1 minute, 1 second'. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 54.76750898361206, "response": "```python\ndef format_duration(seconds):\n    if seconds == 0:\n        return \"now\"\n\n    time_units = [\n        ('year', 31536000),\n        ('day', 86400),\n        ('hour', 3600),\n        ('minute', 60),\n        ('second', 1)\n    ]\n\n    parts = []\n    \n    for name, duration in time_units:\n        if seconds >= duration:\n            value = seconds // duration\n            seconds %= duration\n            unit = name if value == 1 else name + 's'\n            parts.append(f\"{value} {unit}\")\n\n    if len(parts) == 1:\n        return parts[0]\n    \n    return ', '.join(parts[:-1]) + ' and ' + parts[-1]\n```", "error": null, "raw_item": {"task_id": "custom_format_duration", "prompt": "Write format_duration(seconds) that converts an integer number of seconds into a human-readable string using years, days, hours, minutes, and seconds. Skip units that are zero. Use plural form when needed. Example: 3661 → '1 hour, 1 minute, 1 second'. Return only the Python function code with no explanations.", "entry_point": "format_duration", "canonical_solution": "def format_duration(seconds: int) -> str:\n    units = [(\"year\", 365*24*3600), (\"day\", 24*3600), (\"hour\", 3600), (\"minute\", 60), (\"second\", 1)]\n    parts = []\n    for name, length in units:\n        if seconds >= length:\n            count, seconds = divmod(seconds, length)\n            parts.append(f\"{count} {name}{'s' if count != 1 else ''}\")\n    return \", \".join(parts) if parts else \"0 seconds\"", "test": [{"input": [0], "output": "0 seconds"}, {"input": [62], "output": "1 minute, 2 seconds"}, {"input": [3661], "output": "1 hour, 1 minute, 1 second"}, {"input": [31536000], "output": "1 year"}, {"input": [31556926], "output": "1 year, 6 hours, 9 minutes, 26 seconds"}]}}
{"timestamp_utc": "2025-09-26T10:12:58.492768", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 51, "question": "Write parse_key_value_config(text) that parses a configuration string with lines of the form 'key=value'. Ignore blank lines and lines starting with '#'. Return a dictionary with string keys and values converted to int if possible, else string. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 42.86379313468933, "response": "```python\ndef parse_key_value_config(text):\n    \"\"\"\n    Parses a configuration string with lines of the form 'key=value'.\n\n    - Ignores blank lines and lines starting with '#'.\n    - Returns a dictionary with string keys.\n    - Values are converted to int if possible, otherwise they remain strings.\n    \"\"\"\n    config_dict = {}\n    for line in text.splitlines():\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n\n        parts = line.split('=', 1)\n        if len(parts) == 2:\n            key, value_str = parts\n            key = key.strip()\n            value_str = value_str.strip()\n\n            try:\n                value = int(value_str)\n            except ValueError:\n                value = value_str\n\n            config_dict[key] = value\n\n    return config_dict\n```", "error": null, "raw_item": {"task_id": "custom_parse_key_value_config", "prompt": "Write parse_key_value_config(text) that parses a configuration string with lines of the form 'key=value'. Ignore blank lines and lines starting with '#'. Return a dictionary with string keys and values converted to int if possible, else string. Return only the Python function code with no explanations.", "entry_point": "parse_key_value_config", "canonical_solution": "def parse_key_value_config(text: str) -> dict:\n    result = {}\n    for line in text.splitlines():\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        if '=' in line:\n            k,v = line.split('=',1)\n            v = v.strip()\n            if v.isdigit():\n                result[k.strip()] = int(v)\n            else:\n                result[k.strip()] = v\n    return result", "test": [{"input": ["a=1\nb=2\nc=hello"], "output": {"a": 1, "b": 2, "c": "hello"}}, {"input": ["#comment\nx=42\ny=text"], "output": {"x": 42, "y": "text"}}, {"input": [""], "output": {}}]}}
{"timestamp_utc": "2025-09-26T10:14:17.516061", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 52, "question": "Write pretty_print_matrix(matrix) that formats a 2D list of integers into a string where each row is space-separated and rows are separated by newlines. Columns should be aligned to the maximum width of the largest number. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 78.02002263069153, "response": "```python\ndef pretty_print_matrix(matrix):\n    \"\"\"\n    Formats a 2D list of integers into a string with aligned columns.\n\n    Args:\n        matrix: A 2D list (list of lists) of integers.\n\n    Returns:\n        A string representation of the matrix with space-separated\n        elements and newline-separated rows, with columns aligned.\n    \"\"\"\n    if not matrix or not matrix[0]:\n        return \"\\n\".join([\"\"] * len(matrix))\n\n    # Transpose the matrix to easily access columns\n    transposed_matrix = list(zip(*matrix))\n    \n    # Calculate the maximum width for each column\n    col_widths = [max(len(str(item)) for item in col) for col in transposed_matrix]\n\n    # Format each row using the calculated column widths\n    formatted_rows = []\n    for row in matrix:\n        formatted_row = \" \".join(f\"{item:>{width}}\" for item, width in zip(row, col_widths))\n        formatted_rows.append(formatted_row)\n        \n    return \"\\n\".join(formatted_rows)\n```", "error": null, "raw_item": {"task_id": "custom_pretty_print_matrix", "prompt": "Write pretty_print_matrix(matrix) that formats a 2D list of integers into a string where each row is space-separated and rows are separated by newlines. Columns should be aligned to the maximum width of the largest number. Return only the Python function code with no explanations.", "entry_point": "pretty_print_matrix", "canonical_solution": "def pretty_print_matrix(matrix: list[list[int]]) -> str:\n    if not matrix:\n        return ''\n    col_widths = [max(len(str(row[i])) for row in matrix) for i in range(len(matrix[0]))]\n    lines = []\n    for row in matrix:\n        line = ' '.join(str(val).rjust(col_widths[i]) for i,val in enumerate(row))\n        lines.append(line)\n    return '\\n'.join(lines)", "test": [{"input": [[[1, 20], [300, 4]]], "output": "  1 20\n300  4"}, {"input": [[[5]]], "output": "5"}, {"input": [[]], "output": ""}]}}
{"timestamp_utc": "2025-09-26T10:15:09.713763", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 53, "question": "Write unique_permutations(s) that returns all distinct permutations of string s in lexicographic order. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 51.19449591636658, "response": "```python\nimport itertools\n\ndef unique_permutations(s):\n    \"\"\"\n    Returns all distinct permutations of string s in lexicographic order.\n    \"\"\"\n    return sorted(list(set(\"\".join(p) for p in itertools.permutations(s))))\n\n```", "error": null, "raw_item": {"task_id": "custom_unique_permutations", "prompt": "Write unique_permutations(s) that returns all distinct permutations of string s in lexicographic order. Return only the Python function code with no explanations.", "entry_point": "unique_permutations", "canonical_solution": "def unique_permutations(s: str) -> list[str]:\n    from itertools import permutations\n    return sorted(set(''.join(p) for p in permutations(s)))", "test": [{"input": ["aab"], "output": ["aab", "aba", "baa"]}, {"input": ["abc"], "output": ["abc", "acb", "bac", "bca", "cab", "cba"]}, {"input": ["x"], "output": ["x"]}]}}
{"timestamp_utc": "2025-09-26T10:16:22.461950", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 54, "question": "Write format_prime_factors(n) that returns the prime factorization of integer n as a string in the form 'p1^a1 * p2^a2 ...'. If exponent is 1, omit the '^1'. Example: 60 → '2^2 * 3 * 5'. Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 71.74024391174316, "response": "```python\ndef format_prime_factors(n):\n    if n <= 1:\n        return \"\"\n\n    factors = []\n    \n    # Handle factor of 2\n    d = 2\n    if n % d == 0:\n        count = 0\n        while n % d == 0:\n            count += 1\n            n //= d\n        factors.append((d, count))\n\n    # Handle odd factors\n    d = 3\n    while d * d <= n:\n        if n % d == 0:\n            count = 0\n            while n % d == 0:\n                count += 1\n                n //= d\n            factors.append((d, count))\n        d += 2\n\n    # If n is still greater than 1, it must be a prime factor\n    if n > 1:\n        factors.append((n, 1))\n\n    # Format the factors into the string representation\n    parts = []\n    for p, a in factors:\n        if a == 1:\n            parts.append(str(p))\n        else:\n            parts.append(f\"{p}^{a}\")\n            \n    return \" * \".join(parts)\n```", "error": null, "raw_item": {"task_id": "custom_format_prime_factors", "prompt": "Write format_prime_factors(n) that returns the prime factorization of integer n as a string in the form 'p1^a1 * p2^a2 ...'. If exponent is 1, omit the '^1'. Example: 60 → '2^2 * 3 * 5'. Return only the Python function code with no explanations.", "entry_point": "format_prime_factors", "canonical_solution": "def format_prime_factors(n: int) -> str:\n    factors = []\n    d = 2\n    while d*d <= n:\n        count = 0\n        while n % d == 0:\n            n //= d\n            count += 1\n        if count:\n            factors.append(f\"{d}^{count}\" if count>1 else str(d))\n        d += 1\n    if n > 1:\n        factors.append(str(n))\n    return ' * '.join(factors)", "test": [{"input": [60], "output": "2^2 * 3 * 5"}, {"input": [13], "output": "13"}, {"input": [1024], "output": "2^10"}]}}
{"timestamp_utc": "2025-09-26T10:17:57.342241", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 55, "question": "Write validate_expression(expr) that checks if a string is a valid arithmetic expression containing only digits, +, -, *, /, parentheses, and spaces. Return True if valid, else False. Parentheses must be balanced and no invalid sequences allowed (e.g. '*/', '++', empty parentheses). Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 93.87152791023254, "response": "```python\ndef validate_expression(expr):\n    \"\"\"\n    Checks if a string is a valid arithmetic expression.\n    Allowed components: digits, +, -, *, /, parentheses, and spaces.\n    \"\"\"\n    if not isinstance(expr, str) or not expr.strip():\n        return False\n\n    # 1. Check for invalid characters\n    allowed_chars = set(\"0123456789+-*/() \")\n    if any(c not in allowed_chars for c in expr):\n        return False\n\n    # 2. Check for balanced parentheses\n    balance = 0\n    for char in expr:\n        if char == '(':\n            balance += 1\n        elif char == ')':\n            balance -= 1\n        if balance < 0:\n            return False\n    if balance != 0:\n        return False\n\n    # 3. Perform sequence checks on a space-removed version\n    s = expr.replace(' ', '')\n    if not s:\n        return False # Expression was only spaces\n\n    # 3a. Check for empty parentheses\n    if '()' in s:\n        return False\n\n    # 3b. Check for invalid leading/trailing operators\n    if s[0] in '*/' or s[-1] in '+-*/':\n        return False\n\n    # 3c. Check for invalid adjacent character sequences\n    for i in range(len(s) - 1):\n        c1 = s[i]\n        c2 = s[i+1]\n\n        # Invalid operator sequences (e.g., */, //, +*, ++, etc.)\n        if c1 in '+-*/' and c2 in '+-*/':\n            return False\n        \n        # Invalid sequences around parentheses\n        # e.g., 5( , )5 , )( , (* , *)\n        if (c1.isdigit() and c2 == '(') or \\\n           (c1 == ')' and c2.isdigit()) or \\\n           (c1 == ')' and c2 == '(') or \\\n           (c1 == '(' and c2 in '*/') or \\\n           (c1 in '+-*/' and c2 == ')'):\n            return False\n\n    return True\n```", "error": null, "raw_item": {"task_id": "custom_validate_expression", "prompt": "Write validate_expression(expr) that checks if a string is a valid arithmetic expression containing only digits, +, -, *, /, parentheses, and spaces. Return True if valid, else False. Parentheses must be balanced and no invalid sequences allowed (e.g. '*/', '++', empty parentheses). Return only the Python function code with no explanations.", "entry_point": "validate_expression", "canonical_solution": "import re\ndef validate_expression(expr: str) -> bool:\n    expr = expr.strip()\n    if not expr:\n        return False\n    # invalid sequences\n    if re.search(r'[+*/-]{2,}', expr):\n        return False\n    if re.search(r'\\(\\)', expr):\n        return False\n    # parentheses balance\n    stack = []\n    for c in expr:\n        if c == '(':\n            stack.append(c)\n        elif c == ')':\n            if not stack:\n                return False\n            stack.pop()\n    if stack:\n        return False\n    # final safety: try eval\n    try:\n        eval(expr, {\"__builtins__\":None}, {})\n    except:\n        return False\n    return True", "test": [{"input": ["1+2*(3-4)"], "output": true}, {"input": ["(5+6"], "output": false}, {"input": ["1++2"], "output": false}, {"input": ["( )"], "output": false}, {"input": ["10/2-3"], "output": true}]}}
{"timestamp_utc": "2025-09-26T10:18:34.097184", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 56, "question": "Write parse_roman(s) that converts a valid Roman numeral string into an integer. Supports numerals up to 3999 (MMMCMXCIX). Return only the Python function code with no explanations.", "provider": "google", "model": "gemini-2.5-pro", "region": null, "success": true, "response_time": 35.752479791641235, "response": "```python\ndef parse_roman(s: str) -> int:\n    \"\"\"\n    Converts a valid Roman numeral string into an integer.\n    Supports numerals up to 3999 (MMMCMXCIX).\n    \"\"\"\n    roman_map = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000\n    }\n    \n    result = 0\n    prev_value = 0\n    \n    for char in reversed(s):\n        current_value = roman_map[char]\n        if current_value < prev_value:\n            result -= current_value\n        else:\n            result += current_value\n        prev_value = current_value\n            \n    return result\n```", "error": null, "raw_item": {"task_id": "custom_parse_roman", "prompt": "Write parse_roman(s) that converts a valid Roman numeral string into an integer. Supports numerals up to 3999 (MMMCMXCIX). Return only the Python function code with no explanations.", "entry_point": "parse_roman", "canonical_solution": "def parse_roman(s: str) -> int:\n    values = {\"I\":1, \"V\":5, \"X\":10, \"L\":50, \"C\":100, \"D\":500, \"M\":1000}\n    total = 0\n    i = 0\n    while i < len(s):\n        if i+1 < len(s) and values[s[i]] < values[s[i+1]]:\n            total += values[s[i+1]] - values[s[i]]\n            i += 2\n        else:\n            total += values[s[i]]\n            i += 1\n    return total", "test": [{"input": ["III"], "output": 3}, {"input": ["IX"], "output": 9}, {"input": ["LVIII"], "output": 58}, {"input": ["MCMXCIV"], "output": 1994}, {"input": ["MMMCMXCIX"], "output": 3999}]}}
