{"timestamp_utc": "2025-09-27T12:30:08.498834", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 0, "question": "Write find_balanced_sublist(arr) that returns the longest even-length contiguous sublist where sum of first half equals sum of second half. Return empty list if none exists.\n\nReturn only the Python function code with no explanations, comments, or markdown formatting.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 4.934317111968994, "response": "```python\ndef find_balanced_sublist(arr):\n    n = len(arr)\n    if n < 2:\n        return []\n    prefix = [0] * (n + 1)\n    for i in range(1, n + 1):\n        prefix[i] = prefix[i - 1] + arr[i - 1]\n    max_len = (n // 2) * 2\n    for length in range(max_len, 1, -2):\n        m = length // 2\n        for i in range(n - length + 1):\n            if 2 * prefix[i + m] == prefix[i] + prefix[i + 2 * m]:\n                return arr[i:i + length]\n    return []\n```", "error": null, "raw_item": {"task_id": "custom_find_balanced_sublist", "prompt": "Write find_balanced_sublist(arr) that returns the longest even-length contiguous sublist where sum of first half equals sum of second half. Return empty list if none exists.\n\nReturn only the Python function code with no explanations, comments, or markdown formatting.", "entry_point": "find_balanced_sublist", "canonical_solution": "def find_balanced_sublist(arr: list[int]) -> list[int]:\n    n = len(arr)\n    for length in range(n, 1, -1):\n        if length % 2 != 0:\n            continue\n        for start in range(n - length + 1):\n            sub = arr[start:start+length]\n            half = length // 2\n            if sum(sub[:half]) == sum(sub[half:]):\n                return sub\n    return []", "test": [{"input": [[1, 2, 3, 3, 2, 1]], "output": [1, 2, 3, 3, 2, 1]}, {"input": [[5, 1, 2, 1, 5]], "output": []}, {"input": [[1, 1, 1, 1]], "output": [1, 1, 1, 1]}, {"input": [[1, 2, 3]], "output": []}, {"input": [[]], "output": []}, {"input": [[3, 0, 3, 0, 3]], "output": [3, 0, 3, 0]}, {"input": [[2, 1, 1, 2, 3, 4]], "output": [2, 1, 1, 2]}, {"input": [[1, 5, 3, 7]], "output": []}, {"input": [[0, 0, 0, 0]], "output": [0, 0, 0, 0]}]}}
{"timestamp_utc": "2025-09-27T12:30:12.899495", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 1, "question": "Write merge_by_priority(items_a, items_b) that merges two lists of (id, priority) pairs. Keep highest priority for each unique id. Return sorted by priority descending. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 3.398047924041748, "response": "```python\ndef merge_by_priority(items_a, items_b):\n    max_prio = {}\n    for items in [items_a, items_b]:\n        for id_, prio in items:\n            if id_ not in max_prio or prio > max_prio[id_]:\n                max_prio[id_] = prio\n    return sorted(max_prio.items(), key=lambda x: x[1], reverse=True)\n```", "error": null, "raw_item": {"task_id": "custom_merge_by_priority", "prompt": "Write merge_by_priority(items_a, items_b) that merges two lists of (id, priority) pairs. Keep highest priority for each unique id. Return sorted by priority descending. Return only the Python function code with no explanations.", "entry_point": "merge_by_priority", "canonical_solution": "def merge_by_priority(items_a: list[tuple[str, int]], items_b: list[tuple[str, int]]) -> list[tuple[str, int]]:\n    combined = items_a + items_b\n    best = {}\n    for id, priority in combined:\n        if id not in best or priority > best[id]:\n            best[id] = priority\n    return sorted(best.items(), key=lambda x: -x[1])", "test": [{"input": [[["item1", 2], ["item2", 5]], [["item2", 3], ["item3", 4]]], "output": [["item2", 5], ["item3", 4], ["item1", 2]]}, {"input": [[], []], "output": []}, {"input": [[["a", 1]], [["a", 10]]], "output": [["a", 10]]}, {"input": [[["x", 5], ["y", 3]], [["z", 7], ["y", 6]]], "output": [["z", 7], ["y", 6], ["x", 5]]}, {"input": [[["a", 1], ["b", 2]], []], "output": [["b", 2], ["a", 1]]}]}}
{"timestamp_utc": "2025-09-27T12:30:17.811280", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 2, "question": "Write parse_env_config(lines) that parses environment variable lines into dict. Ignore lines starting with '#', lines without '=', and empty keys. Keep last occurrence of duplicate keys. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 3.9099748134613037, "response": "```python\ndef parse_env_config(lines):\n    config = {}\n    for line in lines:\n        line = line.strip()\n        if line.startswith('#') or '=' not in line:\n            continue\n        key, value = line.split('=', 1)\n        key = key.strip()\n        if not key:\n            continue\n        value = value.strip()\n        config[key] = value\n    return config\n```", "error": null, "raw_item": {"task_id": "custom_parse_env_config", "prompt": "Write parse_env_config(lines) that parses environment variable lines into dict. Ignore lines starting with '#', lines without '=', and empty keys. Keep last occurrence of duplicate keys. Return only the Python function code with no explanations.", "entry_point": "parse_env_config", "canonical_solution": "def parse_env_config(lines: list[str]) -> dict[str, str]:\n    env = {}\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith(\"#\") or \"=\" not in line:\n            continue\n        key, value = line.split(\"=\", 1)\n        if key:\n            env[key] = value\n    return env", "test": [{"input": [["DB_HOST=localhost", "DB_PORT=5432", "#comment", "DB_HOST=remotehost", "=fail", "INVALID", ""]], "output": {"DB_HOST": "remotehost", "DB_PORT": "5432"}}, {"input": [["A=1", "B=2", "C=3"]], "output": {"A": "1", "B": "2", "C": "3"}}, {"input": [["# just a comment", "=", "==", "KEY_ONLY=", "NO_EQUALS"]], "output": {"KEY_ONLY": ""}}, {"input": [[]], "output": {}}, {"input": [["k1=v1", "k1=v2", "k1=v3"]], "output": {"k1": "v3"}}]}}
{"timestamp_utc": "2025-09-27T12:30:22.522278", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 3, "question": "Write minimal_partition_difference(nums) that partitions a list into two groups to minimize absolute difference of their sums. Handle empty list case explicitly. Use DP subset sum approach. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 3.7086949348449707, "response": "```python\ndef minimal_partition_difference(nums):\n    if not nums:\n        return 0\n    total = sum(nums)\n    possible_sums = set([0])\n    for num in nums:\n        new_sums = set()\n        for s in possible_sums:\n            new_sums.add(s + num)\n        possible_sums.update(new_sums)\n    target = total // 2\n    best = 0\n    for s in possible_sums:\n        if s <= target and s > best:\n            best = s\n    return abs(2 * best - total)\n```", "error": null, "raw_item": {"task_id": "custom_minimal_partition_difference", "prompt": "Write minimal_partition_difference(nums) that partitions a list into two groups to minimize absolute difference of their sums. Handle empty list case explicitly. Use DP subset sum approach. Return only the Python function code with no explanations.", "entry_point": "minimal_partition_difference", "canonical_solution": "def minimal_partition_difference(nums: list[int]) -> int:\n    if not nums:\n        return 0\n    total = sum(nums)\n    target = total // 2\n    possible = {0}\n    for num in nums:\n        possible |= {x + num for x in possible}\n    best = max(x for x in possible if x <= target)\n    return total - 2 * best", "test": [{"input": [[1, 2, 3, 9]], "output": 3}, {"input": [[1, 2, 3, 4, 5]], "output": 1}, {"input": [[10, 10]], "output": 0}, {"input": [[7]], "output": 7}, {"input": [[]], "output": 0}, {"input": [[1, 1, 1, 1, 1, 1]], "output": 0}, {"input": [[100, 99, 98, 1]], "output": 96}]}}
{"timestamp_utc": "2025-09-27T12:30:26.142732", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 4, "question": "Write normalize_user_roles(users) where users is a dict mapping each user to a LIST of roles. Invert to map each role to list of users. Remove duplicate users per role and sort user lists alphabetically. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.6174378395080566, "response": "```python\ndef normalize_user_roles(users):\n    role_to_users = {}\n    for user, roles in users.items():\n        for role in roles:\n            if role not in role_to_users:\n                role_to_users[role] = []\n            role_to_users[role].append(user)\n    for role in role_to_users:\n        role_to_users[role] = sorted(set(role_to_users[role]))\n    return role_to_users\n```", "error": null, "raw_item": {"task_id": "custom_normalize_user_roles", "prompt": "Write normalize_user_roles(users) where users is a dict mapping each user to a LIST of roles. Invert to map each role to list of users. Remove duplicate users per role and sort user lists alphabetically. Return only the Python function code with no explanations.", "entry_point": "normalize_user_roles", "canonical_solution": "def normalize_user_roles(users: dict[str, list[str]]) -> dict[str, list[str]]:\n    role_to_users = {}\n    for user, roles in users.items():\n        for role in set(roles):  # remove duplicates\n            if role not in role_to_users:\n                role_to_users[role] = []\n            role_to_users[role].append(user)\n    for role in role_to_users:\n        role_to_users[role].sort()\n    return role_to_users", "test": [{"input": [{"alice": ["admin", "editor"], "bob": ["editor", "admin"], "charlie": ["viewer"]}], "output": {"admin": ["alice", "bob"], "editor": ["alice", "bob"], "viewer": ["charlie"]}}, {"input": [{"diana": [], "eva": ["user", "user"], "frank": ["user"]}], "output": {"user": ["eva", "frank"]}}, {"input": [{"a": ["x"], "b": ["y"], "c": ["x", "y"]}], "output": {"x": ["a", "c"], "y": ["b", "c"]}}, {"input": [{}], "output": {}}]}}
{"timestamp_utc": "2025-09-27T12:30:35.526308", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 5, "question": "Write can_form_expression(digits, target) that checks if inserting '+' or '-' operators (or nothing) between digits can reach target value. Use recursive DFS. Must handle multi-digit numbers. Return complete Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 8.381397008895874, "response": "```python\ndef can_form_expression(digits, target):\n    def dfs(start, current_sum):\n        if start == len(digits):\n            return current_sum == target\n        for end in range(start, len(digits)):\n            num = int(digits[start:end+1])\n            if start == 0:\n                if dfs(end + 1, num):\n                    return True\n            else:\n                if dfs(end + 1, current_sum + num) or dfs(end + 1, current_sum - num):\n                    return True\n        return False\n    return dfs(0, 0)\n```", "error": null, "raw_item": {"task_id": "custom_can_form_expression", "prompt": "Write can_form_expression(digits, target) that checks if inserting '+' or '-' operators (or nothing) between digits can reach target value. Use recursive DFS. Must handle multi-digit numbers. Return complete Python function code with no explanations.", "entry_point": "can_form_expression", "canonical_solution": "def can_form_expression(digits: str, target: int) -> bool:\n    def dfs(index: int, current_value: int, expression: str) -> bool:\n        if index == len(digits):\n            return current_value == target\n        for end in range(index + 1, len(digits) + 1):\n            num_str = digits[index:end]\n            num = int(num_str)\n            if index == 0:\n                if dfs(end, num, num_str):\n                    return True\n            else:\n                if dfs(end, current_value + num, expression + '+' + num_str):\n                    return True\n                if dfs(end, current_value - num, expression + '-' + num_str):\n                    return True\n        return False\n    return dfs(0, 0, \"\")", "test": [{"input": ["123", 6], "output": true}, {"input": ["105", 5], "output": true}, {"input": ["123", 123], "output": true}, {"input": ["123", 100], "output": false}, {"input": ["000", 0], "output": true}, {"input": ["1", 1], "output": true}, {"input": ["1", 2], "output": false}]}}
{"timestamp_utc": "2025-09-27T12:30:42.595141", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 6, "question": "Write has_balanced_bits(n) that returns True if binary representation of n has equal number of 0s and 1s. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 6.065540075302124, "response": "```python\ndef has_balanced_bits(n):\n    bin_str = bin(n)[2:]\n    count_ones = bin_str.count('1')\n    count_zeros = bin_str.count('0')\n    return count_ones == count_zeros\n```", "error": null, "raw_item": {"task_id": "custom_has_balanced_bits", "prompt": "Write has_balanced_bits(n) that returns True if binary representation of n has equal number of 0s and 1s. Return only the Python function code with no explanations.", "entry_point": "has_balanced_bits", "canonical_solution": "def has_balanced_bits(n: int) -> bool:\n    bits = bin(n)[2:]\n    return bits.count('0') == bits.count('1')", "test": [{"input": [10], "output": true}, {"input": [7], "output": false}, {"input": [9], "output": true}, {"input": [1], "output": false}, {"input": [51], "output": false}, {"input": [56], "output": true}, {"input": [57], "output": false}, {"input": [2], "output": true}, {"input": [15], "output": false}]}}
{"timestamp_utc": "2025-09-27T12:30:49.044371", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 7, "question": "Write remove_repeating_groups(s, k) that repeatedly removes groups of k identical adjacent characters until no more can be removed. Use stack approach. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 5.447107791900635, "response": "```python\ndef remove_repeating_groups(s, k):\n    stack = []\n    for char in s:\n        if stack and stack[-1][0] == char:\n            stack[-1] = (char, stack[-1][1] + 1)\n            if stack[-1][1] == k:\n                stack.pop()\n        else:\n            stack.append((char, 1))\n    result = []\n    for char, count in stack:\n        result.append(char * count)\n    return ''.join(result)\n```", "error": null, "raw_item": {"task_id": "custom_remove_repeating_groups", "prompt": "Write remove_repeating_groups(s, k) that repeatedly removes groups of k identical adjacent characters until no more can be removed. Use stack approach. Return only the Python function code with no explanations.", "entry_point": "remove_repeating_groups", "canonical_solution": "def remove_repeating_groups(s: str, k: int) -> str:\n    stack = []\n    for char in s:\n        if stack and stack[-1][0] == char:\n            stack[-1][1] += 1\n            if stack[-1][1] == k:\n                stack.pop()\n        else:\n            stack.append([char, 1])\n    return ''.join(char * count for char, count in stack)", "test": [{"input": ["deeedbbcccbdaa", 3], "output": "aa"}, {"input": ["pbbcggttciiippooaais", 2], "output": "ps"}, {"input": ["abcd", 2], "output": "abcd"}, {"input": ["aaa", 3], "output": ""}, {"input": ["aaaabbbbaaaa", 4], "output": ""}, {"input": ["aabbcc", 2], "output": ""}, {"input": ["aabbccddeeedcba", 3], "output": "abc"}, {"input": ["", 3], "output": ""}]}}
{"timestamp_utc": "2025-09-27T12:30:55.860597", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 8, "question": "Write resolve_dependencies(deps) that returns valid module load order from dependency dict. Return None if cycle exists. Use DFS topological sort. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 5.8144848346710205, "response": "```python\ndef resolve_dependencies(deps):\n    # Collect all unique modules\n    all_modules = set(deps.keys())\n    for deps_list in deps.values():\n        all_modules.update(deps_list)\n    \n    # Build graph: edge from dep to dependent (B -> A if A depends on B)\n    graph = {module: [] for module in all_modules}\n    for module, deps_list in deps.items():\n        for dep in deps_list:\n            if dep in all_modules:\n                graph[dep].append(module)\n    \n    # DFS topological sort\n    visited = set()\n    visiting = set()\n    order = []\n    \n    def dfs(node):\n        if node in visiting:\n            return False  # Cycle detected\n        if node in visited:\n            return True\n        visiting.add(node)\n        for neighbor in graph.get(node, []):\n            if not dfs(neighbor):\n                return False\n        visiting.remove(node)\n        visited.add(node)\n        order.append(node)\n        return True\n    \n    for module in all_modules:\n        if module not in visited:\n            if not dfs(module):\n                return None\n    \n    # Reverse to get correct topological order\n    order.reverse()\n    return order\n```", "error": null, "raw_item": {"task_id": "custom_resolve_dependencies", "prompt": "Write resolve_dependencies(deps) that returns valid module load order from dependency dict. Return None if cycle exists. Use DFS topological sort. Return only the Python function code with no explanations.", "entry_point": "resolve_dependencies", "canonical_solution": "def resolve_dependencies(deps: dict[str, list[str]]) -> list[str] | None:\n    visited = {}\n    result = []\n\n    def dfs(node):\n        if node in visited:\n            return visited[node]  # False if cycle\n        visited[node] = False  # mark as visiting\n        for neighbor in deps.get(node, []):\n            res = dfs(neighbor)\n            if res is False:\n                return False\n        visited[node] = True  # mark as visited\n        result.append(node)\n        return True\n\n    for node in deps:\n        if node not in visited:\n            if dfs(node) is False:\n                return None\n    return result[::-1]", "test": [{"input": [{"a": ["b", "c"], "b": ["c"], "c": []}], "output": ["c", "b", "a"]}, {"input": [{"x": ["y"], "y": ["z"], "z": ["x"]}], "output": null}, {"input": [{"m": ["n"], "n": [], "o": []}], "output": ["n", "m", "o"]}, {"input": [{"a": []}], "output": ["a"]}, {"input": [{}], "output": []}]}}
{"timestamp_utc": "2025-09-27T12:30:58.994031", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 9, "question": "Write clean_and_validate_urls(urls) that returns sorted list of unique valid URLs. Valid URLs start with 'http://' or 'https://' (case-insensitive) and contain no spaces. Strip whitespace and remove duplicates. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.1304500102996826, "response": "```python\ndef clean_and_validate_urls(urls):\n    valid_urls = set()\n    for url in urls:\n        url = url.strip()\n        if url.lower().startswith(('http://', 'https://')) and ' ' not in url:\n            valid_urls.add(url)\n    return sorted(list(valid_urls))\n```", "error": null, "raw_item": {"task_id": "custom_clean_and_validate_urls", "prompt": "Write clean_and_validate_urls(urls) that returns sorted list of unique valid URLs. Valid URLs start with 'http://' or 'https://' (case-insensitive) and contain no spaces. Strip whitespace and remove duplicates. Return only the Python function code with no explanations.", "entry_point": "clean_and_validate_urls", "canonical_solution": "def clean_and_validate_urls(urls: list[str]) -> list[str]:\n    valid = set()\n    for url in urls:\n        cleaned = url.strip()\n        if cleaned.lower().startswith(\"http://\") or cleaned.lower().startswith(\"https://\"):\n            if \" \" not in cleaned:\n                valid.add(cleaned)\n    return sorted(valid)", "test": [{"input": [[" http://example.com ", "https://valid.site", "ftp://notvalid", "invalid.com", "https://valid.site"]], "output": ["http://example.com", "https://valid.site"]}, {"input": [[]], "output": []}, {"input": [["   https://a.com  ", "http://b.com", "http://b.com  "]], "output": ["http://b.com", "https://a.com"]}, {"input": [["https://with space.com", "http://ok.com"]], "output": ["http://ok.com"]}, {"input": [["HTTP://UPPERCASE.com"]], "output": ["HTTP://UPPERCASE.com"]}]}}
{"timestamp_utc": "2025-09-27T12:31:02.982528", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 10, "question": "Write normalize_filename(filename) that normalizes filenames by converting to lowercase, keeping only a-z, 0-9, underscore, and dots, removing other characters. Return 'unnamed' if result is empty. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.9858338832855225, "response": "```python\ndef normalize_filename(filename):\n    allowed = 'abcdefghijklmnopqrstuvwxyz0123456789_.'\n    normalized = ''.join(c for c in filename.lower() if c in allowed)\n    return 'unnamed' if not normalized else normalized\n```", "error": null, "raw_item": {"task_id": "custom_normalize_filename", "prompt": "Write normalize_filename(filename) that normalizes filenames by converting to lowercase, keeping only a-z, 0-9, underscore, and dots, removing other characters. Return 'unnamed' if result is empty. Return only the Python function code with no explanations.", "entry_point": "normalize_filename", "canonical_solution": "def normalize_filename(filename: str) -> str:\n    allowed = set(\"abcdefghijklmnopqrstuvwxyz0123456789_.\")\n    result = ''.join(c.lower() for c in filename if c.lower() in allowed)\n    return result if result else \"unnamed\"", "test": [{"input": ["My Report (Final).PDF"], "output": "myreport.final.pdf"}, {"input": ["Résumé_2023!.docx"], "output": "rsum_2023.docx"}, {"input": ["  "], "output": "unnamed"}, {"input": ["file@#name!.TXT"], "output": "filename.txt"}, {"input": ["___"], "output": "___"}, {"input": ["###"], "output": "unnamed"}, {"input": ["ABC123_456.xyz"], "output": "abc123_456.xyz"}]}}
{"timestamp_utc": "2025-09-27T12:31:06.759387", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 11, "question": "Write rank_projects_by_score(projects) that ranks projects by score formula: (stars * 2) + forks - (issues * 3). Return project names sorted by score descending, then alphabetically. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.7757930755615234, "response": "def rank_projects_by_score(projects):\n    scored_projects = [(proj['name'], (proj['stars'] * 2) + proj['forks'] - (proj['issues'] * 3)) for proj in projects]\n    sorted_projects = sorted(scored_projects, key=lambda x: (-x[1], x[0]))\n    return [name for name, score in sorted_projects]", "error": null, "raw_item": {"task_id": "custom_rank_projects_by_score", "prompt": "Write rank_projects_by_score(projects) that ranks projects by score formula: (stars * 2) + forks - (issues * 3). Return project names sorted by score descending, then alphabetically. Return only the Python function code with no explanations.", "entry_point": "rank_projects_by_score", "canonical_solution": "def rank_projects_by_score(projects: list[tuple[str, int, int, int]]) -> list[str]:\n    def score(proj):\n        return (proj[1] * 2) + proj[2] - (proj[3] * 3)\n    return [p[0] for p in sorted(projects, key=lambda p: (-score(p), p[0]))]", "test": [{"input": [[["ProjectA", 100, 50, 10], ["ProjectB", 80, 70, 5], ["ProjectC", 100, 50, 10]]], "output": ["ProjectA", "ProjectC", "ProjectB"]}, {"input": [[["Alpha", 10, 5, 0], ["Beta", 10, 5, 0]]], "output": ["Alpha", "Beta"]}, {"input": [[["AppX", 0, 0, 0], ["AppY", 0, 0, 1]]], "output": ["AppX", "AppY"]}, {"input": [[]], "output": []}, {"input": [[["ToolZ", 5, 5, 10], ["ToolY", 4, 4, 1]]], "output": ["ToolY", "ToolZ"]}]}}
{"timestamp_utc": "2025-09-27T12:31:16.213383", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 12, "question": "Write longest_prime_gap(nums) that finds the longest sequence of non-prime numbers between two prime numbers in the list. Return length of longest gap. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 8.45241904258728, "response": "```python\ndef is_prime(n):\n    if n <= 1:\n        return False\n    if n <= 3:\n        return True\n    if n % 2 == 0 or n % 3 == 0:\n        return False\n    i = 5\n    while i * i <= n:\n        if n % i == 0 or n % (i + 2) == 0:\n            return False\n        i += 6\n    return True\n\ndef longest_prime_gap(nums):\n    if len(nums) < 2:\n        return 0\n    prime_indices = [i for i in range(len(nums)) if is_prime(nums[i])]\n    if len(prime_indices) < 2:\n        return 0\n    max_gap = 0\n    for i in range(1, len(prime_indices)):\n        gap = prime_indices[i] - prime_indices[i-1] - 1\n        max_gap = max(max_gap, gap)\n    return max_gap\n```", "error": null, "raw_item": {"task_id": "custom_longest_prime_gap", "prompt": "Write longest_prime_gap(nums) that finds the longest sequence of non-prime numbers between two prime numbers in the list. Return length of longest gap. Return only the Python function code with no explanations.", "entry_point": "longest_prime_gap", "canonical_solution": "def longest_prime_gap(nums: list[int]) -> int:\n    def is_prime(n: int) -> bool:\n        if n < 2:\n            return False\n        for i in range(2, int(n**0.5)+1):\n            if n % i == 0:\n                return False\n        return True\n\n    indices = [i for i, val in enumerate(nums) if is_prime(val)]\n    if len(indices) < 2:\n        return 0\n\n    max_gap = 0\n    for i in range(len(indices) - 1):\n        start = indices[i]\n        end = indices[i + 1]\n        gap = end - start - 1\n        max_gap = max(max_gap, gap)\n    return max_gap", "test": [{"input": [[4, 6, 7, 8, 9, 10, 11, 4, 6, 13]], "output": 3}, {"input": [[2, 4, 6, 8, 10, 3]], "output": 4}, {"input": [[4, 6, 8, 10]], "output": 0}, {"input": [[3, 4, 5, 6, 7]], "output": 1}, {"input": [[2, 3]], "output": 0}, {"input": [[17, 4, 6, 9, 15, 19, 21, 23]], "output": 4}, {"input": [[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]], "output": 4}]}}
{"timestamp_utc": "2025-09-27T12:31:20.607109", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 13, "question": "Write categorize_commit_message(message) that categorizes commit messages. Return 'feature' for add/implement/feature/new, 'fix' for fix/bug/error/resolve, 'refactor' for refactor/cleanup/restructure, 'docs' for docs/documentation/readme, else 'other'. Case-insensitive. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 3.3916537761688232, "response": "```python\ndef categorize_commit_message(message):\n    msg_lower = message.lower()\n    if any(keyword in msg_lower for keyword in ['add', 'implement', 'feature', 'new']):\n        return 'feature'\n    elif any(keyword in msg_lower for keyword in ['fix', 'bug', 'error', 'resolve']):\n        return 'fix'\n    elif any(keyword in msg_lower for keyword in ['refactor', 'cleanup', 'restructure']):\n        return 'refactor'\n    elif any(keyword in msg_lower for keyword in ['docs', 'documentation', 'readme']):\n        return 'docs'\n    else:\n        return 'other'\n```", "error": null, "raw_item": {"task_id": "custom_categorize_commit_message", "prompt": "Write categorize_commit_message(message) that categorizes commit messages. Return 'feature' for add/implement/feature/new, 'fix' for fix/bug/error/resolve, 'refactor' for refactor/cleanup/restructure, 'docs' for docs/documentation/readme, else 'other'. Case-insensitive. Return only the Python function code with no explanations.", "entry_point": "categorize_commit_message", "canonical_solution": "def categorize_commit_message(message: str) -> str:\n    msg = message.lower()\n    categories = {\n        \"feature\": [\"add\", \"implement\", \"feature\", \"new\"],\n        \"fix\": [\"fix\", \"bug\", \"error\", \"resolve\"],\n        \"refactor\": [\"refactor\", \"cleanup\", \"restructure\"],\n        \"docs\": [\"docs\", \"documentation\", \"readme\"],\n    }\n    for label, keywords in categories.items():\n        if any(kw in msg for kw in keywords):\n            return label\n    return \"other\"", "test": [{"input": ["Fix bug in user login"], "output": "fix"}, {"input": ["Refactor payment module"], "output": "refactor"}, {"input": ["Updated README and docs"], "output": "docs"}, {"input": ["Initial commit"], "output": "other"}, {"input": ["Implemented new feature for signup"], "output": "feature"}, {"input": ["cleanup redundant logic"], "output": "refactor"}, {"input": ["Error handling for empty input"], "output": "fix"}, {"input": ["add configuration support"], "output": "feature"}, {"input": ["Documentation improvements"], "output": "docs"}, {"input": ["Minor UI tweaks"], "output": "other"}]}}
{"timestamp_utc": "2025-09-27T12:32:11.648922", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 14, "question": "Write max_repeated_substring(s) that returns length of longest non-overlapping repeated substring. Use sliding window with seen set. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 50.04004192352295, "response": "```python\ndef max_repeated_substring(s):\n    seen = {}\n    max_len = 0\n    n = len(s)\n    for i in range(n):\n        for j in range(i + 1, n + 1):\n            sub = s[i:j]\n            if sub in seen:\n                prev_i = seen[sub]\n                length = j - i\n                if i >= prev_i + length:\n                    max_len = max(max_len, length)\n            else:\n                seen[sub] = i\n    return max_len\n```", "error": null, "raw_item": {"task_id": "custom_max_repeated_substring", "prompt": "Write max_repeated_substring(s) that returns length of longest non-overlapping repeated substring. Use sliding window with seen set. Return only the Python function code with no explanations.", "entry_point": "max_repeated_substring", "canonical_solution": "def max_repeated_substring(s: str) -> int:\n    n = len(s)\n    max_len = 0\n    for l in range(1, n // 2 + 1):\n        seen = set()\n        i = 0\n        while i + l <= n:\n            substr = s[i:i+l]\n            if substr in seen:\n                max_len = max(max_len, l)\n                i += l  # move forward non-overlapping\n            else:\n                seen.add(substr)\n                i += 1\n    return max_len", "test": [{"input": ["abababc"], "output": 2}, {"input": ["aaaa"], "output": 2}, {"input": ["abcabcabc"], "output": 3}, {"input": ["abcdef"], "output": 0}, {"input": ["ababa"], "output": 1}, {"input": [""], "output": 0}, {"input": ["a"], "output": 0}, {"input": ["abcdabcd"], "output": 4}, {"input": ["xyzxyzabcabc"], "output": 3}, {"input": ["abababab"], "output": 2}]}}
{"timestamp_utc": "2025-09-27T12:32:20.297049", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 15, "question": "Write longest_valid_bracket_substring(s) that returns length of longest valid parentheses substring. Use stack with indices. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 7.64595890045166, "response": "```python\ndef longest_valid_bracket_substring(s):\n    stack = [-1]\n    max_len = 0\n    for i in range(len(s)):\n        if s[i] == '(':\n            stack.append(i)\n        else:\n            stack.pop()\n            if stack:\n                max_len = max(max_len, i - stack[-1])\n            else:\n                stack.append(i)\n    return max_len\n```", "error": null, "raw_item": {"task_id": "custom_longest_valid_bracket_substring", "prompt": "Write longest_valid_bracket_substring(s) that returns length of longest valid parentheses substring. Use stack with indices. Return only the Python function code with no explanations.", "entry_point": "longest_valid_bracket_substring", "canonical_solution": "def longest_valid_bracket_substring(s: str) -> int:\n    stack = [-1]\n    max_len = 0\n\n    for i, ch in enumerate(s):\n        if ch == '(':\n            stack.append(i)\n        else:\n            stack.pop()\n            if not stack:\n                stack.append(i)\n            else:\n                max_len = max(max_len, i - stack[-1])\n\n    return max_len", "test": [{"input": ["(()"], "output": 2}, {"input": [")()())"], "output": 4}, {"input": [""], "output": 0}, {"input": ["((("], "output": 0}, {"input": ["()(()))())"], "output": 6}, {"input": ["((()))"], "output": 6}, {"input": ["()()()"], "output": 6}, {"input": [")((()))("], "output": 6}, {"input": ["(()(((()"], "output": 2}, {"input": ["())(())"], "output": 4}]}}
{"timestamp_utc": "2025-09-27T12:32:23.532847", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 16, "question": "Write summarize_category_totals(purchases) that returns list of [category, total] pairs sorted alphabetically by category. Sum amounts by category. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.2344770431518555, "response": "def summarize_category_totals(purchases):\n    from collections import defaultdict\n    totals = defaultdict(int)\n    for purchase in purchases:\n        totals[purchase['category']] += purchase['amount']\n    result = [[cat, tot] for cat, tot in totals.items()]\n    result.sort(key=lambda x: x[0])\n    return result", "error": null, "raw_item": {"task_id": "custom_summarize_category_totals", "prompt": "Write summarize_category_totals(purchases) that returns list of [category, total] pairs sorted alphabetically by category. Sum amounts by category. Return only the Python function code with no explanations.", "entry_point": "summarize_category_totals", "canonical_solution": "def summarize_category_totals(purchases: list[dict]) -> list[list]:\n    totals = {}\n    for item in purchases:\n        cat = item[\"category\"]\n        amt = item[\"amount\"]\n        totals[cat] = totals.get(cat, 0.0) + amt\n    return sorted([[cat, total] for cat, total in totals.items()])", "test": [{"input": [[{"category": "groceries", "amount": 25.5}, {"category": "electronics", "amount": 99.99}, {"category": "groceries", "amount": 13.0}, {"category": "books", "amount": 10.0}]], "output": [["books", 10.0], ["electronics", 99.99], ["groceries", 38.5]]}, {"input": [[{"category": "a", "amount": 1.0}, {"category": "b", "amount": 2.0}, {"category": "a", "amount": 3.0}, {"category": "c", "amount": 4.0}]], "output": [["a", 4.0], ["b", 2.0], ["c", 4.0]]}, {"input": [[]], "output": []}, {"input": [[{"category": "x", "amount": 0.0}, {"category": "x", "amount": 0.0}]], "output": [["x", 0.0]]}, {"input": [[{"category": "Z", "amount": 2.0}, {"category": "a", "amount": 1.0}]], "output": [["Z", 2.0], ["a", 1.0]]}]}}
{"timestamp_utc": "2025-09-27T12:32:26.843812", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 17, "question": "Write filter_unique_keywords(keywords, banned) that returns sorted unique keywords (lowercased) excluding banned words. Case-insensitive comparison. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.3098111152648926, "response": "```python\ndef filter_unique_keywords(keywords, banned):\n    banned_lower = set(word.lower() for word in banned)\n    unique_keywords = set()\n    for word in keywords:\n        lower_word = word.lower()\n        if lower_word not in banned_lower:\n            unique_keywords.add(lower_word)\n    return sorted(unique_keywords)\n```", "error": null, "raw_item": {"task_id": "custom_filter_unique_keywords", "prompt": "Write filter_unique_keywords(keywords, banned) that returns sorted unique keywords (lowercased) excluding banned words. Case-insensitive comparison. Return only the Python function code with no explanations.", "entry_point": "filter_unique_keywords", "canonical_solution": "def filter_unique_keywords(keywords: list[str], banned: list[str]) -> list[str]:\n    banned_set = set(word.lower() for word in banned)\n    unique = set()\n\n    for word in keywords:\n        w = word.lower()\n        if w not in banned_set:\n            unique.add(w)\n\n    return sorted(unique)", "test": [{"input": [["Python", "code", "AI", "python", "Data", "Code"], ["ai"]], "output": ["code", "data", "python"]}, {"input": [[], ["test"]], "output": []}, {"input": [["ML", "AI", "ml", "AI"], ["ai"]], "output": ["ml"]}, {"input": [["hello", "world", "HELLO", "WORLD"], []], "output": ["hello", "world"]}, {"input": [["Data", "Science", "AI"], ["science", "ai"]], "output": ["data"]}, {"input": [["Python", "PYTHON", "python"], ["PYTHON"]], "output": []}]}}
{"timestamp_utc": "2025-09-27T12:32:45.570281", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 18, "question": "Write next_greater_circular(nums) that returns list where each position contains next greater element circularly. Use monotonic stack. O(n) time. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 17.72472906112671, "response": "```python\ndef next_greater_circular(nums):\n    n = len(nums)\n    stack = []\n    result = [-1] * n\n    for i in range(2 * n - 1, -1, -1):\n        while stack and nums[stack[-1]] <= nums[i % n]:\n            stack.pop()\n        if stack:\n            result[i % n] = nums[stack[-1]]\n        stack.append(i % n)\n    return result\n```", "error": null, "raw_item": {"task_id": "ds_next_greater_circular", "prompt": "Write next_greater_circular(nums) that returns list where each position contains next greater element circularly. Use monotonic stack. O(n) time. Return only the Python function code with no explanations.", "entry_point": "next_greater_circular", "canonical_solution": "def next_greater_circular(nums):\n    n = len(nums)\n    res = [-1]*n\n    stack = []  # indices with decreasing stack by value\n    for i in range(2*n):\n        x = nums[i % n]\n        while stack and nums[stack[-1]] < x:\n            idx = stack.pop()\n            res[idx] = x\n        if i < n:\n            stack.append(i)\n    return res\n", "test": [{"input": [[1, 2, 1]], "output": [2, -1, 2]}, {"input": [[3, 8, 4, 1, 2]], "output": [8, -1, 8, 2, 3]}, {"input": [[5, 4, 3, 2, 1]], "output": [-1, 5, 5, 5, 5]}, {"input": [[2, 2, 2]], "output": [-1, -1, -1]}, {"input": [[]], "output": []}]}}
{"timestamp_utc": "2025-09-27T12:32:48.638093", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 19, "question": "Write normalize_product_code(s) that keeps only alphanumerics and dashes, converts to uppercase, collapses multiple dashes, trims leading/trailing dashes. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.065998077392578, "response": "```python\nimport re\n\ndef normalize_product_code(s):\n    # Keep only alphanumerics and dashes\n    s = re.sub(r'[^a-zA-Z0-9-]', '', s)\n    # Convert to uppercase\n    s = s.upper()\n    # Collapse multiple dashes\n    s = re.sub(r'-+', '-', s)\n    # Trim leading/trailing dashes\n    s = s.strip('-')\n    return s\n```", "error": null, "raw_item": {"task_id": "str_normalize_product_code", "prompt": "Write normalize_product_code(s) that keeps only alphanumerics and dashes, converts to uppercase, collapses multiple dashes, trims leading/trailing dashes. Return only the Python function code with no explanations.", "entry_point": "normalize_product_code", "canonical_solution": "import re\ndef normalize_product_code(s):\n    # keep alnum and dash\n    s = ''.join(ch for ch in s if ch.isalnum() or ch=='-')\n    s = s.upper()\n    s = re.sub(r'-{2,}', '-', s)\n    s = s.strip('-')\n    return s\n", "test": [{"input": [" abC--12__-xx "], "output": "ABC-12-XX"}, {"input": ["---a---b---"], "output": "A-B"}, {"input": ["***"], "output": ""}, {"input": ["proD-uct_99!!"], "output": "PROD-UCT99"}, {"input": [""], "output": ""}]}}
{"timestamp_utc": "2025-09-27T12:32:52.001012", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 20, "question": "Write single_number_triplicates(nums) that finds element appearing once while others appear thrice. Use bitwise counting without hash maps. O(n) time, O(1) space. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.360870838165283, "response": "```python\ndef single_number_triplicates(nums):\n    bit_counts = [0] * 32\n    for num in nums:\n        for i in range(32):\n            if num & (1 << i):\n                bit_counts[i] += 1\n    result = 0\n    for i in range(32):\n        if bit_counts[i] % 3 == 1:\n            result |= (1 << i)\n    return result\n```", "error": null, "raw_item": {"task_id": "bit_single_number_triplicates", "prompt": "Write single_number_triplicates(nums) that finds element appearing once while others appear thrice. Use bitwise counting without hash maps. O(n) time, O(1) space. Return only the Python function code with no explanations.", "entry_point": "single_number_triplicates", "canonical_solution": "def single_number_triplicates(nums):\n    ones = 0\n    twos = 0\n    for x in nums:\n        ones = (ones ^ x) & ~twos\n        twos = (twos ^ x) & ~ones\n    return ones\n", "test": [{"input": [[2, 2, 3, 2]], "output": 3}, {"input": [[0, 1, 0, 1, 0, 1, 99]], "output": 99}, {"input": [[-2, -2, -2, -5]], "output": -5}, {"input": [[7]], "output": 7}, {"input": [[10, 10, 10, -1]], "output": -1}]}}
{"timestamp_utc": "2025-09-27T12:32:58.776841", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 21, "question": "Write can_finish_prereqs(pairs) where pairs are (a,b) meaning 'b precedes a'. Return True if acyclic. Use topological sort without external libraries. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 5.7741858959198, "response": "```python\nfrom collections import defaultdict\n\ndef can_finish_prereqs(pairs):\n    adj = defaultdict(list)\n    indegree = defaultdict(int)\n    all_nodes = set()\n    for a, b in pairs:\n        adj[b].append(a)\n        indegree[a] += 1\n        all_nodes.add(a)\n        all_nodes.add(b)\n    queue = [node for node in all_nodes if indegree[node] == 0]\n    count = 0\n    while queue:\n        node = queue.pop(0)\n        count += 1\n        for nei in adj[node]:\n            indegree[nei] -= 1\n            if indegree[nei] == 0:\n                queue.append(nei)\n    return count == len(all_nodes)\n```", "error": null, "raw_item": {"task_id": "graph_can_finish_prereqs", "prompt": "Write can_finish_prereqs(pairs) where pairs are (a,b) meaning 'b precedes a'. Return True if acyclic. Use topological sort without external libraries. Return only the Python function code with no explanations.", "entry_point": "can_finish_prereqs", "canonical_solution": "from collections import defaultdict, deque\ndef can_finish_prereqs(pairs):\n    adj = defaultdict(list)\n    indeg = defaultdict(int)\n    nodes = set()\n    for a,b in pairs:\n        adj[b].append(a)\n        indeg[a] += 1\n        nodes.add(a); nodes.add(b)\n        if b not in indeg: indeg[b] = indeg.get(b,0)\n    q = deque([v for v in nodes if indeg.get(v,0)==0])\n    visited = 0\n    while q:\n        v = q.popleft()\n        visited += 1\n        for w in adj[v]:\n            indeg[w] -= 1\n            if indeg[w]==0:\n                q.append(w)\n    return visited == len(nodes)\n", "test": [{"input": [[["C2", "C1"], ["C3", "C2"]]], "output": true}, {"input": [[["A", "B"], ["B", "C"], ["C", "A"]]], "output": false}, {"input": [[["A", "B"]]], "output": true}, {"input": [[["X", "Y"], ["Y", "Z"], ["Z", "X"]]], "output": false}, {"input": [[[]]], "output": true}]}}
{"timestamp_utc": "2025-09-27T12:33:04.199574", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 22, "question": "Write safe_deep_get(obj, path, default=None) that safely traverses nested dicts/lists/tuples using path keys/indices. Return default if any access fails. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 4.420998811721802, "response": "```python\ndef safe_deep_get(obj, path, default=None):\n    current = obj\n    for key in path:\n        try:\n            current = current[key]\n        except (KeyError, IndexError, TypeError):\n            return default\n    return current\n```", "error": null, "raw_item": {"task_id": "se_safe_deep_get", "entry_point": "safe_deep_get", "prompt": "Write safe_deep_get(obj, path, default=None) that safely traverses nested dicts/lists/tuples using path keys/indices. Return default if any access fails. Return only the Python function code with no explanations.", "canonical_solution": "def safe_deep_get(obj, path, default=None):\n    cur = obj\n    for key in path:\n        if isinstance(cur, dict):\n            if key in cur:\n                cur = cur[key]\n            else:\n                return default\n        elif isinstance(cur, (list, tuple)):\n            if isinstance(key, int) and -len(cur) <= key < len(cur):\n                cur = cur[key]\n            else:\n                return default\n        else:\n            return default\n    return cur\n", "test": [{"input": [{"a": {"b": [10, 20, {"c": 42}]}}, ["a", "b", 2, "c"], null], "output": 42}, {"input": [{"a": [1, 2, 3]}, ["a", 5], "x"], "output": "x"}, {"input": [{"x": 0}, ["y"], 99], "output": 99}, {"input": [[1, 2, 3], [0], null], "output": 1}, {"input": [[1, 2, 3], ["0"], "err"], "output": "err"}]}}
{"timestamp_utc": "2025-09-27T12:33:08.907433", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 23, "question": "Write clean_and_split_sentences(text) that removes non-alphanumeric chars except .!?, normalizes whitespace, splits on sentence delimiters, returns cleaned sentence list. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 3.7060980796813965, "response": "```python\nimport re\n\ndef clean_and_split_sentences(text):\n    # Remove non-alphanumeric characters except . ! ?\n    cleaned = re.sub(r'[^a-zA-Z0-9\\s.!?]', '', text)\n    # Normalize whitespace: replace multiple spaces with single, strip\n    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n    # Split on sentence delimiters: . ! ? followed by space\n    sentences = re.split(r'(?<=[.!?])\\s+', cleaned)\n    # Return list of stripped sentences, filtering out empty ones\n    return [s.strip() for s in sentences if s.strip()]\n```", "error": null, "raw_item": {"task_id": "str_clean_and_split_sentences", "entry_point": "clean_and_split_sentences", "prompt": "Write clean_and_split_sentences(text) that removes non-alphanumeric chars except .!?, normalizes whitespace, splits on sentence delimiters, returns cleaned sentence list. Return only the Python function code with no explanations.", "canonical_solution": "import re\n\ndef clean_and_split_sentences(text):\n    # Keep only letters, digits, punctuation .,!,?\n    text = re.sub(r\"[^A-Za-z0-9.!?\\s]\", \"\", text)\n    # Normalize whitespace\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    # Split on sentence delimiters\n    parts = re.split(r\"[.!?]\", text)\n    # Clean and filter\n    result = [p.strip() for p in parts if p.strip()]\n    return result\n", "test": [{"input": ["Hello!!   How are---you???   Fine."], "output": ["Hello", "How areyou", "Fine"]}, {"input": ["  multiple   spaces   and ###symbols!!"], "output": ["multiple spaces and symbols"]}, {"input": ["Nothing to clean"], "output": ["Nothing to clean"]}, {"input": ["???"], "output": []}]}}
{"timestamp_utc": "2025-09-27T12:33:11.778859", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 24, "question": "Write count_set_bits(n) that counts 1-bits in binary representation using efficient bit manipulation (Brian Kernighan's algorithm). Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 1.8536481857299805, "response": "```python\ndef count_set_bits(n):\n    count = 0\n    while n > 0:\n        count += 1\n        n &= n - 1\n    return count\n```", "error": null, "raw_item": {"task_id": "bit_counting_set_bits", "entry_point": "count_set_bits", "prompt": "Write count_set_bits(n) that counts 1-bits in binary representation using efficient bit manipulation (Brian Kernighan's algorithm). Return only the Python function code with no explanations.", "canonical_solution": "def count_set_bits(n):\n    if n < 0:\n        raise ValueError(\"Input must be a non-negative integer.\")\n    count = 0\n    while n:\n        n &= n - 1  # Clear the least significant bit set\n        count += 1\n    return count\n", "test": [{"input": [11], "output": 3}, {"input": [0], "output": 0}, {"input": [255], "output": 8}, {"input": [1023], "output": 10}, {"input": [1], "output": 1}]}}
{"timestamp_utc": "2025-09-27T12:33:17.915222", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 25, "question": "Write filter_map_validate(records) that normalizes, validates, and filters product records, returning sorted list of valid IDs. Complex multi-step validation with price parsing, type constraints, and conditional rules. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 5.135074853897095, "response": "```python\ndef filter_map_validate(records):\n    valid_ids = []\n    for record in records:\n        # Normalize and parse price (remove $, commas, convert to float)\n        try:\n            price_str = record.get('price', '').replace('$', '').replace(',', '').strip()\n            price = float(price_str)\n            if price < 0:\n                continue  # Invalid negative price\n            record['price'] = price\n        except ValueError:\n            continue  # Invalid price format\n        \n        # Normalize name (strip and title case)\n        name = record.get('name', '').strip().title()\n        record['name'] = name\n        \n        # Type constraints: must be one of allowed categories\n        allowed_types = ['electronics', 'books', 'clothing']\n        rec_type = record.get('type', '').lower()\n        if rec_type not in allowed_types:\n            continue\n        \n        # Conditional validation rules\n        if rec_type == 'electronics':\n            if not (price > 100 and len(name) > 3):\n                continue\n        elif rec_type == 'books':\n            if not (price > 10 and price < 200):\n                continue\n        elif rec_type == 'clothing':\n            if not (price > 20 and ' ' in name):  # Assume name has space for brand and item\n                continue\n        \n        # Additional rule: ID must be integer or convertible to int\n        try:\n            rec_id = int(record.get('id'))\n            if rec_id <= 0:\n                continue\n            valid_ids.append(rec_id)\n        except (ValueError, TypeError):\n            continue\n    \n    # Sort and return unique valid IDs\n    return sorted(set(valid_ids))\n```", "error": null, "raw_item": {"task_id": "se_filter_map_validate_nested", "entry_point": "filter_map_validate", "prompt": "Write filter_map_validate(records) that normalizes, validates, and filters product records, returning sorted list of valid IDs. Complex multi-step validation with price parsing, type constraints, and conditional rules. Return only the Python function code with no explanations.", "canonical_solution": "import re\n\ntype_order = {\"ent\": 0, \"pro\": 1, \"std\": 2}\n\ndef _parse_price(x):\n    if isinstance(x, (int, float)):\n        return float(x) if x >= 0 else None\n    if not isinstance(x, str):\n        return None\n    s = x.strip()\n    if not s:\n        return None\n    s = re.sub(r\"[\\s$€£¥]\", \"\", s)\n    if \",\" in s and \".\" in s:\n        if s.find(\",\") < s.find(\".\"):\n            s = s.replace(\",\", \"\")\n        else:\n            s = s.replace(\".\", \"\").replace(\",\", \".\")\n    elif \",\" in s:\n        s = s.replace(\",\", \".\")\n    try:\n        v = float(s)\n        return v if v >= 0 else None\n    except Exception:\n        return None\n\ndef _to_int(x):\n    if isinstance(x, bool):\n        return None\n    if isinstance(x, int):\n        return x\n    if isinstance(x, str):\n        s = x.strip()\n        if s and s.lstrip(\"-+\").isdigit():\n            try:\n                return int(s)\n            except Exception:\n                return None\n    return None\n\ndef _to_float(x):\n    if isinstance(x, (int, float)):\n        return float(x)\n    if isinstance(x, str):\n        try:\n            return float(x.strip())\n        except Exception:\n            return None\n    return None\n\ndef _to_pct(x):\n    if x is None:\n        return None\n    if isinstance(x, (int, float)):\n        v = float(x)\n    elif isinstance(x, str):\n        try:\n            v = float(x.strip().strip('%'))\n        except Exception:\n            return None\n    else:\n        return None\n    if v < 0:\n        v = 0.0\n    if v > 100:\n        v = 100.0\n    return v\n\ndef filter_map_validate(records):\n    if not isinstance(records, list):\n        return []\n    kept = []\n    for rec in records:\n        if not isinstance(rec, dict):\n            continue\n        # --- id ---\n        rid = rec.get(\"id\")\n        rid = str(rid).strip() if rid is not None else \"\"\n        if not rid:\n            continue\n        # --- meta ---\n        meta = rec.get(\"meta\") or {}\n        if not isinstance(meta, dict):\n            meta = {}\n        rtype = str(meta.get(\"type\") or \"\").strip().lower()\n        flags = meta.get(\"flags\")\n        if isinstance(flags, list):\n            flags_norm = [str(t).strip().lower() for t in flags if isinstance(t, (str, int, float))]\n        else:\n            flags_norm = []\n        if rtype not in (\"std\",\"pro\",\"ent\"):\n            continue\n        # --- price ---\n        price = _parse_price(rec.get(\"price\"))\n        if price is None:\n            continue\n        # --- attrs ---\n        attrs = rec.get(\"attrs\") or {}\n        if not isinstance(attrs, dict):\n            attrs = {}\n        color = attrs.get(\"color\")\n        color = str(color).strip().lower() if isinstance(color, str) else None\n        size = attrs.get(\"size\")\n        if size is not None:\n            size = _to_int(size)\n        weight = attrs.get(\"weight\")\n        if weight is not None:\n            weight = _to_float(weight)\n        cond = attrs.get(\"condition\")\n        cond = str(cond).strip().upper() if isinstance(cond, str) else None\n        discount = _to_pct(attrs.get(\"discount\"))\n        # --- stock ---\n        stock = _to_int(rec.get(\"stock\"))\n        if stock is None:\n            stock = 0\n        if stock < 0:\n            stock = 0\n        # --- Validation A: color/flag gate ---\n        if not ((color in {\"red\",\"blue\",\"green\"}) or (\"eco\" in flags_norm)):\n            continue\n        # --- Validation B: price caps ---\n        if rtype in (\"std\",\"pro\") and price > 1000:\n            continue\n        if rtype == \"ent\" and price > 5000:\n            continue\n        # --- Validation C: refurb implies good condition ---\n        if \"refurb\" in flags_norm:\n            if cond not in {\"A\",\"B\"}:\n                continue\n        # --- Validation D: ent requires size>=10 and stock>=1 ---\n        if rtype == \"ent\":\n            if size is None or size < 10 or stock < 1:\n                continue\n        # --- Validation E: pro weight <= 50 if provided ---\n        if rtype == \"pro\" and weight is not None and weight > 50.0:\n            continue\n        kept.append({\n            \"id\": rid,\n            \"type\": rtype,\n            \"price\": price\n        })\n    # sort: type order (ent > pro > std) i.e., ent first, then pro, then std\n    kept.sort(key=lambda r: (type_order.get(r[\"type\"], 3), r[\"price\"], r[\"id\"].lower()))\n    return [r[\"id\"] for r in kept]\n", "test": [{"input": [[{"id": " A-1 ", "meta": {"type": "ent", "flags": ["Eco"]}, "price": "€4,999.00", "attrs": {"size": "12", "color": "Green"}, "stock": "5"}, {"id": "B-2", "meta": {"type": "pro", "flags": ["refurb"]}, "price": "$800", "attrs": {"weight": "49.5", "color": "blue", "condition": "B"}, "stock": 0}, {"id": "c-3", "meta": {"type": "std", "flags": []}, "price": "1200", "attrs": {"color": "red"}, "stock": 10}, {"id": "d-4", "meta": {"type": "ent", "flags": ["eco", "refurb"]}, "price": "5100", "attrs": {"size": 15, "color": "green", "condition": "A"}, "stock": 2}, {"id": "e-5", "meta": {"type": "pro", "flags": []}, "price": "999.99", "attrs": {"color": "yellow"}, "stock": 7}]], "output": ["A-1", "B-2"]}, {"input": [[{"id": 101, "meta": {"type": "pro", "flags": ["eco"]}, "price": "1,000.00", "attrs": {"color": "RED", "weight": "50"}, "stock": "-3"}, {"id": 102, "meta": {"type": "pro", "flags": ["eco"]}, "price": "1,000.01", "attrs": {"color": "GREEN", "weight": "10"}, "stock": "0"}, {"id": 103, "meta": {"type": "std", "flags": ["eco"]}, "price": "$0", "attrs": {"color": "green"}, "stock": "0"}]], "output": ["101", "103"]}, {"input": [[{"id": "X", "meta": {"type": "ent", "flags": ["REFURB"]}, "price": "$4500", "attrs": {"size": "9", "color": "blue", "condition": "A"}, "stock": 1}, {"id": "Y", "meta": {"type": "ent", "flags": []}, "price": "$4500", "attrs": {"size": "12", "color": "blue"}, "stock": 0}, {"id": "Z", "meta": {"type": "ent", "flags": []}, "price": "$4500", "attrs": {"size": "12", "color": "blue"}, "stock": 3}]], "output": ["Z"]}, {"input": [[{"id": "bad", "meta": {"type": "other", "flags": ["eco"]}, "price": "100", "attrs": {"color": "red"}, "stock": 1}, {"id": "ok-std", "meta": {"type": "std", "flags": ["eco"]}, "price": "1000", "attrs": {"color": "green"}, "stock": 0}]], "output": ["ok-std"]}, {"input": [[{"id": "keep-pro-over-std", "meta": {"type": "pro", "flags": ["eco"]}, "price": "500", "attrs": {"color": "blue"}}, {"id": "keep-ent-first", "meta": {"type": "ent", "flags": ["eco"]}, "price": "1200", "attrs": {"color": "green", "size": 20}, "stock": 2}, {"id": "keep-std-last", "meta": {"type": "std", "flags": ["eco"]}, "price": "100", "attrs": {"color": "red"}}]], "output": ["keep-ent-first", "keep-pro-over-std", "keep-std-last"]}]}}
{"timestamp_utc": "2025-09-27T12:33:22.351871", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 26, "question": "Write sliding_window_max(arr, k) that returns maximum element in each sliding window of size k using deque. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 3.435148000717163, "response": "```python\ndef sliding_window_max(arr, k):\n    if not arr or k == 0:\n        return []\n    from collections import deque\n    dq = deque()\n    result = []\n    for i in range(len(arr)):\n        while dq and dq[0] <= i - k:\n            dq.popleft()\n        while dq and arr[dq[-1]] <= arr[i]:\n            dq.pop()\n        dq.append(i)\n        if i >= k - 1:\n            result.append(arr[dq[0]])\n    return result\n```", "error": null, "raw_item": {"task_id": "custom_sliding_window_max", "prompt": "Write sliding_window_max(arr, k) that returns maximum element in each sliding window of size k using deque. Return only the Python function code with no explanations.", "entry_point": "sliding_window_max", "canonical_solution": "from collections import deque\n\ndef sliding_window_max(arr: list[int], k: int) -> list[int]:\n    if not arr or k == 0:\n        return []\n    \n    dq = deque()\n    result = []\n    \n    for i in range(len(arr)):\n        # Remove elements outside current window\n        while dq and dq[0] <= i - k:\n            dq.popleft()\n        \n        # Remove elements smaller than current element\n        while dq and arr[dq[-1]] <= arr[i]:\n            dq.pop()\n        \n        dq.append(i)\n        \n        # Add maximum to result if window is complete\n        if i >= k - 1:\n            result.append(arr[dq[0]])\n    \n    return result", "test": [{"input": [[1, 3, -1, -3, 5, 3, 6, 7], 3], "output": [3, 3, 5, 5, 6, 7]}, {"input": [[1, 2, 3], 1], "output": [1, 2, 3]}, {"input": [[5, 4, 3, 2, 1], 2], "output": [5, 4, 3, 2]}, {"input": [[1], 1], "output": [1]}, {"input": [[], 3], "output": []}, {"input": [[7, 2, 4], 3], "output": [7]}]}}
{"timestamp_utc": "2025-09-27T12:33:25.799991", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 27, "question": "Write rotate_matrix(matrix) that rotates n×n matrix 90 degrees clockwise in-place using transpose and reverse. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.447033166885376, "response": "def rotate_matrix(matrix):\n    n = len(matrix)\n    # Transpose\n    for i in range(n):\n        for j in range(i + 1, n):\n            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n    # Reverse each row\n    for row in matrix:\n        row.reverse()", "error": null, "raw_item": {"task_id": "custom_rotate_matrix", "prompt": "Write rotate_matrix(matrix) that rotates n×n matrix 90 degrees clockwise in-place using transpose and reverse. Return only the Python function code with no explanations.", "entry_point": "rotate_matrix", "canonical_solution": "def rotate_matrix(matrix: list[list[int]]) -> list[list[int]]:\n    if not matrix or not matrix[0]:\n        return matrix\n    \n    n = len(matrix)\n    \n    # Transpose the matrix\n    for i in range(n):\n        for j in range(i, n):\n            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n    \n    # Reverse each row\n    for i in range(n):\n        matrix[i].reverse()\n    \n    return matrix", "test": [{"input": [[[1, 2, 3], [4, 5, 6], [7, 8, 9]]], "output": [[7, 4, 1], [8, 5, 2], [9, 6, 3]]}, {"input": [[[1, 2], [3, 4]]], "output": [[3, 1], [4, 2]]}, {"input": [[[1]]], "output": [[1]]}, {"input": [[]], "output": []}, {"input": [[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]], "output": [[13, 9, 5, 1], [14, 10, 6, 2], [15, 11, 7, 3], [16, 12, 8, 4]]}]}}
{"timestamp_utc": "2025-09-27T12:33:29.281992", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 28, "question": "Write is_arithmetic_sequence(seq) that checks if sequence forms arithmetic progression with common difference > 0. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.48048996925354, "response": "```python\ndef is_arithmetic_sequence(seq):\n    if len(seq) < 2:\n        return False\n    diff = seq[1] - seq[0]\n    if diff <= 0:\n        return False\n    for i in range(2, len(seq)):\n        if seq[i] - seq[i-1] != diff:\n            return False\n    return True\n```", "error": null, "raw_item": {"task_id": "alg_arithmetic_sequence", "entry_point": "is_arithmetic_sequence", "prompt": "Write is_arithmetic_sequence(seq) that checks if sequence forms arithmetic progression with common difference > 0. Return only the Python function code with no explanations.", "canonical_solution": "def is_arithmetic_sequence(seq):\n    if len(seq) < 2:\n        return False\n    diff = seq[1] - seq[0]\n    if diff <= 0:\n        return False\n    for i in range(2, len(seq)):\n        if seq[i] - seq[i-1] != diff:\n            return False\n    return True", "test": [{"input": [[1, 3, 5, 7, 9]], "output": true}, {"input": [[2, 4, 6, 8]], "output": true}, {"input": [[5, 5, 5]], "output": false}, {"input": [[1, 2, 4, 8]], "output": false}, {"input": [[10, 5, 0]], "output": false}]}}
{"timestamp_utc": "2025-09-27T12:33:32.457755", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 29, "question": "Write classify_severity(msg) that returns HIGH if msg contains 'error' or 'critical', MEDIUM if contains 'warning', LOW otherwise. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.1737959384918213, "response": "def classify_severity(msg):\n    if 'error' in msg or 'critical' in msg:\n        return 'HIGH'\n    elif 'warning' in msg:\n        return 'MEDIUM'\n    else:\n        return 'LOW'", "error": null, "raw_item": {"task_id": "se_severity_classifier", "entry_point": "classify_severity", "prompt": "Write classify_severity(msg) that returns HIGH if msg contains 'error' or 'critical', MEDIUM if contains 'warning', LOW otherwise. Return only the Python function code with no explanations.", "canonical_solution": "def classify_severity(msg):\n    msg_lower = msg.lower()\n    if 'error' in msg_lower or 'critical' in msg_lower:\n        return 'HIGH'\n    elif 'warning' in msg_lower:\n        return 'MEDIUM'\n    else:\n        return 'LOW'", "test": [{"input": ["System error occurred"], "output": "HIGH"}, {"input": ["Critical failure detected"], "output": "HIGH"}, {"input": ["Warning: disk space low"], "output": "MEDIUM"}, {"input": ["Info: task completed"], "output": "LOW"}, {"input": ["ERROR in database"], "output": "HIGH"}]}}
{"timestamp_utc": "2025-09-27T12:33:35.252753", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 30, "question": "Write find_peak_index(arr) that finds index of first element that is greater than both neighbors. Return -1 if no peak exists. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 1.791923999786377, "response": "```python\ndef find_peak_index(arr):\n    for i in range(1, len(arr) - 1):\n        if arr[i] > arr[i - 1] and arr[i] > arr[i + 1]:\n            return i\n    return -1\n```", "error": null, "raw_item": {"task_id": "alg_peak_finder", "entry_point": "find_peak_index", "prompt": "Write find_peak_index(arr) that finds index of first element that is greater than both neighbors. Return -1 if no peak exists. Return only the Python function code with no explanations.", "canonical_solution": "def find_peak_index(arr):\n    if len(arr) < 3:\n        return -1\n    for i in range(1, len(arr) - 1):\n        if arr[i] > arr[i-1] and arr[i] > arr[i+1]:\n            return i\n    return -1", "test": [{"input": [[1, 3, 2, 4, 1]], "output": 1}, {"input": [[1, 2, 3, 2, 1]], "output": 2}, {"input": [[1, 2, 3, 4, 5]], "output": -1}, {"input": [[5, 4, 3, 2, 1]], "output": -1}, {"input": [[1, 3, 1]], "output": 1}]}}
{"timestamp_utc": "2025-09-27T12:33:41.445388", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 31, "question": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 5.191059827804565, "response": "```python\nfrom collections import defaultdict\n\ndef find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"\n    if not words:\n        return []\n    \n    # Use a dictionary to group anagrams by sorted letters as key\n    anagram_groups = defaultdict(list)\n    for word in words:\n        key = ''.join(sorted(word))\n        anagram_groups[key].append(word)\n    \n    # Sort words within each group and collect groups\n    groups_list = []\n    for group in anagram_groups.values():\n        sorted_group = sorted(group)\n        groups_list.append(sorted_group)\n    \n    # Sort the groups by the first word in each group\n    groups_list.sort(key=lambda x: x[0])\n    \n    return groups_list\n``` \n\nThis function efficiently groups anagrams using a dictionary keyed by the sorted string of each word. It handles the sorting requirements: words within groups are sorted alphabetically, and groups are sorted by their first word. Time complexity is O(N * M log M), where N is the number of words and M is the average word length, dominated by sorting the letters for each word. Space complexity is O(N * M) for storing the groups. The code uses `collections.defaultdict` for concise group handling and assumes all words are lowercase as per the examples.", "error": null, "raw_item": {"task_id": "custom_find_anagrams", "prompt": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"\n    ", "entry_point": "find_anagrams", "canonical_solution": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    from collections import defaultdict\n    \n    anagram_groups = defaultdict(list)\n    \n    for word in words:\n        # Use sorted characters as key\n        key = ''.join(sorted(word))\n        anagram_groups[key].append(word)\n    \n    result = []\n    for group in anagram_groups.values():\n        group.sort()\n        result.append(group)\n    \n    # Sort groups by their first word\n    result.sort(key=lambda x: x[0])\n    \n    return result", "test": [{"input": [["eat", "tea", "tan", "ate", "nat", "bat"]], "output": [["ate", "eat", "tea"], ["bat"], ["nat", "tan"]]}, {"input": [["hello", "world"]], "output": [["hello"], ["world"]]}, {"input": [[]], "output": []}, {"input": [["a", "aa", "aaa"]], "output": [["a"], ["aa"], ["aaa"]]}, {"input": [["abc", "bca", "cab", "xyz"]], "output": [["abc", "bca", "cab"], ["xyz"]]}]}}
{"timestamp_utc": "2025-09-27T12:33:45.270098", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 32, "question": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.822849988937378, "response": "```python\ndef merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"\n    if not intervals:\n        return []\n    \n    # Sort intervals by start time\n    intervals.sort(key=lambda x: x[0])\n    \n    merged = [intervals[0]]\n    for current in intervals[1:]:\n        last = merged[-1]\n        if current[0] <= last[1]:\n            # Overlap, merge\n            last[1] = max(last[1], current[1])\n        else:\n            # No overlap, add new interval\n            merged.append(current)\n    \n    return merged\n```", "error": null, "raw_item": {"task_id": "custom_merge_intervals", "prompt": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"\n    ", "entry_point": "merge_intervals", "canonical_solution": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    if not intervals:\n        return []\n    \n    # Sort intervals by start time\n    intervals.sort(key=lambda x: x[0])\n    \n    merged = [intervals[0]]\n    \n    for current in intervals[1:]:\n        last = merged[-1]\n        \n        # Check if current interval overlaps with last merged interval\n        if current[0] <= last[1]:\n            # Merge intervals\n            last[1] = max(last[1], current[1])\n        else:\n            # No overlap, add current interval\n            merged.append(current)\n    \n    return merged", "test": [{"input": [[[1, 3], [2, 6], [8, 10], [15, 18]]], "output": [[1, 6], [8, 10], [15, 18]]}, {"input": [[[1, 4], [4, 5]]], "output": [[1, 5]]}, {"input": [[[1, 4], [0, 2], [3, 5]]], "output": [[0, 5]]}, {"input": [[]], "output": []}, {"input": [[[1, 2]]], "output": [[1, 2]]}, {"input": [[[1, 4], [2, 3]]], "output": [[1, 4]]}]}}
{"timestamp_utc": "2025-09-27T12:33:51.094807", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 33, "question": "def binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 4.822494029998779, "response": "```python\ndef binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"\n    if not root:\n        return []\n    \n    result = []\n    \n    def dfs(node, path):\n        if not node:\n            return\n        # Build the path\n        if path:\n            current_path = path + \"->\" + str(node['val'])\n        else:\n            current_path = str(node['val'])\n        # If it's a leaf, add to result\n        if not node['left'] and not node['right']:\n            result.append(current_path)\n        else:\n            # Recurse on children\n            dfs(node['left'], current_path)\n            dfs(node['right'], current_path)\n    \n    dfs(root, \"\")\n    return result\n```", "error": null, "raw_item": {"task_id": "custom_binary_tree_paths", "prompt": "def binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"\n    ", "entry_point": "binary_tree_paths", "canonical_solution": "def binary_tree_paths(root: dict | None) -> list[str]:\n    if not root:\n        return []\n    \n    paths = []\n    \n    def dfs(node, path):\n        if not node:\n            return\n        \n        # Add current node to path\n        current_path = path + [str(node['val'])]\n        \n        # If leaf node, add path to result\n        if not node['left'] and not node['right']:\n            paths.append('->'.join(current_path))\n            return\n        \n        # Recurse on children\n        if node['left']:\n            dfs(node['left'], current_path)\n        if node['right']:\n            dfs(node['right'], current_path)\n    \n    dfs(root, [])\n    return paths", "test": [{"input": [{"val": 1, "left": {"val": 2, "left": null, "right": {"val": 5, "left": null, "right": null}}, "right": {"val": 3, "left": null, "right": null}}], "output": ["1->2->5", "1->3"]}, {"input": [{"val": 1, "left": null, "right": null}], "output": ["1"]}, {"input": [null], "output": []}, {"input": [{"val": 1, "left": {"val": 2, "left": null, "right": null}, "right": {"val": 3, "left": null, "right": null}}], "output": ["1->2", "1->3"]}]}}
{"timestamp_utc": "2025-09-27T12:34:01.849153", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 34, "question": "def word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 9.752554893493652, "response": "### Step-by-Step Reasoning\n\n1. **Understand the Problem**: \n   - We need to check if string `s` (composed of space-separated words) matches the `pattern` (a string of letters).\n   - \"Matches\" means there's a one-to-one correspondence (bijection) between each unique letter in `pattern` and each unique word in `s`.\n   - The lengths must match: the number of letters in `pattern` should equal the number of words in `s`.\n   - If a letter in `pattern` maps to a word, no other letter can map to that word, and vice versa.\n\n2. **Edge Cases to Consider**:\n   - `pattern` and `s` have different lengths (e.g., pattern=\"ab\", s=\"dog\" → False).\n   - Empty strings (e.g., pattern=\"\", s=\"\" → True, but check constraints).\n   - Single-element cases (e.g., pattern=\"a\", s=\"dog\" → True).\n   - Repeating letters/words that violate bijection (e.g., pattern=\"aa\", s=\"dog cat\" → False).\n   - All identical letters/words (e.g., pattern=\"aaa\", s=\"dog dog dog\" → False).\n\n3. **Algorithm Approach**:\n   - Split `s` into a list of words (e.g., \"dog cat\" → [\"dog\", \"cat\"]).\n   - If `len(pattern) != len(words)`, return False.\n   - Use two dictionaries:\n     - One to map each `pattern` letter to a word.\n     - One to map each word to a `pattern` letter.\n   - Iterate through `pattern` and `words`:\n     - For each pair (letter, word):\n       - If `letter` is already mapped, check if it matches the current `word`. If not, return False.\n       - If `word` is already mapped, check if it matches the current `letter`. If not, return False.\n       - Otherwise, add the mappings.\n   - If the loop completes without conflicts, return True.\n\n4. **Solution Code**:\n   ```python\n   def word_pattern(pattern: str, s: str) -> bool:\n       words = s.split()  # Split s into a list of words\n       \n       # Check if lengths match\n       if len(pattern) != len(words):\n           return False\n       \n       # Dictionaries for bijection check\n       letter_to_word = {}\n       word_to_letter = {}\n       \n       for letter, word in zip(pattern, words):\n           # Check if letter is already mapped\n           if letter in letter_to_word:\n               if letter_to_word[letter] != word:\n                   return False\n           else:\n               letter_to_word[letter] = word\n           \n           # Check if word is already mapped\n           if word in word_to_letter:\n               if word_to_letter[word] != letter:\n                   return False\n           else:\n               word_to_letter[word] = letter\n       \n       return True\n   ```\n\n5. **Explanation of Code**:\n   - `s.split()` handles splitting by spaces and gives a list of words.\n   - The `zip` function pairs each letter with its corresponding word.\n   - The two dictionaries ensure bijection: `letter_to_word` prevents one letter mapping to multiple words, and `word_to_letter` prevents one word mapping to multiple letters.\n   - Time complexity: O(n), where n is the length of `pattern` (since we iterate once).\n   - Space complexity: O(n) for the dictionaries.\n\n6. **Testing with Examples**:\n   - `word_pattern(\"abba\", \"dog cat cat dog\")` → True (a→dog, b→cat, bijection holds).\n   - `word_pattern(\"abba\", \"dog cat cat fish\")` → False (b maps to both \"cat\" and \"fish\").\n   - `word_pattern(\"aaaa\", \"dog cat cat dog\")` → False (all letters are 'a', but words differ).\n   - `word_pattern(\"abba\", \"dog dog dog dog\")` → False ('a' maps to \"dog\", so 'b' can't).\n\nThis solution is efficient, clear, and handles all constraints. If you have more test cases or need modifications, let me know!", "error": null, "raw_item": {"task_id": "custom_word_pattern", "prompt": "def word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"\n    ", "entry_point": "word_pattern", "canonical_solution": "def word_pattern(pattern: str, s: str) -> bool:\n    words = s.split()\n    \n    if len(pattern) != len(words):\n        return False\n    \n    char_to_word = {}\n    word_to_char = {}\n    \n    for char, word in zip(pattern, words):\n        # Check char -> word mapping\n        if char in char_to_word:\n            if char_to_word[char] != word:\n                return False\n        else:\n            char_to_word[char] = word\n        \n        # Check word -> char mapping (bijection)\n        if word in word_to_char:\n            if word_to_char[word] != char:\n                return False\n        else:\n            word_to_char[word] = char\n    \n    return True", "test": [{"input": ["abba", "dog cat cat dog"], "output": true}, {"input": ["abba", "dog cat cat fish"], "output": false}, {"input": ["aaaa", "dog cat cat dog"], "output": false}, {"input": ["abba", "dog dog dog dog"], "output": false}, {"input": ["abc", "dog cat fish"], "output": true}, {"input": ["a", "dog"], "output": true}, {"input": ["ab", "dog"], "output": false}]}}
{"timestamp_utc": "2025-09-27T12:34:10.244511", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 35, "question": "class MinStack:\n    \"\"\"\n    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\n    Implement the MinStack class:\n    - MinStack() initializes the stack object.\n    - push(val) pushes the element val onto the stack.\n    - pop() removes the element on the top of the stack.\n    - top() gets the top element of the stack.\n    - get_min() retrieves the minimum element in the stack.\n\n    You must implement a solution with O(1) time complexity for each function.\n\n    Examples:\n    >>> stack = MinStack()\n    >>> stack.push(-2)\n    >>> stack.push(0)\n    >>> stack.push(-3)\n    >>> stack.get_min()\n    -3\n    >>> stack.pop()\n    >>> stack.top()\n    0\n    >>> stack.get_min()\n    -2\n    \"\"\"", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 7.392949104309082, "response": "```python\nclass MinStack:\n    def __init__(self):\n        self.stack = []  # Main stack to store elements\n        self.min_stack = []  # Stack to track minimums\n\n    def push(self, val: int) -> None:\n        self.stack.append(val)\n        # Push to min_stack if it's empty or val is <= current min\n        if not self.min_stack or val <= self.min_stack[-1]:\n            self.min_stack.append(val)\n\n    def pop(self) -> None:\n        if self.stack:\n            popped = self.stack.pop()\n            # If the popped value is the current min, pop from min_stack\n            if self.min_stack and popped == self.min_stack[-1]:\n                self.min_stack.pop()\n\n    def top(self) -> int:\n        if self.stack:\n            return self.stack[-1]\n        # Assuming stack is not empty as per problem constraints, but for robustness:\n        raise IndexError(\"Stack is empty\")\n\n    def get_min(self) -> int:\n        if self.min_stack:\n            return self.min_stack[-1]\n        # Assuming stack is not empty, but for robustness:\n        raise ValueError(\"Stack is empty\")\n```\n\n### Explanation:\n- **Initialization**: Two lists (`stack` and `min_stack`) are used. `stack` holds all elements, `min_stack` tracks the minimum values.\n- **push(val)**: Appends `val` to `stack`. If `min_stack` is empty or `val` is less than or equal to the current minimum (`min_stack[-1]`), also append `val` to `min_stack`. This ensures `min_stack` always has the minimum up to the current point.\n- **pop()**: Removes the top element from `stack`. If that element is equal to the top of `min_stack`, removes it from `min_stack` as well, updating the minimum for the remaining stack.\n- **top()**: Returns the top element of `stack` (last appended).\n- **get_min()**: Returns the top of `min_stack`, which is the current minimum in the stack.\n\nThis implementation achieves O(1) time complexity for all operations, as list append/pop operations are O(1) in Python. Space complexity is O(n), where n is the number of elements, in the worst case (e.g., when elements are pushed in decreasing order). The example in the query works as demonstrated.", "error": null, "raw_item": {"task_id": "custom_min_stack", "prompt": "class MinStack:\n    \"\"\"\n    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\n    Implement the MinStack class:\n    - MinStack() initializes the stack object.\n    - push(val) pushes the element val onto the stack.\n    - pop() removes the element on the top of the stack.\n    - top() gets the top element of the stack.\n    - get_min() retrieves the minimum element in the stack.\n\n    You must implement a solution with O(1) time complexity for each function.\n\n    Examples:\n    >>> stack = MinStack()\n    >>> stack.push(-2)\n    >>> stack.push(0)\n    >>> stack.push(-3)\n    >>> stack.get_min()\n    -3\n    >>> stack.pop()\n    >>> stack.top()\n    0\n    >>> stack.get_min()\n    -2\n    \"\"\"\n    ", "entry_point": "MinStack", "canonical_solution": "class MinStack:\n    def __init__(self):\n        self.stack = []\n        self.min_stack = []\n    \n    def push(self, val: int) -> None:\n        self.stack.append(val)\n        # Push to min_stack if it's empty or val is <= current minimum\n        if not self.min_stack or val <= self.min_stack[-1]:\n            self.min_stack.append(val)\n    \n    def pop(self) -> None:\n        if self.stack:\n            val = self.stack.pop()\n            # Pop from min_stack if the popped value was the minimum\n            if self.min_stack and val == self.min_stack[-1]:\n                self.min_stack.pop()\n    \n    def top(self) -> int:\n        return self.stack[-1] if self.stack else None\n    \n    def get_min(self) -> int:\n        return self.min_stack[-1] if self.min_stack else None", "test": [{"input": [["MinStack", "push", "push", "push", "get_min", "pop", "top", "get_min"], [[], [-2], [0], [-3], [], [], [], []]], "output": [null, null, null, null, -3, null, 0, -2]}, {"input": [["MinStack", "push", "push", "get_min", "get_min", "pop", "get_min"], [[], [1], [2], [], [], [], []]], "output": [null, null, null, 1, 1, null, 1]}, {"input": [["MinStack", "push", "get_min", "pop", "push", "get_min"], [[], [1], [], [], [2], []]], "output": [null, null, 1, null, null, 2]}]}}
{"timestamp_utc": "2025-09-27T12:34:17.208363", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 36, "question": "class LRUCache:\n    \"\"\"\n    Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.\n\n    Implement the LRUCache class:\n    - LRUCache(capacity) Initialize the LRU cache with positive size capacity.\n    - get(key) Return the value of the key if the key exists, otherwise return -1.\n    - put(key, value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache.\n      If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\n    The functions get and put must each run in O(1) average time complexity.\n\n    Examples:\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 5.960878133773804, "response": "```python\nclass Node:\n    def __init__(self, key=0, val=0):\n        self.key = key\n        self.val = val\n        self.prev = None\n        self.next = None\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}  # key -> Node\n        self.head = Node()  # dummy head\n        self.tail = Node()  # dummy tail\n        self.head.next = self.tail\n        self.tail.prev = self.head\n        self.size = 0\n\n    def _remove(self, node):\n        node.prev.next = node.next\n        node.next.prev = node.prev\n\n    def _add_to_head(self, node):\n        node.next = self.head.next\n        node.prev = self.head\n        self.head.next.prev = node\n        self.head.next = node\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            node = self.cache[key]\n            self._remove(node)\n            self._add_to_head(node)\n            return node.val\n        else:\n            return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            node = self.cache[key]\n            node.val = value\n            self._remove(node)\n            self._add_to_head(node)\n        else:\n            node = Node(key, value)\n            self.cache[key] = node\n            self._add_to_head(node)\n            self.size += 1\n            if self.size > self.capacity:\n                # Evict the least recently used (tail.prev)\n                to_remove = self.tail.prev\n                self._remove(to_remove)\n                del self.cache[to_remove.key]\n                self.size -= 1\n```", "error": null, "raw_item": {"task_id": "custom_lru_cache", "prompt": "class LRUCache:\n    \"\"\"\n    Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.\n\n    Implement the LRUCache class:\n    - LRUCache(capacity) Initialize the LRU cache with positive size capacity.\n    - get(key) Return the value of the key if the key exists, otherwise return -1.\n    - put(key, value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache.\n      If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\n    The functions get and put must each run in O(1) average time complexity.\n\n    Examples:\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"\n    ", "entry_point": "LRUCache", "canonical_solution": "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        # Use a list to maintain order (least recent at index 0)\n        self.order = []\n    \n    def get(self, key: int) -> int:\n        if key in self.cache:\n            # Move to end (most recently used)\n            self.order.remove(key)\n            self.order.append(key)\n            return self.cache[key]\n        return -1\n    \n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            # Update existing key\n            self.cache[key] = value\n            self.order.remove(key)\n            self.order.append(key)\n        else:\n            # Add new key\n            if len(self.cache) >= self.capacity:\n                # Remove least recently used\n                lru_key = self.order.pop(0)\n                del self.cache[lru_key]\n            \n            self.cache[key] = value\n            self.order.append(key)", "test": [{"input": [["LRUCache", "put", "put", "get", "put", "get", "put", "get", "get", "get"], [[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]], "output": [null, null, null, 1, null, -1, null, -1, 3, 4]}, {"input": [["LRUCache", "put", "get", "put", "get", "get"], [[1], [2, 1], [2], [3, 2], [2], [3]]], "output": [null, null, 1, null, -1, 2]}]}}
{"timestamp_utc": "2025-09-27T12:34:44.994560", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 37, "question": "def validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 26.784504890441895, "response": "```python\ndef validate_ip_address(ip: str) -> str:\n    # Check for IPv4\n    parts = ip.split('.')\n    if len(parts) == 4:\n        for p in parts:\n            if not p or (p[0] == '0' and len(p) > 1):\n                return \"Neither\"\n            try:\n                num = int(p)\n                if num < 0 or num > 255:\n                    return \"Neither\"\n            except ValueError:\n                return \"Neither\"\n        return \"IPv4\"\n    \n    # Check for IPv6\n    parts = ip.split(':')\n    if len(parts) == 8:\n        for p in parts:\n            if not p or len(p) > 4:\n                return \"Neither\"\n            try:\n                int(p, 16)\n            except ValueError:\n                return \"Neither\"\n        return \"IPv6\"\n    \n    return \"Neither\"\n```", "error": null, "raw_item": {"task_id": "custom_validate_ip_address", "prompt": "def validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"\n    ", "entry_point": "validate_ip_address", "canonical_solution": "def validate_ip_address(ip: str) -> str:\n    def is_valid_ipv4(ip):\n        parts = ip.split('.')\n        if len(parts) != 4:\n            return False\n        \n        for part in parts:\n            if not part or len(part) > 3:\n                return False\n            \n            # Check for leading zeros\n            if len(part) > 1 and part[0] == '0':\n                return False\n            \n            # Check if all characters are digits\n            if not part.isdigit():\n                return False\n            \n            # Check range\n            num = int(part)\n            if num < 0 or num > 255:\n                return False\n        \n        return True\n    \n    def is_valid_ipv6(ip):\n        parts = ip.split(':')\n        if len(parts) != 8:\n            return False\n        \n        for part in parts:\n            if not part or len(part) > 4:\n                return False\n            \n            # Check if all characters are valid hex\n            for char in part:\n                if char not in '0123456789abcdefABCDEF':\n                    return False\n        \n        return True\n    \n    if is_valid_ipv4(ip):\n        return \"IPv4\"\n    elif is_valid_ipv6(ip):\n        return \"IPv6\"\n    else:\n        return \"Neither\"", "test": [{"input": ["172.16.254.1"], "output": "IPv4"}, {"input": ["2001:0db8:85a3:0000:0000:8a2e:0370:7334"], "output": "IPv6"}, {"input": ["256.256.256.256"], "output": "Neither"}, {"input": ["192.168.1.1.1"], "output": "Neither"}, {"input": ["192.168.01.1"], "output": "Neither"}, {"input": ["2001:0db8:85a3::8a2e:0370:7334"], "output": "Neither"}, {"input": [""], "output": "Neither"}]}}
{"timestamp_utc": "2025-09-27T12:34:48.951116", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 38, "question": "Merge two dictionaries with integer values by keeping the maximum value for each key.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.95463490486145, "response": "```python\ndef merge_dicts_max(dict1, dict2):\n    \"\"\"\n    Merges two dictionaries by keeping the maximum value for each key.\n    \n    Args:\n    dict1 (dict): First dictionary with integer values.\n    dict2 (dict): Second dictionary with integer values.\n    \n    Returns:\n    dict: Merged dictionary with maximum values for each key.\n    \"\"\"\n    merged = dict1.copy()  # Start with a copy of dict1\n    for key, value in dict2.items():\n        if key in merged:\n            merged[key] = max(merged[key], value)\n        else:\n            merged[key] = value\n    return merged\n\n# Example usage:\ndict1 = {'a': 1, 'b': 2}\ndict2 = {'a': 3, 'c': 4}\nresult = merge_dicts_max(dict1, dict2)\nprint(result)  # Output: {'a': 3, 'b': 2, 'c': 4}\n```\n\nThis function iterates through the second dictionary and updates the merged dictionary (initially a copy of the first) by taking the maximum value for overlapping keys. Keys unique to each dictionary are included as-is. All values are assumed to be integers as specified.", "error": null, "raw_item": {"task_id": "MyBench/dict_merge_max", "prompt": "Merge two dictionaries with integer values by keeping the maximum value for each key.", "entry_point": "merge_max", "canonical_solution": "def merge_max(d1, d2):\n    out = dict(d1)\n    for k,v in d2.items():\n        out[k] = max(out.get(k, v), v)\n    return out", "test": [{"input": [{"a": 1, "b": 5}, {"b": 3, "c": 10}], "output": {"a": 1, "b": 5, "c": 10}}, {"input": [{}, {"x": 7}], "output": {"x": 7}}, {"input": [{"a": 5}, {"a": 5}], "output": {"a": 5}}, {"input": [{"m": -1, "n": 2}, {"m": -5, "o": 10}], "output": {"m": -1, "n": 2, "o": 10}}, {"input": [{}, {}], "output": {}}]}}
{"timestamp_utc": "2025-09-27T12:34:53.560134", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 39, "question": "Invert a dictionary where values may not be unique. Return a new dictionary mapping each value to a list of keys that had that value.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 3.60657000541687, "response": "```python\nfrom collections import defaultdict\n\ndef invert_dict(original_dict):\n    \"\"\"\n    Inverts a dictionary where values may not be unique.\n    Returns a new dictionary mapping each value to a list of keys that had that value.\n    \n    Args:\n    original_dict (dict): The dictionary to invert.\n    \n    Returns:\n    dict: The inverted dictionary with values as keys and lists of original keys as values.\n    \"\"\"\n    inverted = defaultdict(list)\n    for key, value in original_dict.items():\n        inverted[value].append(key)\n    return dict(inverted)\n```\n\n### Example Usage:\n```python\noriginal = {'a': 1, 'b': 2, 'c': 1, 'd': 3}\ninverted = invert_dict(original)\nprint(inverted)  # Output: {1: ['a', 'c'], 2: ['b'], 3: ['d']}\n```\n\nThis function uses `collections.defaultdict` to efficiently handle the list accumulation for each value, avoiding the need for manual checks if a key exists in the inverted dictionary. It ensures all values from the original dictionary are included, even if they map to single keys (as lists).", "error": null, "raw_item": {"task_id": "dict_invert_multival", "prompt": "Invert a dictionary where values may not be unique. Return a new dictionary mapping each value to a list of keys that had that value.", "entry_point": "invert_multival", "canonical_solution": "def invert_multival(d):\n    out={}\n    for k,v in d.items():\n        out.setdefault(v, []).append(k)\n    return out", "test": [{"input": [{"a": 1, "b": 2, "c": 1}], "output": {"1": ["a", "c"], "2": ["b"]}}, {"input": [{}], "output": {}}, {"input": [{"x": "hi", "y": "hi", "z": "bye"}], "output": {"hi": ["x", "y"], "bye": ["z"]}}, {"input": [{"p": 0, "q": 0, "r": 0}], "output": {"0": ["p", "q", "r"]}}, {"input": [{"k": 42}], "output": {"42": ["k"]}}]}}
{"timestamp_utc": "2025-09-27T12:35:04.062429", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 40, "question": "Return True if an integer has even parity (even number of 1 bits in binary), else False.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 9.499171018600464, "response": "```python\ndef has_even_parity(n):\n    \"\"\"\n    Returns True if the integer n has even parity (even number of 1 bits in binary), else False.\n    \"\"\"\n    parity = 0\n    while n:\n        parity ^= 1  # Toggle parity for each set bit\n        n &= n - 1   # Remove the lowest set bit\n    return parity == 0\n``` \n\nThis function uses bit manipulation to efficiently compute parity. It iterates through the set bits of `n`, toggling a parity flag each time, and returns `True` if the final parity is even (i.e., 0). For example:  \n- `has_even_parity(0)` → `True` (0 ones)  \n- `has_even_parity(1)` → `False` (1 one)  \n- `has_even_parity(3)` → `False` (binary 11, 2 ones)  \n- `has_even_parity(4)` → `True` (binary 100, 1 one)  \n- `has_even_parity(7)` → `True` (binary 111, 3 ones)  \n\nThe approach is O(number of set bits), which is efficient. If `n` is negative, Python's two's complement representation handles it correctly, but parity is typically defined for positive integers; the function works for any integer.", "error": null, "raw_item": {"task_id": "bitwise_parity", "prompt": "Return True if an integer has even parity (even number of 1 bits in binary), else False.", "entry_point": "even_parity", "canonical_solution": "def even_parity(n):\n    c=0\n    while n:\n        n&=n-1\n        c^=1\n    return c==0", "test": [{"input": [3], "output": false}, {"input": [5], "output": true}, {"input": [0], "output": true}, {"input": [15], "output": true}, {"input": [16], "output": false}, {"input": [255], "output": true}]}}
{"timestamp_utc": "2025-09-27T12:35:07.203009", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 41, "question": "Swap two integers without using a temporary variable, using bitwise XOR. Return the swapped pair as a tuple. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.1383519172668457, "response": "```python\ndef swap_xor(a, b):\n    a = a ^ b\n    b = a ^ b\n    a = a ^ b\n    return a, b\n```", "error": null, "raw_item": {"task_id": "bitwise_swap", "prompt": "Swap two integers without using a temporary variable, using bitwise XOR. Return the swapped pair as a tuple. Return only the Python function code with no explanations.", "entry_point": "swap_xor", "canonical_solution": "def swap_xor(a,b):\n    a=a^b; b=a^b; a=a^b\n    return (a,b)", "test": [{"input": [2, 5], "output": [5, 2]}, {"input": [0, 7], "output": [7, 0]}, {"input": [-3, 9], "output": [9, -3]}, {"input": [42, 42], "output": [42, 42]}, {"input": [1000000, 123456], "output": [123456, 1000000]}]}}
{"timestamp_utc": "2025-09-27T12:35:12.915365", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 42, "question": "Compute factorial of n recursively. Assume n >= 0. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 4.710486888885498, "response": "```python\ndef factorial(n):\n    if n == 0:\n        return 1\n    else:\n        return n * factorial(n - 1)\n```", "error": null, "raw_item": {"task_id": "recursion_factorial", "prompt": "Compute factorial of n recursively. Assume n >= 0. Return only the Python function code with no explanations.", "entry_point": "factorial", "canonical_solution": "def factorial(n):\n    return 1 if n<=1 else n*factorial(n-1)", "test": [{"input": [0], "output": 1}, {"input": [1], "output": 1}, {"input": [5], "output": 120}, {"input": [10], "output": 3628800}, {"input": [3], "output": 6}]}}
{"timestamp_utc": "2025-09-27T12:35:15.681455", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 43, "question": "Return the BFS traversal order of a graph represented as adjacency list dict, starting from given node. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 1.760300874710083, "response": "```python\nfrom collections import deque\n\ndef bfs(graph, start):\n    if start not in graph:\n        return []\n    \n    visited = set()\n    queue = deque([start])\n    visited.add(start)\n    result = []\n    \n    while queue:\n        node = queue.popleft()\n        result.append(node)\n        \n        for neighbor in graph[node]:\n            if neighbor not in visited:\n                visited.add(neighbor)\n                queue.append(neighbor)\n    \n    return result\n```", "error": null, "raw_item": {"task_id": "graph_bfs_order", "prompt": "Return the BFS traversal order of a graph represented as adjacency list dict, starting from given node. Return only the Python function code with no explanations.", "entry_point": "bfs_order", "canonical_solution": "from collections import deque\n\ndef bfs_order(graph,start):\n    seen={start}; q=deque([start]); order=[]\n    while q:\n        u=q.popleft(); order.append(u)\n        for v in sorted(graph.get(u,[])):\n            if v not in seen:\n                seen.add(v); q.append(v)\n    return order", "test": [{"input": [{"A": ["B", "C"], "B": ["D"], "C": [], "D": []}, "A"], "output": ["A", "B", "C", "D"]}, {"input": [{"1": ["2"], "2": ["3"], "3": []}, "1"], "output": ["1", "2", "3"]}, {"input": [{"x": []}, "x"], "output": ["x"]}, {"input": [{"a": ["b"], "b": ["a"]}, "a"], "output": ["a", "b"]}, {"input": [{"m": ["n", "o"], "n": [], "o": []}, "m"], "output": ["m", "n", "o"]}]}}
{"timestamp_utc": "2025-09-27T12:35:19.054367", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 44, "question": "Given a CSV string with header 'name,value' and multiple rows, return the sum of the 'value' column as int. Assume comma-separated, no quotes. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.371229887008667, "response": "def sum_csv_values(csv_string):\n    lines = csv_string.strip().split('\\n')\n    total = 0\n    for line in lines[1:]:  # Skip header\n        if line.strip():\n            parts = line.split(',')\n            if len(parts) >= 2:\n                total += int(parts[1])\n    return total", "error": null, "raw_item": {"task_id": "parsing_csv_sum", "prompt": "Given a CSV string with header 'name,value' and multiple rows, return the sum of the 'value' column as int. Assume comma-separated, no quotes. Return only the Python function code with no explanations.", "entry_point": "csv_sum", "canonical_solution": "def csv_sum(text):\n    lines=text.strip().split('\\n')\n    if len(lines) <= 1:\n        return 0\n    total=0\n    for line in lines[1:]:\n        if line.strip():\n            name,val=line.split(',')\n            total+=int(val)\n    return total", "test": [{"input": ["name,value\\na,3\\nb,7\\nc,10"], "output": 20}, {"input": ["name,value\\n"], "output": 0}, {"input": ["name,value\\nfoo,0\\nbar,0"], "output": 0}, {"input": ["name,value\\nx,100"], "output": 100}, {"input": ["name,value\\na,1\\nb,2\\nc,3\\nd,4"], "output": 10}]}}
{"timestamp_utc": "2025-09-27T12:35:22.143967", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 45, "question": "Extract all sequences of digits from a string using regex and return them as a list of strings. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.087470054626465, "response": "```python\nimport re\n\ndef extract_digits(s):\n    return re.findall(r'\\d+', s)\n```", "error": null, "raw_item": {"task_id": "parsing_regex_digits", "prompt": "Extract all sequences of digits from a string using regex and return them as a list of strings. Return only the Python function code with no explanations.", "entry_point": "extract_digits", "canonical_solution": "import re\n\ndef extract_digits(s):\n    return re.findall(r'\\d+', s)", "test": [{"input": ["abc123de45f6"], "output": ["123", "45", "6"]}, {"input": ["no digits here"], "output": []}, {"input": ["2025year"], "output": ["2025"]}, {"input": ["a1b2c3d4"], "output": ["1", "2", "3", "4"]}, {"input": ["007bond"], "output": ["007"]}]}}
{"timestamp_utc": "2025-09-27T12:35:25.885192", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 46, "question": "Return the length of the longest increasing subsequence (LIS) in a list of integers. O(n^2) solution is fine. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.7397360801696777, "response": "```python\ndef longest_increasing_subsequence(nums):\n    if not nums:\n        return 0\n    n = len(nums)\n    dp = [1] * n\n    for i in range(1, n):\n        for j in range(i):\n            if nums[i] > nums[j]:\n                dp[i] = max(dp[i], dp[j] + 1)\n    return max(dp)\n```", "error": null, "raw_item": {"task_id": "algorithms_longest_increasing", "prompt": "Return the length of the longest increasing subsequence (LIS) in a list of integers. O(n^2) solution is fine. Return only the Python function code with no explanations.", "entry_point": "lis_length", "canonical_solution": "def lis_length(nums):\n    if not nums: return 0\n    dp=[1]*len(nums)\n    for i in range(len(nums)):\n        for j in range(i):\n            if nums[j]<nums[i]:\n                dp[i]=max(dp[i],dp[j]+1)\n    return max(dp)", "test": [{"input": [[10, 9, 2, 5, 3, 7, 101, 18]], "output": 4}, {"input": [[1, 2, 3, 4, 5]], "output": 5}, {"input": [[5, 4, 3, 2, 1]], "output": 1}, {"input": [[]], "output": 0}, {"input": [[2, 2, 2]], "output": 1}]}}
{"timestamp_utc": "2025-09-27T12:35:29.527364", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 47, "question": "0/1 Knapsack: given weights, values, and capacity W, return the maximum achievable value. Use DP. weights and values are equal length. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.639087677001953, "response": "```python\ndef knapsack(weights, values, W):\n    n = len(weights)\n    dp = [[0] * (W + 1) for _ in range(n + 1)]\n    for i in range(1, n + 1):\n        for w in range(1, W + 1):\n            if weights[i - 1] <= w:\n                dp[i][w] = max(dp[i - 1][w], dp[i - 1][w - weights[i - 1]] + values[i - 1])\n            else:\n                dp[i][w] = dp[i - 1][w]\n    return dp[n][W]\n```", "error": null, "raw_item": {"task_id": "algorithms_knapsack01", "prompt": "0/1 Knapsack: given weights, values, and capacity W, return the maximum achievable value. Use DP. weights and values are equal length. Return only the Python function code with no explanations.", "entry_point": "knapsack01", "canonical_solution": "def knapsack01(weights, values, W):\n    n=len(weights)\n    dp=[[0]*(W+1) for _ in range(n+1)]\n    for i in range(1,n+1):\n        for w in range(W+1):\n            dp[i][w]=dp[i-1][w]\n            if weights[i-1]<=w:\n                dp[i][w]=max(dp[i][w], values[i-1]+dp[i-1][w-weights[i-1]])\n    return dp[n][W]", "test": [{"input": [[2, 3, 4], [4, 5, 6], 5], "output": 9}, {"input": [[1, 2, 3], [6, 10, 12], 5], "output": 22}, {"input": [[5], [10], 5], "output": 10}, {"input": [[5], [10], 4], "output": 0}, {"input": [[], [], 10], "output": 0}]}}
{"timestamp_utc": "2025-09-27T12:35:35.441318", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 48, "question": "Write parse_csv_numbers(text) that parses a CSV string of integers separated by commas and newlines. Return a 2D list of integers. Ignore empty lines. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 4.912613868713379, "response": "```python\ndef parse_csv_numbers(text):\n    result = []\n    for line in text.split('\\n'):\n        line = line.strip()\n        if not line:\n            continue\n        row = [int(x.strip()) for x in line.split(',') if x.strip()]\n        result.append(row)\n    return result\n```", "error": null, "raw_item": {"task_id": "custom_parse_csv_numbers", "prompt": "Write parse_csv_numbers(text) that parses a CSV string of integers separated by commas and newlines. Return a 2D list of integers. Ignore empty lines. Return only the Python function code with no explanations.", "entry_point": "parse_csv_numbers", "canonical_solution": "def parse_csv_numbers(text: str) -> list[list[int]]:\n    rows = []\n    for line in text.strip().splitlines():\n        if not line.strip():\n            continue\n        row = [int(x.strip()) for x in line.split(',') if x.strip()]\n        rows.append(row)\n    return rows", "test": [{"input": ["1,2,3\n4,5,6"], "output": [[1, 2, 3], [4, 5, 6]]}, {"input": ["10,20\n30\n\n40,50"], "output": [[10, 20], [30], [40, 50]]}, {"input": ["   7 , 8 ,9  "], "output": [[7, 8, 9]]}, {"input": [""], "output": []}]}}
{"timestamp_utc": "2025-09-27T12:35:38.508564", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 49, "question": "Write normalize_json_keys(obj) that recursively converts all dictionary keys in a JSON-like object to lowercase strings. Works for nested dicts and lists. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.0649871826171875, "response": "```python\ndef normalize_json_keys(obj):\n    if isinstance(obj, dict):\n        return {key.lower(): normalize_json_keys(value) for key, value in obj.items()}\n    elif isinstance(obj, list):\n        return [normalize_json_keys(item) for item in obj]\n    else:\n        return obj\n```", "error": null, "raw_item": {"task_id": "custom_normalize_json_keys", "prompt": "Write normalize_json_keys(obj) that recursively converts all dictionary keys in a JSON-like object to lowercase strings. Works for nested dicts and lists. Return only the Python function code with no explanations.", "entry_point": "normalize_json_keys", "canonical_solution": "def normalize_json_keys(obj):\n    if isinstance(obj, dict):\n        return {str(k).lower(): normalize_json_keys(v) for k, v in obj.items()}\n    if isinstance(obj, list):\n        return [normalize_json_keys(x) for x in obj]\n    return obj", "test": [{"input": [{"Name": "Alice", "AGE": 30}], "output": {"name": "Alice", "age": 30}}, {"input": [[{"X": 1}, {"Y": 2}]], "output": [{"x": 1}, {"y": 2}]}, {"input": [{"Nested": {"KEY": 5}}], "output": {"nested": {"key": 5}}}, {"input": [123], "output": 123}]}}
{"timestamp_utc": "2025-09-27T12:35:44.987765", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 50, "question": "Write format_duration(seconds) that converts an integer number of seconds into a human-readable string using years, days, hours, minutes, and seconds. Skip units that are zero. Use plural form when needed. Example: 3661 → '1 hour, 1 minute, 1 second'. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 5.478245735168457, "response": "```python\ndef format_duration(seconds):\n    if seconds == 0:\n        return \"0 seconds\"\n    \n    # Calculate units\n    year_sec = 365 * 24 * 3600\n    day_sec = 24 * 3600\n    hour_sec = 3600\n    min_sec = 60\n    \n    years = seconds // year_sec\n    days = (seconds % year_sec) // day_sec\n    hours = (seconds % day_sec) // hour_sec\n    minutes = (seconds % hour_sec) // min_sec\n    secs = seconds % min_sec\n    \n    parts = []\n    if years > 0:\n        parts.append(f\"{years} {'year' if years == 1 else 'years'}\")\n    if days > 0:\n        parts.append(f\"{days} {'day' if days == 1 else 'days'}\")\n    if hours > 0:\n        parts.append(f\"{hours} {'hour' if hours == 1 else 'hours'}\")\n    if minutes > 0:\n        parts.append(f\"{minutes} {'minute' if minutes == 1 else 'minutes'}\")\n    if secs > 0:\n        parts.append(f\"{secs} {'second' if secs == 1 else 'seconds'}\")\n    \n    return ', '.join(parts)\n```", "error": null, "raw_item": {"task_id": "custom_format_duration", "prompt": "Write format_duration(seconds) that converts an integer number of seconds into a human-readable string using years, days, hours, minutes, and seconds. Skip units that are zero. Use plural form when needed. Example: 3661 → '1 hour, 1 minute, 1 second'. Return only the Python function code with no explanations.", "entry_point": "format_duration", "canonical_solution": "def format_duration(seconds: int) -> str:\n    units = [(\"year\", 365*24*3600), (\"day\", 24*3600), (\"hour\", 3600), (\"minute\", 60), (\"second\", 1)]\n    parts = []\n    for name, length in units:\n        if seconds >= length:\n            count, seconds = divmod(seconds, length)\n            parts.append(f\"{count} {name}{'s' if count != 1 else ''}\")\n    return \", \".join(parts) if parts else \"0 seconds\"", "test": [{"input": [0], "output": "0 seconds"}, {"input": [62], "output": "1 minute, 2 seconds"}, {"input": [3661], "output": "1 hour, 1 minute, 1 second"}, {"input": [31536000], "output": "1 year"}, {"input": [31556926], "output": "1 year, 6 hours, 9 minutes, 26 seconds"}]}}
{"timestamp_utc": "2025-09-27T12:35:48.552213", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 51, "question": "Write parse_key_value_config(text) that parses a configuration string with lines of the form 'key=value'. Ignore blank lines and lines starting with '#'. Return a dictionary with string keys and values converted to int if possible, else string. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.5629470348358154, "response": "```python\ndef parse_key_value_config(text):\n    config = {}\n    for line in text.split('\\n'):\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        if '=' in line:\n            key, value = line.split('=', 1)\n            key = key.strip()\n            value = value.strip()\n            try:\n                value = int(value)\n            except ValueError:\n                pass\n            config[key] = value\n    return config\n```", "error": null, "raw_item": {"task_id": "custom_parse_key_value_config", "prompt": "Write parse_key_value_config(text) that parses a configuration string with lines of the form 'key=value'. Ignore blank lines and lines starting with '#'. Return a dictionary with string keys and values converted to int if possible, else string. Return only the Python function code with no explanations.", "entry_point": "parse_key_value_config", "canonical_solution": "def parse_key_value_config(text: str) -> dict:\n    result = {}\n    for line in text.splitlines():\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        if '=' in line:\n            k,v = line.split('=',1)\n            v = v.strip()\n            if v.isdigit():\n                result[k.strip()] = int(v)\n            else:\n                result[k.strip()] = v\n    return result", "test": [{"input": ["a=1\nb=2\nc=hello"], "output": {"a": 1, "b": 2, "c": "hello"}}, {"input": ["#comment\nx=42\ny=text"], "output": {"x": 42, "y": "text"}}, {"input": [""], "output": {}}]}}
{"timestamp_utc": "2025-09-27T12:35:53.256955", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 52, "question": "Write pretty_print_matrix(matrix) that formats a 2D list of integers into a string where each row is space-separated and rows are separated by newlines. Columns should be aligned to the maximum width of the largest number. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 3.7034809589385986, "response": "```python\ndef pretty_print_matrix(matrix):\n    if not matrix or not matrix[0]:\n        return \"\"\n    # Find the maximum width of any number in the matrix\n    max_width = max(len(str(num)) for row in matrix for num in row)\n    # Format each row\n    lines = []\n    for row in matrix:\n        formatted_row = [f\"{num:>{max_width}}\" for num in row]\n        lines.append(\" \".join(formatted_row))\n    return \"\\n\".join(lines)\n```", "error": null, "raw_item": {"task_id": "custom_pretty_print_matrix", "prompt": "Write pretty_print_matrix(matrix) that formats a 2D list of integers into a string where each row is space-separated and rows are separated by newlines. Columns should be aligned to the maximum width of the largest number. Return only the Python function code with no explanations.", "entry_point": "pretty_print_matrix", "canonical_solution": "def pretty_print_matrix(matrix: list[list[int]]) -> str:\n    if not matrix:\n        return ''\n    col_widths = [max(len(str(row[i])) for row in matrix) for i in range(len(matrix[0]))]\n    lines = []\n    for row in matrix:\n        line = ' '.join(str(val).rjust(col_widths[i]) for i,val in enumerate(row))\n        lines.append(line)\n    return '\\n'.join(lines)", "test": [{"input": [[[1, 20], [300, 4]]], "output": "  1 20\n300  4"}, {"input": [[[5]]], "output": "5"}, {"input": [[]], "output": ""}]}}
{"timestamp_utc": "2025-09-27T12:35:56.533775", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 53, "question": "Write unique_permutations(s) that returns all distinct permutations of string s in lexicographic order. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.274296998977661, "response": "```python\nimport itertools\n\ndef unique_permutations(s):\n    perms = set(itertools.permutations(s))\n    return sorted([''.join(p) for p in perms])\n```", "error": null, "raw_item": {"task_id": "custom_unique_permutations", "prompt": "Write unique_permutations(s) that returns all distinct permutations of string s in lexicographic order. Return only the Python function code with no explanations.", "entry_point": "unique_permutations", "canonical_solution": "def unique_permutations(s: str) -> list[str]:\n    from itertools import permutations\n    return sorted(set(''.join(p) for p in permutations(s)))", "test": [{"input": ["aab"], "output": ["aab", "aba", "baa"]}, {"input": ["abc"], "output": ["abc", "acb", "bac", "bca", "cab", "cba"]}, {"input": ["x"], "output": ["x"]}]}}
{"timestamp_utc": "2025-09-27T12:36:00.935139", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 54, "question": "Write format_prime_factors(n) that returns the prime factorization of integer n as a string in the form 'p1^a1 * p2^a2 ...'. If exponent is 1, omit the '^1'. Example: 60 → '2^2 * 3 * 5'. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 3.3989062309265137, "response": "```python\ndef format_prime_factors(n):\n    if n == 1:\n        return '1'\n    factors = {}\n    # Handle factor 2\n    while n % 2 == 0:\n        factors[2] = factors.get(2, 0) + 1\n        n //= 2\n    # Handle odd factors\n    i = 3\n    while i * i <= n:\n        while n % i == 0:\n            factors[i] = factors.get(i, 0) + 1\n            n //= i\n        i += 2\n    if n > 1:\n        factors[n] = 1\n    # Format the result\n    parts = []\n    for p in sorted(factors):\n        exp = factors[p]\n        if exp == 1:\n            parts.append(str(p))\n        else:\n            parts.append(f\"{p}^{exp}\")\n    return ' * '.join(parts)\n```", "error": null, "raw_item": {"task_id": "custom_format_prime_factors", "prompt": "Write format_prime_factors(n) that returns the prime factorization of integer n as a string in the form 'p1^a1 * p2^a2 ...'. If exponent is 1, omit the '^1'. Example: 60 → '2^2 * 3 * 5'. Return only the Python function code with no explanations.", "entry_point": "format_prime_factors", "canonical_solution": "def format_prime_factors(n: int) -> str:\n    factors = []\n    d = 2\n    while d*d <= n:\n        count = 0\n        while n % d == 0:\n            n //= d\n            count += 1\n        if count:\n            factors.append(f\"{d}^{count}\" if count>1 else str(d))\n        d += 1\n    if n > 1:\n        factors.append(str(n))\n    return ' * '.join(factors)", "test": [{"input": [60], "output": "2^2 * 3 * 5"}, {"input": [13], "output": "13"}, {"input": [1024], "output": "2^10"}]}}
{"timestamp_utc": "2025-09-27T12:36:11.174053", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 55, "question": "Write validate_expression(expr) that checks if a string is a valid arithmetic expression containing only digits, +, -, *, /, parentheses, and spaces. Return True if valid, else False. Parentheses must be balanced and no invalid sequences allowed (e.g. '*/', '++', empty parentheses). Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 9.23674488067627, "response": "```python\nimport ast\n\ndef validate_expression(expr):\n    expr = expr.replace(' ', '')\n    if not expr:\n        return False\n    allowed = set('0123456789+-*/()')\n    if any(c not in allowed for c in expr):\n        return False\n    try:\n        ast.parse(expr, mode='eval')\n        return True\n    except SyntaxError:\n        return False\n```", "error": null, "raw_item": {"task_id": "custom_validate_expression", "prompt": "Write validate_expression(expr) that checks if a string is a valid arithmetic expression containing only digits, +, -, *, /, parentheses, and spaces. Return True if valid, else False. Parentheses must be balanced and no invalid sequences allowed (e.g. '*/', '++', empty parentheses). Return only the Python function code with no explanations.", "entry_point": "validate_expression", "canonical_solution": "import re\ndef validate_expression(expr: str) -> bool:\n    expr = expr.strip()\n    if not expr:\n        return False\n    # invalid sequences\n    if re.search(r'[+*/-]{2,}', expr):\n        return False\n    if re.search(r'\\(\\)', expr):\n        return False\n    # parentheses balance\n    stack = []\n    for c in expr:\n        if c == '(':\n            stack.append(c)\n        elif c == ')':\n            if not stack:\n                return False\n            stack.pop()\n    if stack:\n        return False\n    # final safety: try eval\n    try:\n        eval(expr, {\"__builtins__\":None}, {})\n    except:\n        return False\n    return True", "test": [{"input": ["1+2*(3-4)"], "output": true}, {"input": ["(5+6"], "output": false}, {"input": ["1++2"], "output": false}, {"input": ["( )"], "output": false}, {"input": ["10/2-3"], "output": true}]}}
{"timestamp_utc": "2025-09-27T12:36:15.174839", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 56, "question": "Write parse_roman(s) that converts a valid Roman numeral string into an integer. Supports numerals up to 3999 (MMMCMXCIX). Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-code-fast-1", "region": null, "success": true, "response_time": 2.998192071914673, "response": "```python\ndef parse_roman(s):\n    roman = {'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, 'D': 500, 'M': 1000}\n    total = 0\n    prev = 0\n    for char in reversed(s):\n        val = roman[char]\n        if val < prev:\n            total -= val\n        else:\n            total += val\n        prev = val\n    return total\n```", "error": null, "raw_item": {"task_id": "custom_parse_roman", "prompt": "Write parse_roman(s) that converts a valid Roman numeral string into an integer. Supports numerals up to 3999 (MMMCMXCIX). Return only the Python function code with no explanations.", "entry_point": "parse_roman", "canonical_solution": "def parse_roman(s: str) -> int:\n    values = {\"I\":1, \"V\":5, \"X\":10, \"L\":50, \"C\":100, \"D\":500, \"M\":1000}\n    total = 0\n    i = 0\n    while i < len(s):\n        if i+1 < len(s) and values[s[i]] < values[s[i+1]]:\n            total += values[s[i+1]] - values[s[i]]\n            i += 2\n        else:\n            total += values[s[i]]\n            i += 1\n    return total", "test": [{"input": ["III"], "output": 3}, {"input": ["IX"], "output": 9}, {"input": ["LVIII"], "output": 58}, {"input": ["MCMXCIV"], "output": 1994}, {"input": ["MMMCMXCIX"], "output": 3999}]}}
