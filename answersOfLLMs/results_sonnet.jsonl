{"timestamp_utc": "2025-09-16T06:13:58.335926", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 0, "question": "Write find_balanced_sublist(arr) that returns the longest even-length contiguous sublist where sum of first half equals sum of second half. Return empty list if none exists.\n\nReturn only the Python function code with no explanations, comments, or markdown formatting.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 4.143600940704346, "response": "```python\ndef find_balanced_sublist(arr):\n    if not arr:\n        return []\n    \n    longest = []\n    n = len(arr)\n    \n    for i in range(n):\n        for j in range(i + 1, n + 1):\n            sublist = arr[i:j]\n            length = len(sublist)\n            \n            if length % 2 == 0:\n                mid = length // 2\n                first_half_sum = sum(sublist[:mid])\n                second_half_sum = sum(sublist[mid:])\n                \n                if first_half_sum == second_half_sum and length > len(longest):\n                    longest = sublist\n    \n    return longest\n```", "error": null, "raw_item": {"task_id": "custom_find_balanced_sublist", "prompt": "Write find_balanced_sublist(arr) that returns the longest even-length contiguous sublist where sum of first half equals sum of second half. Return empty list if none exists.\n\nReturn only the Python function code with no explanations, comments, or markdown formatting.", "entry_point": "find_balanced_sublist", "canonical_solution": "def find_balanced_sublist(arr: list[int]) -> list[int]:\n    n = len(arr)\n    for length in range(n, 1, -1):\n        if length % 2 != 0:\n            continue\n        for start in range(n - length + 1):\n            sub = arr[start:start+length]\n            half = length // 2\n            if sum(sub[:half]) == sum(sub[half:]):\n                return sub\n    return []", "test": [{"input": [[1, 2, 3, 3, 2, 1]], "output": [1, 2, 3, 3, 2, 1]}, {"input": [[5, 1, 2, 1, 5]], "output": []}, {"input": [[1, 1, 1, 1]], "output": [1, 1, 1, 1]}, {"input": [[1, 2, 3]], "output": []}, {"input": [[]], "output": []}, {"input": [[3, 0, 3, 0, 3]], "output": [3, 0, 3, 0]}, {"input": [[2, 1, 1, 2, 3, 4]], "output": [2, 1, 1, 2]}, {"input": [[1, 5, 3, 7]], "output": []}, {"input": [[0, 0, 0, 0]], "output": [0, 0, 0, 0]}]}}
{"timestamp_utc": "2025-09-16T06:14:02.118532", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 1, "question": "Write merge_by_priority(items_a, items_b) that merges two lists of (id, priority) pairs. Keep highest priority for each unique id. Return sorted by priority descending. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.7799930572509766, "response": "```python\ndef merge_by_priority(items_a, items_b):\n    merged = {}\n    \n    for item_id, priority in items_a + items_b:\n        if item_id not in merged or priority > merged[item_id]:\n            merged[item_id] = priority\n    \n    return sorted([(item_id, priority) for item_id, priority in merged.items()], \n                  key=lambda x: x[1], reverse=True)\n```", "error": null, "raw_item": {"task_id": "custom_merge_by_priority", "prompt": "Write merge_by_priority(items_a, items_b) that merges two lists of (id, priority) pairs. Keep highest priority for each unique id. Return sorted by priority descending. Return only the Python function code with no explanations.", "entry_point": "merge_by_priority", "canonical_solution": "def merge_by_priority(items_a: list[tuple[str, int]], items_b: list[tuple[str, int]]) -> list[tuple[str, int]]:\n    combined = items_a + items_b\n    best = {}\n    for id, priority in combined:\n        if id not in best or priority > best[id]:\n            best[id] = priority\n    return sorted(best.items(), key=lambda x: -x[1])", "test": [{"input": [[["item1", 2], ["item2", 5]], [["item2", 3], ["item3", 4]]], "output": [["item2", 5], ["item3", 4], ["item1", 2]]}, {"input": [[], []], "output": []}, {"input": [[["a", 1]], [["a", 10]]], "output": [["a", 10]]}, {"input": [[["x", 5], ["y", 3]], [["z", 7], ["y", 6]]], "output": [["z", 7], ["y", 6], ["x", 5]]}, {"input": [[["a", 1], ["b", 2]], []], "output": [["b", 2], ["a", 1]]}]}}
{"timestamp_utc": "2025-09-16T06:14:05.190087", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 2, "question": "Write parse_env_config(lines) that parses environment variable lines into dict. Ignore lines starting with '#', lines without '=', and empty keys. Keep last occurrence of duplicate keys. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.0701050758361816, "response": "```python\ndef parse_env_config(lines):\n    config = {}\n    for line in lines:\n        line = line.strip()\n        if line.startswith('#') or '=' not in line:\n            continue\n        key, value = line.split('=', 1)\n        key = key.strip()\n        if key:\n            config[key] = value.strip()\n    return config\n```", "error": null, "raw_item": {"task_id": "custom_parse_env_config", "prompt": "Write parse_env_config(lines) that parses environment variable lines into dict. Ignore lines starting with '#', lines without '=', and empty keys. Keep last occurrence of duplicate keys. Return only the Python function code with no explanations.", "entry_point": "parse_env_config", "canonical_solution": "def parse_env_config(lines: list[str]) -> dict[str, str]:\n    env = {}\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith(\"#\") or \"=\" not in line:\n            continue\n        key, value = line.split(\"=\", 1)\n        if key:\n            env[key] = value\n    return env", "test": [{"input": [["DB_HOST=localhost", "DB_PORT=5432", "#comment", "DB_HOST=remotehost", "=fail", "INVALID", ""]], "output": {"DB_HOST": "remotehost", "DB_PORT": "5432"}}, {"input": [["A=1", "B=2", "C=3"]], "output": {"A": "1", "B": "2", "C": "3"}}, {"input": [["# just a comment", "=", "==", "KEY_ONLY=", "NO_EQUALS"]], "output": {"KEY_ONLY": ""}}, {"input": [[]], "output": {}}, {"input": [["k1=v1", "k1=v2", "k1=v3"]], "output": {"k1": "v3"}}]}}
{"timestamp_utc": "2025-09-16T06:14:10.075241", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 3, "question": "Write minimal_partition_difference(nums) that partitions a list into two groups to minimize absolute difference of their sums. Handle empty list case explicitly. Use DP subset sum approach. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.883665084838867, "response": "```python\ndef minimal_partition_difference(nums):\n    if not nums:\n        return 0\n    \n    total_sum = sum(nums)\n    target = total_sum // 2\n    n = len(nums)\n    \n    dp = [[False] * (target + 1) for _ in range(n + 1)]\n    \n    for i in range(n + 1):\n        dp[i][0] = True\n    \n    for i in range(1, n + 1):\n        for j in range(1, target + 1):\n            dp[i][j] = dp[i-1][j]\n            if j >= nums[i-1]:\n                dp[i][j] = dp[i][j] or dp[i-1][j - nums[i-1]]\n    \n    for j in range(target, -1, -1):\n        if dp[n][j]:\n            return total_sum - 2 * j\n    \n    return total_sum\n```", "error": null, "raw_item": {"task_id": "custom_minimal_partition_difference", "prompt": "Write minimal_partition_difference(nums) that partitions a list into two groups to minimize absolute difference of their sums. Handle empty list case explicitly. Use DP subset sum approach. Return only the Python function code with no explanations.", "entry_point": "minimal_partition_difference", "canonical_solution": "def minimal_partition_difference(nums: list[int]) -> int:\n    if not nums:\n        return 0\n    total = sum(nums)\n    target = total // 2\n    possible = {0}\n    for num in nums:\n        possible |= {x + num for x in possible}\n    best = max(x for x in possible if x <= target)\n    return total - 2 * best", "test": [{"input": [[1, 2, 3, 9]], "output": 3}, {"input": [[1, 2, 3, 4, 5]], "output": 1}, {"input": [[10, 10]], "output": 0}, {"input": [[7]], "output": 7}, {"input": [[]], "output": 0}, {"input": [[1, 1, 1, 1, 1, 1]], "output": 0}, {"input": [[100, 99, 98, 1]], "output": 96}]}}
{"timestamp_utc": "2025-09-16T06:14:14.072443", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 4, "question": "Write normalize_user_roles(users) where users is a dict mapping each user to a LIST of roles. Invert to map each role to list of users. Remove duplicate users per role and sort user lists alphabetically. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.9954428672790527, "response": "```python\ndef normalize_user_roles(users):\n    role_to_users = {}\n    for user, roles in users.items():\n        for role in roles:\n            if role not in role_to_users:\n                role_to_users[role] = []\n            if user not in role_to_users[role]:\n                role_to_users[role].append(user)\n    \n    for role in role_to_users:\n        role_to_users[role].sort()\n    \n    return role_to_users\n```", "error": null, "raw_item": {"task_id": "custom_normalize_user_roles", "prompt": "Write normalize_user_roles(users) where users is a dict mapping each user to a LIST of roles. Invert to map each role to list of users. Remove duplicate users per role and sort user lists alphabetically. Return only the Python function code with no explanations.", "entry_point": "normalize_user_roles", "canonical_solution": "def normalize_user_roles(users: dict[str, list[str]]) -> dict[str, list[str]]:\n    role_to_users = {}\n    for user, roles in users.items():\n        for role in set(roles):  # remove duplicates\n            if role not in role_to_users:\n                role_to_users[role] = []\n            role_to_users[role].append(user)\n    for role in role_to_users:\n        role_to_users[role].sort()\n    return role_to_users", "test": [{"input": [{"alice": ["admin", "editor"], "bob": ["editor", "admin"], "charlie": ["viewer"]}], "output": {"admin": ["alice", "bob"], "editor": ["alice", "bob"], "viewer": ["charlie"]}}, {"input": [{"diana": [], "eva": ["user", "user"], "frank": ["user"]}], "output": {"user": ["eva", "frank"]}}, {"input": [{"a": ["x"], "b": ["y"], "c": ["x", "y"]}], "output": {"x": ["a", "c"], "y": ["b", "c"]}}, {"input": [{}], "output": {}}]}}
{"timestamp_utc": "2025-09-16T06:14:21.078443", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 5, "question": "Write can_form_expression(digits, target) that checks if inserting '+' or '-' operators (or nothing) between digits can reach target value. Use recursive DFS. Must handle multi-digit numbers. Return complete Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 6.003955125808716, "response": "```python\ndef can_form_expression(digits, target):\n    def dfs(index, current_value, current_number, last_number, operator):\n        if index == len(digits):\n            final_value = current_value\n            if operator == '+':\n                final_value += current_number\n            elif operator == '-':\n                final_value -= current_number\n            else:\n                final_value = current_number\n            return final_value == target\n        \n        digit = int(digits[index])\n        new_number = current_number * 10 + digit\n        \n        # Continue building current number\n        if dfs(index + 1, current_value, new_number, last_number, operator):\n            return True\n        \n        # Add operator after current number\n        if index > 0:\n            next_value = current_value\n            if operator == '+':\n                next_value += current_number\n            elif operator == '-':\n                next_value -= current_number\n            else:\n                next_value = current_number\n            \n            # Try '+' operator\n            if dfs(index + 1, next_value, digit, current_number, '+'):\n                return True\n            \n            # Try '-' operator  \n            if dfs(index + 1, next_value, digit, current_number, '-'):\n                return True\n        \n        return False\n    \n    if not digits:\n        return target == 0\n    \n    return dfs(1, 0, int(digits[0]), 0, None)\n```", "error": null, "raw_item": {"task_id": "custom_can_form_expression", "prompt": "Write can_form_expression(digits, target) that checks if inserting '+' or '-' operators (or nothing) between digits can reach target value. Use recursive DFS. Must handle multi-digit numbers. Return complete Python function code with no explanations.", "entry_point": "can_form_expression", "canonical_solution": "def can_form_expression(digits: str, target: int) -> bool:\n    def dfs(index: int, current_value: int, expression: str) -> bool:\n        if index == len(digits):\n            return current_value == target\n        for end in range(index + 1, len(digits) + 1):\n            num_str = digits[index:end]\n            num = int(num_str)\n            if index == 0:\n                if dfs(end, num, num_str):\n                    return True\n            else:\n                if dfs(end, current_value + num, expression + '+' + num_str):\n                    return True\n                if dfs(end, current_value - num, expression + '-' + num_str):\n                    return True\n        return False\n    return dfs(0, 0, \"\")", "test": [{"input": ["123", 6], "output": true}, {"input": ["105", 5], "output": true}, {"input": ["123", 123], "output": true}, {"input": ["123", 100], "output": false}, {"input": ["000", 0], "output": true}, {"input": ["1", 1], "output": true}, {"input": ["1", 2], "output": false}]}}
{"timestamp_utc": "2025-09-16T06:14:24.796670", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 6, "question": "Write has_balanced_bits(n) that returns True if binary representation of n has equal number of 0s and 1s. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.7154197692871094, "response": "```python\ndef has_balanced_bits(n):\n    binary = bin(n)[2:]\n    return binary.count('0') == binary.count('1')\n```", "error": null, "raw_item": {"task_id": "custom_has_balanced_bits", "prompt": "Write has_balanced_bits(n) that returns True if binary representation of n has equal number of 0s and 1s. Return only the Python function code with no explanations.", "entry_point": "has_balanced_bits", "canonical_solution": "def has_balanced_bits(n: int) -> bool:\n    bits = bin(n)[2:]\n    return bits.count('0') == bits.count('1')", "test": [{"input": [10], "output": true}, {"input": [7], "output": false}, {"input": [9], "output": true}, {"input": [1], "output": false}, {"input": [51], "output": false}, {"input": [56], "output": true}, {"input": [57], "output": false}, {"input": [2], "output": true}, {"input": [15], "output": false}]}}
{"timestamp_utc": "2025-09-16T06:14:29.508296", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 7, "question": "Write remove_repeating_groups(s, k) that repeatedly removes groups of k identical adjacent characters until no more can be removed. Use stack approach. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.710085868835449, "response": "```python\ndef remove_repeating_groups(s, k):\n    stack = []\n    \n    for char in s:\n        if stack and stack[-1][0] == char:\n            stack[-1] = (char, stack[-1][1] + 1)\n        else:\n            stack.append((char, 1))\n        \n        if stack[-1][1] == k:\n            stack.pop()\n    \n    result = []\n    for char, count in stack:\n        result.append(char * count)\n    \n    return ''.join(result)\n```", "error": null, "raw_item": {"task_id": "custom_remove_repeating_groups", "prompt": "Write remove_repeating_groups(s, k) that repeatedly removes groups of k identical adjacent characters until no more can be removed. Use stack approach. Return only the Python function code with no explanations.", "entry_point": "remove_repeating_groups", "canonical_solution": "def remove_repeating_groups(s: str, k: int) -> str:\n    stack = []\n    for char in s:\n        if stack and stack[-1][0] == char:\n            stack[-1][1] += 1\n            if stack[-1][1] == k:\n                stack.pop()\n        else:\n            stack.append([char, 1])\n    return ''.join(char * count for char, count in stack)", "test": [{"input": ["deeedbbcccbdaa", 3], "output": "aa"}, {"input": ["pbbcggttciiippooaais", 2], "output": "ps"}, {"input": ["abcd", 2], "output": "abcd"}, {"input": ["aaa", 3], "output": ""}, {"input": ["aaaabbbbaaaa", 4], "output": ""}, {"input": ["aabbcc", 2], "output": ""}, {"input": ["aabbccddeeedcba", 3], "output": "abc"}, {"input": ["", 3], "output": ""}]}}
{"timestamp_utc": "2025-09-16T06:14:34.669499", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 8, "question": "Write resolve_dependencies(deps) that returns valid module load order from dependency dict. Return None if cycle exists. Use DFS topological sort. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 4.157921075820923, "response": "```python\ndef resolve_dependencies(deps):\n    def dfs(node, visited, rec_stack, result):\n        visited.add(node)\n        rec_stack.add(node)\n        \n        for neighbor in deps.get(node, []):\n            if neighbor not in visited:\n                if not dfs(neighbor, visited, rec_stack, result):\n                    return False\n            elif neighbor in rec_stack:\n                return False\n        \n        rec_stack.remove(node)\n        result.append(node)\n        return True\n    \n    visited = set()\n    result = []\n    \n    for node in deps:\n        if node not in visited:\n            if not dfs(node, visited, set(), result):\n                return None\n    \n    # Add nodes that have no dependencies but are referenced as dependencies\n    all_nodes = set(deps.keys())\n    for dep_list in deps.values():\n        all_nodes.update(dep_list)\n    \n    for node in all_nodes:\n        if node not in visited:\n            result.append(node)\n    \n    return result[::-1]\n```", "error": null, "raw_item": {"task_id": "custom_resolve_dependencies", "prompt": "Write resolve_dependencies(deps) that returns valid module load order from dependency dict. Return None if cycle exists. Use DFS topological sort. Return only the Python function code with no explanations.", "entry_point": "resolve_dependencies", "canonical_solution": "def resolve_dependencies(deps: dict[str, list[str]]) -> list[str] | None:\n    visited = {}\n    result = []\n\n    def dfs(node):\n        if node in visited:\n            return visited[node]  # False if cycle\n        visited[node] = False  # mark as visiting\n        for neighbor in deps.get(node, []):\n            res = dfs(neighbor)\n            if res is False:\n                return False\n        visited[node] = True  # mark as visited\n        result.append(node)\n        return True\n\n    for node in deps:\n        if node not in visited:\n            if dfs(node) is False:\n                return None\n    return result[::-1]", "test": [{"input": [{"a": ["b", "c"], "b": ["c"], "c": []}], "output": ["c", "b", "a"]}, {"input": [{"x": ["y"], "y": ["z"], "z": ["x"]}], "output": null}, {"input": [{"m": ["n"], "n": [], "o": []}], "output": ["n", "m", "o"]}, {"input": [{"a": []}], "output": ["a"]}, {"input": [{}], "output": []}]}}
{"timestamp_utc": "2025-09-16T06:14:39.517375", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 9, "question": "Write clean_and_validate_urls(urls) that returns sorted list of unique valid URLs. Valid URLs start with 'http://' or 'https://' (case-insensitive) and contain no spaces. Strip whitespace and remove duplicates. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.846569776535034, "response": "```python\ndef clean_and_validate_urls(urls):\n    valid_urls = set()\n    \n    for url in urls:\n        # Strip whitespace\n        cleaned_url = url.strip()\n        \n        # Check if URL is valid\n        if (cleaned_url.lower().startswith('http://') or \n            cleaned_url.lower().startswith('https://')) and ' ' not in cleaned_url:\n            valid_urls.add(cleaned_url)\n    \n    return sorted(list(valid_urls))\n```", "error": null, "raw_item": {"task_id": "custom_clean_and_validate_urls", "prompt": "Write clean_and_validate_urls(urls) that returns sorted list of unique valid URLs. Valid URLs start with 'http://' or 'https://' (case-insensitive) and contain no spaces. Strip whitespace and remove duplicates. Return only the Python function code with no explanations.", "entry_point": "clean_and_validate_urls", "canonical_solution": "def clean_and_validate_urls(urls: list[str]) -> list[str]:\n    valid = set()\n    for url in urls:\n        cleaned = url.strip()\n        if cleaned.lower().startswith(\"http://\") or cleaned.lower().startswith(\"https://\"):\n            if \" \" not in cleaned:\n                valid.add(cleaned)\n    return sorted(valid)", "test": [{"input": [[" http://example.com ", "https://valid.site", "ftp://notvalid", "invalid.com", "https://valid.site"]], "output": ["http://example.com", "https://valid.site"]}, {"input": [[]], "output": []}, {"input": [["   https://a.com  ", "http://b.com", "http://b.com  "]], "output": ["http://b.com", "https://a.com"]}, {"input": [["https://with space.com", "http://ok.com"]], "output": ["http://ok.com"]}, {"input": [["HTTP://UPPERCASE.com"]], "output": ["HTTP://UPPERCASE.com"]}]}}
{"timestamp_utc": "2025-09-16T06:14:43.150364", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 10, "question": "Write normalize_filename(filename) that normalizes filenames by converting to lowercase, keeping only a-z, 0-9, underscore, and dots, removing other characters. Return 'unnamed' if result is empty. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.630082845687866, "response": "```python\ndef normalize_filename(filename):\n    import re\n    normalized = re.sub(r'[^a-z0-9_.]', '', filename.lower())\n    return normalized if normalized else 'unnamed'\n```", "error": null, "raw_item": {"task_id": "custom_normalize_filename", "prompt": "Write normalize_filename(filename) that normalizes filenames by converting to lowercase, keeping only a-z, 0-9, underscore, and dots, removing other characters. Return 'unnamed' if result is empty. Return only the Python function code with no explanations.", "entry_point": "normalize_filename", "canonical_solution": "def normalize_filename(filename: str) -> str:\n    allowed = set(\"abcdefghijklmnopqrstuvwxyz0123456789_.\")\n    result = ''.join(c.lower() for c in filename if c.lower() in allowed)\n    return result if result else \"unnamed\"", "test": [{"input": ["My Report (Final).PDF"], "output": "myreport.final.pdf"}, {"input": ["Résumé_2023!.docx"], "output": "rsum_2023.docx"}, {"input": ["  "], "output": "unnamed"}, {"input": ["file@#name!.TXT"], "output": "filename.txt"}, {"input": ["___"], "output": "___"}, {"input": ["###"], "output": "unnamed"}, {"input": ["ABC123_456.xyz"], "output": "abc123_456.xyz"}]}}
{"timestamp_utc": "2025-09-16T06:14:46.533967", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 11, "question": "Write rank_projects_by_score(projects) that ranks projects by score formula: (stars * 2) + forks - (issues * 3). Return project names sorted by score descending, then alphabetically. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.3815360069274902, "response": "```python\ndef rank_projects_by_score(projects):\n    def calculate_score(project):\n        return (project['stars'] * 2) + project['forks'] - (project['issues'] * 3)\n    \n    scored_projects = [(project['name'], calculate_score(project)) for project in projects]\n    scored_projects.sort(key=lambda x: (-x[1], x[0]))\n    \n    return [name for name, score in scored_projects]\n```", "error": null, "raw_item": {"task_id": "custom_rank_projects_by_score", "prompt": "Write rank_projects_by_score(projects) that ranks projects by score formula: (stars * 2) + forks - (issues * 3). Return project names sorted by score descending, then alphabetically. Return only the Python function code with no explanations.", "entry_point": "rank_projects_by_score", "canonical_solution": "def rank_projects_by_score(projects: list[tuple[str, int, int, int]]) -> list[str]:\n    def score(proj):\n        return (proj[1] * 2) + proj[2] - (proj[3] * 3)\n    return [p[0] for p in sorted(projects, key=lambda p: (-score(p), p[0]))]", "test": [{"input": [[["ProjectA", 100, 50, 10], ["ProjectB", 80, 70, 5], ["ProjectC", 100, 50, 10]]], "output": ["ProjectA", "ProjectC", "ProjectB"]}, {"input": [[["Alpha", 10, 5, 0], ["Beta", 10, 5, 0]]], "output": ["Alpha", "Beta"]}, {"input": [[["AppX", 0, 0, 0], ["AppY", 0, 0, 1]]], "output": ["AppX", "AppY"]}, {"input": [[]], "output": []}, {"input": [[["ToolZ", 5, 5, 10], ["ToolY", 4, 4, 1]]], "output": ["ToolY", "ToolZ"]}]}}
{"timestamp_utc": "2025-09-16T06:14:51.729527", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 12, "question": "Write longest_prime_gap(nums) that finds the longest sequence of non-prime numbers between two prime numbers in the list. Return length of longest gap. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 4.193387985229492, "response": "```python\ndef longest_prime_gap(nums):\n    def is_prime(n):\n        if n < 2:\n            return False\n        if n == 2:\n            return True\n        if n % 2 == 0:\n            return False\n        for i in range(3, int(n**0.5) + 1, 2):\n            if n % i == 0:\n                return False\n        return True\n    \n    if len(nums) < 2:\n        return 0\n    \n    max_gap = 0\n    current_gap = 0\n    found_first_prime = False\n    \n    for num in nums:\n        if is_prime(num):\n            if found_first_prime:\n                max_gap = max(max_gap, current_gap)\n            found_first_prime = True\n            current_gap = 0\n        else:\n            if found_first_prime:\n                current_gap += 1\n    \n    return max_gap\n```", "error": null, "raw_item": {"task_id": "custom_longest_prime_gap", "prompt": "Write longest_prime_gap(nums) that finds the longest sequence of non-prime numbers between two prime numbers in the list. Return length of longest gap. Return only the Python function code with no explanations.", "entry_point": "longest_prime_gap", "canonical_solution": "def longest_prime_gap(nums: list[int]) -> int:\n    def is_prime(n: int) -> bool:\n        if n < 2:\n            return False\n        for i in range(2, int(n**0.5)+1):\n            if n % i == 0:\n                return False\n        return True\n\n    indices = [i for i, val in enumerate(nums) if is_prime(val)]\n    if len(indices) < 2:\n        return 0\n\n    max_gap = 0\n    for i in range(len(indices) - 1):\n        start = indices[i]\n        end = indices[i + 1]\n        gap = end - start - 1\n        max_gap = max(max_gap, gap)\n    return max_gap", "test": [{"input": [[4, 6, 7, 8, 9, 10, 11, 4, 6, 13]], "output": 3}, {"input": [[2, 4, 6, 8, 10, 3]], "output": 4}, {"input": [[4, 6, 8, 10]], "output": 0}, {"input": [[3, 4, 5, 6, 7]], "output": 1}, {"input": [[2, 3]], "output": 0}, {"input": [[17, 4, 6, 9, 15, 19, 21, 23]], "output": 4}, {"input": [[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]], "output": 4}]}}
{"timestamp_utc": "2025-09-16T06:14:56.257555", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 13, "question": "Write categorize_commit_message(message) that categorizes commit messages. Return 'feature' for add/implement/feature/new, 'fix' for fix/bug/error/resolve, 'refactor' for refactor/cleanup/restructure, 'docs' for docs/documentation/readme, else 'other'. Case-insensitive. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.525624990463257, "response": "```python\ndef categorize_commit_message(message):\n    message_lower = message.lower()\n    \n    feature_keywords = ['add', 'implement', 'feature', 'new']\n    fix_keywords = ['fix', 'bug', 'error', 'resolve']\n    refactor_keywords = ['refactor', 'cleanup', 'restructure']\n    docs_keywords = ['docs', 'documentation', 'readme']\n    \n    for keyword in feature_keywords:\n        if keyword in message_lower:\n            return 'feature'\n    \n    for keyword in fix_keywords:\n        if keyword in message_lower:\n            return 'fix'\n    \n    for keyword in refactor_keywords:\n        if keyword in message_lower:\n            return 'refactor'\n    \n    for keyword in docs_keywords:\n        if keyword in message_lower:\n            return 'docs'\n    \n    return 'other'\n```", "error": null, "raw_item": {"task_id": "custom_categorize_commit_message", "prompt": "Write categorize_commit_message(message) that categorizes commit messages. Return 'feature' for add/implement/feature/new, 'fix' for fix/bug/error/resolve, 'refactor' for refactor/cleanup/restructure, 'docs' for docs/documentation/readme, else 'other'. Case-insensitive. Return only the Python function code with no explanations.", "entry_point": "categorize_commit_message", "canonical_solution": "def categorize_commit_message(message: str) -> str:\n    msg = message.lower()\n    categories = {\n        \"feature\": [\"add\", \"implement\", \"feature\", \"new\"],\n        \"fix\": [\"fix\", \"bug\", \"error\", \"resolve\"],\n        \"refactor\": [\"refactor\", \"cleanup\", \"restructure\"],\n        \"docs\": [\"docs\", \"documentation\", \"readme\"],\n    }\n    for label, keywords in categories.items():\n        if any(kw in msg for kw in keywords):\n            return label\n    return \"other\"", "test": [{"input": ["Fix bug in user login"], "output": "fix"}, {"input": ["Refactor payment module"], "output": "refactor"}, {"input": ["Updated README and docs"], "output": "docs"}, {"input": ["Initial commit"], "output": "other"}, {"input": ["Implemented new feature for signup"], "output": "feature"}, {"input": ["cleanup redundant logic"], "output": "refactor"}, {"input": ["Error handling for empty input"], "output": "fix"}, {"input": ["add configuration support"], "output": "feature"}, {"input": ["Documentation improvements"], "output": "docs"}, {"input": ["Minor UI tweaks"], "output": "other"}]}}
{"timestamp_utc": "2025-09-16T06:14:59.813269", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 14, "question": "Write max_repeated_substring(s) that returns length of longest non-overlapping repeated substring. Use sliding window with seen set. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.5536019802093506, "response": "```python\ndef max_repeated_substring(s):\n    n = len(s)\n    max_len = 0\n    \n    for length in range(1, n // 2 + 1):\n        seen = set()\n        left = 0\n        \n        for right in range(length, n + 1, length):\n            substring = s[left:right]\n            \n            if substring in seen:\n                max_len = max(max_len, length)\n            else:\n                seen.add(substring)\n            \n            left = right\n    \n    return max_len\n```", "error": null, "raw_item": {"task_id": "custom_max_repeated_substring", "prompt": "Write max_repeated_substring(s) that returns length of longest non-overlapping repeated substring. Use sliding window with seen set. Return only the Python function code with no explanations.", "entry_point": "max_repeated_substring", "canonical_solution": "def max_repeated_substring(s: str) -> int:\n    n = len(s)\n    max_len = 0\n    for l in range(1, n // 2 + 1):\n        seen = set()\n        i = 0\n        while i + l <= n:\n            substr = s[i:i+l]\n            if substr in seen:\n                max_len = max(max_len, l)\n                i += l  # move forward non-overlapping\n            else:\n                seen.add(substr)\n                i += 1\n    return max_len", "test": [{"input": ["abababc"], "output": 2}, {"input": ["aaaa"], "output": 2}, {"input": ["abcabcabc"], "output": 3}, {"input": ["abcdef"], "output": 0}, {"input": ["ababa"], "output": 1}, {"input": [""], "output": 0}, {"input": ["a"], "output": 0}, {"input": ["abcdabcd"], "output": 4}, {"input": ["xyzxyzabcabc"], "output": 3}, {"input": ["abababab"], "output": 2}]}}
{"timestamp_utc": "2025-09-16T06:15:02.922028", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 15, "question": "Write longest_valid_bracket_substring(s) that returns length of longest valid parentheses substring. Use stack with indices. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.1064178943634033, "response": "```python\ndef longest_valid_bracket_substring(s):\n    stack = [-1]\n    max_length = 0\n    \n    for i in range(len(s)):\n        if s[i] == '(':\n            stack.append(i)\n        else:\n            stack.pop()\n            if not stack:\n                stack.append(i)\n            else:\n                max_length = max(max_length, i - stack[-1])\n    \n    return max_length\n```", "error": null, "raw_item": {"task_id": "custom_longest_valid_bracket_substring", "prompt": "Write longest_valid_bracket_substring(s) that returns length of longest valid parentheses substring. Use stack with indices. Return only the Python function code with no explanations.", "entry_point": "longest_valid_bracket_substring", "canonical_solution": "def longest_valid_bracket_substring(s: str) -> int:\n    stack = [-1]\n    max_len = 0\n\n    for i, ch in enumerate(s):\n        if ch == '(':\n            stack.append(i)\n        else:\n            stack.pop()\n            if not stack:\n                stack.append(i)\n            else:\n                max_len = max(max_len, i - stack[-1])\n\n    return max_len", "test": [{"input": ["(()"], "output": 2}, {"input": [")()())"], "output": 4}, {"input": [""], "output": 0}, {"input": ["((("], "output": 0}, {"input": ["()(()))())"], "output": 6}, {"input": ["((()))"], "output": 6}, {"input": ["()()()"], "output": 6}, {"input": [")((()))("], "output": 6}, {"input": ["(()(((()"], "output": 2}, {"input": ["())(())"], "output": 4}]}}
{"timestamp_utc": "2025-09-16T06:15:07.274788", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 16, "question": "Write summarize_category_totals(purchases) that returns list of [category, total] pairs sorted alphabetically by category. Sum amounts by category. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.351154088973999, "response": "```python\ndef summarize_category_totals(purchases):\n    category_totals = {}\n    for purchase in purchases:\n        category = purchase['category']\n        amount = purchase['amount']\n        if category in category_totals:\n            category_totals[category] += amount\n        else:\n            category_totals[category] = amount\n    \n    result = [[category, total] for category, total in category_totals.items()]\n    result.sort(key=lambda x: x[0])\n    return result\n```", "error": null, "raw_item": {"task_id": "custom_summarize_category_totals", "prompt": "Write summarize_category_totals(purchases) that returns list of [category, total] pairs sorted alphabetically by category. Sum amounts by category. Return only the Python function code with no explanations.", "entry_point": "summarize_category_totals", "canonical_solution": "def summarize_category_totals(purchases: list[dict]) -> list[list]:\n    totals = {}\n    for item in purchases:\n        cat = item[\"category\"]\n        amt = item[\"amount\"]\n        totals[cat] = totals.get(cat, 0.0) + amt\n    return sorted([[cat, total] for cat, total in totals.items()])", "test": [{"input": [[{"category": "groceries", "amount": 25.5}, {"category": "electronics", "amount": 99.99}, {"category": "groceries", "amount": 13.0}, {"category": "books", "amount": 10.0}]], "output": [["books", 10.0], ["electronics", 99.99], ["groceries", 38.5]]}, {"input": [[{"category": "a", "amount": 1.0}, {"category": "b", "amount": 2.0}, {"category": "a", "amount": 3.0}, {"category": "c", "amount": 4.0}]], "output": [["a", 4.0], ["b", 2.0], ["c", 4.0]]}, {"input": [[]], "output": []}, {"input": [[{"category": "x", "amount": 0.0}, {"category": "x", "amount": 0.0}]], "output": [["x", 0.0]]}, {"input": [[{"category": "Z", "amount": 2.0}, {"category": "a", "amount": 1.0}]], "output": [["Z", 2.0], ["a", 1.0]]}]}}
{"timestamp_utc": "2025-09-16T06:15:11.293129", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 17, "question": "Write filter_unique_keywords(keywords, banned) that returns sorted unique keywords (lowercased) excluding banned words. Case-insensitive comparison. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.016178846359253, "response": "```python\ndef filter_unique_keywords(keywords, banned):\n    banned_lower = {word.lower() for word in banned}\n    unique_keywords = {word.lower() for word in keywords if word.lower() not in banned_lower}\n    return sorted(unique_keywords)\n```", "error": null, "raw_item": {"task_id": "custom_filter_unique_keywords", "prompt": "Write filter_unique_keywords(keywords, banned) that returns sorted unique keywords (lowercased) excluding banned words. Case-insensitive comparison. Return only the Python function code with no explanations.", "entry_point": "filter_unique_keywords", "canonical_solution": "def filter_unique_keywords(keywords: list[str], banned: list[str]) -> list[str]:\n    banned_set = set(word.lower() for word in banned)\n    unique = set()\n\n    for word in keywords:\n        w = word.lower()\n        if w not in banned_set:\n            unique.add(w)\n\n    return sorted(unique)", "test": [{"input": [["Python", "code", "AI", "python", "Data", "Code"], ["ai"]], "output": ["code", "data", "python"]}, {"input": [[], ["test"]], "output": []}, {"input": [["ML", "AI", "ml", "AI"], ["ai"]], "output": ["ml"]}, {"input": [["hello", "world", "HELLO", "WORLD"], []], "output": ["hello", "world"]}, {"input": [["Data", "Science", "AI"], ["science", "ai"]], "output": ["data"]}, {"input": [["Python", "PYTHON", "python"], ["PYTHON"]], "output": []}]}}
{"timestamp_utc": "2025-09-16T06:15:15.083447", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 18, "question": "Write next_greater_circular(nums) that returns list where each position contains next greater element circularly. Use monotonic stack. O(n) time. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.789151906967163, "response": "```python\ndef next_greater_circular(nums):\n    n = len(nums)\n    result = [-1] * n\n    stack = []\n    \n    for i in range(2 * n):\n        while stack and nums[stack[-1]] < nums[i % n]:\n            result[stack.pop()] = nums[i % n]\n        if i < n:\n            stack.append(i)\n    \n    return result\n```", "error": null, "raw_item": {"task_id": "ds_next_greater_circular", "prompt": "Write next_greater_circular(nums) that returns list where each position contains next greater element circularly. Use monotonic stack. O(n) time. Return only the Python function code with no explanations.", "entry_point": "next_greater_circular", "canonical_solution": "def next_greater_circular(nums):\n    n = len(nums)\n    res = [-1]*n\n    stack = []  # indices with decreasing stack by value\n    for i in range(2*n):\n        x = nums[i % n]\n        while stack and nums[stack[-1]] < x:\n            idx = stack.pop()\n            res[idx] = x\n        if i < n:\n            stack.append(i)\n    return res\n", "test": [{"input": [[1, 2, 1]], "output": [2, -1, 2]}, {"input": [[3, 8, 4, 1, 2]], "output": [8, -1, 8, 2, 3]}, {"input": [[5, 4, 3, 2, 1]], "output": [-1, 5, 5, 5, 5]}, {"input": [[2, 2, 2]], "output": [-1, -1, -1]}, {"input": [[]], "output": []}]}}
{"timestamp_utc": "2025-09-16T06:15:19.076471", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 19, "question": "Write normalize_product_code(s) that keeps only alphanumerics and dashes, converts to uppercase, collapses multiple dashes, trims leading/trailing dashes. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.9894449710845947, "response": "```python\ndef normalize_product_code(s):\n    import re\n    # Keep only alphanumerics and dashes\n    cleaned = re.sub(r'[^a-zA-Z0-9-]', '', s)\n    # Convert to uppercase\n    cleaned = cleaned.upper()\n    # Collapse multiple dashes\n    cleaned = re.sub(r'-+', '-', cleaned)\n    # Trim leading/trailing dashes\n    cleaned = cleaned.strip('-')\n    return cleaned\n```", "error": null, "raw_item": {"task_id": "str_normalize_product_code", "prompt": "Write normalize_product_code(s) that keeps only alphanumerics and dashes, converts to uppercase, collapses multiple dashes, trims leading/trailing dashes. Return only the Python function code with no explanations.", "entry_point": "normalize_product_code", "canonical_solution": "import re\ndef normalize_product_code(s):\n    # keep alnum and dash\n    s = ''.join(ch for ch in s if ch.isalnum() or ch=='-')\n    s = s.upper()\n    s = re.sub(r'-{2,}', '-', s)\n    s = s.strip('-')\n    return s\n", "test": [{"input": [" abC--12__-xx "], "output": "ABC-12-XX"}, {"input": ["---a---b---"], "output": "A-B"}, {"input": ["***"], "output": ""}, {"input": ["proD-uct_99!!"], "output": "PROD-UCT99"}, {"input": [""], "output": ""}]}}
{"timestamp_utc": "2025-09-16T06:15:22.373643", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 20, "question": "Write single_number_triplicates(nums) that finds element appearing once while others appear thrice. Use bitwise counting without hash maps. O(n) time, O(1) space. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.2950680255889893, "response": "```python\ndef single_number_triplicates(nums):\n    ones = twos = 0\n    for num in nums:\n        ones = (ones ^ num) & ~twos\n        twos = (twos ^ num) & ~ones\n    return ones\n```", "error": null, "raw_item": {"task_id": "bit_single_number_triplicates", "prompt": "Write single_number_triplicates(nums) that finds element appearing once while others appear thrice. Use bitwise counting without hash maps. O(n) time, O(1) space. Return only the Python function code with no explanations.", "entry_point": "single_number_triplicates", "canonical_solution": "def single_number_triplicates(nums):\n    ones = 0\n    twos = 0\n    for x in nums:\n        ones = (ones ^ x) & ~twos\n        twos = (twos ^ x) & ~ones\n    return ones\n", "test": [{"input": [[2, 2, 3, 2]], "output": 3}, {"input": [[0, 1, 0, 1, 0, 1, 99]], "output": 99}, {"input": [[-2, -2, -2, -5]], "output": -5}, {"input": [[7]], "output": 7}, {"input": [[10, 10, 10, -1]], "output": -1}]}}
{"timestamp_utc": "2025-09-16T06:15:27.950872", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 21, "question": "Write can_finish_prereqs(pairs) where pairs are (a,b) meaning 'b precedes a'. Return True if acyclic. Use topological sort without external libraries. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 4.574747085571289, "response": "```python\ndef can_finish_prereqs(pairs):\n    if not pairs:\n        return True\n    \n    # Build adjacency list and in-degree count\n    graph = {}\n    in_degree = {}\n    \n    for a, b in pairs:\n        if b not in graph:\n            graph[b] = []\n        if a not in graph:\n            graph[a] = []\n        if a not in in_degree:\n            in_degree[a] = 0\n        if b not in in_degree:\n            in_degree[b] = 0\n            \n        graph[b].append(a)\n        in_degree[a] += 1\n    \n    # Find nodes with no incoming edges\n    queue = []\n    for node in in_degree:\n        if in_degree[node] == 0:\n            queue.append(node)\n    \n    processed = 0\n    \n    # Process nodes with no incoming edges\n    while queue:\n        node = queue.pop(0)\n        processed += 1\n        \n        for neighbor in graph[node]:\n            in_degree[neighbor] -= 1\n            if in_degree[neighbor] == 0:\n                queue.append(neighbor)\n    \n    return processed == len(in_degree)\n```", "error": null, "raw_item": {"task_id": "graph_can_finish_prereqs", "prompt": "Write can_finish_prereqs(pairs) where pairs are (a,b) meaning 'b precedes a'. Return True if acyclic. Use topological sort without external libraries. Return only the Python function code with no explanations.", "entry_point": "can_finish_prereqs", "canonical_solution": "from collections import defaultdict, deque\ndef can_finish_prereqs(pairs):\n    adj = defaultdict(list)\n    indeg = defaultdict(int)\n    nodes = set()\n    for a,b in pairs:\n        adj[b].append(a)\n        indeg[a] += 1\n        nodes.add(a); nodes.add(b)\n        if b not in indeg: indeg[b] = indeg.get(b,0)\n    q = deque([v for v in nodes if indeg.get(v,0)==0])\n    visited = 0\n    while q:\n        v = q.popleft()\n        visited += 1\n        for w in adj[v]:\n            indeg[w] -= 1\n            if indeg[w]==0:\n                q.append(w)\n    return visited == len(nodes)\n", "test": [{"input": [[["C2", "C1"], ["C3", "C2"]]], "output": true}, {"input": [[["A", "B"], ["B", "C"], ["C", "A"]]], "output": false}, {"input": [[["A", "B"]]], "output": true}, {"input": [[["X", "Y"], ["Y", "Z"], ["Z", "X"]]], "output": false}, {"input": [[[]]], "output": true}]}}
{"timestamp_utc": "2025-09-16T06:15:31.149130", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 22, "question": "Write safe_deep_get(obj, path, default=None) that safely traverses nested dicts/lists/tuples using path keys/indices. Return default if any access fails. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.1955699920654297, "response": "```python\ndef safe_deep_get(obj, path, default=None):\n    current = obj\n    for key in path:\n        try:\n            if isinstance(current, dict):\n                current = current[key]\n            elif isinstance(current, (list, tuple)):\n                current = current[int(key)]\n            else:\n                return default\n        except (KeyError, IndexError, ValueError, TypeError):\n            return default\n    return current\n```", "error": null, "raw_item": {"task_id": "se_safe_deep_get", "entry_point": "safe_deep_get", "prompt": "Write safe_deep_get(obj, path, default=None) that safely traverses nested dicts/lists/tuples using path keys/indices. Return default if any access fails. Return only the Python function code with no explanations.", "canonical_solution": "def safe_deep_get(obj, path, default=None):\n    cur = obj\n    for key in path:\n        if isinstance(cur, dict):\n            if key in cur:\n                cur = cur[key]\n            else:\n                return default\n        elif isinstance(cur, (list, tuple)):\n            if isinstance(key, int) and -len(cur) <= key < len(cur):\n                cur = cur[key]\n            else:\n                return default\n        else:\n            return default\n    return cur\n", "test": [{"input": [{"a": {"b": [10, 20, {"c": 42}]}}, ["a", "b", 2, "c"], null], "output": 42}, {"input": [{"a": [1, 2, 3]}, ["a", 5], "x"], "output": "x"}, {"input": [{"x": 0}, ["y"], 99], "output": 99}, {"input": [[1, 2, 3], [0], null], "output": 1}, {"input": [[1, 2, 3], ["0"], "err"], "output": "err"}]}}
{"timestamp_utc": "2025-09-16T06:15:35.655429", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 23, "question": "Write clean_and_split_sentences(text) that removes non-alphanumeric chars except .!?, normalizes whitespace, splits on sentence delimiters, returns cleaned sentence list. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.5037598609924316, "response": "```python\ndef clean_and_split_sentences(text):\n    import re\n    \n    # Remove non-alphanumeric chars except .!?\n    cleaned = re.sub(r'[^a-zA-Z0-9.!?\\s]', '', text)\n    \n    # Normalize whitespace\n    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n    \n    # Split on sentence delimiters\n    sentences = re.split(r'[.!?]+', cleaned)\n    \n    # Remove empty strings and strip whitespace\n    sentences = [s.strip() for s in sentences if s.strip()]\n    \n    return sentences\n```", "error": null, "raw_item": {"task_id": "str_clean_and_split_sentences", "entry_point": "clean_and_split_sentences", "prompt": "Write clean_and_split_sentences(text) that removes non-alphanumeric chars except .!?, normalizes whitespace, splits on sentence delimiters, returns cleaned sentence list. Return only the Python function code with no explanations.", "canonical_solution": "import re\n\ndef clean_and_split_sentences(text):\n    # Keep only letters, digits, punctuation .,!,?\n    text = re.sub(r\"[^A-Za-z0-9.!?\\s]\", \"\", text)\n    # Normalize whitespace\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    # Split on sentence delimiters\n    parts = re.split(r\"[.!?]\", text)\n    # Clean and filter\n    result = [p.strip() for p in parts if p.strip()]\n    return result\n", "test": [{"input": ["Hello!!   How are---you???   Fine."], "output": ["Hello", "How areyou", "Fine"]}, {"input": ["  multiple   spaces   and ###symbols!!"], "output": ["multiple spaces and symbols"]}, {"input": ["Nothing to clean"], "output": ["Nothing to clean"]}, {"input": ["???"], "output": []}]}}
{"timestamp_utc": "2025-09-16T06:15:38.310994", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 24, "question": "Write count_set_bits(n) that counts 1-bits in binary representation using efficient bit manipulation (Brian Kernighan's algorithm). Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 1.6535181999206543, "response": "```python\ndef count_set_bits(n):\n    count = 0\n    while n:\n        n &= n - 1\n        count += 1\n    return count\n```", "error": null, "raw_item": {"task_id": "bit_counting_set_bits", "entry_point": "count_set_bits", "prompt": "Write count_set_bits(n) that counts 1-bits in binary representation using efficient bit manipulation (Brian Kernighan's algorithm). Return only the Python function code with no explanations.", "canonical_solution": "def count_set_bits(n):\n    if n < 0:\n        raise ValueError(\"Input must be a non-negative integer.\")\n    count = 0\n    while n:\n        n &= n - 1  # Clear the least significant bit set\n        count += 1\n    return count\n", "test": [{"input": [11], "output": 3}, {"input": [0], "output": 0}, {"input": [255], "output": 8}, {"input": [1023], "output": 10}, {"input": [1], "output": 1}]}}
{"timestamp_utc": "2025-09-16T06:15:56.423581", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 25, "question": "Write filter_map_validate(records) that normalizes, validates, and filters product records, returning sorted list of valid IDs. Complex multi-step validation with price parsing, type constraints, and conditional rules. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 17.111257076263428, "response": "```python\ndef filter_map_validate(records):\n    import re\n    \n    valid_records = []\n    \n    for record in records:\n        try:\n            # Normalize record\n            normalized = {}\n            for key, value in record.items():\n                if isinstance(value, str):\n                    normalized[key.lower().strip()] = value.strip()\n                else:\n                    normalized[key.lower().strip()] = value\n            \n            # Required fields check\n            required_fields = ['id', 'name', 'price', 'type']\n            if not all(field in normalized for field in required_fields):\n                continue\n            \n            # ID validation\n            product_id = normalized['id']\n            if not isinstance(product_id, (str, int)) or str(product_id).strip() == '':\n                continue\n            product_id = str(product_id).strip()\n            \n            # Name validation\n            name = normalized['name']\n            if not isinstance(name, str) or len(name) < 1 or len(name) > 100:\n                continue\n            \n            # Price parsing and validation\n            price = normalized['price']\n            if isinstance(price, str):\n                # Remove currency symbols and whitespace\n                price_clean = re.sub(r'[^\\d.,\\-]', '', price)\n                # Handle comma as decimal separator\n                if ',' in price_clean and '.' in price_clean:\n                    # Assume comma is thousands separator if dot comes after\n                    if price_clean.rfind(',') < price_clean.rfind('.'):\n                        price_clean = price_clean.replace(',', '')\n                    else:\n                        # Assume dot is thousands separator\n                        price_clean = price_clean.replace('.', '').replace(',', '.')\n                elif ',' in price_clean:\n                    # Check if comma is likely decimal separator\n                    comma_pos = price_clean.rfind(',')\n                    if len(price_clean) - comma_pos <= 3:\n                        price_clean = price_clean.replace(',', '.')\n                    else:\n                        price_clean = price_clean.replace(',', '')\n                \n                try:\n                    price = float(price_clean)\n                except ValueError:\n                    continue\n            elif not isinstance(price, (int, float)):\n                continue\n            else:\n                price = float(price)\n            \n            if price < 0:\n                continue\n            \n            # Type validation\n            product_type = normalized['type'].lower()\n            valid_types = ['electronics', 'clothing', 'books', 'home', 'sports', 'toys']\n            if product_type not in valid_types:\n                continue\n            \n            # Conditional rules based on type\n            if product_type == 'electronics':\n                if price > 10000:\n                    continue\n                if 'warranty' in normalized:\n                    warranty = normalized['warranty']\n                    if isinstance(warranty, str):\n                        warranty_months = re.findall(r'\\d+', warranty)\n                        if warranty_months and int(warranty_months[0]) < 6:\n                            continue\n            \n            elif product_type == 'clothing':\n                if 'size' in normalized:\n                    size = normalized['size'].upper()\n                    valid_sizes = ['XS', 'S', 'M', 'L', 'XL', 'XXL']\n                    if size not in valid_sizes:\n                        continue\n            \n            elif product_type == 'books':\n                if price > 200:\n                    continue\n                if 'pages' in normalized:\n                    try:\n                        pages = int(normalized['pages'])\n                        if pages < 10:\n                            continue\n                    except (ValueError, TypeError):\n                        continue\n            \n            # Category validation if present\n            if 'category' in normalized:\n                category = normalized['category']\n                if not isinstance(category, str) or len(category.strip()) == 0:\n                    continue\n            \n            # Stock validation if present\n            if 'stock' in normalized:\n                try:\n                    stock = int(normalized['stock'])\n                    if stock < 0:\n                        continue\n                except (ValueError, TypeError):\n                    continue\n            \n            # Rating validation if present\n            if 'rating' in normalized:\n                try:\n                    rating = float(normalized['rating'])\n                    if rating < 0 or rating > 5:\n                        continue\n                except (ValueError, TypeError):\n                    continue\n            \n            # Additional business rules\n            if price == 0 and product_type in ['electronics', 'clothing']:\n                continue\n            \n            if 'brand' in normalized and len(normalized['brand']) > 50:\n                continue\n            \n            valid_records.append(product_id)\n            \n        except Exception:\n            continue\n    \n    # Remove duplicates and sort\n    unique_ids = list(set(valid_records))\n    \n    # Sort with custom logic - numeric IDs first, then alphabetic\n    def sort_key(item):\n        if item.isdigit():\n            return (0, int(item))\n        else:\n            return (1, item.lower())\n    \n    return sorted(unique_ids, key=sort_key)\n```", "error": null, "raw_item": {"task_id": "se_filter_map_validate_nested", "entry_point": "filter_map_validate", "prompt": "Write filter_map_validate(records) that normalizes, validates, and filters product records, returning sorted list of valid IDs. Complex multi-step validation with price parsing, type constraints, and conditional rules. Return only the Python function code with no explanations.", "canonical_solution": "import re\n\ntype_order = {\"ent\": 0, \"pro\": 1, \"std\": 2}\n\ndef _parse_price(x):\n    if isinstance(x, (int, float)):\n        return float(x) if x >= 0 else None\n    if not isinstance(x, str):\n        return None\n    s = x.strip()\n    if not s:\n        return None\n    s = re.sub(r\"[\\s$€£¥]\", \"\", s)\n    if \",\" in s and \".\" in s:\n        if s.find(\",\") < s.find(\".\"):\n            s = s.replace(\",\", \"\")\n        else:\n            s = s.replace(\".\", \"\").replace(\",\", \".\")\n    elif \",\" in s:\n        s = s.replace(\",\", \".\")\n    try:\n        v = float(s)\n        return v if v >= 0 else None\n    except Exception:\n        return None\n\ndef _to_int(x):\n    if isinstance(x, bool):\n        return None\n    if isinstance(x, int):\n        return x\n    if isinstance(x, str):\n        s = x.strip()\n        if s and s.lstrip(\"-+\").isdigit():\n            try:\n                return int(s)\n            except Exception:\n                return None\n    return None\n\ndef _to_float(x):\n    if isinstance(x, (int, float)):\n        return float(x)\n    if isinstance(x, str):\n        try:\n            return float(x.strip())\n        except Exception:\n            return None\n    return None\n\ndef _to_pct(x):\n    if x is None:\n        return None\n    if isinstance(x, (int, float)):\n        v = float(x)\n    elif isinstance(x, str):\n        try:\n            v = float(x.strip().strip('%'))\n        except Exception:\n            return None\n    else:\n        return None\n    if v < 0:\n        v = 0.0\n    if v > 100:\n        v = 100.0\n    return v\n\ndef filter_map_validate(records):\n    if not isinstance(records, list):\n        return []\n    kept = []\n    for rec in records:\n        if not isinstance(rec, dict):\n            continue\n        # --- id ---\n        rid = rec.get(\"id\")\n        rid = str(rid).strip() if rid is not None else \"\"\n        if not rid:\n            continue\n        # --- meta ---\n        meta = rec.get(\"meta\") or {}\n        if not isinstance(meta, dict):\n            meta = {}\n        rtype = str(meta.get(\"type\") or \"\").strip().lower()\n        flags = meta.get(\"flags\")\n        if isinstance(flags, list):\n            flags_norm = [str(t).strip().lower() for t in flags if isinstance(t, (str, int, float))]\n        else:\n            flags_norm = []\n        if rtype not in (\"std\",\"pro\",\"ent\"):\n            continue\n        # --- price ---\n        price = _parse_price(rec.get(\"price\"))\n        if price is None:\n            continue\n        # --- attrs ---\n        attrs = rec.get(\"attrs\") or {}\n        if not isinstance(attrs, dict):\n            attrs = {}\n        color = attrs.get(\"color\")\n        color = str(color).strip().lower() if isinstance(color, str) else None\n        size = attrs.get(\"size\")\n        if size is not None:\n            size = _to_int(size)\n        weight = attrs.get(\"weight\")\n        if weight is not None:\n            weight = _to_float(weight)\n        cond = attrs.get(\"condition\")\n        cond = str(cond).strip().upper() if isinstance(cond, str) else None\n        discount = _to_pct(attrs.get(\"discount\"))\n        # --- stock ---\n        stock = _to_int(rec.get(\"stock\"))\n        if stock is None:\n            stock = 0\n        if stock < 0:\n            stock = 0\n        # --- Validation A: color/flag gate ---\n        if not ((color in {\"red\",\"blue\",\"green\"}) or (\"eco\" in flags_norm)):\n            continue\n        # --- Validation B: price caps ---\n        if rtype in (\"std\",\"pro\") and price > 1000:\n            continue\n        if rtype == \"ent\" and price > 5000:\n            continue\n        # --- Validation C: refurb implies good condition ---\n        if \"refurb\" in flags_norm:\n            if cond not in {\"A\",\"B\"}:\n                continue\n        # --- Validation D: ent requires size>=10 and stock>=1 ---\n        if rtype == \"ent\":\n            if size is None or size < 10 or stock < 1:\n                continue\n        # --- Validation E: pro weight <= 50 if provided ---\n        if rtype == \"pro\" and weight is not None and weight > 50.0:\n            continue\n        kept.append({\n            \"id\": rid,\n            \"type\": rtype,\n            \"price\": price\n        })\n    # sort: type order (ent > pro > std) i.e., ent first, then pro, then std\n    kept.sort(key=lambda r: (type_order.get(r[\"type\"], 3), r[\"price\"], r[\"id\"].lower()))\n    return [r[\"id\"] for r in kept]\n", "test": [{"input": [[{"id": " A-1 ", "meta": {"type": "ent", "flags": ["Eco"]}, "price": "€4,999.00", "attrs": {"size": "12", "color": "Green"}, "stock": "5"}, {"id": "B-2", "meta": {"type": "pro", "flags": ["refurb"]}, "price": "$800", "attrs": {"weight": "49.5", "color": "blue", "condition": "B"}, "stock": 0}, {"id": "c-3", "meta": {"type": "std", "flags": []}, "price": "1200", "attrs": {"color": "red"}, "stock": 10}, {"id": "d-4", "meta": {"type": "ent", "flags": ["eco", "refurb"]}, "price": "5100", "attrs": {"size": 15, "color": "green", "condition": "A"}, "stock": 2}, {"id": "e-5", "meta": {"type": "pro", "flags": []}, "price": "999.99", "attrs": {"color": "yellow"}, "stock": 7}]], "output": ["A-1", "B-2"]}, {"input": [[{"id": 101, "meta": {"type": "pro", "flags": ["eco"]}, "price": "1,000.00", "attrs": {"color": "RED", "weight": "50"}, "stock": "-3"}, {"id": 102, "meta": {"type": "pro", "flags": ["eco"]}, "price": "1,000.01", "attrs": {"color": "GREEN", "weight": "10"}, "stock": "0"}, {"id": 103, "meta": {"type": "std", "flags": ["eco"]}, "price": "$0", "attrs": {"color": "green"}, "stock": "0"}]], "output": ["101", "103"]}, {"input": [[{"id": "X", "meta": {"type": "ent", "flags": ["REFURB"]}, "price": "$4500", "attrs": {"size": "9", "color": "blue", "condition": "A"}, "stock": 1}, {"id": "Y", "meta": {"type": "ent", "flags": []}, "price": "$4500", "attrs": {"size": "12", "color": "blue"}, "stock": 0}, {"id": "Z", "meta": {"type": "ent", "flags": []}, "price": "$4500", "attrs": {"size": "12", "color": "blue"}, "stock": 3}]], "output": ["Z"]}, {"input": [[{"id": "bad", "meta": {"type": "other", "flags": ["eco"]}, "price": "100", "attrs": {"color": "red"}, "stock": 1}, {"id": "ok-std", "meta": {"type": "std", "flags": ["eco"]}, "price": "1000", "attrs": {"color": "green"}, "stock": 0}]], "output": ["ok-std"]}, {"input": [[{"id": "keep-pro-over-std", "meta": {"type": "pro", "flags": ["eco"]}, "price": "500", "attrs": {"color": "blue"}}, {"id": "keep-ent-first", "meta": {"type": "ent", "flags": ["eco"]}, "price": "1200", "attrs": {"color": "green", "size": 20}, "stock": 2}, {"id": "keep-std-last", "meta": {"type": "std", "flags": ["eco"]}, "price": "100", "attrs": {"color": "red"}}]], "output": ["keep-ent-first", "keep-pro-over-std", "keep-std-last"]}]}}
{"timestamp_utc": "2025-09-16T06:16:00.927832", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 26, "question": "Write sliding_window_max(arr, k) that returns maximum element in each sliding window of size k using deque. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.50134015083313, "response": "```python\nfrom collections import deque\n\ndef sliding_window_max(arr, k):\n    if not arr or k <= 0 or k > len(arr):\n        return []\n    \n    dq = deque()\n    result = []\n    \n    for i in range(len(arr)):\n        # Remove elements outside current window\n        while dq and dq[0] <= i - k:\n            dq.popleft()\n        \n        # Remove elements smaller than current element\n        while dq and arr[dq[-1]] <= arr[i]:\n            dq.pop()\n        \n        dq.append(i)\n        \n        # Add to result when window is complete\n        if i >= k - 1:\n            result.append(arr[dq[0]])\n    \n    return result\n```", "error": null, "raw_item": {"task_id": "custom_sliding_window_max", "prompt": "Write sliding_window_max(arr, k) that returns maximum element in each sliding window of size k using deque. Return only the Python function code with no explanations.", "entry_point": "sliding_window_max", "canonical_solution": "from collections import deque\n\ndef sliding_window_max(arr: list[int], k: int) -> list[int]:\n    if not arr or k == 0:\n        return []\n    \n    dq = deque()\n    result = []\n    \n    for i in range(len(arr)):\n        # Remove elements outside current window\n        while dq and dq[0] <= i - k:\n            dq.popleft()\n        \n        # Remove elements smaller than current element\n        while dq and arr[dq[-1]] <= arr[i]:\n            dq.pop()\n        \n        dq.append(i)\n        \n        # Add maximum to result if window is complete\n        if i >= k - 1:\n            result.append(arr[dq[0]])\n    \n    return result", "test": [{"input": [[1, 3, -1, -3, 5, 3, 6, 7], 3], "output": [3, 3, 5, 5, 6, 7]}, {"input": [[1, 2, 3], 1], "output": [1, 2, 3]}, {"input": [[5, 4, 3, 2, 1], 2], "output": [5, 4, 3, 2]}, {"input": [[1], 1], "output": [1]}, {"input": [[], 3], "output": []}, {"input": [[7, 2, 4], 3], "output": [7]}]}}
{"timestamp_utc": "2025-09-16T06:16:04.409100", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 27, "question": "Write rotate_matrix(matrix) that rotates n×n matrix 90 degrees clockwise in-place using transpose and reverse. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.4788458347320557, "response": "```python\ndef rotate_matrix(matrix):\n    n = len(matrix)\n    \n    # Transpose the matrix\n    for i in range(n):\n        for j in range(i, n):\n            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n    \n    # Reverse each row\n    for i in range(n):\n        matrix[i].reverse()\n```", "error": null, "raw_item": {"task_id": "custom_rotate_matrix", "prompt": "Write rotate_matrix(matrix) that rotates n×n matrix 90 degrees clockwise in-place using transpose and reverse. Return only the Python function code with no explanations.", "entry_point": "rotate_matrix", "canonical_solution": "def rotate_matrix(matrix: list[list[int]]) -> list[list[int]]:\n    if not matrix or not matrix[0]:\n        return matrix\n    \n    n = len(matrix)\n    \n    # Transpose the matrix\n    for i in range(n):\n        for j in range(i, n):\n            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n    \n    # Reverse each row\n    for i in range(n):\n        matrix[i].reverse()\n    \n    return matrix", "test": [{"input": [[[1, 2, 3], [4, 5, 6], [7, 8, 9]]], "output": [[7, 4, 1], [8, 5, 2], [9, 6, 3]]}, {"input": [[[1, 2], [3, 4]]], "output": [[3, 1], [4, 2]]}, {"input": [[[1]]], "output": [[1]]}, {"input": [[]], "output": []}, {"input": [[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]], "output": [[13, 9, 5, 1], [14, 10, 6, 2], [15, 11, 7, 3], [16, 12, 8, 4]]}]}}
{"timestamp_utc": "2025-09-16T06:16:08.929795", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 28, "question": "Write is_arithmetic_sequence(seq) that checks if sequence forms arithmetic progression with common difference > 0. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.5184998512268066, "response": "```python\ndef is_arithmetic_sequence(seq):\n    if len(seq) < 2:\n        return False\n    \n    diff = seq[1] - seq[0]\n    if diff <= 0:\n        return False\n    \n    for i in range(2, len(seq)):\n        if seq[i] - seq[i-1] != diff:\n            return False\n    \n    return True\n```", "error": null, "raw_item": {"task_id": "alg_arithmetic_sequence", "entry_point": "is_arithmetic_sequence", "prompt": "Write is_arithmetic_sequence(seq) that checks if sequence forms arithmetic progression with common difference > 0. Return only the Python function code with no explanations.", "canonical_solution": "def is_arithmetic_sequence(seq):\n    if len(seq) < 2:\n        return False\n    diff = seq[1] - seq[0]\n    if diff <= 0:\n        return False\n    for i in range(2, len(seq)):\n        if seq[i] - seq[i-1] != diff:\n            return False\n    return True", "test": [{"input": [[1, 3, 5, 7, 9]], "output": true}, {"input": [[2, 4, 6, 8]], "output": true}, {"input": [[5, 5, 5]], "output": false}, {"input": [[1, 2, 4, 8]], "output": false}, {"input": [[10, 5, 0]], "output": false}]}}
{"timestamp_utc": "2025-09-16T06:16:12.873626", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 29, "question": "Write classify_severity(msg) that returns HIGH if msg contains 'error' or 'critical', MEDIUM if contains 'warning', LOW otherwise. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.9417378902435303, "response": "```python\ndef classify_severity(msg):\n    msg_lower = msg.lower()\n    if 'error' in msg_lower or 'critical' in msg_lower:\n        return 'HIGH'\n    elif 'warning' in msg_lower:\n        return 'MEDIUM'\n    else:\n        return 'LOW'\n```", "error": null, "raw_item": {"task_id": "se_severity_classifier", "entry_point": "classify_severity", "prompt": "Write classify_severity(msg) that returns HIGH if msg contains 'error' or 'critical', MEDIUM if contains 'warning', LOW otherwise. Return only the Python function code with no explanations.", "canonical_solution": "def classify_severity(msg):\n    msg_lower = msg.lower()\n    if 'error' in msg_lower or 'critical' in msg_lower:\n        return 'HIGH'\n    elif 'warning' in msg_lower:\n        return 'MEDIUM'\n    else:\n        return 'LOW'", "test": [{"input": ["System error occurred"], "output": "HIGH"}, {"input": ["Critical failure detected"], "output": "HIGH"}, {"input": ["Warning: disk space low"], "output": "MEDIUM"}, {"input": ["Info: task completed"], "output": "LOW"}, {"input": ["ERROR in database"], "output": "HIGH"}]}}
{"timestamp_utc": "2025-09-16T06:16:16.275786", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 30, "question": "Write find_peak_index(arr) that finds index of first element that is greater than both neighbors. Return -1 if no peak exists. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.399945020675659, "response": "```python\ndef find_peak_index(arr):\n    if len(arr) < 3:\n        return -1\n    \n    for i in range(1, len(arr) - 1):\n        if arr[i] > arr[i-1] and arr[i] > arr[i+1]:\n            return i\n    \n    return -1\n```", "error": null, "raw_item": {"task_id": "alg_peak_finder", "entry_point": "find_peak_index", "prompt": "Write find_peak_index(arr) that finds index of first element that is greater than both neighbors. Return -1 if no peak exists. Return only the Python function code with no explanations.", "canonical_solution": "def find_peak_index(arr):\n    if len(arr) < 3:\n        return -1\n    for i in range(1, len(arr) - 1):\n        if arr[i] > arr[i-1] and arr[i] > arr[i+1]:\n            return i\n    return -1", "test": [{"input": [[1, 3, 2, 4, 1]], "output": 1}, {"input": [[1, 2, 3, 2, 1]], "output": 2}, {"input": [[1, 2, 3, 4, 5]], "output": -1}, {"input": [[5, 4, 3, 2, 1]], "output": -1}, {"input": [[1, 3, 1]], "output": 1}]}}
{"timestamp_utc": "2025-09-16T06:16:28.789433", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 31, "question": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 11.511086225509644, "response": "Looking at this problem, I need to:\n\n1. Group words that are anagrams of each other\n2. Sort words within each group alphabetically\n3. Sort groups by their first word alphabetically\n\nTwo words are anagrams if they contain the same letters with the same frequency. I can use sorted characters as a key to group anagrams together.\n\nHere's my solution:\n\n```python\ndef find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"\n    if not words:\n        return []\n    \n    # Dictionary to group anagrams\n    # Key: sorted characters of the word\n    # Value: list of words that are anagrams\n    anagram_groups = {}\n    \n    for word in words:\n        # Create a key by sorting the characters in the word\n        key = ''.join(sorted(word))\n        \n        if key not in anagram_groups:\n            anagram_groups[key] = []\n        anagram_groups[key].append(word)\n    \n    # Sort words within each group alphabetically\n    for group in anagram_groups.values():\n        group.sort()\n    \n    # Convert to list of groups and sort by the first word in each group\n    result = list(anagram_groups.values())\n    result.sort(key=lambda group: group[0])\n    \n    return result\n```\n\nLet me trace through the first example:\n- Input: `[\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"]`\n- \"eat\" → key: \"aet\" → group: [\"eat\"]\n- \"tea\" → key: \"aet\" → group: [\"eat\", \"tea\"] \n- \"tan\" → key: \"ant\" → group: [\"tan\"]\n- \"ate\" → key: \"aet\" → group: [\"eat\", \"tea\", \"ate\"]\n- \"nat\" → key: \"ant\" → group: [\"tan\", \"nat\"]\n- \"bat\" → key: \"abt\" → group: [\"bat\"]\n\nAfter sorting within groups:\n- \"aet\": [\"ate\", \"eat\", \"tea\"]\n- \"ant\": [\"nat\", \"tan\"]  \n- \"abt\": [\"bat\"]\n\nAfter sorting groups by first word: `[['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]`\n\nThe algorithm works by:\n1. Using sorted characters as a canonical representation for anagrams\n2. Grouping words with the same sorted character pattern\n3. Sorting words within each group alphabetically\n4. Sorting the groups by their first (lexicographically smallest) word\n\nTime complexity: O(n * m * log(m) + n * log(n)) where n is the number of words and m is the average length of words.\nSpace complexity: O(n * m) for storing the groups.", "error": null, "raw_item": {"task_id": "custom_find_anagrams", "prompt": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"\n    ", "entry_point": "find_anagrams", "canonical_solution": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    from collections import defaultdict\n    \n    anagram_groups = defaultdict(list)\n    \n    for word in words:\n        # Use sorted characters as key\n        key = ''.join(sorted(word))\n        anagram_groups[key].append(word)\n    \n    result = []\n    for group in anagram_groups.values():\n        group.sort()\n        result.append(group)\n    \n    # Sort groups by their first word\n    result.sort(key=lambda x: x[0])\n    \n    return result", "test": [{"input": [["eat", "tea", "tan", "ate", "nat", "bat"]], "output": [["ate", "eat", "tea"], ["bat"], ["nat", "tan"]]}, {"input": [["hello", "world"]], "output": [["hello"], ["world"]]}, {"input": [[]], "output": []}, {"input": [["a", "aa", "aaa"]], "output": [["a"], ["aa"], ["aaa"]]}, {"input": [["abc", "bca", "cab", "xyz"]], "output": [["abc", "bca", "cab"], ["xyz"]]}]}}
{"timestamp_utc": "2025-09-16T06:16:40.785270", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 32, "question": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 10.993027210235596, "response": "Looking at this problem, I need to merge overlapping intervals. The key insights are:\n\n1. Sort intervals by their start times to process them in order\n2. For each interval, check if it overlaps with the previous merged interval\n3. If it overlaps, merge them by extending the end time\n4. If it doesn't overlap, add it as a new interval\n\nTwo intervals overlap if the start of the current interval is less than or equal to the end of the previous interval.\n\n```python\ndef merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"\n    if not intervals:\n        return []\n    \n    # Sort intervals by start time\n    intervals.sort(key=lambda x: x[0])\n    \n    merged = [intervals[0]]\n    \n    for current in intervals[1:]:\n        last_merged = merged[-1]\n        \n        # Check if current interval overlaps with the last merged interval\n        if current[0] <= last_merged[1]:\n            # Merge by extending the end time\n            last_merged[1] = max(last_merged[1], current[1])\n        else:\n            # No overlap, add current interval\n            merged.append(current)\n    \n    return merged\n```\n\nLet me trace through the examples:\n\n**Example 1:** `[[1, 3], [2, 6], [8, 10], [15, 18]]`\n- After sorting: `[[1, 3], [2, 6], [8, 10], [15, 18]]` (already sorted)\n- Start with `merged = [[1, 3]]`\n- `[2, 6]`: 2 ≤ 3, so merge → `[[1, 6]]`\n- `[8, 10]`: 8 > 6, so add → `[[1, 6], [8, 10]]`\n- `[15, 18]`: 15 > 10, so add → `[[1, 6], [8, 10], [15, 18]]`\n\n**Example 2:** `[[1, 4], [4, 5]]`\n- `[4, 5]`: 4 ≤ 4, so merge → `[[1, 5]]`\n\n**Example 3:** `[[1, 4], [0, 2], [3, 5]]`\n- After sorting: `[[0, 2], [1, 4], [3, 5]]`\n- Start with `merged = [[0, 2]]`\n- `[1, 4]`: 1 ≤ 2, so merge → `[[0, 4]]`\n- `[3, 5]`: 3 ≤ 4, so merge → `[[0, 5]]`\n\nThe algorithm runs in O(n log n) time due to sorting, and O(1) extra space if we don't count the output array.", "error": null, "raw_item": {"task_id": "custom_merge_intervals", "prompt": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"\n    ", "entry_point": "merge_intervals", "canonical_solution": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    if not intervals:\n        return []\n    \n    # Sort intervals by start time\n    intervals.sort(key=lambda x: x[0])\n    \n    merged = [intervals[0]]\n    \n    for current in intervals[1:]:\n        last = merged[-1]\n        \n        # Check if current interval overlaps with last merged interval\n        if current[0] <= last[1]:\n            # Merge intervals\n            last[1] = max(last[1], current[1])\n        else:\n            # No overlap, add current interval\n            merged.append(current)\n    \n    return merged", "test": [{"input": [[[1, 3], [2, 6], [8, 10], [15, 18]]], "output": [[1, 6], [8, 10], [15, 18]]}, {"input": [[[1, 4], [4, 5]]], "output": [[1, 5]]}, {"input": [[[1, 4], [0, 2], [3, 5]]], "output": [[0, 5]]}, {"input": [[]], "output": []}, {"input": [[[1, 2]]], "output": [[1, 2]]}, {"input": [[[1, 4], [2, 3]]], "output": [[1, 4]]}]}}
{"timestamp_utc": "2025-09-16T06:16:51.004072", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 33, "question": "def binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 9.21642804145813, "response": "Looking at this problem, I need to find all paths from root to leaf nodes in a binary tree and return them as strings with arrows.\n\nLet me break down the approach:\n1. Handle the base case where root is None\n2. Use DFS to traverse the tree\n3. Keep track of the current path\n4. When I reach a leaf node (no left or right children), add the path to results\n5. Format the path with arrows between values\n\nHere's my solution:\n\n```python\ndef binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"\n    if not root:\n        return []\n    \n    result = []\n    \n    def dfs(node, path):\n        # If this is a leaf node (no left or right children)\n        if not node['left'] and not node['right']:\n            result.append(path)\n            return\n        \n        # Recursively explore left subtree\n        if node['left']:\n            dfs(node['left'], path + '->' + str(node['left']['val']))\n        \n        # Recursively explore right subtree\n        if node['right']:\n            dfs(node['right'], path + '->' + str(node['right']['val']))\n    \n    # Start DFS from root\n    dfs(root, str(root['val']))\n    \n    return result\n```\n\nThe algorithm works as follows:\n\n1. **Base case**: If root is None, return empty list\n2. **DFS helper function**: Takes current node and current path string\n3. **Leaf detection**: If node has no left or right children, it's a leaf - add current path to results\n4. **Recursive exploration**: For each existing child, extend the path with arrow and child's value, then recurse\n5. **Path building**: Build path string incrementally using arrow notation\n\nTime complexity: O(N) where N is the number of nodes, since we visit each node once.\nSpace complexity: O(H) for recursion stack where H is the height of the tree, plus O(P×L) for storing paths where P is number of paths and L is average path length.\n\nThe solution handles all the test cases:\n- Tree with multiple paths: `['1->2->5', '1->3']`\n- Single node tree: `['1']` \n- Empty tree: `[]`", "error": null, "raw_item": {"task_id": "custom_binary_tree_paths", "prompt": "def binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"\n    ", "entry_point": "binary_tree_paths", "canonical_solution": "def binary_tree_paths(root: dict | None) -> list[str]:\n    if not root:\n        return []\n    \n    paths = []\n    \n    def dfs(node, path):\n        if not node:\n            return\n        \n        # Add current node to path\n        current_path = path + [str(node['val'])]\n        \n        # If leaf node, add path to result\n        if not node['left'] and not node['right']:\n            paths.append('->'.join(current_path))\n            return\n        \n        # Recurse on children\n        if node['left']:\n            dfs(node['left'], current_path)\n        if node['right']:\n            dfs(node['right'], current_path)\n    \n    dfs(root, [])\n    return paths", "test": [{"input": [{"val": 1, "left": {"val": 2, "left": null, "right": {"val": 5, "left": null, "right": null}}, "right": {"val": 3, "left": null, "right": null}}], "output": ["1->2->5", "1->3"]}, {"input": [{"val": 1, "left": null, "right": null}], "output": ["1"]}, {"input": [null], "output": []}, {"input": [{"val": 1, "left": {"val": 2, "left": null, "right": null}, "right": {"val": 3, "left": null, "right": null}}], "output": ["1->2", "1->3"]}]}}
{"timestamp_utc": "2025-09-16T06:17:01.891756", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 34, "question": "def word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 9.885617971420288, "response": "Looking at this problem, I need to check if there's a bijection (one-to-one correspondence) between letters in the pattern and words in the string.\n\nLet me break down what this means:\n1. Each letter in the pattern must map to exactly one unique word\n2. Each word must map to exactly one unique letter\n3. The mapping must be consistent throughout\n\nHere's my solution:\n\n```python\ndef word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"\n    words = s.split()\n    \n    # First check: pattern and words must have same length\n    if len(pattern) != len(words):\n        return False\n    \n    # Create mappings in both directions\n    char_to_word = {}\n    word_to_char = {}\n    \n    for char, word in zip(pattern, words):\n        # Check if char already has a mapping\n        if char in char_to_word:\n            if char_to_word[char] != word:\n                return False\n        else:\n            char_to_word[char] = word\n        \n        # Check if word already has a mapping\n        if word in word_to_char:\n            if word_to_char[word] != char:\n                return False\n        else:\n            word_to_char[word] = char\n    \n    return True\n```\n\nLet me trace through the examples:\n\n1. `word_pattern(\"abba\", \"dog cat cat dog\")`:\n   - `a` maps to `dog`, `b` maps to `cat`\n   - When we see `b` again, it correctly maps to `cat`\n   - When we see `a` again, it correctly maps to `dog`\n   - Bijection exists → `True`\n\n2. `word_pattern(\"abba\", \"dog cat cat fish\")`:\n   - `a` maps to `dog`, `b` maps to `cat`\n   - When we see `a` again, it should map to `dog` but we have `fish`\n   - Bijection broken → `False`\n\n3. `word_pattern(\"aaaa\", \"dog cat cat dog\")`:\n   - `a` maps to `dog`\n   - When we see `a` again, it should map to `dog` but we have `cat`\n   - Bijection broken → `False`\n\n4. `word_pattern(\"abba\", \"dog dog dog dog\")`:\n   - `a` maps to `dog`, `b` tries to map to `dog`\n   - But `dog` is already mapped to `a`, so `b` can't also map to `dog`\n   - Bijection broken → `False`\n\nThe algorithm works by maintaining two dictionaries to ensure the mapping is truly bijective - each character maps to exactly one word, and each word maps to exactly one character.", "error": null, "raw_item": {"task_id": "custom_word_pattern", "prompt": "def word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"\n    ", "entry_point": "word_pattern", "canonical_solution": "def word_pattern(pattern: str, s: str) -> bool:\n    words = s.split()\n    \n    if len(pattern) != len(words):\n        return False\n    \n    char_to_word = {}\n    word_to_char = {}\n    \n    for char, word in zip(pattern, words):\n        # Check char -> word mapping\n        if char in char_to_word:\n            if char_to_word[char] != word:\n                return False\n        else:\n            char_to_word[char] = word\n        \n        # Check word -> char mapping (bijection)\n        if word in word_to_char:\n            if word_to_char[word] != char:\n                return False\n        else:\n            word_to_char[word] = char\n    \n    return True", "test": [{"input": ["abba", "dog cat cat dog"], "output": true}, {"input": ["abba", "dog cat cat fish"], "output": false}, {"input": ["aaaa", "dog cat cat dog"], "output": false}, {"input": ["abba", "dog dog dog dog"], "output": false}, {"input": ["abc", "dog cat fish"], "output": true}, {"input": ["a", "dog"], "output": true}, {"input": ["ab", "dog"], "output": false}]}}
{"timestamp_utc": "2025-09-16T06:17:15.347100", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 35, "question": "class MinStack:\n    \"\"\"\n    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\n    Implement the MinStack class:\n    - MinStack() initializes the stack object.\n    - push(val) pushes the element val onto the stack.\n    - pop() removes the element on the top of the stack.\n    - top() gets the top element of the stack.\n    - get_min() retrieves the minimum element in the stack.\n\n    You must implement a solution with O(1) time complexity for each function.\n\n    Examples:\n    >>> stack = MinStack()\n    >>> stack.push(-2)\n    >>> stack.push(0)\n    >>> stack.push(-3)\n    >>> stack.get_min()\n    -3\n    >>> stack.pop()\n    >>> stack.top()\n    0\n    >>> stack.get_min()\n    -2\n    \"\"\"", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 12.452769994735718, "response": "Looking at this problem, I need to design a stack that can retrieve the minimum element in O(1) time. The key insight is that I need to keep track of the minimum value as elements are added and removed.\n\nHere are two effective approaches:\n\n## Approach 1: Two Stacks (Main + Min Stack)\n\n```python\nclass MinStack:\n    def __init__(self):\n        \"\"\"Initialize the stack object.\"\"\"\n        self.stack = []      # Main stack to store all elements\n        self.min_stack = []  # Stack to store minimum values\n    \n    def push(self, val: int) -> None:\n        \"\"\"Push element val onto the stack.\"\"\"\n        self.stack.append(val)\n        \n        # Push to min_stack if it's empty or val is <= current minimum\n        if not self.min_stack or val <= self.min_stack[-1]:\n            self.min_stack.append(val)\n    \n    def pop(self) -> None:\n        \"\"\"Remove the element on top of the stack.\"\"\"\n        if self.stack:\n            popped = self.stack.pop()\n            # If popped element was the minimum, remove it from min_stack too\n            if self.min_stack and popped == self.min_stack[-1]:\n                self.min_stack.pop()\n    \n    def top(self) -> int:\n        \"\"\"Get the top element of the stack.\"\"\"\n        return self.stack[-1] if self.stack else None\n    \n    def get_min(self) -> int:\n        \"\"\"Retrieve the minimum element in the stack.\"\"\"\n        return self.min_stack[-1] if self.min_stack else None\n```\n\n## Approach 2: Single Stack with Tuples\n\n```python\nclass MinStack:\n    def __init__(self):\n        \"\"\"Initialize the stack object.\"\"\"\n        self.stack = []  # Each element is (value, current_minimum)\n    \n    def push(self, val: int) -> None:\n        \"\"\"Push element val onto the stack.\"\"\"\n        if not self.stack:\n            current_min = val\n        else:\n            current_min = min(val, self.stack[-1][1])\n        \n        self.stack.append((val, current_min))\n    \n    def pop(self) -> None:\n        \"\"\"Remove the element on top of the stack.\"\"\"\n        if self.stack:\n            self.stack.pop()\n    \n    def top(self) -> int:\n        \"\"\"Get the top element of the stack.\"\"\"\n        return self.stack[-1][0] if self.stack else None\n    \n    def get_min(self) -> int:\n        \"\"\"Retrieve the minimum element in the stack.\"\"\"\n        return self.stack[-1][1] if self.stack else None\n```\n\n## Test the implementation:\n\n```python\n# Test with the provided example\nstack = MinStack()\nstack.push(-2)\nstack.push(0)\nstack.push(-3)\nprint(stack.get_min())  # Output: -3\nstack.pop()\nprint(stack.top())      # Output: 0\nprint(stack.get_min())  # Output: -2\n\n# Additional test cases\nstack2 = MinStack()\nstack2.push(5)\nstack2.push(3)\nstack2.push(7)\nstack2.push(1)\nprint(stack2.get_min())  # Output: 1\nstack2.pop()\nprint(stack2.get_min())  # Output: 3\nstack2.push(2)\nprint(stack2.get_min())  # Output: 2\n```\n\n## Key Points:\n\n1. **Two Stacks Approach**: \n   - Uses separate stacks for values and minimums\n   - More memory efficient when there are fewer minimum changes\n   - Important: Use `<=` when pushing to min_stack to handle duplicates correctly\n\n2. **Single Stack with Tuples**:\n   - Each stack element stores both value and current minimum\n   - Simpler logic but uses more memory\n   - Each element knows the minimum up to that point\n\n3. **Time Complexity**: O(1) for all operations\n4. **Space Complexity**: O(n) where n is the number of elements\n\nBoth approaches work well. The two-stack approach is generally more memory-efficient, while the tuple approach is simpler to understand and implement.", "error": null, "raw_item": {"task_id": "custom_min_stack", "prompt": "class MinStack:\n    \"\"\"\n    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\n    Implement the MinStack class:\n    - MinStack() initializes the stack object.\n    - push(val) pushes the element val onto the stack.\n    - pop() removes the element on the top of the stack.\n    - top() gets the top element of the stack.\n    - get_min() retrieves the minimum element in the stack.\n\n    You must implement a solution with O(1) time complexity for each function.\n\n    Examples:\n    >>> stack = MinStack()\n    >>> stack.push(-2)\n    >>> stack.push(0)\n    >>> stack.push(-3)\n    >>> stack.get_min()\n    -3\n    >>> stack.pop()\n    >>> stack.top()\n    0\n    >>> stack.get_min()\n    -2\n    \"\"\"\n    ", "entry_point": "MinStack", "canonical_solution": "class MinStack:\n    def __init__(self):\n        self.stack = []\n        self.min_stack = []\n    \n    def push(self, val: int) -> None:\n        self.stack.append(val)\n        # Push to min_stack if it's empty or val is <= current minimum\n        if not self.min_stack or val <= self.min_stack[-1]:\n            self.min_stack.append(val)\n    \n    def pop(self) -> None:\n        if self.stack:\n            val = self.stack.pop()\n            # Pop from min_stack if the popped value was the minimum\n            if self.min_stack and val == self.min_stack[-1]:\n                self.min_stack.pop()\n    \n    def top(self) -> int:\n        return self.stack[-1] if self.stack else None\n    \n    def get_min(self) -> int:\n        return self.min_stack[-1] if self.min_stack else None", "test": [{"input": [["MinStack", "push", "push", "push", "get_min", "pop", "top", "get_min"], [[], [-2], [0], [-3], [], [], [], []]], "output": [null, null, null, null, -3, null, 0, -2]}, {"input": [["MinStack", "push", "push", "get_min", "get_min", "pop", "get_min"], [[], [1], [2], [], [], [], []]], "output": [null, null, null, 1, 1, null, 1]}, {"input": [["MinStack", "push", "get_min", "pop", "push", "get_min"], [[], [1], [], [], [2], []]], "output": [null, null, 1, null, null, 2]}]}}
{"timestamp_utc": "2025-09-16T06:17:27.835051", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 36, "question": "class LRUCache:\n    \"\"\"\n    Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.\n\n    Implement the LRUCache class:\n    - LRUCache(capacity) Initialize the LRU cache with positive size capacity.\n    - get(key) Return the value of the key if the key exists, otherwise return -1.\n    - put(key, value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache.\n      If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\n    The functions get and put must each run in O(1) average time complexity.\n\n    Examples:\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 11.48555612564087, "response": "Looking at this LRU Cache problem, I need to implement a data structure that maintains insertion/access order while providing O(1) operations. The key insight is to use a combination of a hash map for O(1) lookups and a doubly linked list for O(1) insertion/deletion operations.\n\nHere's my implementation:\n\n```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}  # key -> node mapping\n        \n        # Create dummy head and tail nodes for easier manipulation\n        self.head = Node(0, 0)\n        self.tail = Node(0, 0)\n        self.head.next = self.tail\n        self.tail.prev = self.head\n    \n    def get(self, key: int) -> int:\n        if key in self.cache:\n            node = self.cache[key]\n            # Move to front (most recently used)\n            self._remove(node)\n            self._add_to_front(node)\n            return node.value\n        return -1\n    \n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            # Update existing key\n            node = self.cache[key]\n            node.value = value\n            # Move to front\n            self._remove(node)\n            self._add_to_front(node)\n        else:\n            # Add new key-value pair\n            if len(self.cache) >= self.capacity:\n                # Remove least recently used (from tail)\n                lru = self.tail.prev\n                self._remove(lru)\n                del self.cache[lru.key]\n            \n            # Add new node to front\n            new_node = Node(key, value)\n            self.cache[key] = new_node\n            self._add_to_front(new_node)\n    \n    def _remove(self, node):\n        \"\"\"Remove node from doubly linked list\"\"\"\n        node.prev.next = node.next\n        node.next.prev = node.prev\n    \n    def _add_to_front(self, node):\n        \"\"\"Add node right after head (most recently used position)\"\"\"\n        node.prev = self.head\n        node.next = self.head.next\n        self.head.next.prev = node\n        self.head.next = node\n\nclass Node:\n    def __init__(self, key: int, value: int):\n        self.key = key\n        self.value = value\n        self.prev = None\n        self.next = None\n```\n\n**Key Design Decisions:**\n\n1. **Doubly Linked List**: Allows O(1) insertion and deletion at any position\n2. **Hash Map**: Provides O(1) lookup to find nodes by key\n3. **Dummy Head/Tail**: Simplifies edge cases when adding/removing nodes\n4. **Node Structure**: Stores both key and value (key needed for deletion from hash map)\n\n**How it works:**\n\n- **Most Recently Used**: Items are added right after the head\n- **Least Recently Used**: Items near the tail are the oldest\n- **Get Operation**: Move accessed item to front\n- **Put Operation**: \n  - If key exists: update value and move to front\n  - If new key: add to front, evict from tail if over capacity\n\n**Time Complexity:** O(1) for both get and put operations\n**Space Complexity:** O(capacity) for storing the cache\n\nThe implementation handles all the edge cases and maintains the LRU property efficiently by keeping the most recently used items at the front and evicting from the back when needed.", "error": null, "raw_item": {"task_id": "custom_lru_cache", "prompt": "class LRUCache:\n    \"\"\"\n    Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.\n\n    Implement the LRUCache class:\n    - LRUCache(capacity) Initialize the LRU cache with positive size capacity.\n    - get(key) Return the value of the key if the key exists, otherwise return -1.\n    - put(key, value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache.\n      If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\n    The functions get and put must each run in O(1) average time complexity.\n\n    Examples:\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"\n    ", "entry_point": "LRUCache", "canonical_solution": "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        # Use a list to maintain order (least recent at index 0)\n        self.order = []\n    \n    def get(self, key: int) -> int:\n        if key in self.cache:\n            # Move to end (most recently used)\n            self.order.remove(key)\n            self.order.append(key)\n            return self.cache[key]\n        return -1\n    \n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            # Update existing key\n            self.cache[key] = value\n            self.order.remove(key)\n            self.order.append(key)\n        else:\n            # Add new key\n            if len(self.cache) >= self.capacity:\n                # Remove least recently used\n                lru_key = self.order.pop(0)\n                del self.cache[lru_key]\n            \n            self.cache[key] = value\n            self.order.append(key)", "test": [{"input": [["LRUCache", "put", "put", "get", "put", "get", "put", "get", "get", "get"], [[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]], "output": [null, null, null, 1, null, -1, null, -1, 3, 4]}, {"input": [["LRUCache", "put", "get", "put", "get", "get"], [[1], [2, 1], [2], [3, 2], [2], [3]]], "output": [null, null, 1, null, -1, 2]}]}}
{"timestamp_utc": "2025-09-16T06:17:43.153656", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 37, "question": "def validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 14.316665887832642, "response": "Looking at this problem, I need to validate both IPv4 and IPv6 addresses according to their specific rules.\n\nLet me break down the validation logic:\n\n**IPv4 validation:**\n- Exactly 4 parts separated by dots\n- Each part must be a valid decimal number 0-255\n- No leading zeros except for \"0\" itself\n\n**IPv6 validation:**\n- Exactly 8 parts separated by colons\n- Each part must be 1-4 hexadecimal digits\n- Leading zeros are allowed\n\nHere's my solution:\n\n```python\ndef validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"\n    \n    def is_valid_ipv4(ip: str) -> bool:\n        parts = ip.split('.')\n        if len(parts) != 4:\n            return False\n        \n        for part in parts:\n            # Check if part is empty\n            if not part:\n                return False\n            \n            # Check for leading zeros (except for \"0\" itself)\n            if len(part) > 1 and part[0] == '0':\n                return False\n            \n            # Check if all characters are digits\n            if not part.isdigit():\n                return False\n            \n            # Check if number is in valid range\n            num = int(part)\n            if num > 255:\n                return False\n        \n        return True\n    \n    def is_valid_ipv6(ip: str) -> bool:\n        parts = ip.split(':')\n        if len(parts) != 8:\n            return False\n        \n        for part in parts:\n            # Check if part is empty or too long\n            if not part or len(part) > 4:\n                return False\n            \n            # Check if all characters are valid hexadecimal\n            for char in part:\n                if char not in '0123456789abcdefABCDEF':\n                    return False\n        \n        return True\n    \n    # Try IPv4 first\n    if '.' in ip and ':' not in ip:\n        if is_valid_ipv4(ip):\n            return \"IPv4\"\n    \n    # Try IPv6\n    elif ':' in ip and '.' not in ip:\n        if is_valid_ipv6(ip):\n            return \"IPv6\"\n    \n    return \"Neither\"\n```\n\nLet me test this with the provided examples:\n\n```python\n# Test cases\nprint(validate_ip_address(\"172.16.254.1\"))  # \"IPv4\"\nprint(validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\"))  # \"IPv6\"\nprint(validate_ip_address(\"256.256.256.256\"))  # \"Neither\"\nprint(validate_ip_address(\"192.168.1.1.1\"))  # \"Neither\"\n\n# Additional test cases\nprint(validate_ip_address(\"192.168.01.1\"))  # \"Neither\" (leading zero)\nprint(validate_ip_address(\"192.168..1\"))  # \"Neither\" (empty part)\nprint(validate_ip_address(\"2001:0db8:85a3::8a2e:0370:7334\"))  # \"Neither\" (wrong format)\nprint(validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:733g\"))  # \"Neither\" (invalid hex)\n```\n\nThe solution handles all the edge cases:\n- Leading zeros in IPv4 (not allowed except for \"0\")\n- Empty parts after splitting\n- Invalid characters\n- Numbers out of range for IPv4\n- Wrong number of parts\n- Mixed formats (containing both dots and colons)", "error": null, "raw_item": {"task_id": "custom_validate_ip_address", "prompt": "def validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"\n    ", "entry_point": "validate_ip_address", "canonical_solution": "def validate_ip_address(ip: str) -> str:\n    def is_valid_ipv4(ip):\n        parts = ip.split('.')\n        if len(parts) != 4:\n            return False\n        \n        for part in parts:\n            if not part or len(part) > 3:\n                return False\n            \n            # Check for leading zeros\n            if len(part) > 1 and part[0] == '0':\n                return False\n            \n            # Check if all characters are digits\n            if not part.isdigit():\n                return False\n            \n            # Check range\n            num = int(part)\n            if num < 0 or num > 255:\n                return False\n        \n        return True\n    \n    def is_valid_ipv6(ip):\n        parts = ip.split(':')\n        if len(parts) != 8:\n            return False\n        \n        for part in parts:\n            if not part or len(part) > 4:\n                return False\n            \n            # Check if all characters are valid hex\n            for char in part:\n                if char not in '0123456789abcdefABCDEF':\n                    return False\n        \n        return True\n    \n    if is_valid_ipv4(ip):\n        return \"IPv4\"\n    elif is_valid_ipv6(ip):\n        return \"IPv6\"\n    else:\n        return \"Neither\"", "test": [{"input": ["172.16.254.1"], "output": "IPv4"}, {"input": ["2001:0db8:85a3:0000:0000:8a2e:0370:7334"], "output": "IPv6"}, {"input": ["256.256.256.256"], "output": "Neither"}, {"input": ["192.168.1.1.1"], "output": "Neither"}, {"input": ["192.168.01.1"], "output": "Neither"}, {"input": ["2001:0db8:85a3::8a2e:0370:7334"], "output": "Neither"}, {"input": [""], "output": "Neither"}]}}
{"timestamp_utc": "2025-09-16T06:18:03.406430", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 38, "question": "Merge two dictionaries with integer values by keeping the maximum value for each key.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 19.251603364944458, "response": "Here are several ways to merge two dictionaries by keeping the maximum value for each key:\n\n## Method 1: Using Dictionary Comprehension (Recommended)\n\n```python\ndef merge_max_values(dict1, dict2):\n    \"\"\"Merge two dictionaries keeping the maximum value for each key.\"\"\"\n    all_keys = set(dict1.keys()) | set(dict2.keys())\n    return {key: max(dict1.get(key, float('-inf')), dict2.get(key, float('-inf'))) \n            for key in all_keys}\n\n# Example usage\ndict1 = {'a': 5, 'b': 10, 'c': 3}\ndict2 = {'b': 7, 'c': 15, 'd': 2}\n\nresult = merge_max_values(dict1, dict2)\nprint(result)  # {'a': 5, 'b': 10, 'c': 15, 'd': 2}\n```\n\n## Method 2: Using collections.defaultdict\n\n```python\nfrom collections import defaultdict\n\ndef merge_max_values_defaultdict(dict1, dict2):\n    \"\"\"Merge dictionaries using defaultdict.\"\"\"\n    result = defaultdict(lambda: float('-inf'))\n    \n    # Update with values from both dictionaries\n    for key, value in dict1.items():\n        result[key] = max(result[key], value)\n    \n    for key, value in dict2.items():\n        result[key] = max(result[key], value)\n    \n    return dict(result)\n\n# Example usage\ndict1 = {'a': 5, 'b': 10, 'c': 3}\ndict2 = {'b': 7, 'c': 15, 'd': 2}\n\nresult = merge_max_values_defaultdict(dict1, dict2)\nprint(result)  # {'a': 5, 'b': 10, 'c': 15, 'd': 2}\n```\n\n## Method 3: Using a Simple Loop\n\n```python\ndef merge_max_values_loop(dict1, dict2):\n    \"\"\"Merge dictionaries using a simple loop.\"\"\"\n    result = dict1.copy()  # Start with a copy of dict1\n    \n    for key, value in dict2.items():\n        if key in result:\n            result[key] = max(result[key], value)\n        else:\n            result[key] = value\n    \n    return result\n\n# Example usage\ndict1 = {'a': 5, 'b': 10, 'c': 3}\ndict2 = {'b': 7, 'c': 15, 'd': 2}\n\nresult = merge_max_values_loop(dict1, dict2)\nprint(result)  # {'a': 5, 'b': 10, 'c': 15, 'd': 2}\n```\n\n## Method 4: For Multiple Dictionaries\n\n```python\ndef merge_max_values_multiple(*dicts):\n    \"\"\"Merge multiple dictionaries keeping maximum values.\"\"\"\n    if not dicts:\n        return {}\n    \n    all_keys = set()\n    for d in dicts:\n        all_keys.update(d.keys())\n    \n    result = {}\n    for key in all_keys:\n        values = [d.get(key, float('-inf')) for d in dicts if key in d]\n        result[key] = max(values)\n    \n    return result\n\n# Example usage\ndict1 = {'a': 5, 'b': 10, 'c': 3}\ndict2 = {'b': 7, 'c': 15, 'd': 2}\ndict3 = {'a': 8, 'd': 1, 'e': 12}\n\nresult = merge_max_values_multiple(dict1, dict2, dict3)\nprint(result)  # {'a': 8, 'b': 10, 'c': 15, 'd': 2, 'e': 12}\n```\n\n## Method 5: Using Counter (if working with counts)\n\n```python\nfrom collections import Counter\n\ndef merge_max_counters(dict1, dict2):\n    \"\"\"Merge two dictionaries using Counter operations.\"\"\"\n    c1, c2 = Counter(dict1), Counter(dict2)\n    \n    # Get all keys and keep maximum values\n    result = {}\n    for key in set(c1.keys()) | set(c2.keys()):\n        result[key] = max(c1.get(key, 0), c2.get(key, 0))\n    \n    return result\n\n# Example usage\ndict1 = {'a': 5, 'b': 10, 'c': 3}\ndict2 = {'b': 7, 'c': 15, 'd': 2}\n\nresult = merge_max_counters(dict1, dict2)\nprint(result)  # {'a': 5, 'b': 10, 'c': 15, 'd': 2}\n```\n\n## Complete Example with Testing\n\n```python\ndef test_merge_functions():\n    \"\"\"Test all merge functions with various cases.\"\"\"\n    \n    # Test case 1: Normal case\n    dict1 = {'a': 5, 'b': 10, 'c': 3}\n    dict2 = {'b': 7, 'c': 15, 'd': 2}\n    expected = {'a': 5, 'b': 10, 'c': 15, 'd': 2}\n    \n    # Test case 2: One empty dictionary\n    dict3 = {}\n    dict4 = {'x': 1, 'y': 2}\n    expected2 = {'x': 1, 'y': 2}\n    \n    # Test case 3: No overlapping keys\n    dict5 = {'a': 1, 'b': 2}\n    dict6 = {'c': 3, 'd': 4}\n    expected3 = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\n    \n    print(\"Test Case 1:\")\n    print(f\"Result: {merge_max_values(dict1, dict2)}\")\n    print(f\"Expected: {expected}\")\n    \n    print(\"\\nTest Case 2:\")\n    print(f\"Result: {merge_max_values(dict3, dict4)}\")\n    print(f\"Expected: {expected2}\")\n    \n    print(\"\\nTest Case 3:\")\n    print(f\"Result: {merge_max_values(dict5, dict6)}\")\n    print(f\"Expected: {expected3}\")\n\n# Run tests\ntest_merge_functions()\n```\n\n**Key Points:**\n\n1. **Method 1 (Dictionary Comprehension)** is generally the most Pythonic and efficient\n2. **Method 3 (Simple Loop)** is easiest to understand and modify\n3. **Method 4** handles multiple dictionaries at once\n4. All methods preserve keys from both dictionaries\n5. Use `float('-inf')` as default to handle cases where a key exists in only one dictionary\n\nChoose the method that best fits your specific use case and coding style preferences!", "error": null, "raw_item": {"task_id": "MyBench/dict_merge_max", "prompt": "Merge two dictionaries with integer values by keeping the maximum value for each key.", "entry_point": "merge_max", "canonical_solution": "def merge_max(d1, d2):\n    out = dict(d1)\n    for k,v in d2.items():\n        out[k] = max(out.get(k, v), v)\n    return out", "test": [{"input": [{"a": 1, "b": 5}, {"b": 3, "c": 10}], "output": {"a": 1, "b": 5, "c": 10}}, {"input": [{}, {"x": 7}], "output": {"x": 7}}, {"input": [{"a": 5}, {"a": 5}], "output": {"a": 5}}, {"input": [{"m": -1, "n": 2}, {"m": -5, "o": 10}], "output": {"m": -1, "n": 2, "o": 10}}, {"input": [{}, {}], "output": {}}]}}
{"timestamp_utc": "2025-09-16T06:18:16.554896", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 39, "question": "Invert a dictionary where values may not be unique. Return a new dictionary mapping each value to a list of keys that had that value.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 12.145849704742432, "response": "Here are a few ways to invert a dictionary where values may not be unique:\n\n## Method 1: Using a loop with setdefault()\n\n```python\ndef invert_dict(d):\n    \"\"\"\n    Invert a dictionary, mapping each value to a list of keys that had that value.\n    \n    Args:\n        d: Dictionary to invert\n        \n    Returns:\n        Dictionary mapping values to lists of keys\n    \"\"\"\n    inverted = {}\n    for key, value in d.items():\n        inverted.setdefault(value, []).append(key)\n    return inverted\n```\n\n## Method 2: Using defaultdict\n\n```python\nfrom collections import defaultdict\n\ndef invert_dict(d):\n    \"\"\"\n    Invert a dictionary using defaultdict.\n    \n    Args:\n        d: Dictionary to invert\n        \n    Returns:\n        Dictionary mapping values to lists of keys\n    \"\"\"\n    inverted = defaultdict(list)\n    for key, value in d.items():\n        inverted[value].append(key)\n    return dict(inverted)  # Convert back to regular dict if needed\n```\n\n## Method 3: Using dictionary comprehension with groupby\n\n```python\nfrom itertools import groupby\n\ndef invert_dict(d):\n    \"\"\"\n    Invert a dictionary using itertools.groupby.\n    \n    Args:\n        d: Dictionary to invert\n        \n    Returns:\n        Dictionary mapping values to lists of keys\n    \"\"\"\n    # Sort by value to group consecutive items with same value\n    sorted_items = sorted(d.items(), key=lambda x: x[1])\n    return {value: [key for key, _ in group] \n            for value, group in groupby(sorted_items, key=lambda x: x[1])}\n```\n\n## Example usage:\n\n```python\n# Test the function\noriginal = {\n    'a': 1,\n    'b': 2,\n    'c': 1,\n    'd': 3,\n    'e': 2,\n    'f': 1\n}\n\nresult = invert_dict(original)\nprint(result)\n# Output: {1: ['a', 'c', 'f'], 2: ['b', 'e'], 3: ['d']}\n\n# Test with different data types\nmixed_dict = {\n    'name': 'John',\n    'age': 25,\n    'city': 'NYC',\n    'country': 'USA',\n    'nickname': 'John',\n    'zip': 25\n}\n\nresult2 = invert_dict(mixed_dict)\nprint(result2)\n# Output: {'John': ['name', 'nickname'], 25: ['age', 'zip'], 'NYC': ['city'], 'USA': ['country']}\n```\n\n## Key points:\n\n1. **Method 1** is the most straightforward and readable\n2. **Method 2** with `defaultdict` is very clean and efficient\n3. **Method 3** with `groupby` is more functional but requires sorting first\n\nAll methods handle:\n- Non-unique values correctly\n- Any hashable data types as values\n- Empty dictionaries\n- Preserving the order of keys (in the order they appear in the original dictionary)\n\nThe `defaultdict` approach (Method 2) is generally recommended as it's both efficient and readable.", "error": null, "raw_item": {"task_id": "dict_invert_multival", "prompt": "Invert a dictionary where values may not be unique. Return a new dictionary mapping each value to a list of keys that had that value.", "entry_point": "invert_multival", "canonical_solution": "def invert_multival(d):\n    out={}\n    for k,v in d.items():\n        out.setdefault(v, []).append(k)\n    return out", "test": [{"input": [{"a": 1, "b": 2, "c": 1}], "output": {"1": ["a", "c"], "2": ["b"]}}, {"input": [{}], "output": {}}, {"input": [{"x": "hi", "y": "hi", "z": "bye"}], "output": {"hi": ["x", "y"], "bye": ["z"]}}, {"input": [{"p": 0, "q": 0, "r": 0}], "output": {"0": ["p", "q", "r"]}}, {"input": [{"k": 42}], "output": {"42": ["k"]}}]}}
{"timestamp_utc": "2025-09-16T06:18:29.066067", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 40, "question": "Return True if an integer has even parity (even number of 1 bits in binary), else False.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 11.509385824203491, "response": "Here are several ways to check if an integer has even parity:\n\n## Method 1: Count bits using built-in function\n```python\ndef has_even_parity(n):\n    \"\"\"Return True if n has even number of 1 bits, False otherwise.\"\"\"\n    return bin(n).count('1') % 2 == 0\n```\n\n## Method 2: Using bit manipulation (Brian Kernighan's algorithm)\n```python\ndef has_even_parity(n):\n    \"\"\"Return True if n has even number of 1 bits, False otherwise.\"\"\"\n    count = 0\n    while n:\n        count += 1\n        n &= n - 1  # Remove the rightmost set bit\n    return count % 2 == 0\n```\n\n## Method 3: XOR-based approach (most efficient)\n```python\ndef has_even_parity(n):\n    \"\"\"Return True if n has even number of 1 bits, False otherwise.\"\"\"\n    parity = 0\n    while n:\n        parity ^= 1\n        n &= n - 1  # Remove the rightmost set bit\n    return parity == 0\n```\n\n## Method 4: Using bit_count() (Python 3.10+)\n```python\ndef has_even_parity(n):\n    \"\"\"Return True if n has even number of 1 bits, False otherwise.\"\"\"\n    return n.bit_count() % 2 == 0\n```\n\n## Test examples:\n```python\n# Test the function\ntest_cases = [0, 1, 2, 3, 4, 5, 6, 7, 8, 15, 16]\n\nfor num in test_cases:\n    binary = bin(num)[2:]  # Remove '0b' prefix\n    ones_count = binary.count('1')\n    result = has_even_parity(num)\n    print(f\"{num:2d} = {binary:>4s} -> {ones_count} ones -> Even parity: {result}\")\n```\n\nOutput:\n```\n 0 =    0 -> 0 ones -> Even parity: True\n 1 =    1 -> 1 ones -> Even parity: False\n 2 =   10 -> 1 ones -> Even parity: False\n 3 =   11 -> 2 ones -> Even parity: True\n 4 =  100 -> 1 ones -> Even parity: False\n 5 =  101 -> 2 ones -> Even parity: True\n 6 =  110 -> 2 ones -> Even parity: True\n 7 =  111 -> 3 ones -> Even parity: False\n 8 = 1000 -> 1 ones -> Even parity: False\n15 = 1111 -> 4 ones -> Even parity: True\n16 = 10000 -> 1 ones -> Even parity: False\n```\n\n**Recommendation**: Use Method 1 (`bin(n).count('1') % 2 == 0`) for simplicity and readability, or Method 4 if you're using Python 3.10+. Method 3 is the most efficient for very large numbers or performance-critical applications.", "error": null, "raw_item": {"task_id": "bitwise_parity", "prompt": "Return True if an integer has even parity (even number of 1 bits in binary), else False.", "entry_point": "even_parity", "canonical_solution": "def even_parity(n):\n    c=0\n    while n:\n        n&=n-1\n        c^=1\n    return c==0", "test": [{"input": [3], "output": false}, {"input": [5], "output": true}, {"input": [0], "output": true}, {"input": [15], "output": true}, {"input": [16], "output": false}, {"input": [255], "output": true}]}}
{"timestamp_utc": "2025-09-16T06:18:33.095766", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 41, "question": "Swap two integers without using a temporary variable, using bitwise XOR. Return the swapped pair as a tuple. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.026465892791748, "response": "```python\ndef swap_without_temp(a, b):\n    a = a ^ b\n    b = a ^ b\n    a = a ^ b\n    return (a, b)\n```", "error": null, "raw_item": {"task_id": "bitwise_swap", "prompt": "Swap two integers without using a temporary variable, using bitwise XOR. Return the swapped pair as a tuple. Return only the Python function code with no explanations.", "entry_point": "swap_xor", "canonical_solution": "def swap_xor(a,b):\n    a=a^b; b=a^b; a=a^b\n    return (a,b)", "test": [{"input": [2, 5], "output": [5, 2]}, {"input": [0, 7], "output": [7, 0]}, {"input": [-3, 9], "output": [9, -3]}, {"input": [42, 42], "output": [42, 42]}, {"input": [1000000, 123456], "output": [123456, 1000000]}]}}
{"timestamp_utc": "2025-09-16T06:18:36.677042", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 42, "question": "Compute factorial of n recursively. Assume n >= 0. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.5786831378936768, "response": "```python\ndef factorial(n):\n    if n == 0 or n == 1:\n        return 1\n    return n * factorial(n - 1)\n```", "error": null, "raw_item": {"task_id": "recursion_factorial", "prompt": "Compute factorial of n recursively. Assume n >= 0. Return only the Python function code with no explanations.", "entry_point": "factorial", "canonical_solution": "def factorial(n):\n    return 1 if n<=1 else n*factorial(n-1)", "test": [{"input": [0], "output": 1}, {"input": [1], "output": 1}, {"input": [5], "output": 120}, {"input": [10], "output": 3628800}, {"input": [3], "output": 6}]}}
{"timestamp_utc": "2025-09-16T06:18:41.077807", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 43, "question": "Return the BFS traversal order of a graph represented as adjacency list dict, starting from given node. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.3980872631073, "response": "```python\nfrom collections import deque\n\ndef bfs_traversal(graph, start):\n    visited = set()\n    queue = deque([start])\n    result = []\n    \n    while queue:\n        node = queue.popleft()\n        if node not in visited:\n            visited.add(node)\n            result.append(node)\n            for neighbor in graph.get(node, []):\n                if neighbor not in visited:\n                    queue.append(neighbor)\n    \n    return result\n```", "error": null, "raw_item": {"task_id": "graph_bfs_order", "prompt": "Return the BFS traversal order of a graph represented as adjacency list dict, starting from given node. Return only the Python function code with no explanations.", "entry_point": "bfs_order", "canonical_solution": "from collections import deque\n\ndef bfs_order(graph,start):\n    seen={start}; q=deque([start]); order=[]\n    while q:\n        u=q.popleft(); order.append(u)\n        for v in sorted(graph.get(u,[])):\n            if v not in seen:\n                seen.add(v); q.append(v)\n    return order", "test": [{"input": [{"A": ["B", "C"], "B": ["D"], "C": [], "D": []}, "A"], "output": ["A", "B", "C", "D"]}, {"input": [{"1": ["2"], "2": ["3"], "3": []}, "1"], "output": ["1", "2", "3"]}, {"input": [{"x": []}, "x"], "output": ["x"]}, {"input": [{"a": ["b"], "b": ["a"]}, "a"], "output": ["a", "b"]}, {"input": [{"m": ["n", "o"], "n": [], "o": []}, "m"], "output": ["m", "n", "o"]}]}}
{"timestamp_utc": "2025-09-16T06:18:44.930642", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 44, "question": "Given a CSV string with header 'name,value' and multiple rows, return the sum of the 'value' column as int. Assume comma-separated, no quotes. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.850555896759033, "response": "```python\ndef sum_csv_values(csv_string):\n    lines = csv_string.strip().split('\\n')\n    total = 0\n    for line in lines[1:]:\n        name, value = line.split(',')\n        total += int(value)\n    return total\n```", "error": null, "raw_item": {"task_id": "parsing_csv_sum", "prompt": "Given a CSV string with header 'name,value' and multiple rows, return the sum of the 'value' column as int. Assume comma-separated, no quotes. Return only the Python function code with no explanations.", "entry_point": "csv_sum", "canonical_solution": "def csv_sum(text):\n    lines=text.strip().split('\\n')\n    if len(lines) <= 1:\n        return 0\n    total=0\n    for line in lines[1:]:\n        if line.strip():\n            name,val=line.split(',')\n            total+=int(val)\n    return total", "test": [{"input": ["name,value\\na,3\\nb,7\\nc,10"], "output": 20}, {"input": ["name,value\\n"], "output": 0}, {"input": ["name,value\\nfoo,0\\nbar,0"], "output": 0}, {"input": ["name,value\\nx,100"], "output": 100}, {"input": ["name,value\\na,1\\nb,2\\nc,3\\nd,4"], "output": 10}]}}
{"timestamp_utc": "2025-09-16T06:18:48.858802", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 45, "question": "Extract all sequences of digits from a string using regex and return them as a list of strings. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.9266927242279053, "response": "```python\nimport re\n\ndef extract_digit_sequences(text):\n    return re.findall(r'\\d+', text)\n```", "error": null, "raw_item": {"task_id": "parsing_regex_digits", "prompt": "Extract all sequences of digits from a string using regex and return them as a list of strings. Return only the Python function code with no explanations.", "entry_point": "extract_digits", "canonical_solution": "import re\n\ndef extract_digits(s):\n    return re.findall(r'\\d+', s)", "test": [{"input": ["abc123de45f6"], "output": ["123", "45", "6"]}, {"input": ["no digits here"], "output": []}, {"input": ["2025year"], "output": ["2025"]}, {"input": ["a1b2c3d4"], "output": ["1", "2", "3", "4"]}, {"input": ["007bond"], "output": ["007"]}]}}
{"timestamp_utc": "2025-09-16T06:18:52.639405", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 46, "question": "Return the length of the longest increasing subsequence (LIS) in a list of integers. O(n^2) solution is fine. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.7791929244995117, "response": "```python\ndef lengthOfLIS(nums):\n    if not nums:\n        return 0\n    \n    dp = [1] * len(nums)\n    \n    for i in range(1, len(nums)):\n        for j in range(i):\n            if nums[j] < nums[i]:\n                dp[i] = max(dp[i], dp[j] + 1)\n    \n    return max(dp)\n```", "error": null, "raw_item": {"task_id": "algorithms_longest_increasing", "prompt": "Return the length of the longest increasing subsequence (LIS) in a list of integers. O(n^2) solution is fine. Return only the Python function code with no explanations.", "entry_point": "lis_length", "canonical_solution": "def lis_length(nums):\n    if not nums: return 0\n    dp=[1]*len(nums)\n    for i in range(len(nums)):\n        for j in range(i):\n            if nums[j]<nums[i]:\n                dp[i]=max(dp[i],dp[j]+1)\n    return max(dp)", "test": [{"input": [[10, 9, 2, 5, 3, 7, 101, 18]], "output": 4}, {"input": [[1, 2, 3, 4, 5]], "output": 5}, {"input": [[5, 4, 3, 2, 1]], "output": 1}, {"input": [[]], "output": 0}, {"input": [[2, 2, 2]], "output": 1}]}}
{"timestamp_utc": "2025-09-16T06:18:56.222806", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 47, "question": "0/1 Knapsack: given weights, values, and capacity W, return the maximum achievable value. Use DP. weights and values are equal length. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.581131935119629, "response": "```python\ndef knapsack(weights, values, W):\n    n = len(weights)\n    dp = [[0 for _ in range(W + 1)] for _ in range(n + 1)]\n    \n    for i in range(1, n + 1):\n        for w in range(1, W + 1):\n            if weights[i-1] <= w:\n                dp[i][w] = max(values[i-1] + dp[i-1][w-weights[i-1]], dp[i-1][w])\n            else:\n                dp[i][w] = dp[i-1][w]\n    \n    return dp[n][W]\n```", "error": null, "raw_item": {"task_id": "algorithms_knapsack01", "prompt": "0/1 Knapsack: given weights, values, and capacity W, return the maximum achievable value. Use DP. weights and values are equal length. Return only the Python function code with no explanations.", "entry_point": "knapsack01", "canonical_solution": "def knapsack01(weights, values, W):\n    n=len(weights)\n    dp=[[0]*(W+1) for _ in range(n+1)]\n    for i in range(1,n+1):\n        for w in range(W+1):\n            dp[i][w]=dp[i-1][w]\n            if weights[i-1]<=w:\n                dp[i][w]=max(dp[i][w], values[i-1]+dp[i-1][w-weights[i-1]])\n    return dp[n][W]", "test": [{"input": [[2, 3, 4], [4, 5, 6], 5], "output": 9}, {"input": [[1, 2, 3], [6, 10, 12], 5], "output": 22}, {"input": [[5], [10], 5], "output": 10}, {"input": [[5], [10], 4], "output": 0}, {"input": [[], [], 10], "output": 0}]}}
{"timestamp_utc": "2025-09-16T06:18:59.389658", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 48, "question": "Write parse_csv_numbers(text) that parses a CSV string of integers separated by commas and newlines. Return a 2D list of integers. Ignore empty lines. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.164152145385742, "response": "```python\ndef parse_csv_numbers(text):\n    lines = text.strip().split('\\n')\n    result = []\n    for line in lines:\n        line = line.strip()\n        if line:\n            row = [int(x.strip()) for x in line.split(',')]\n            result.append(row)\n    return result\n```", "error": null, "raw_item": {"task_id": "custom_parse_csv_numbers", "prompt": "Write parse_csv_numbers(text) that parses a CSV string of integers separated by commas and newlines. Return a 2D list of integers. Ignore empty lines. Return only the Python function code with no explanations.", "entry_point": "parse_csv_numbers", "canonical_solution": "def parse_csv_numbers(text: str) -> list[list[int]]:\n    rows = []\n    for line in text.strip().splitlines():\n        if not line.strip():\n            continue\n        row = [int(x.strip()) for x in line.split(',') if x.strip()]\n        rows.append(row)\n    return rows", "test": [{"input": ["1,2,3\n4,5,6"], "output": [[1, 2, 3], [4, 5, 6]]}, {"input": ["10,20\n30\n\n40,50"], "output": [[10, 20], [30], [40, 50]]}, {"input": ["   7 , 8 ,9  "], "output": [[7, 8, 9]]}, {"input": [""], "output": []}]}}
{"timestamp_utc": "2025-09-16T06:19:02.465059", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 49, "question": "Write normalize_json_keys(obj) that recursively converts all dictionary keys in a JSON-like object to lowercase strings. Works for nested dicts and lists. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.0732860565185547, "response": "```python\ndef normalize_json_keys(obj):\n    if isinstance(obj, dict):\n        return {str(key).lower(): normalize_json_keys(value) for key, value in obj.items()}\n    elif isinstance(obj, list):\n        return [normalize_json_keys(item) for item in obj]\n    else:\n        return obj\n```", "error": null, "raw_item": {"task_id": "custom_normalize_json_keys", "prompt": "Write normalize_json_keys(obj) that recursively converts all dictionary keys in a JSON-like object to lowercase strings. Works for nested dicts and lists. Return only the Python function code with no explanations.", "entry_point": "normalize_json_keys", "canonical_solution": "def normalize_json_keys(obj):\n    if isinstance(obj, dict):\n        return {str(k).lower(): normalize_json_keys(v) for k, v in obj.items()}\n    if isinstance(obj, list):\n        return [normalize_json_keys(x) for x in obj]\n    return obj", "test": [{"input": [{"Name": "Alice", "AGE": 30}], "output": {"name": "Alice", "age": 30}}, {"input": [[{"X": 1}, {"Y": 2}]], "output": [{"x": 1}, {"y": 2}]}, {"input": [{"Nested": {"KEY": 5}}], "output": {"nested": {"key": 5}}}, {"input": [123], "output": 123}]}}
{"timestamp_utc": "2025-09-16T06:19:07.093779", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 50, "question": "Write format_duration(seconds) that converts an integer number of seconds into a human-readable string using years, days, hours, minutes, and seconds. Skip units that are zero. Use plural form when needed. Example: 3661 → '1 hour, 1 minute, 1 second'. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.6275410652160645, "response": "```python\ndef format_duration(seconds):\n    if seconds == 0:\n        return \"now\"\n    \n    units = [\n        (\"year\", 365 * 24 * 60 * 60),\n        (\"day\", 24 * 60 * 60),\n        (\"hour\", 60 * 60),\n        (\"minute\", 60),\n        (\"second\", 1)\n    ]\n    \n    parts = []\n    \n    for unit_name, unit_seconds in units:\n        if seconds >= unit_seconds:\n            count = seconds // unit_seconds\n            seconds %= unit_seconds\n            \n            if count == 1:\n                parts.append(f\"1 {unit_name}\")\n            else:\n                parts.append(f\"{count} {unit_name}s\")\n    \n    if len(parts) == 1:\n        return parts[0]\n    elif len(parts) == 2:\n        return f\"{parts[0]} and {parts[1]}\"\n    else:\n        return \", \".join(parts[:-1]) + \" and \" + parts[-1]\n```", "error": null, "raw_item": {"task_id": "custom_format_duration", "prompt": "Write format_duration(seconds) that converts an integer number of seconds into a human-readable string using years, days, hours, minutes, and seconds. Skip units that are zero. Use plural form when needed. Example: 3661 → '1 hour, 1 minute, 1 second'. Return only the Python function code with no explanations.", "entry_point": "format_duration", "canonical_solution": "def format_duration(seconds: int) -> str:\n    units = [(\"year\", 365*24*3600), (\"day\", 24*3600), (\"hour\", 3600), (\"minute\", 60), (\"second\", 1)]\n    parts = []\n    for name, length in units:\n        if seconds >= length:\n            count, seconds = divmod(seconds, length)\n            parts.append(f\"{count} {name}{'s' if count != 1 else ''}\")\n    return \", \".join(parts) if parts else \"0 seconds\"", "test": [{"input": [0], "output": "0 seconds"}, {"input": [62], "output": "1 minute, 2 seconds"}, {"input": [3661], "output": "1 hour, 1 minute, 1 second"}, {"input": [31536000], "output": "1 year"}, {"input": [31556926], "output": "1 year, 6 hours, 9 minutes, 26 seconds"}]}}
{"timestamp_utc": "2025-09-16T06:19:11.162861", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 51, "question": "Write parse_key_value_config(text) that parses a configuration string with lines of the form 'key=value'. Ignore blank lines and lines starting with '#'. Return a dictionary with string keys and values converted to int if possible, else string. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.0668020248413086, "response": "```python\ndef parse_key_value_config(text):\n    config = {}\n    for line in text.strip().split('\\n'):\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        if '=' in line:\n            key, value = line.split('=', 1)\n            key = key.strip()\n            value = value.strip()\n            try:\n                value = int(value)\n            except ValueError:\n                pass\n            config[key] = value\n    return config\n```", "error": null, "raw_item": {"task_id": "custom_parse_key_value_config", "prompt": "Write parse_key_value_config(text) that parses a configuration string with lines of the form 'key=value'. Ignore blank lines and lines starting with '#'. Return a dictionary with string keys and values converted to int if possible, else string. Return only the Python function code with no explanations.", "entry_point": "parse_key_value_config", "canonical_solution": "def parse_key_value_config(text: str) -> dict:\n    result = {}\n    for line in text.splitlines():\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        if '=' in line:\n            k,v = line.split('=',1)\n            v = v.strip()\n            if v.isdigit():\n                result[k.strip()] = int(v)\n            else:\n                result[k.strip()] = v\n    return result", "test": [{"input": ["a=1\nb=2\nc=hello"], "output": {"a": 1, "b": 2, "c": "hello"}}, {"input": ["#comment\nx=42\ny=text"], "output": {"x": 42, "y": "text"}}, {"input": [""], "output": {}}]}}
{"timestamp_utc": "2025-09-16T06:19:15.255928", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 52, "question": "Write pretty_print_matrix(matrix) that formats a 2D list of integers into a string where each row is space-separated and rows are separated by newlines. Columns should be aligned to the maximum width of the largest number. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.090880870819092, "response": "```python\ndef pretty_print_matrix(matrix):\n    if not matrix or not matrix[0]:\n        return \"\"\n    \n    max_width = max(len(str(num)) for row in matrix for num in row)\n    \n    result = []\n    for row in matrix:\n        formatted_row = \" \".join(str(num).rjust(max_width) for num in row)\n        result.append(formatted_row)\n    \n    return \"\\n\".join(result)\n```", "error": null, "raw_item": {"task_id": "custom_pretty_print_matrix", "prompt": "Write pretty_print_matrix(matrix) that formats a 2D list of integers into a string where each row is space-separated and rows are separated by newlines. Columns should be aligned to the maximum width of the largest number. Return only the Python function code with no explanations.", "entry_point": "pretty_print_matrix", "canonical_solution": "def pretty_print_matrix(matrix: list[list[int]]) -> str:\n    if not matrix:\n        return ''\n    col_widths = [max(len(str(row[i])) for row in matrix) for i in range(len(matrix[0]))]\n    lines = []\n    for row in matrix:\n        line = ' '.join(str(val).rjust(col_widths[i]) for i,val in enumerate(row))\n        lines.append(line)\n    return '\\n'.join(lines)", "test": [{"input": [[[1, 20], [300, 4]]], "output": "  1 20\n300  4"}, {"input": [[[5]]], "output": "5"}, {"input": [[]], "output": ""}]}}
{"timestamp_utc": "2025-09-16T06:19:19.556599", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 53, "question": "Write unique_permutations(s) that returns all distinct permutations of string s in lexicographic order. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.298009157180786, "response": "```python\ndef unique_permutations(s):\n    def backtrack(chars, path, used, result):\n        if len(path) == len(chars):\n            result.append(''.join(path))\n            return\n        \n        for i in range(len(chars)):\n            if used[i]:\n                continue\n            if i > 0 and chars[i] == chars[i-1] and not used[i-1]:\n                continue\n            \n            used[i] = True\n            path.append(chars[i])\n            backtrack(chars, path, used, result)\n            path.pop()\n            used[i] = False\n    \n    chars = sorted(list(s))\n    result = []\n    used = [False] * len(chars)\n    backtrack(chars, [], used, result)\n    return result\n```", "error": null, "raw_item": {"task_id": "custom_unique_permutations", "prompt": "Write unique_permutations(s) that returns all distinct permutations of string s in lexicographic order. Return only the Python function code with no explanations.", "entry_point": "unique_permutations", "canonical_solution": "def unique_permutations(s: str) -> list[str]:\n    from itertools import permutations\n    return sorted(set(''.join(p) for p in permutations(s)))", "test": [{"input": ["aab"], "output": ["aab", "aba", "baa"]}, {"input": ["abc"], "output": ["abc", "acb", "bac", "bca", "cab", "cba"]}, {"input": ["x"], "output": ["x"]}]}}
{"timestamp_utc": "2025-09-16T06:19:23.954107", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 54, "question": "Write format_prime_factors(n) that returns the prime factorization of integer n as a string in the form 'p1^a1 * p2^a2 ...'. If exponent is 1, omit the '^1'. Example: 60 → '2^2 * 3 * 5'. Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 3.3945789337158203, "response": "```python\ndef format_prime_factors(n):\n    if n <= 1:\n        return str(n)\n    \n    factors = []\n    d = 2\n    \n    while d * d <= n:\n        count = 0\n        while n % d == 0:\n            n //= d\n            count += 1\n        if count > 0:\n            if count == 1:\n                factors.append(str(d))\n            else:\n                factors.append(f\"{d}^{count}\")\n        d += 1\n    \n    if n > 1:\n        factors.append(str(n))\n    \n    return \" * \".join(factors)\n```", "error": null, "raw_item": {"task_id": "custom_format_prime_factors", "prompt": "Write format_prime_factors(n) that returns the prime factorization of integer n as a string in the form 'p1^a1 * p2^a2 ...'. If exponent is 1, omit the '^1'. Example: 60 → '2^2 * 3 * 5'. Return only the Python function code with no explanations.", "entry_point": "format_prime_factors", "canonical_solution": "def format_prime_factors(n: int) -> str:\n    factors = []\n    d = 2\n    while d*d <= n:\n        count = 0\n        while n % d == 0:\n            n //= d\n            count += 1\n        if count:\n            factors.append(f\"{d}^{count}\" if count>1 else str(d))\n        d += 1\n    if n > 1:\n        factors.append(str(n))\n    return ' * '.join(factors)", "test": [{"input": [60], "output": "2^2 * 3 * 5"}, {"input": [13], "output": "13"}, {"input": [1024], "output": "2^10"}]}}
{"timestamp_utc": "2025-09-16T06:19:34.511771", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 55, "question": "Write validate_expression(expr) that checks if a string is a valid arithmetic expression containing only digits, +, -, *, /, parentheses, and spaces. Return True if valid, else False. Parentheses must be balanced and no invalid sequences allowed (e.g. '*/', '++', empty parentheses). Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 9.555135011672974, "response": "```python\ndef validate_expression(expr):\n    if not expr or not expr.strip():\n        return False\n    \n    # Remove spaces\n    expr = expr.replace(' ', '')\n    \n    # Check for valid characters\n    valid_chars = set('0123456789+-*/().')\n    if not all(c in valid_chars for c in expr):\n        return False\n    \n    # Check balanced parentheses\n    paren_count = 0\n    for c in expr:\n        if c == '(':\n            paren_count += 1\n        elif c == ')':\n            paren_count -= 1\n            if paren_count < 0:\n                return False\n    if paren_count != 0:\n        return False\n    \n    # Check for invalid sequences\n    operators = set('+-*/')\n    prev_char = None\n    i = 0\n    \n    while i < len(expr):\n        c = expr[i]\n        \n        # Check for empty parentheses\n        if c == '(' and i + 1 < len(expr) and expr[i + 1] == ')':\n            return False\n        \n        # Check for invalid operator sequences\n        if c in operators:\n            if prev_char is None or prev_char in operators or prev_char == '(':\n                # Allow unary + or - at start or after (\n                if c not in '+-' or (prev_char is not None and prev_char not in '('):\n                    return False\n            # Check for consecutive operators\n            if i + 1 < len(expr) and expr[i + 1] in operators:\n                return False\n        \n        # Check for operators before closing parenthesis\n        if c == ')' and prev_char in operators:\n            return False\n        \n        # Check for invalid starts after opening parenthesis\n        if prev_char == '(' and c in '*/':\n            return False\n        \n        # Update previous character (ignore spaces)\n        if c != ' ':\n            prev_char = c\n        \n        i += 1\n    \n    # Expression cannot end with an operator\n    if expr and expr[-1] in operators:\n        return False\n    \n    # Expression cannot start with */ operators\n    if expr and expr[0] in '*/':\n        return False\n    \n    return True\n```", "error": null, "raw_item": {"task_id": "custom_validate_expression", "prompt": "Write validate_expression(expr) that checks if a string is a valid arithmetic expression containing only digits, +, -, *, /, parentheses, and spaces. Return True if valid, else False. Parentheses must be balanced and no invalid sequences allowed (e.g. '*/', '++', empty parentheses). Return only the Python function code with no explanations.", "entry_point": "validate_expression", "canonical_solution": "import re\ndef validate_expression(expr: str) -> bool:\n    expr = expr.strip()\n    if not expr:\n        return False\n    # invalid sequences\n    if re.search(r'[+*/-]{2,}', expr):\n        return False\n    if re.search(r'\\(\\)', expr):\n        return False\n    # parentheses balance\n    stack = []\n    for c in expr:\n        if c == '(':\n            stack.append(c)\n        elif c == ')':\n            if not stack:\n                return False\n            stack.pop()\n    if stack:\n        return False\n    # final safety: try eval\n    try:\n        eval(expr, {\"__builtins__\":None}, {})\n    except:\n        return False\n    return True", "test": [{"input": ["1+2*(3-4)"], "output": true}, {"input": ["(5+6"], "output": false}, {"input": ["1++2"], "output": false}, {"input": ["( )"], "output": false}, {"input": ["10/2-3"], "output": true}]}}
{"timestamp_utc": "2025-09-16T06:19:38.124431", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 56, "question": "Write parse_roman(s) that converts a valid Roman numeral string into an integer. Supports numerals up to 3999 (MMMCMXCIX). Return only the Python function code with no explanations.", "provider": "bedrock", "model": "us.anthropic.claude-sonnet-4-20250514-v1:0", "region": "us-east-1", "success": true, "response_time": 2.6101980209350586, "response": "```python\ndef parse_roman(s):\n    roman_values = {\n        'I': 1, 'V': 5, 'X': 10, 'L': 50,\n        'C': 100, 'D': 500, 'M': 1000\n    }\n    \n    total = 0\n    prev_value = 0\n    \n    for char in reversed(s):\n        value = roman_values[char]\n        if value < prev_value:\n            total -= value\n        else:\n            total += value\n        prev_value = value\n    \n    return total\n```", "error": null, "raw_item": {"task_id": "custom_parse_roman", "prompt": "Write parse_roman(s) that converts a valid Roman numeral string into an integer. Supports numerals up to 3999 (MMMCMXCIX). Return only the Python function code with no explanations.", "entry_point": "parse_roman", "canonical_solution": "def parse_roman(s: str) -> int:\n    values = {\"I\":1, \"V\":5, \"X\":10, \"L\":50, \"C\":100, \"D\":500, \"M\":1000}\n    total = 0\n    i = 0\n    while i < len(s):\n        if i+1 < len(s) and values[s[i]] < values[s[i+1]]:\n            total += values[s[i+1]] - values[s[i]]\n            i += 2\n        else:\n            total += values[s[i]]\n            i += 1\n    return total", "test": [{"input": ["III"], "output": 3}, {"input": ["IX"], "output": 9}, {"input": ["LVIII"], "output": 58}, {"input": ["MCMXCIV"], "output": 1994}, {"input": ["MMMCMXCIX"], "output": 3999}]}}
