{"timestamp_utc": "2025-09-27T11:44:20.630693", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 0, "question": "Write find_balanced_sublist(arr) that returns the longest even-length contiguous sublist where sum of first half equals sum of second half. Return empty list if none exists.\n\nReturn only the Python function code with no explanations, comments, or markdown formatting.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 26.964892148971558, "response": "```python\ndef find_balanced_sublist(arr):\n    n = len(arr)\n    if n == 0:\n        return []\n    prefix = [0] * (n + 1)\n    for i in range(1, n + 1):\n        prefix[i] = prefix[i - 1] + arr[i - 1]\n    max_even = (n // 2) * 2\n    for length in range(max_even, 0, -2):\n        k = length // 2\n        for i in range(n - length + 1):\n            sum1 = prefix[i + k] - prefix[i]\n            sum2 = prefix[i + length] - prefix[i + k]\n            if sum1 == sum2:\n                return arr[i:i + length]\n    return []\n```", "error": null, "raw_item": {"task_id": "custom_find_balanced_sublist", "prompt": "Write find_balanced_sublist(arr) that returns the longest even-length contiguous sublist where sum of first half equals sum of second half. Return empty list if none exists.\n\nReturn only the Python function code with no explanations, comments, or markdown formatting.", "entry_point": "find_balanced_sublist", "canonical_solution": "def find_balanced_sublist(arr: list[int]) -> list[int]:\n    n = len(arr)\n    for length in range(n, 1, -1):\n        if length % 2 != 0:\n            continue\n        for start in range(n - length + 1):\n            sub = arr[start:start+length]\n            half = length // 2\n            if sum(sub[:half]) == sum(sub[half:]):\n                return sub\n    return []", "test": [{"input": [[1, 2, 3, 3, 2, 1]], "output": [1, 2, 3, 3, 2, 1]}, {"input": [[5, 1, 2, 1, 5]], "output": []}, {"input": [[1, 1, 1, 1]], "output": [1, 1, 1, 1]}, {"input": [[1, 2, 3]], "output": []}, {"input": [[]], "output": []}, {"input": [[3, 0, 3, 0, 3]], "output": [3, 0, 3, 0]}, {"input": [[2, 1, 1, 2, 3, 4]], "output": [2, 1, 1, 2]}, {"input": [[1, 5, 3, 7]], "output": []}, {"input": [[0, 0, 0, 0]], "output": [0, 0, 0, 0]}]}}
{"timestamp_utc": "2025-09-27T11:44:31.374291", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 1, "question": "Write merge_by_priority(items_a, items_b) that merges two lists of (id, priority) pairs. Keep highest priority for each unique id. Return sorted by priority descending. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 9.742111921310425, "response": "```python\ndef merge_by_priority(items_a, items_b):\n    priority_dict = {}\n    for id_, prio in items_a + items_b:\n        if id_ not in priority_dict or prio > priority_dict[id_]:\n            priority_dict[id_] = prio\n    merged = [(id_, prio) for id_, prio in priority_dict.items()]\n    return sorted(merged, key=lambda x: x[1], reverse=True)\n```", "error": null, "raw_item": {"task_id": "custom_merge_by_priority", "prompt": "Write merge_by_priority(items_a, items_b) that merges two lists of (id, priority) pairs. Keep highest priority for each unique id. Return sorted by priority descending. Return only the Python function code with no explanations.", "entry_point": "merge_by_priority", "canonical_solution": "def merge_by_priority(items_a: list[tuple[str, int]], items_b: list[tuple[str, int]]) -> list[tuple[str, int]]:\n    combined = items_a + items_b\n    best = {}\n    for id, priority in combined:\n        if id not in best or priority > best[id]:\n            best[id] = priority\n    return sorted(best.items(), key=lambda x: -x[1])", "test": [{"input": [[["item1", 2], ["item2", 5]], [["item2", 3], ["item3", 4]]], "output": [["item2", 5], ["item3", 4], ["item1", 2]]}, {"input": [[], []], "output": []}, {"input": [[["a", 1]], [["a", 10]]], "output": [["a", 10]]}, {"input": [[["x", 5], ["y", 3]], [["z", 7], ["y", 6]]], "output": [["z", 7], ["y", 6], ["x", 5]]}, {"input": [[["a", 1], ["b", 2]], []], "output": [["b", 2], ["a", 1]]}]}}
{"timestamp_utc": "2025-09-27T11:44:47.022721", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 2, "question": "Write parse_env_config(lines) that parses environment variable lines into dict. Ignore lines starting with '#', lines without '=', and empty keys. Keep last occurrence of duplicate keys. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 14.646822929382324, "response": "```python\ndef parse_env_config(lines):\n    config = {}\n    for line in lines:\n        line = line.strip()\n        if line.startswith('#') or not line:\n            continue\n        if '=' not in line:\n            continue\n        key, value = line.split('=', 1)\n        key = key.strip()\n        value = value.strip()\n        if not key:\n            continue\n        config[key] = value\n    return config\n```", "error": null, "raw_item": {"task_id": "custom_parse_env_config", "prompt": "Write parse_env_config(lines) that parses environment variable lines into dict. Ignore lines starting with '#', lines without '=', and empty keys. Keep last occurrence of duplicate keys. Return only the Python function code with no explanations.", "entry_point": "parse_env_config", "canonical_solution": "def parse_env_config(lines: list[str]) -> dict[str, str]:\n    env = {}\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith(\"#\") or \"=\" not in line:\n            continue\n        key, value = line.split(\"=\", 1)\n        if key:\n            env[key] = value\n    return env", "test": [{"input": [["DB_HOST=localhost", "DB_PORT=5432", "#comment", "DB_HOST=remotehost", "=fail", "INVALID", ""]], "output": {"DB_HOST": "remotehost", "DB_PORT": "5432"}}, {"input": [["A=1", "B=2", "C=3"]], "output": {"A": "1", "B": "2", "C": "3"}}, {"input": [["# just a comment", "=", "==", "KEY_ONLY=", "NO_EQUALS"]], "output": {"KEY_ONLY": ""}}, {"input": [[]], "output": {}}, {"input": [["k1=v1", "k1=v2", "k1=v3"]], "output": {"k1": "v3"}}]}}
{"timestamp_utc": "2025-09-27T11:45:36.607951", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 3, "question": "Write minimal_partition_difference(nums) that partitions a list into two groups to minimize absolute difference of their sums. Handle empty list case explicitly. Use DP subset sum approach. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 48.58299207687378, "response": "```python\ndef minimal_partition_difference(nums):\n    if not nums:\n        return 0\n    total = sum(nums)\n    target = total // 2\n    dp = [False] * (target + 1)\n    dp[0] = True\n    for num in nums:\n        for j in range(target, num - 1, -1):\n            if dp[j - num]:\n                dp[j] = True\n    for j in range(target, -1, -1):\n        if dp[j]:\n            return abs(2 * j - total)\n    return total\n```", "error": null, "raw_item": {"task_id": "custom_minimal_partition_difference", "prompt": "Write minimal_partition_difference(nums) that partitions a list into two groups to minimize absolute difference of their sums. Handle empty list case explicitly. Use DP subset sum approach. Return only the Python function code with no explanations.", "entry_point": "minimal_partition_difference", "canonical_solution": "def minimal_partition_difference(nums: list[int]) -> int:\n    if not nums:\n        return 0\n    total = sum(nums)\n    target = total // 2\n    possible = {0}\n    for num in nums:\n        possible |= {x + num for x in possible}\n    best = max(x for x in possible if x <= target)\n    return total - 2 * best", "test": [{"input": [[1, 2, 3, 9]], "output": 3}, {"input": [[1, 2, 3, 4, 5]], "output": 1}, {"input": [[10, 10]], "output": 0}, {"input": [[7]], "output": 7}, {"input": [[]], "output": 0}, {"input": [[1, 1, 1, 1, 1, 1]], "output": 0}, {"input": [[100, 99, 98, 1]], "output": 96}]}}
{"timestamp_utc": "2025-09-27T11:46:11.264525", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 4, "question": "Write normalize_user_roles(users) where users is a dict mapping each user to a LIST of roles. Invert to map each role to list of users. Remove duplicate users per role and sort user lists alphabetically. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 33.653186082839966, "response": "```python\ndef normalize_user_roles(users):\n    role_to_users = {}\n    for user, roles in users.items():\n        for role in roles:\n            if role not in role_to_users:\n                role_to_users[role] = set()\n            role_to_users[role].add(user)\n    for role in role_to_users:\n        role_to_users[role] = sorted(list(role_to_users[role]))\n    return role_to_users\n```", "error": null, "raw_item": {"task_id": "custom_normalize_user_roles", "prompt": "Write normalize_user_roles(users) where users is a dict mapping each user to a LIST of roles. Invert to map each role to list of users. Remove duplicate users per role and sort user lists alphabetically. Return only the Python function code with no explanations.", "entry_point": "normalize_user_roles", "canonical_solution": "def normalize_user_roles(users: dict[str, list[str]]) -> dict[str, list[str]]:\n    role_to_users = {}\n    for user, roles in users.items():\n        for role in set(roles):  # remove duplicates\n            if role not in role_to_users:\n                role_to_users[role] = []\n            role_to_users[role].append(user)\n    for role in role_to_users:\n        role_to_users[role].sort()\n    return role_to_users", "test": [{"input": [{"alice": ["admin", "editor"], "bob": ["editor", "admin"], "charlie": ["viewer"]}], "output": {"admin": ["alice", "bob"], "editor": ["alice", "bob"], "viewer": ["charlie"]}}, {"input": [{"diana": [], "eva": ["user", "user"], "frank": ["user"]}], "output": {"user": ["eva", "frank"]}}, {"input": [{"a": ["x"], "b": ["y"], "c": ["x", "y"]}], "output": {"x": ["a", "c"], "y": ["b", "c"]}}, {"input": [{}], "output": {}}]}}
{"timestamp_utc": "2025-09-27T11:48:30.906521", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 5, "question": "Write can_form_expression(digits, target) that checks if inserting '+' or '-' operators (or nothing) between digits can reach target value. Use recursive DFS. Must handle multi-digit numbers. Return complete Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 138.64001297950745, "response": "```python\ndef can_form_expression(digits, target):\n    n = len(digits)\n    \n    def dfs(pos, current_sum):\n        if pos == n:\n            return current_sum == target\n        num = 0\n        for i in range(pos, n):\n            if i > pos and digits[pos] == '0':\n                break\n            num = num * 10 + int(digits[i])\n            if dfs(i + 1, current_sum + num):\n                return True\n            if pos != 0:\n                if dfs(i + 1, current_sum - num):\n                    return True\n        return False\n    \n    return dfs(0, 0)\n```", "error": null, "raw_item": {"task_id": "custom_can_form_expression", "prompt": "Write can_form_expression(digits, target) that checks if inserting '+' or '-' operators (or nothing) between digits can reach target value. Use recursive DFS. Must handle multi-digit numbers. Return complete Python function code with no explanations.", "entry_point": "can_form_expression", "canonical_solution": "def can_form_expression(digits: str, target: int) -> bool:\n    def dfs(index: int, current_value: int, expression: str) -> bool:\n        if index == len(digits):\n            return current_value == target\n        for end in range(index + 1, len(digits) + 1):\n            num_str = digits[index:end]\n            num = int(num_str)\n            if index == 0:\n                if dfs(end, num, num_str):\n                    return True\n            else:\n                if dfs(end, current_value + num, expression + '+' + num_str):\n                    return True\n                if dfs(end, current_value - num, expression + '-' + num_str):\n                    return True\n        return False\n    return dfs(0, 0, \"\")", "test": [{"input": ["123", 6], "output": true}, {"input": ["105", 5], "output": true}, {"input": ["123", 123], "output": true}, {"input": ["123", 100], "output": false}, {"input": ["000", 0], "output": true}, {"input": ["1", 1], "output": true}, {"input": ["1", 2], "output": false}]}}
{"timestamp_utc": "2025-09-27T11:49:13.460112", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 6, "question": "Write has_balanced_bits(n) that returns True if binary representation of n has equal number of 0s and 1s. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 41.55188727378845, "response": "```python\ndef has_balanced_bits(n):\n    b = bin(n)[2:]\n    return b.count('0') == b.count('1')\n```", "error": null, "raw_item": {"task_id": "custom_has_balanced_bits", "prompt": "Write has_balanced_bits(n) that returns True if binary representation of n has equal number of 0s and 1s. Return only the Python function code with no explanations.", "entry_point": "has_balanced_bits", "canonical_solution": "def has_balanced_bits(n: int) -> bool:\n    bits = bin(n)[2:]\n    return bits.count('0') == bits.count('1')", "test": [{"input": [10], "output": true}, {"input": [7], "output": false}, {"input": [9], "output": true}, {"input": [1], "output": false}, {"input": [51], "output": false}, {"input": [56], "output": true}, {"input": [57], "output": false}, {"input": [2], "output": true}, {"input": [15], "output": false}]}}
{"timestamp_utc": "2025-09-27T11:49:41.652824", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 7, "question": "Write remove_repeating_groups(s, k) that repeatedly removes groups of k identical adjacent characters until no more can be removed. Use stack approach. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 27.190430879592896, "response": "```python\ndef remove_repeating_groups(s, k):\n    stack = []\n    for char in s:\n        if stack and stack[-1][0] == char:\n            stack[-1][1] += 1\n            if stack[-1][1] == k:\n                stack.pop()\n        else:\n            stack.append([char, 1])\n    result = ''\n    for char, count in stack:\n        result += char * count\n    return result\n```", "error": null, "raw_item": {"task_id": "custom_remove_repeating_groups", "prompt": "Write remove_repeating_groups(s, k) that repeatedly removes groups of k identical adjacent characters until no more can be removed. Use stack approach. Return only the Python function code with no explanations.", "entry_point": "remove_repeating_groups", "canonical_solution": "def remove_repeating_groups(s: str, k: int) -> str:\n    stack = []\n    for char in s:\n        if stack and stack[-1][0] == char:\n            stack[-1][1] += 1\n            if stack[-1][1] == k:\n                stack.pop()\n        else:\n            stack.append([char, 1])\n    return ''.join(char * count for char, count in stack)", "test": [{"input": ["deeedbbcccbdaa", 3], "output": "aa"}, {"input": ["pbbcggttciiippooaais", 2], "output": "ps"}, {"input": ["abcd", 2], "output": "abcd"}, {"input": ["aaa", 3], "output": ""}, {"input": ["aaaabbbbaaaa", 4], "output": ""}, {"input": ["aabbcc", 2], "output": ""}, {"input": ["aabbccddeeedcba", 3], "output": "abc"}, {"input": ["", 3], "output": ""}]}}
{"timestamp_utc": "2025-09-27T11:50:24.988260", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 8, "question": "Write resolve_dependencies(deps) that returns valid module load order from dependency dict. Return None if cycle exists. Use DFS topological sort. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 42.33322191238403, "response": "```python\nfrom collections import defaultdict\n\ndef resolve_dependencies(deps):\n    all_nodes = set(deps.keys()) | {d for v in deps.values() for d in v}\n    graph = defaultdict(list)\n    for k, v in deps.items():\n        graph[k] = v\n    visited = {node: 0 for node in all_nodes}\n    order = []\n\n    def dfs(node):\n        if visited[node] == 1:\n            return False\n        if visited[node] == 2:\n            return True\n        visited[node] = 1\n        for dep in graph[node]:\n            if not dfs(dep):\n                return False\n        visited[node] = 2\n        order.append(node)\n        return True\n\n    for node in all_nodes:\n        if visited[node] == 0:\n            if not dfs(node):\n                return None\n    return order\n```", "error": null, "raw_item": {"task_id": "custom_resolve_dependencies", "prompt": "Write resolve_dependencies(deps) that returns valid module load order from dependency dict. Return None if cycle exists. Use DFS topological sort. Return only the Python function code with no explanations.", "entry_point": "resolve_dependencies", "canonical_solution": "def resolve_dependencies(deps: dict[str, list[str]]) -> list[str] | None:\n    visited = {}\n    result = []\n\n    def dfs(node):\n        if node in visited:\n            return visited[node]  # False if cycle\n        visited[node] = False  # mark as visiting\n        for neighbor in deps.get(node, []):\n            res = dfs(neighbor)\n            if res is False:\n                return False\n        visited[node] = True  # mark as visited\n        result.append(node)\n        return True\n\n    for node in deps:\n        if node not in visited:\n            if dfs(node) is False:\n                return None\n    return result[::-1]", "test": [{"input": [{"a": ["b", "c"], "b": ["c"], "c": []}], "output": ["c", "b", "a"]}, {"input": [{"x": ["y"], "y": ["z"], "z": ["x"]}], "output": null}, {"input": [{"m": ["n"], "n": [], "o": []}], "output": ["n", "m", "o"]}, {"input": [{"a": []}], "output": ["a"]}, {"input": [{}], "output": []}]}}
{"timestamp_utc": "2025-09-27T11:50:42.421301", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 9, "question": "Write clean_and_validate_urls(urls) that returns sorted list of unique valid URLs. Valid URLs start with 'http://' or 'https://' (case-insensitive) and contain no spaces. Strip whitespace and remove duplicates. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 16.430009126663208, "response": "```python\ndef clean_and_validate_urls(urls):\n    valid = set()\n    for url in urls:\n        url = url.strip()\n        if not url:\n            continue\n        lower_url = url.lower()\n        if (lower_url.startswith('http://') or lower_url.startswith('https://')) and ' ' not in url:\n            valid.add(url)\n    return sorted(list(valid))\n```", "error": null, "raw_item": {"task_id": "custom_clean_and_validate_urls", "prompt": "Write clean_and_validate_urls(urls) that returns sorted list of unique valid URLs. Valid URLs start with 'http://' or 'https://' (case-insensitive) and contain no spaces. Strip whitespace and remove duplicates. Return only the Python function code with no explanations.", "entry_point": "clean_and_validate_urls", "canonical_solution": "def clean_and_validate_urls(urls: list[str]) -> list[str]:\n    valid = set()\n    for url in urls:\n        cleaned = url.strip()\n        if cleaned.lower().startswith(\"http://\") or cleaned.lower().startswith(\"https://\"):\n            if \" \" not in cleaned:\n                valid.add(cleaned)\n    return sorted(valid)", "test": [{"input": [[" http://example.com ", "https://valid.site", "ftp://notvalid", "invalid.com", "https://valid.site"]], "output": ["http://example.com", "https://valid.site"]}, {"input": [[]], "output": []}, {"input": [["   https://a.com  ", "http://b.com", "http://b.com  "]], "output": ["http://b.com", "https://a.com"]}, {"input": [["https://with space.com", "http://ok.com"]], "output": ["http://ok.com"]}, {"input": [["HTTP://UPPERCASE.com"]], "output": ["HTTP://UPPERCASE.com"]}]}}
{"timestamp_utc": "2025-09-27T11:50:51.007994", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 10, "question": "Write normalize_filename(filename) that normalizes filenames by converting to lowercase, keeping only a-z, 0-9, underscore, and dots, removing other characters. Return 'unnamed' if result is empty. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 7.584623336791992, "response": "```python\ndef normalize_filename(filename):\n    normalized = ''.join(c for c in filename.lower() if c.isalnum() or c in '_.')\n\n    return normalized if normalized else 'unnamed'\n```", "error": null, "raw_item": {"task_id": "custom_normalize_filename", "prompt": "Write normalize_filename(filename) that normalizes filenames by converting to lowercase, keeping only a-z, 0-9, underscore, and dots, removing other characters. Return 'unnamed' if result is empty. Return only the Python function code with no explanations.", "entry_point": "normalize_filename", "canonical_solution": "def normalize_filename(filename: str) -> str:\n    allowed = set(\"abcdefghijklmnopqrstuvwxyz0123456789_.\")\n    result = ''.join(c.lower() for c in filename if c.lower() in allowed)\n    return result if result else \"unnamed\"", "test": [{"input": ["My Report (Final).PDF"], "output": "myreport.final.pdf"}, {"input": ["Résumé_2023!.docx"], "output": "rsum_2023.docx"}, {"input": ["  "], "output": "unnamed"}, {"input": ["file@#name!.TXT"], "output": "filename.txt"}, {"input": ["___"], "output": "___"}, {"input": ["###"], "output": "unnamed"}, {"input": ["ABC123_456.xyz"], "output": "abc123_456.xyz"}]}}
{"timestamp_utc": "2025-09-27T11:51:00.505567", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 11, "question": "Write rank_projects_by_score(projects) that ranks projects by score formula: (stars * 2) + forks - (issues * 3). Return project names sorted by score descending, then alphabetically. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 8.494671821594238, "response": "```python\ndef rank_projects_by_score(projects):\n    def score(p):\n        return (p['stars'] * 2) + p['forks'] - (p['issues'] * 3)\n    sorted_projects = sorted(projects, key=lambda p: (-score(p), p['name']))\n    return [p['name'] for p in sorted_projects]\n```", "error": null, "raw_item": {"task_id": "custom_rank_projects_by_score", "prompt": "Write rank_projects_by_score(projects) that ranks projects by score formula: (stars * 2) + forks - (issues * 3). Return project names sorted by score descending, then alphabetically. Return only the Python function code with no explanations.", "entry_point": "rank_projects_by_score", "canonical_solution": "def rank_projects_by_score(projects: list[tuple[str, int, int, int]]) -> list[str]:\n    def score(proj):\n        return (proj[1] * 2) + proj[2] - (proj[3] * 3)\n    return [p[0] for p in sorted(projects, key=lambda p: (-score(p), p[0]))]", "test": [{"input": [[["ProjectA", 100, 50, 10], ["ProjectB", 80, 70, 5], ["ProjectC", 100, 50, 10]]], "output": ["ProjectA", "ProjectC", "ProjectB"]}, {"input": [[["Alpha", 10, 5, 0], ["Beta", 10, 5, 0]]], "output": ["Alpha", "Beta"]}, {"input": [[["AppX", 0, 0, 0], ["AppY", 0, 0, 1]]], "output": ["AppX", "AppY"]}, {"input": [[]], "output": []}, {"input": [[["ToolZ", 5, 5, 10], ["ToolY", 4, 4, 1]]], "output": ["ToolY", "ToolZ"]}]}}
{"timestamp_utc": "2025-09-27T11:51:24.978207", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 12, "question": "Write longest_prime_gap(nums) that finds the longest sequence of non-prime numbers between two prime numbers in the list. Return length of longest gap. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 23.469488859176636, "response": "```python\ndef longest_prime_gap(nums):\n    def is_prime(n):\n        if n <= 1:\n            return False\n        if n <= 3:\n            return True\n        if n % 2 == 0 or n % 3 == 0:\n            return False\n        i = 5\n        while i * i <= n:\n            if n % i == 0 or n % (i + 2) == 0:\n                return False\n            i += 6\n        return True\n    \n    prime_indices = [i for i in range(len(nums)) if is_prime(nums[i])]\n    if len(prime_indices) < 2:\n        return 0\n    max_gap = 0\n    for k in range(1, len(prime_indices)):\n        gap = prime_indices[k] - prime_indices[k - 1] - 1\n        if gap > max_gap:\n            max_gap = gap\n    return max_gap\n```", "error": null, "raw_item": {"task_id": "custom_longest_prime_gap", "prompt": "Write longest_prime_gap(nums) that finds the longest sequence of non-prime numbers between two prime numbers in the list. Return length of longest gap. Return only the Python function code with no explanations.", "entry_point": "longest_prime_gap", "canonical_solution": "def longest_prime_gap(nums: list[int]) -> int:\n    def is_prime(n: int) -> bool:\n        if n < 2:\n            return False\n        for i in range(2, int(n**0.5)+1):\n            if n % i == 0:\n                return False\n        return True\n\n    indices = [i for i, val in enumerate(nums) if is_prime(val)]\n    if len(indices) < 2:\n        return 0\n\n    max_gap = 0\n    for i in range(len(indices) - 1):\n        start = indices[i]\n        end = indices[i + 1]\n        gap = end - start - 1\n        max_gap = max(max_gap, gap)\n    return max_gap", "test": [{"input": [[4, 6, 7, 8, 9, 10, 11, 4, 6, 13]], "output": 3}, {"input": [[2, 4, 6, 8, 10, 3]], "output": 4}, {"input": [[4, 6, 8, 10]], "output": 0}, {"input": [[3, 4, 5, 6, 7]], "output": 1}, {"input": [[2, 3]], "output": 0}, {"input": [[17, 4, 6, 9, 15, 19, 21, 23]], "output": 4}, {"input": [[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]], "output": 4}]}}
{"timestamp_utc": "2025-09-27T11:51:42.285577", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 13, "question": "Write categorize_commit_message(message) that categorizes commit messages. Return 'feature' for add/implement/feature/new, 'fix' for fix/bug/error/resolve, 'refactor' for refactor/cleanup/restructure, 'docs' for docs/documentation/readme, else 'other'. Case-insensitive. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 16.304295301437378, "response": "```python\ndef categorize_commit_message(message):\n    msg = message.lower()\n    feature_keywords = ['add', 'implement', 'feature', 'new']\n    fix_keywords = ['fix', 'bug', 'error', 'resolve']\n    refactor_keywords = ['refactor', 'cleanup', 'restructure']\n    docs_keywords = ['docs', 'documentation', 'readme']\n    for kw in feature_keywords:\n        if kw in msg:\n            return 'feature'\n    for kw in fix_keywords:\n        if kw in msg:\n            return 'fix'\n    for kw in refactor_keywords:\n        if kw in msg:\n            return 'refactor'\n    for kw in docs_keywords:\n        if kw in msg:\n            return 'docs'\n    return 'other'\n```", "error": null, "raw_item": {"task_id": "custom_categorize_commit_message", "prompt": "Write categorize_commit_message(message) that categorizes commit messages. Return 'feature' for add/implement/feature/new, 'fix' for fix/bug/error/resolve, 'refactor' for refactor/cleanup/restructure, 'docs' for docs/documentation/readme, else 'other'. Case-insensitive. Return only the Python function code with no explanations.", "entry_point": "categorize_commit_message", "canonical_solution": "def categorize_commit_message(message: str) -> str:\n    msg = message.lower()\n    categories = {\n        \"feature\": [\"add\", \"implement\", \"feature\", \"new\"],\n        \"fix\": [\"fix\", \"bug\", \"error\", \"resolve\"],\n        \"refactor\": [\"refactor\", \"cleanup\", \"restructure\"],\n        \"docs\": [\"docs\", \"documentation\", \"readme\"],\n    }\n    for label, keywords in categories.items():\n        if any(kw in msg for kw in keywords):\n            return label\n    return \"other\"", "test": [{"input": ["Fix bug in user login"], "output": "fix"}, {"input": ["Refactor payment module"], "output": "refactor"}, {"input": ["Updated README and docs"], "output": "docs"}, {"input": ["Initial commit"], "output": "other"}, {"input": ["Implemented new feature for signup"], "output": "feature"}, {"input": ["cleanup redundant logic"], "output": "refactor"}, {"input": ["Error handling for empty input"], "output": "fix"}, {"input": ["add configuration support"], "output": "feature"}, {"input": ["Documentation improvements"], "output": "docs"}, {"input": ["Minor UI tweaks"], "output": "other"}]}}
{"timestamp_utc": "2025-09-27T11:56:39.066949", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 14, "question": "Write max_repeated_substring(s) that returns length of longest non-overlapping repeated substring. Use sliding window with seen set. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 295.77868008613586, "response": "```python\ndef max_repeated_substring(s):\n    n = len(s)\n    if n < 2:\n        return 0\n\n    def has_repeat(L):\n        seen = set()\n        ptr = 0\n        MOD1, BASE1 = 10**11 + 7, 29\n        MOD2, BASE2 = 10**11 + 9, 31\n        pow1 = [1] * (n + 1)\n        pow2 = [1] * (n + 1)\n        for i in range(1, n + 1):\n            pow1[i] = pow1[i - 1] * BASE1 % MOD1\n            pow2[i] = pow2[i - 1] * BASE2 % MOD2\n        pre1 = [0] * (n + 1)\n        pre2 = [0] * (n + 1)\n        for i in range(n):\n            val = ord(s[i]) - ord('a') + 1\n            pre1[i + 1] = (pre1[i] * BASE1 + val) % MOD1\n            pre2[i + 1] = (pre2[i] * BASE2 + val) % MOD2\n        def get_hash(start, leng):\n            end = start + leng\n            h1 = (pre1[end] - pre1[start] * pow1[leng] % MOD1 + MOD1) % MOD1\n            h2 = (pre2[end] - pre2[start] * pow2[leng] % MOD2 + MOD2) % MOD2\n            return (h1, h2)\n        for i in range(n - L + 1):\n            while ptr <= i - L and ptr < n - L + 1:\n                h = get_hash(ptr, L)\n                seen.add(h)\n                ptr += 1\n            h = get_hash(i, L)\n            if h in seen:\n                return True\n        return False\n\n    low, high = 0, n // 2\n    while low < high:\n        mid = (low + high + 1) // 2\n        if has_repeat(mid):\n            low = mid\n        else:\n            high = mid - 1\n    return low\n```", "error": null, "raw_item": {"task_id": "custom_max_repeated_substring", "prompt": "Write max_repeated_substring(s) that returns length of longest non-overlapping repeated substring. Use sliding window with seen set. Return only the Python function code with no explanations.", "entry_point": "max_repeated_substring", "canonical_solution": "def max_repeated_substring(s: str) -> int:\n    n = len(s)\n    max_len = 0\n    for l in range(1, n // 2 + 1):\n        seen = set()\n        i = 0\n        while i + l <= n:\n            substr = s[i:i+l]\n            if substr in seen:\n                max_len = max(max_len, l)\n                i += l  # move forward non-overlapping\n            else:\n                seen.add(substr)\n                i += 1\n    return max_len", "test": [{"input": ["abababc"], "output": 2}, {"input": ["aaaa"], "output": 2}, {"input": ["abcabcabc"], "output": 3}, {"input": ["abcdef"], "output": 0}, {"input": ["ababa"], "output": 1}, {"input": [""], "output": 0}, {"input": ["a"], "output": 0}, {"input": ["abcdabcd"], "output": 4}, {"input": ["xyzxyzabcabc"], "output": 3}, {"input": ["abababab"], "output": 2}]}}
{"timestamp_utc": "2025-09-27T11:56:53.708845", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 15, "question": "Write longest_valid_bracket_substring(s) that returns length of longest valid parentheses substring. Use stack with indices. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 13.637787818908691, "response": "```python\ndef longest_valid_bracket_substring(s):\n    stack = [-1]\n    max_len = 0\n    for i in range(len(s)):\n        if s[i] == '(':\n            stack.append(i)\n        else:\n            stack.pop()\n            if not stack:\n                stack.append(i)\n            else:\n                max_len = max(max_len, i - stack[-1])\n    return max_len\n```", "error": null, "raw_item": {"task_id": "custom_longest_valid_bracket_substring", "prompt": "Write longest_valid_bracket_substring(s) that returns length of longest valid parentheses substring. Use stack with indices. Return only the Python function code with no explanations.", "entry_point": "longest_valid_bracket_substring", "canonical_solution": "def longest_valid_bracket_substring(s: str) -> int:\n    stack = [-1]\n    max_len = 0\n\n    for i, ch in enumerate(s):\n        if ch == '(':\n            stack.append(i)\n        else:\n            stack.pop()\n            if not stack:\n                stack.append(i)\n            else:\n                max_len = max(max_len, i - stack[-1])\n\n    return max_len", "test": [{"input": ["(()"], "output": 2}, {"input": [")()())"], "output": 4}, {"input": [""], "output": 0}, {"input": ["((("], "output": 0}, {"input": ["()(()))())"], "output": 6}, {"input": ["((()))"], "output": 6}, {"input": ["()()()"], "output": 6}, {"input": [")((()))("], "output": 6}, {"input": ["(()(((()"], "output": 2}, {"input": ["())(())"], "output": 4}]}}
{"timestamp_utc": "2025-09-27T11:57:11.283971", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 16, "question": "Write summarize_category_totals(purchases) that returns list of [category, total] pairs sorted alphabetically by category. Sum amounts by category. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 16.519332885742188, "response": "```python\nfrom collections import defaultdict\n\ndef summarize_category_totals(purchases):\n    totals = defaultdict(float)\n    for purchase in purchases:\n        category = purchase['category']\n        amount = purchase['amount']\n        totals[category] += amount\n    sorted_totals = [[category, totals[category]] for category in sorted(totals)]\n    return sorted_totals\n```", "error": null, "raw_item": {"task_id": "custom_summarize_category_totals", "prompt": "Write summarize_category_totals(purchases) that returns list of [category, total] pairs sorted alphabetically by category. Sum amounts by category. Return only the Python function code with no explanations.", "entry_point": "summarize_category_totals", "canonical_solution": "def summarize_category_totals(purchases: list[dict]) -> list[list]:\n    totals = {}\n    for item in purchases:\n        cat = item[\"category\"]\n        amt = item[\"amount\"]\n        totals[cat] = totals.get(cat, 0.0) + amt\n    return sorted([[cat, total] for cat, total in totals.items()])", "test": [{"input": [[{"category": "groceries", "amount": 25.5}, {"category": "electronics", "amount": 99.99}, {"category": "groceries", "amount": 13.0}, {"category": "books", "amount": 10.0}]], "output": [["books", 10.0], ["electronics", 99.99], ["groceries", 38.5]]}, {"input": [[{"category": "a", "amount": 1.0}, {"category": "b", "amount": 2.0}, {"category": "a", "amount": 3.0}, {"category": "c", "amount": 4.0}]], "output": [["a", 4.0], ["b", 2.0], ["c", 4.0]]}, {"input": [[]], "output": []}, {"input": [[{"category": "x", "amount": 0.0}, {"category": "x", "amount": 0.0}]], "output": [["x", 0.0]]}, {"input": [[{"category": "Z", "amount": 2.0}, {"category": "a", "amount": 1.0}]], "output": [["Z", 2.0], ["a", 1.0]]}]}}
{"timestamp_utc": "2025-09-27T11:57:25.032640", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 17, "question": "Write filter_unique_keywords(keywords, banned) that returns sorted unique keywords (lowercased) excluding banned words. Case-insensitive comparison. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 12.735953092575073, "response": "```python\ndef filter_unique_keywords(keywords, banned):\n    banned_set = set(word.lower() for word in banned)\n    unique_keywords = set(kw.lower() for kw in keywords)\n    filtered = sorted(kw for kw in unique_keywords if kw not in banned_set)\n    return filtered\n```", "error": null, "raw_item": {"task_id": "custom_filter_unique_keywords", "prompt": "Write filter_unique_keywords(keywords, banned) that returns sorted unique keywords (lowercased) excluding banned words. Case-insensitive comparison. Return only the Python function code with no explanations.", "entry_point": "filter_unique_keywords", "canonical_solution": "def filter_unique_keywords(keywords: list[str], banned: list[str]) -> list[str]:\n    banned_set = set(word.lower() for word in banned)\n    unique = set()\n\n    for word in keywords:\n        w = word.lower()\n        if w not in banned_set:\n            unique.add(w)\n\n    return sorted(unique)", "test": [{"input": [["Python", "code", "AI", "python", "Data", "Code"], ["ai"]], "output": ["code", "data", "python"]}, {"input": [[], ["test"]], "output": []}, {"input": [["ML", "AI", "ml", "AI"], ["ai"]], "output": ["ml"]}, {"input": [["hello", "world", "HELLO", "WORLD"], []], "output": ["hello", "world"]}, {"input": [["Data", "Science", "AI"], ["science", "ai"]], "output": ["data"]}, {"input": [["Python", "PYTHON", "python"], ["PYTHON"]], "output": []}]}}
{"timestamp_utc": "2025-09-27T11:59:13.737021", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 18, "question": "Write next_greater_circular(nums) that returns list where each position contains next greater element circularly. Use monotonic stack. O(n) time. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 107.70107889175415, "response": "```python\ndef next_greater_circular(nums):\n    n = len(nums)\n    res = [-1] * n\n    stack = []\n    for i in range(2 * n):\n        while stack and nums[stack[-1]] < nums[i % n]:\n            res[stack.pop()] = nums[i % n]\n        if i < n:\n            stack.append(i)\n    return res\n```", "error": null, "raw_item": {"task_id": "ds_next_greater_circular", "prompt": "Write next_greater_circular(nums) that returns list where each position contains next greater element circularly. Use monotonic stack. O(n) time. Return only the Python function code with no explanations.", "entry_point": "next_greater_circular", "canonical_solution": "def next_greater_circular(nums):\n    n = len(nums)\n    res = [-1]*n\n    stack = []  # indices with decreasing stack by value\n    for i in range(2*n):\n        x = nums[i % n]\n        while stack and nums[stack[-1]] < x:\n            idx = stack.pop()\n            res[idx] = x\n        if i < n:\n            stack.append(i)\n    return res\n", "test": [{"input": [[1, 2, 1]], "output": [2, -1, 2]}, {"input": [[3, 8, 4, 1, 2]], "output": [8, -1, 8, 2, 3]}, {"input": [[5, 4, 3, 2, 1]], "output": [-1, 5, 5, 5, 5]}, {"input": [[2, 2, 2]], "output": [-1, -1, -1]}, {"input": [[]], "output": []}]}}
{"timestamp_utc": "2025-09-27T11:59:33.033540", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 19, "question": "Write normalize_product_code(s) that keeps only alphanumerics and dashes, converts to uppercase, collapses multiple dashes, trims leading/trailing dashes. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 18.29460620880127, "response": "```python\nimport re\n\ndef normalize_product_code(s):\n    s = s.upper()\n    s = re.sub(r'[^A-Z0-9-]', '', s)\n    s = re.sub(r'-+', '-', s)\n    s = s.strip('-')\n    return s\n```", "error": null, "raw_item": {"task_id": "str_normalize_product_code", "prompt": "Write normalize_product_code(s) that keeps only alphanumerics and dashes, converts to uppercase, collapses multiple dashes, trims leading/trailing dashes. Return only the Python function code with no explanations.", "entry_point": "normalize_product_code", "canonical_solution": "import re\ndef normalize_product_code(s):\n    # keep alnum and dash\n    s = ''.join(ch for ch in s if ch.isalnum() or ch=='-')\n    s = s.upper()\n    s = re.sub(r'-{2,}', '-', s)\n    s = s.strip('-')\n    return s\n", "test": [{"input": [" abC--12__-xx "], "output": "ABC-12-XX"}, {"input": ["---a---b---"], "output": "A-B"}, {"input": ["***"], "output": ""}, {"input": ["proD-uct_99!!"], "output": "PROD-UCT99"}, {"input": [""], "output": ""}]}}
{"timestamp_utc": "2025-09-27T12:00:45.462872", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 20, "question": "Write single_number_triplicates(nums) that finds element appearing once while others appear thrice. Use bitwise counting without hash maps. O(n) time, O(1) space. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 71.42823123931885, "response": "```python\ndef single_number_triplicates(nums):\n    ones = 0\n    twos = 0\n    for num in nums:\n        ones = (ones ^ num) & ~twos\n        twos = (twos ^ num) & ~ones\n    return ones\n```", "error": null, "raw_item": {"task_id": "bit_single_number_triplicates", "prompt": "Write single_number_triplicates(nums) that finds element appearing once while others appear thrice. Use bitwise counting without hash maps. O(n) time, O(1) space. Return only the Python function code with no explanations.", "entry_point": "single_number_triplicates", "canonical_solution": "def single_number_triplicates(nums):\n    ones = 0\n    twos = 0\n    for x in nums:\n        ones = (ones ^ x) & ~twos\n        twos = (twos ^ x) & ~ones\n    return ones\n", "test": [{"input": [[2, 2, 3, 2]], "output": 3}, {"input": [[0, 1, 0, 1, 0, 1, 99]], "output": 99}, {"input": [[-2, -2, -2, -5]], "output": -5}, {"input": [[7]], "output": 7}, {"input": [[10, 10, 10, -1]], "output": -1}]}}
{"timestamp_utc": "2025-09-27T12:01:23.424000", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 21, "question": "Write can_finish_prereqs(pairs) where pairs are (a,b) meaning 'b precedes a'. Return True if acyclic. Use topological sort without external libraries. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 36.95867300033569, "response": "```python\nfrom collections import defaultdict, deque\n\ndef can_finish_prereqs(pairs):\n    all_nodes = set()\n    for a, b in pairs:\n        all_nodes.add(a)\n        all_nodes.add(b)\n    graph = defaultdict(list)\n    indegree = defaultdict(int)\n    for a, b in pairs:\n        graph[b].append(a)\n        indegree[a] += 1\n    queue = deque([node for node in all_nodes if indegree[node] == 0])\n    count = 0\n    while queue:\n        curr = queue.popleft()\n        count += 1\n        for nei in graph[curr]:\n            indegree[nei] -= 1\n            if indegree[nei] == 0:\n                queue.append(nei)\n    return count == len(all_nodes)\n```", "error": null, "raw_item": {"task_id": "graph_can_finish_prereqs", "prompt": "Write can_finish_prereqs(pairs) where pairs are (a,b) meaning 'b precedes a'. Return True if acyclic. Use topological sort without external libraries. Return only the Python function code with no explanations.", "entry_point": "can_finish_prereqs", "canonical_solution": "from collections import defaultdict, deque\ndef can_finish_prereqs(pairs):\n    adj = defaultdict(list)\n    indeg = defaultdict(int)\n    nodes = set()\n    for a,b in pairs:\n        adj[b].append(a)\n        indeg[a] += 1\n        nodes.add(a); nodes.add(b)\n        if b not in indeg: indeg[b] = indeg.get(b,0)\n    q = deque([v for v in nodes if indeg.get(v,0)==0])\n    visited = 0\n    while q:\n        v = q.popleft()\n        visited += 1\n        for w in adj[v]:\n            indeg[w] -= 1\n            if indeg[w]==0:\n                q.append(w)\n    return visited == len(nodes)\n", "test": [{"input": [[["C2", "C1"], ["C3", "C2"]]], "output": true}, {"input": [[["A", "B"], ["B", "C"], ["C", "A"]]], "output": false}, {"input": [[["A", "B"]]], "output": true}, {"input": [[["X", "Y"], ["Y", "Z"], ["Z", "X"]]], "output": false}, {"input": [[[]]], "output": true}]}}
{"timestamp_utc": "2025-09-27T12:01:39.809563", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 22, "question": "Write safe_deep_get(obj, path, default=None) that safely traverses nested dicts/lists/tuples using path keys/indices. Return default if any access fails. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 15.382551908493042, "response": "```python\ndef safe_deep_get(obj, path, default=None):\n    current = obj\n    for key in path:\n        try:\n            current = current[key]\n        except (KeyError, IndexError, TypeError):\n            return default\n    return current\n```", "error": null, "raw_item": {"task_id": "se_safe_deep_get", "entry_point": "safe_deep_get", "prompt": "Write safe_deep_get(obj, path, default=None) that safely traverses nested dicts/lists/tuples using path keys/indices. Return default if any access fails. Return only the Python function code with no explanations.", "canonical_solution": "def safe_deep_get(obj, path, default=None):\n    cur = obj\n    for key in path:\n        if isinstance(cur, dict):\n            if key in cur:\n                cur = cur[key]\n            else:\n                return default\n        elif isinstance(cur, (list, tuple)):\n            if isinstance(key, int) and -len(cur) <= key < len(cur):\n                cur = cur[key]\n            else:\n                return default\n        else:\n            return default\n    return cur\n", "test": [{"input": [{"a": {"b": [10, 20, {"c": 42}]}}, ["a", "b", 2, "c"], null], "output": 42}, {"input": [{"a": [1, 2, 3]}, ["a", 5], "x"], "output": "x"}, {"input": [{"x": 0}, ["y"], 99], "output": 99}, {"input": [[1, 2, 3], [0], null], "output": 1}, {"input": [[1, 2, 3], ["0"], "err"], "output": "err"}]}}
{"timestamp_utc": "2025-09-27T12:08:31.808307", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 23, "question": "Write clean_and_split_sentences(text) that removes non-alphanumeric chars except .!?, normalizes whitespace, splits on sentence delimiters, returns cleaned sentence list. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 410.9959239959717, "response": "```python\nimport re\n\ndef clean_and_split_sentences(text):\n    cleaned = re.sub(r'[^\\w\\s.!?]', '', text)\n    normalized = re.sub(r'\\s+', ' ', cleaned).strip()\n    parts = re.split(r'([.!?])', normalized)\n    sentences = []\n    current = ''\n    for i in range(len(parts)):\n        current += parts[i]\n        if i % 2 == 1:\n            sentences.append(current)\n            current = ''\n    if current:\n        sentences.append(current)\n    sentences = [s.strip() for s in sentences if s.strip()]\n    return sentences\n```", "error": null, "raw_item": {"task_id": "str_clean_and_split_sentences", "entry_point": "clean_and_split_sentences", "prompt": "Write clean_and_split_sentences(text) that removes non-alphanumeric chars except .!?, normalizes whitespace, splits on sentence delimiters, returns cleaned sentence list. Return only the Python function code with no explanations.", "canonical_solution": "import re\n\ndef clean_and_split_sentences(text):\n    # Keep only letters, digits, punctuation .,!,?\n    text = re.sub(r\"[^A-Za-z0-9.!?\\s]\", \"\", text)\n    # Normalize whitespace\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    # Split on sentence delimiters\n    parts = re.split(r\"[.!?]\", text)\n    # Clean and filter\n    result = [p.strip() for p in parts if p.strip()]\n    return result\n", "test": [{"input": ["Hello!!   How are---you???   Fine."], "output": ["Hello", "How areyou", "Fine"]}, {"input": ["  multiple   spaces   and ###symbols!!"], "output": ["multiple spaces and symbols"]}, {"input": ["Nothing to clean"], "output": ["Nothing to clean"]}, {"input": ["???"], "output": []}]}}
{"timestamp_utc": "2025-09-27T12:09:14.270142", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 24, "question": "Write count_set_bits(n) that counts 1-bits in binary representation using efficient bit manipulation (Brian Kernighan's algorithm). Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 41.45732498168945, "response": "```python\ndef count_set_bits(n):\n    count = 0\n    while n:\n        n &= (n - 1)\n        count += 1\n    return count\n```", "error": null, "raw_item": {"task_id": "bit_counting_set_bits", "entry_point": "count_set_bits", "prompt": "Write count_set_bits(n) that counts 1-bits in binary representation using efficient bit manipulation (Brian Kernighan's algorithm). Return only the Python function code with no explanations.", "canonical_solution": "def count_set_bits(n):\n    if n < 0:\n        raise ValueError(\"Input must be a non-negative integer.\")\n    count = 0\n    while n:\n        n &= n - 1  # Clear the least significant bit set\n        count += 1\n    return count\n", "test": [{"input": [11], "output": 3}, {"input": [0], "output": 0}, {"input": [255], "output": 8}, {"input": [1023], "output": 10}, {"input": [1], "output": 1}]}}
{"timestamp_utc": "2025-09-27T12:09:35.263963", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 25, "question": "Write filter_map_validate(records) that normalizes, validates, and filters product records, returning sorted list of valid IDs. Complex multi-step validation with price parsing, type constraints, and conditional rules. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 19.990492820739746, "response": "```python\ndef filter_map_validate(records):\n    valid_ids = []\n    for record in records:\n        # Normalize\n        if 'id' not in record or not isinstance(record['id'], int):\n            continue\n        if 'name' not in record or not isinstance(record['name'], str) or not record['name'].strip():\n            continue\n        if 'price' not in record:\n            continue\n        try:\n            price = float(record['price'].replace('$', '').replace(',', '').strip())\n            if price < 0:\n                continue\n        except ValueError:\n            continue\n        if 'type' not in record or record['type'] not in ['electronics', 'clothing', 'food']:\n            continue\n        \n        # Conditional rules\n        if record['type'] == 'electronics':\n            if 'warranty' not in record or not isinstance(record['warranty'], int) or record['warranty'] <= 0:\n                continue\n        if record['type'] == 'food':\n            if 'expiration' not in record or not record['expiration']:\n                continue\n        \n        # If all validations pass\n        valid_ids.append(record['id'])\n    \n    return sorted(valid_ids)\n```", "error": null, "raw_item": {"task_id": "se_filter_map_validate_nested", "entry_point": "filter_map_validate", "prompt": "Write filter_map_validate(records) that normalizes, validates, and filters product records, returning sorted list of valid IDs. Complex multi-step validation with price parsing, type constraints, and conditional rules. Return only the Python function code with no explanations.", "canonical_solution": "import re\n\ntype_order = {\"ent\": 0, \"pro\": 1, \"std\": 2}\n\ndef _parse_price(x):\n    if isinstance(x, (int, float)):\n        return float(x) if x >= 0 else None\n    if not isinstance(x, str):\n        return None\n    s = x.strip()\n    if not s:\n        return None\n    s = re.sub(r\"[\\s$€£¥]\", \"\", s)\n    if \",\" in s and \".\" in s:\n        if s.find(\",\") < s.find(\".\"):\n            s = s.replace(\",\", \"\")\n        else:\n            s = s.replace(\".\", \"\").replace(\",\", \".\")\n    elif \",\" in s:\n        s = s.replace(\",\", \".\")\n    try:\n        v = float(s)\n        return v if v >= 0 else None\n    except Exception:\n        return None\n\ndef _to_int(x):\n    if isinstance(x, bool):\n        return None\n    if isinstance(x, int):\n        return x\n    if isinstance(x, str):\n        s = x.strip()\n        if s and s.lstrip(\"-+\").isdigit():\n            try:\n                return int(s)\n            except Exception:\n                return None\n    return None\n\ndef _to_float(x):\n    if isinstance(x, (int, float)):\n        return float(x)\n    if isinstance(x, str):\n        try:\n            return float(x.strip())\n        except Exception:\n            return None\n    return None\n\ndef _to_pct(x):\n    if x is None:\n        return None\n    if isinstance(x, (int, float)):\n        v = float(x)\n    elif isinstance(x, str):\n        try:\n            v = float(x.strip().strip('%'))\n        except Exception:\n            return None\n    else:\n        return None\n    if v < 0:\n        v = 0.0\n    if v > 100:\n        v = 100.0\n    return v\n\ndef filter_map_validate(records):\n    if not isinstance(records, list):\n        return []\n    kept = []\n    for rec in records:\n        if not isinstance(rec, dict):\n            continue\n        # --- id ---\n        rid = rec.get(\"id\")\n        rid = str(rid).strip() if rid is not None else \"\"\n        if not rid:\n            continue\n        # --- meta ---\n        meta = rec.get(\"meta\") or {}\n        if not isinstance(meta, dict):\n            meta = {}\n        rtype = str(meta.get(\"type\") or \"\").strip().lower()\n        flags = meta.get(\"flags\")\n        if isinstance(flags, list):\n            flags_norm = [str(t).strip().lower() for t in flags if isinstance(t, (str, int, float))]\n        else:\n            flags_norm = []\n        if rtype not in (\"std\",\"pro\",\"ent\"):\n            continue\n        # --- price ---\n        price = _parse_price(rec.get(\"price\"))\n        if price is None:\n            continue\n        # --- attrs ---\n        attrs = rec.get(\"attrs\") or {}\n        if not isinstance(attrs, dict):\n            attrs = {}\n        color = attrs.get(\"color\")\n        color = str(color).strip().lower() if isinstance(color, str) else None\n        size = attrs.get(\"size\")\n        if size is not None:\n            size = _to_int(size)\n        weight = attrs.get(\"weight\")\n        if weight is not None:\n            weight = _to_float(weight)\n        cond = attrs.get(\"condition\")\n        cond = str(cond).strip().upper() if isinstance(cond, str) else None\n        discount = _to_pct(attrs.get(\"discount\"))\n        # --- stock ---\n        stock = _to_int(rec.get(\"stock\"))\n        if stock is None:\n            stock = 0\n        if stock < 0:\n            stock = 0\n        # --- Validation A: color/flag gate ---\n        if not ((color in {\"red\",\"blue\",\"green\"}) or (\"eco\" in flags_norm)):\n            continue\n        # --- Validation B: price caps ---\n        if rtype in (\"std\",\"pro\") and price > 1000:\n            continue\n        if rtype == \"ent\" and price > 5000:\n            continue\n        # --- Validation C: refurb implies good condition ---\n        if \"refurb\" in flags_norm:\n            if cond not in {\"A\",\"B\"}:\n                continue\n        # --- Validation D: ent requires size>=10 and stock>=1 ---\n        if rtype == \"ent\":\n            if size is None or size < 10 or stock < 1:\n                continue\n        # --- Validation E: pro weight <= 50 if provided ---\n        if rtype == \"pro\" and weight is not None and weight > 50.0:\n            continue\n        kept.append({\n            \"id\": rid,\n            \"type\": rtype,\n            \"price\": price\n        })\n    # sort: type order (ent > pro > std) i.e., ent first, then pro, then std\n    kept.sort(key=lambda r: (type_order.get(r[\"type\"], 3), r[\"price\"], r[\"id\"].lower()))\n    return [r[\"id\"] for r in kept]\n", "test": [{"input": [[{"id": " A-1 ", "meta": {"type": "ent", "flags": ["Eco"]}, "price": "€4,999.00", "attrs": {"size": "12", "color": "Green"}, "stock": "5"}, {"id": "B-2", "meta": {"type": "pro", "flags": ["refurb"]}, "price": "$800", "attrs": {"weight": "49.5", "color": "blue", "condition": "B"}, "stock": 0}, {"id": "c-3", "meta": {"type": "std", "flags": []}, "price": "1200", "attrs": {"color": "red"}, "stock": 10}, {"id": "d-4", "meta": {"type": "ent", "flags": ["eco", "refurb"]}, "price": "5100", "attrs": {"size": 15, "color": "green", "condition": "A"}, "stock": 2}, {"id": "e-5", "meta": {"type": "pro", "flags": []}, "price": "999.99", "attrs": {"color": "yellow"}, "stock": 7}]], "output": ["A-1", "B-2"]}, {"input": [[{"id": 101, "meta": {"type": "pro", "flags": ["eco"]}, "price": "1,000.00", "attrs": {"color": "RED", "weight": "50"}, "stock": "-3"}, {"id": 102, "meta": {"type": "pro", "flags": ["eco"]}, "price": "1,000.01", "attrs": {"color": "GREEN", "weight": "10"}, "stock": "0"}, {"id": 103, "meta": {"type": "std", "flags": ["eco"]}, "price": "$0", "attrs": {"color": "green"}, "stock": "0"}]], "output": ["101", "103"]}, {"input": [[{"id": "X", "meta": {"type": "ent", "flags": ["REFURB"]}, "price": "$4500", "attrs": {"size": "9", "color": "blue", "condition": "A"}, "stock": 1}, {"id": "Y", "meta": {"type": "ent", "flags": []}, "price": "$4500", "attrs": {"size": "12", "color": "blue"}, "stock": 0}, {"id": "Z", "meta": {"type": "ent", "flags": []}, "price": "$4500", "attrs": {"size": "12", "color": "blue"}, "stock": 3}]], "output": ["Z"]}, {"input": [[{"id": "bad", "meta": {"type": "other", "flags": ["eco"]}, "price": "100", "attrs": {"color": "red"}, "stock": 1}, {"id": "ok-std", "meta": {"type": "std", "flags": ["eco"]}, "price": "1000", "attrs": {"color": "green"}, "stock": 0}]], "output": ["ok-std"]}, {"input": [[{"id": "keep-pro-over-std", "meta": {"type": "pro", "flags": ["eco"]}, "price": "500", "attrs": {"color": "blue"}}, {"id": "keep-ent-first", "meta": {"type": "ent", "flags": ["eco"]}, "price": "1200", "attrs": {"color": "green", "size": 20}, "stock": 2}, {"id": "keep-std-last", "meta": {"type": "std", "flags": ["eco"]}, "price": "100", "attrs": {"color": "red"}}]], "output": ["keep-ent-first", "keep-pro-over-std", "keep-std-last"]}]}}
{"timestamp_utc": "2025-09-27T12:09:59.428541", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 26, "question": "Write sliding_window_max(arr, k) that returns maximum element in each sliding window of size k using deque. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 23.16083025932312, "response": "```python\nfrom collections import deque\n\ndef sliding_window_max(arr, k):\n    if not arr:\n        return []\n    deq = deque()\n    result = []\n    for i in range(len(arr)):\n        while deq and arr[deq[-1]] < arr[i]:\n            deq.pop()\n        deq.append(i)\n        while deq and deq[0] < i - k + 1:\n            deq.popleft()\n        if i >= k - 1:\n            result.append(arr[deq[0]])\n    return result\n```", "error": null, "raw_item": {"task_id": "custom_sliding_window_max", "prompt": "Write sliding_window_max(arr, k) that returns maximum element in each sliding window of size k using deque. Return only the Python function code with no explanations.", "entry_point": "sliding_window_max", "canonical_solution": "from collections import deque\n\ndef sliding_window_max(arr: list[int], k: int) -> list[int]:\n    if not arr or k == 0:\n        return []\n    \n    dq = deque()\n    result = []\n    \n    for i in range(len(arr)):\n        # Remove elements outside current window\n        while dq and dq[0] <= i - k:\n            dq.popleft()\n        \n        # Remove elements smaller than current element\n        while dq and arr[dq[-1]] <= arr[i]:\n            dq.pop()\n        \n        dq.append(i)\n        \n        # Add maximum to result if window is complete\n        if i >= k - 1:\n            result.append(arr[dq[0]])\n    \n    return result", "test": [{"input": [[1, 3, -1, -3, 5, 3, 6, 7], 3], "output": [3, 3, 5, 5, 6, 7]}, {"input": [[1, 2, 3], 1], "output": [1, 2, 3]}, {"input": [[5, 4, 3, 2, 1], 2], "output": [5, 4, 3, 2]}, {"input": [[1], 1], "output": [1]}, {"input": [[], 3], "output": []}, {"input": [[7, 2, 4], 3], "output": [7]}]}}
{"timestamp_utc": "2025-09-27T12:10:07.977774", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 27, "question": "Write rotate_matrix(matrix) that rotates n×n matrix 90 degrees clockwise in-place using transpose and reverse. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 7.546583890914917, "response": "```python\ndef rotate_matrix(matrix):\n    n = len(matrix)\n    # Transpose the matrix\n    for i in range(n):\n        for j in range(i + 1, n):\n            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n    # Reverse each row\n    for i in range(n):\n        matrix[i].reverse()\n```", "error": null, "raw_item": {"task_id": "custom_rotate_matrix", "prompt": "Write rotate_matrix(matrix) that rotates n×n matrix 90 degrees clockwise in-place using transpose and reverse. Return only the Python function code with no explanations.", "entry_point": "rotate_matrix", "canonical_solution": "def rotate_matrix(matrix: list[list[int]]) -> list[list[int]]:\n    if not matrix or not matrix[0]:\n        return matrix\n    \n    n = len(matrix)\n    \n    # Transpose the matrix\n    for i in range(n):\n        for j in range(i, n):\n            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n    \n    # Reverse each row\n    for i in range(n):\n        matrix[i].reverse()\n    \n    return matrix", "test": [{"input": [[[1, 2, 3], [4, 5, 6], [7, 8, 9]]], "output": [[7, 4, 1], [8, 5, 2], [9, 6, 3]]}, {"input": [[[1, 2], [3, 4]]], "output": [[3, 1], [4, 2]]}, {"input": [[[1]]], "output": [[1]]}, {"input": [[]], "output": []}, {"input": [[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]], "output": [[13, 9, 5, 1], [14, 10, 6, 2], [15, 11, 7, 3], [16, 12, 8, 4]]}]}}
{"timestamp_utc": "2025-09-27T12:10:18.477802", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 28, "question": "Write is_arithmetic_sequence(seq) that checks if sequence forms arithmetic progression with common difference > 0. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 9.496402263641357, "response": "```python\ndef is_arithmetic_sequence(seq):\n    if len(seq) < 2:\n        return False\n    d = seq[1] - seq[0]\n    if d <= 0:\n        return False\n    for i in range(2, len(seq)):\n        if seq[i] - seq[i-1] != d:\n            return False\n    return True\n```", "error": null, "raw_item": {"task_id": "alg_arithmetic_sequence", "entry_point": "is_arithmetic_sequence", "prompt": "Write is_arithmetic_sequence(seq) that checks if sequence forms arithmetic progression with common difference > 0. Return only the Python function code with no explanations.", "canonical_solution": "def is_arithmetic_sequence(seq):\n    if len(seq) < 2:\n        return False\n    diff = seq[1] - seq[0]\n    if diff <= 0:\n        return False\n    for i in range(2, len(seq)):\n        if seq[i] - seq[i-1] != diff:\n            return False\n    return True", "test": [{"input": [[1, 3, 5, 7, 9]], "output": true}, {"input": [[2, 4, 6, 8]], "output": true}, {"input": [[5, 5, 5]], "output": false}, {"input": [[1, 2, 4, 8]], "output": false}, {"input": [[10, 5, 0]], "output": false}]}}
{"timestamp_utc": "2025-09-27T12:10:27.514934", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 29, "question": "Write classify_severity(msg) that returns HIGH if msg contains 'error' or 'critical', MEDIUM if contains 'warning', LOW otherwise. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 8.03580617904663, "response": "```python\ndef classify_severity(msg):\n    if 'error' in msg or 'critical' in msg:\n        return 'HIGH'\n    elif 'warning' in msg:\n        return 'MEDIUM'\n    else:\n        return 'LOW'\n```", "error": null, "raw_item": {"task_id": "se_severity_classifier", "entry_point": "classify_severity", "prompt": "Write classify_severity(msg) that returns HIGH if msg contains 'error' or 'critical', MEDIUM if contains 'warning', LOW otherwise. Return only the Python function code with no explanations.", "canonical_solution": "def classify_severity(msg):\n    msg_lower = msg.lower()\n    if 'error' in msg_lower or 'critical' in msg_lower:\n        return 'HIGH'\n    elif 'warning' in msg_lower:\n        return 'MEDIUM'\n    else:\n        return 'LOW'", "test": [{"input": ["System error occurred"], "output": "HIGH"}, {"input": ["Critical failure detected"], "output": "HIGH"}, {"input": ["Warning: disk space low"], "output": "MEDIUM"}, {"input": ["Info: task completed"], "output": "LOW"}, {"input": ["ERROR in database"], "output": "HIGH"}]}}
{"timestamp_utc": "2025-09-27T12:10:39.674180", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 30, "question": "Write find_peak_index(arr) that finds index of first element that is greater than both neighbors. Return -1 if no peak exists. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 11.158220052719116, "response": "```python\ndef find_peak_index(arr):\n    for i in range(1, len(arr) - 1):\n        if arr[i] > arr[i - 1] and arr[i] > arr[i + 1]:\n            return i\n    return -1\n```", "error": null, "raw_item": {"task_id": "alg_peak_finder", "entry_point": "find_peak_index", "prompt": "Write find_peak_index(arr) that finds index of first element that is greater than both neighbors. Return -1 if no peak exists. Return only the Python function code with no explanations.", "canonical_solution": "def find_peak_index(arr):\n    if len(arr) < 3:\n        return -1\n    for i in range(1, len(arr) - 1):\n        if arr[i] > arr[i-1] and arr[i] > arr[i+1]:\n            return i\n    return -1", "test": [{"input": [[1, 3, 2, 4, 1]], "output": 1}, {"input": [[1, 2, 3, 2, 1]], "output": 2}, {"input": [[1, 2, 3, 4, 5]], "output": -1}, {"input": [[5, 4, 3, 2, 1]], "output": -1}, {"input": [[1, 3, 1]], "output": 1}]}}
{"timestamp_utc": "2025-09-27T12:11:04.562408", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 31, "question": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 23.884218215942383, "response": "```python\nfrom collections import defaultdict\n\ndef find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"\n    if not words:\n        return []\n    \n    anagram_map = defaultdict(list)\n    for word in words:\n        sorted_word = ''.join(sorted(word))\n        anagram_map[sorted_word].append(word)\n    \n    groups = []\n    for group in anagram_map.values():\n        group.sort()\n        groups.append(group)\n    \n    groups.sort(key=lambda g: g[0])\n    return groups\n```", "error": null, "raw_item": {"task_id": "custom_find_anagrams", "prompt": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    \"\"\"\n    Given a list of words, group anagrams together.\n    Return a list of groups, where each group contains anagrams.\n    Words within each group should be sorted alphabetically.\n    Groups should be sorted by their first word alphabetically.\n\n    Examples:\n    >>> find_anagrams([\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"])\n    [['ate', 'eat', 'tea'], ['bat'], ['nat', 'tan']]\n\n    >>> find_anagrams([\"hello\", \"world\"])\n    [['hello'], ['world']]\n\n    >>> find_anagrams([])\n    []\n\n    >>> find_anagrams([\"a\", \"aa\", \"aaa\"])\n    [['a'], ['aa'], ['aaa']]\n    \"\"\"\n    ", "entry_point": "find_anagrams", "canonical_solution": "def find_anagrams(words: list[str]) -> list[list[str]]:\n    from collections import defaultdict\n    \n    anagram_groups = defaultdict(list)\n    \n    for word in words:\n        # Use sorted characters as key\n        key = ''.join(sorted(word))\n        anagram_groups[key].append(word)\n    \n    result = []\n    for group in anagram_groups.values():\n        group.sort()\n        result.append(group)\n    \n    # Sort groups by their first word\n    result.sort(key=lambda x: x[0])\n    \n    return result", "test": [{"input": [["eat", "tea", "tan", "ate", "nat", "bat"]], "output": [["ate", "eat", "tea"], ["bat"], ["nat", "tan"]]}, {"input": [["hello", "world"]], "output": [["hello"], ["world"]]}, {"input": [[]], "output": []}, {"input": [["a", "aa", "aaa"]], "output": [["a"], ["aa"], ["aaa"]]}, {"input": [["abc", "bca", "cab", "xyz"]], "output": [["abc", "bca", "cab"], ["xyz"]]}]}}
{"timestamp_utc": "2025-09-27T12:11:35.480583", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 32, "question": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 29.915457010269165, "response": "```python\ndef merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"\n    if not intervals:\n        return []\n    \n    intervals.sort(key=lambda x: x[0])\n    result = [intervals[0]]\n    \n    for interval in intervals[1:]:\n        if interval[0] <= result[-1][1]:\n            result[-1][1] = max(result[-1][1], interval[1])\n        else:\n            result.append(interval)\n    \n    return result\n```", "error": null, "raw_item": {"task_id": "custom_merge_intervals", "prompt": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Given a list of intervals where intervals[i] = [start_i, end_i],\n    merge all overlapping intervals and return a list of non-overlapping intervals.\n\n    Examples:\n    >>> merge_intervals([[1, 3], [2, 6], [8, 10], [15, 18]])\n    [[1, 6], [8, 10], [15, 18]]\n\n    >>> merge_intervals([[1, 4], [4, 5]])\n    [[1, 5]]\n\n    >>> merge_intervals([[1, 4], [0, 2], [3, 5]])\n    [[0, 5]]\n\n    >>> merge_intervals([])\n    []\n    \"\"\"\n    ", "entry_point": "merge_intervals", "canonical_solution": "def merge_intervals(intervals: list[list[int]]) -> list[list[int]]:\n    if not intervals:\n        return []\n    \n    # Sort intervals by start time\n    intervals.sort(key=lambda x: x[0])\n    \n    merged = [intervals[0]]\n    \n    for current in intervals[1:]:\n        last = merged[-1]\n        \n        # Check if current interval overlaps with last merged interval\n        if current[0] <= last[1]:\n            # Merge intervals\n            last[1] = max(last[1], current[1])\n        else:\n            # No overlap, add current interval\n            merged.append(current)\n    \n    return merged", "test": [{"input": [[[1, 3], [2, 6], [8, 10], [15, 18]]], "output": [[1, 6], [8, 10], [15, 18]]}, {"input": [[[1, 4], [4, 5]]], "output": [[1, 5]]}, {"input": [[[1, 4], [0, 2], [3, 5]]], "output": [[0, 5]]}, {"input": [[]], "output": []}, {"input": [[[1, 2]]], "output": [[1, 2]]}, {"input": [[[1, 4], [2, 3]]], "output": [[1, 4]]}]}}
{"timestamp_utc": "2025-09-27T12:11:53.606533", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 33, "question": "def binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 17.12450671195984, "response": "```python\ndef binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"\n    if not root:\n        return []\n    \n    result = []\n    \n    def dfs(node, current_path):\n        current_path.append(str(node['val']))\n        \n        if not node['left'] and not node['right']:\n            result.append('->'.join(current_path))\n        else:\n            if node['left']:\n                dfs(node['left'], current_path)\n            if node['right']:\n                dfs(node['right'], current_path)\n        \n        current_path.pop()\n    \n    dfs(root, [])\n    return result\n```", "error": null, "raw_item": {"task_id": "custom_binary_tree_paths", "prompt": "def binary_tree_paths(root: dict | None) -> list[str]:\n    \"\"\"\n    Given a binary tree represented as nested dictionaries with 'val', 'left', and 'right' keys,\n    return all root-to-leaf paths as strings with arrows.\n\n    Tree format: {'val': int, 'left': dict|None, 'right': dict|None}\n\n    Examples:\n    >>> binary_tree_paths({'val': 1, 'left': {'val': 2, 'left': None, 'right': {'val': 5, 'left': None, 'right': None}}, 'right': {'val': 3, 'left': None, 'right': None}})\n    ['1->2->5', '1->3']\n\n    >>> binary_tree_paths({'val': 1, 'left': None, 'right': None})\n    ['1']\n\n    >>> binary_tree_paths(None)\n    []\n    \"\"\"\n    ", "entry_point": "binary_tree_paths", "canonical_solution": "def binary_tree_paths(root: dict | None) -> list[str]:\n    if not root:\n        return []\n    \n    paths = []\n    \n    def dfs(node, path):\n        if not node:\n            return\n        \n        # Add current node to path\n        current_path = path + [str(node['val'])]\n        \n        # If leaf node, add path to result\n        if not node['left'] and not node['right']:\n            paths.append('->'.join(current_path))\n            return\n        \n        # Recurse on children\n        if node['left']:\n            dfs(node['left'], current_path)\n        if node['right']:\n            dfs(node['right'], current_path)\n    \n    dfs(root, [])\n    return paths", "test": [{"input": [{"val": 1, "left": {"val": 2, "left": null, "right": {"val": 5, "left": null, "right": null}}, "right": {"val": 3, "left": null, "right": null}}], "output": ["1->2->5", "1->3"]}, {"input": [{"val": 1, "left": null, "right": null}], "output": ["1"]}, {"input": [null], "output": []}, {"input": [{"val": 1, "left": {"val": 2, "left": null, "right": null}, "right": {"val": 3, "left": null, "right": null}}], "output": ["1->2", "1->3"]}]}}
{"timestamp_utc": "2025-09-27T12:12:17.769742", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 34, "question": "def word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 23.160375118255615, "response": "```python\ndef word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"\n    words = s.split()\n    if len(pattern) != len(words):\n        return False\n    \n    char_to_word = {}\n    word_to_char = {}\n    \n    for i in range(len(pattern)):\n        char = pattern[i]\n        word = words[i]\n        \n        if char in char_to_word:\n            if char_to_word[char] != word:\n                return False\n        else:\n            if word in word_to_char:\n                return False\n            char_to_word[char] = word\n            word_to_char[word] = char\n    \n    return True\n```", "error": null, "raw_item": {"task_id": "custom_word_pattern", "prompt": "def word_pattern(pattern: str, s: str) -> bool:\n    \"\"\"\n    Given a pattern and a string s, find if s follows the same pattern.\n    Here follow means a full match, such that there is a bijection between\n    a letter in pattern and a non-empty word in s.\n\n    Examples:\n    >>> word_pattern(\"abba\", \"dog cat cat dog\")\n    True\n\n    >>> word_pattern(\"abba\", \"dog cat cat fish\")\n    False\n\n    >>> word_pattern(\"aaaa\", \"dog cat cat dog\")\n    False\n\n    >>> word_pattern(\"abba\", \"dog dog dog dog\")\n    False\n    \"\"\"\n    ", "entry_point": "word_pattern", "canonical_solution": "def word_pattern(pattern: str, s: str) -> bool:\n    words = s.split()\n    \n    if len(pattern) != len(words):\n        return False\n    \n    char_to_word = {}\n    word_to_char = {}\n    \n    for char, word in zip(pattern, words):\n        # Check char -> word mapping\n        if char in char_to_word:\n            if char_to_word[char] != word:\n                return False\n        else:\n            char_to_word[char] = word\n        \n        # Check word -> char mapping (bijection)\n        if word in word_to_char:\n            if word_to_char[word] != char:\n                return False\n        else:\n            word_to_char[word] = char\n    \n    return True", "test": [{"input": ["abba", "dog cat cat dog"], "output": true}, {"input": ["abba", "dog cat cat fish"], "output": false}, {"input": ["aaaa", "dog cat cat dog"], "output": false}, {"input": ["abba", "dog dog dog dog"], "output": false}, {"input": ["abc", "dog cat fish"], "output": true}, {"input": ["a", "dog"], "output": true}, {"input": ["ab", "dog"], "output": false}]}}
{"timestamp_utc": "2025-09-27T12:12:41.227789", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 35, "question": "class MinStack:\n    \"\"\"\n    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\n    Implement the MinStack class:\n    - MinStack() initializes the stack object.\n    - push(val) pushes the element val onto the stack.\n    - pop() removes the element on the top of the stack.\n    - top() gets the top element of the stack.\n    - get_min() retrieves the minimum element in the stack.\n\n    You must implement a solution with O(1) time complexity for each function.\n\n    Examples:\n    >>> stack = MinStack()\n    >>> stack.push(-2)\n    >>> stack.push(0)\n    >>> stack.push(-3)\n    >>> stack.get_min()\n    -3\n    >>> stack.pop()\n    >>> stack.top()\n    0\n    >>> stack.get_min()\n    -2\n    \"\"\"", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 22.455301761627197, "response": "```python\nclass MinStack:\n    def __init__(self):\n        self.stack = []\n        self.min_stack = []\n\n    def push(self, val):\n        self.stack.append(val)\n        if not self.min_stack or val <= self.min_stack[-1]:\n            self.min_stack.append(val)\n\n    def pop(self):\n        if self.stack:\n            val = self.stack.pop()\n            if self.min_stack and val == self.min_stack[-1]:\n                self.min_stack.pop()\n\n    def top(self):\n        if self.stack:\n            return self.stack[-1]\n\n    def get_min(self):\n        if self.min_stack:\n            return self.min_stack[-1]\n```", "error": null, "raw_item": {"task_id": "custom_min_stack", "prompt": "class MinStack:\n    \"\"\"\n    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.\n\n    Implement the MinStack class:\n    - MinStack() initializes the stack object.\n    - push(val) pushes the element val onto the stack.\n    - pop() removes the element on the top of the stack.\n    - top() gets the top element of the stack.\n    - get_min() retrieves the minimum element in the stack.\n\n    You must implement a solution with O(1) time complexity for each function.\n\n    Examples:\n    >>> stack = MinStack()\n    >>> stack.push(-2)\n    >>> stack.push(0)\n    >>> stack.push(-3)\n    >>> stack.get_min()\n    -3\n    >>> stack.pop()\n    >>> stack.top()\n    0\n    >>> stack.get_min()\n    -2\n    \"\"\"\n    ", "entry_point": "MinStack", "canonical_solution": "class MinStack:\n    def __init__(self):\n        self.stack = []\n        self.min_stack = []\n    \n    def push(self, val: int) -> None:\n        self.stack.append(val)\n        # Push to min_stack if it's empty or val is <= current minimum\n        if not self.min_stack or val <= self.min_stack[-1]:\n            self.min_stack.append(val)\n    \n    def pop(self) -> None:\n        if self.stack:\n            val = self.stack.pop()\n            # Pop from min_stack if the popped value was the minimum\n            if self.min_stack and val == self.min_stack[-1]:\n                self.min_stack.pop()\n    \n    def top(self) -> int:\n        return self.stack[-1] if self.stack else None\n    \n    def get_min(self) -> int:\n        return self.min_stack[-1] if self.min_stack else None", "test": [{"input": [["MinStack", "push", "push", "push", "get_min", "pop", "top", "get_min"], [[], [-2], [0], [-3], [], [], [], []]], "output": [null, null, null, null, -3, null, 0, -2]}, {"input": [["MinStack", "push", "push", "get_min", "get_min", "pop", "get_min"], [[], [1], [2], [], [], [], []]], "output": [null, null, null, 1, 1, null, 1]}, {"input": [["MinStack", "push", "get_min", "pop", "push", "get_min"], [[], [1], [], [], [2], []]], "output": [null, null, 1, null, null, 2]}]}}
{"timestamp_utc": "2025-09-27T12:13:54.558610", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 36, "question": "class LRUCache:\n    \"\"\"\n    Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.\n\n    Implement the LRUCache class:\n    - LRUCache(capacity) Initialize the LRU cache with positive size capacity.\n    - get(key) Return the value of the key if the key exists, otherwise return -1.\n    - put(key, value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache.\n      If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\n    The functions get and put must each run in O(1) average time complexity.\n\n    Examples:\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 72.32852005958557, "response": "```python\nclass Node:\n    def __init__(self, key, val):\n        self.key = key\n        self.val = val\n        self.prev = None\n        self.next = None\n\nclass LRUCache:\n    \"\"\"\n    Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.\n\n    Implement the LRUCache class:\n    - LRUCache(capacity) Initialize the LRU cache with positive size capacity.\n    - get(key) Return the value of the key if the key exists, otherwise return -1.\n    - put(key, value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache.\n      If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\n    The functions get and put must each run in O(1) average time complexity.\n\n    Examples:\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"\n\n    def __init__(self, capacity: int):\n        self.cap = capacity\n        self.cache = {}  # key to node\n        self.head = Node(0, 0)\n        self.tail = Node(0, 0)\n        self.head.next = self.tail\n        self.tail.prev = self.head\n\n    def _remove(self, node):\n        prev = node.prev\n        next_ = node.next\n        prev.next = next_\n        next_.prev = prev\n\n    def _add(self, node):\n        prev = self.tail.prev\n        prev.next = node\n        node.prev = prev\n        node.next = self.tail\n        self.tail.prev = node\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        node = self.cache[key]\n        self._remove(node)\n        self._add(node)\n        return node.val\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            node = self.cache[key]\n            self._remove(node)\n            node.val = value\n            self._add(node)\n            return\n        if len(self.cache) >= self.cap:\n            lru = self.head.next\n            self._remove(lru)\n            del self.cache[lru.key]\n        node = Node(key, value)\n        self._add(node)\n        self.cache[key] = node\n```", "error": null, "raw_item": {"task_id": "custom_lru_cache", "prompt": "class LRUCache:\n    \"\"\"\n    Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.\n\n    Implement the LRUCache class:\n    - LRUCache(capacity) Initialize the LRU cache with positive size capacity.\n    - get(key) Return the value of the key if the key exists, otherwise return -1.\n    - put(key, value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache.\n      If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\n    The functions get and put must each run in O(1) average time complexity.\n\n    Examples:\n    >>> cache = LRUCache(2)\n    >>> cache.put(1, 1)\n    >>> cache.put(2, 2)\n    >>> cache.get(1)\n    1\n    >>> cache.put(3, 3)\n    >>> cache.get(2)\n    -1\n    >>> cache.put(4, 4)\n    >>> cache.get(1)\n    -1\n    >>> cache.get(3)\n    3\n    >>> cache.get(4)\n    4\n    \"\"\"\n    ", "entry_point": "LRUCache", "canonical_solution": "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        # Use a list to maintain order (least recent at index 0)\n        self.order = []\n    \n    def get(self, key: int) -> int:\n        if key in self.cache:\n            # Move to end (most recently used)\n            self.order.remove(key)\n            self.order.append(key)\n            return self.cache[key]\n        return -1\n    \n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            # Update existing key\n            self.cache[key] = value\n            self.order.remove(key)\n            self.order.append(key)\n        else:\n            # Add new key\n            if len(self.cache) >= self.capacity:\n                # Remove least recently used\n                lru_key = self.order.pop(0)\n                del self.cache[lru_key]\n            \n            self.cache[key] = value\n            self.order.append(key)", "test": [{"input": [["LRUCache", "put", "put", "get", "put", "get", "put", "get", "get", "get"], [[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]], "output": [null, null, null, 1, null, -1, null, -1, 3, 4]}, {"input": [["LRUCache", "put", "get", "put", "get", "get"], [[1], [2, 1], [2], [3, 2], [2], [3]]], "output": [null, null, 1, null, -1, 2]}]}}
{"timestamp_utc": "2025-09-27T12:14:24.663788", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 37, "question": "def validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 29.0986270904541, "response": "```python\ndef validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"\n\n    def is_valid_ipv4(s: str) -> bool:\n        parts = s.split('.')\n        if len(parts) != 4:\n            return False\n        for part in parts:\n            if not part.isdigit():\n                return False\n            num = int(part)\n            if num < 0 or num > 255:\n                return False\n            if len(part) > 1 and part[0] == '0':\n                return False\n        return True\n\n    def is_valid_ipv6(s: str) -> bool:\n        parts = s.split(':')\n        if len(parts) != 8:\n            return False\n        for part in parts:\n            if len(part) < 1 or len(part) > 4:\n                return False\n            for char in part:\n                if not (char.isdigit() or char.lower() in 'abcdef'):\n                    return False\n        return True\n\n    if is_valid_ipv4(ip):\n        return \"IPv4\"\n    elif is_valid_ipv6(ip):\n        return \"IPv6\"\n    else:\n        return \"Neither\"\n```", "error": null, "raw_item": {"task_id": "custom_validate_ip_address", "prompt": "def validate_ip_address(ip: str) -> str:\n    \"\"\"\n    Given a string ip, return \"IPv4\" if it's a valid IPv4 address,\n    \"IPv6\" if it's a valid IPv6 address, or \"Neither\" if it's not a valid IP address.\n\n    IPv4 rules:\n    - Four decimal numbers separated by dots\n    - Each number is 0-255\n    - No leading zeros except for \"0\" itself\n\n    IPv6 rules:\n    - Eight hexadecimal groups separated by colons\n    - Each group is 1-4 hexadecimal digits\n    - Leading zeros in a group are allowed\n\n    Examples:\n    >>> validate_ip_address(\"172.16.254.1\")\n    \"IPv4\"\n\n    >>> validate_ip_address(\"2001:0db8:85a3:0000:0000:8a2e:0370:7334\")\n    \"IPv6\"\n\n    >>> validate_ip_address(\"256.256.256.256\")\n    \"Neither\"\n\n    >>> validate_ip_address(\"192.168.1.1.1\")\n    \"Neither\"\n    \"\"\"\n    ", "entry_point": "validate_ip_address", "canonical_solution": "def validate_ip_address(ip: str) -> str:\n    def is_valid_ipv4(ip):\n        parts = ip.split('.')\n        if len(parts) != 4:\n            return False\n        \n        for part in parts:\n            if not part or len(part) > 3:\n                return False\n            \n            # Check for leading zeros\n            if len(part) > 1 and part[0] == '0':\n                return False\n            \n            # Check if all characters are digits\n            if not part.isdigit():\n                return False\n            \n            # Check range\n            num = int(part)\n            if num < 0 or num > 255:\n                return False\n        \n        return True\n    \n    def is_valid_ipv6(ip):\n        parts = ip.split(':')\n        if len(parts) != 8:\n            return False\n        \n        for part in parts:\n            if not part or len(part) > 4:\n                return False\n            \n            # Check if all characters are valid hex\n            for char in part:\n                if char not in '0123456789abcdefABCDEF':\n                    return False\n        \n        return True\n    \n    if is_valid_ipv4(ip):\n        return \"IPv4\"\n    elif is_valid_ipv6(ip):\n        return \"IPv6\"\n    else:\n        return \"Neither\"", "test": [{"input": ["172.16.254.1"], "output": "IPv4"}, {"input": ["2001:0db8:85a3:0000:0000:8a2e:0370:7334"], "output": "IPv6"}, {"input": ["256.256.256.256"], "output": "Neither"}, {"input": ["192.168.1.1.1"], "output": "Neither"}, {"input": ["192.168.01.1"], "output": "Neither"}, {"input": ["2001:0db8:85a3::8a2e:0370:7334"], "output": "Neither"}, {"input": [""], "output": "Neither"}]}}
{"timestamp_utc": "2025-09-27T12:14:43.815990", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 38, "question": "Merge two dictionaries with integer values by keeping the maximum value for each key.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 18.147905111312866, "response": "Sure, I'll assume you're asking about merging two dictionaries in Python (a common language for such tasks), where both dictionaries have hashable keys (e.g., strings) and integer values. The goal is to create a new dictionary that includes all unique keys from both, and for any overlapping keys, we keep the maximum value.\n\n### Example Dictionaries\nLet's say we have:\n```python\ndict1 = {'a': 5, 'b': 10, 'c': 3}\ndict2 = {'b': 7, 'c': 15, 'd': 2}\n```\n\nThe merged result should be:\n- 'a': 5 (only in dict1)\n- 'b': 10 (max of 10 from dict1 and 7 from dict2)\n- 'c': 15 (max of 3 from dict1 and 15 from dict2)\n- 'd': 2 (only in dict2)\n\nResult: `{'a': 5, 'b': 10, 'c': 15, 'd': 2}`\n\n### Solution\nYou can achieve this using a dictionary comprehension with `dict.keys()` and the `max()` function. Here's a simple function to do it:\n\n```python\ndef merge_dicts_max(dict1, dict2):\n    # Get all unique keys from both dictionaries\n    all_keys = set(dict1.keys()) | set(dict2.keys())\n    \n    # Create a new dict with the max value for each key\n    merged = {}\n    for key in all_keys:\n        # Use max, with a default of float('-inf') if key is missing\n        val1 = dict1.get(key, float('-inf'))\n        val2 = dict2.get(key, float('-inf'))\n        merged[key] = max(val1, val2)\n    \n    return merged\n\n# Example usage\ndict1 = {'a': 5, 'b': 10, 'c': 3}\ndict2 = {'b': 7, 'c': 15, 'd': 2}\nresult = merge_dicts_max(dict1, dict2)\nprint(result)  # Output: {'a': 5, 'b': 10, 'c': 15, 'd': 2}\n```\n\n### Explanation\n- We use a set union (`|`) to get all unique keys.\n- For each key, we retrieve the value from each dict using `.get()` (with a very low default to handle missing keys).\n- We take the `max` of the two values and store it in the new dictionary.\n\n### Alternatives\n- **Using dict comprehension directly** (more concise, Python 3.9+ for simplicity):\n  ```python\n  def merge_dicts_max(dict1, dict2):\n      all_keys = set(dict1) | set(dict2)\n      return {key: max(dict1.get(key, float('-inf')), dict2.get(key, float('-inf'))) for key in all_keys}\n  ```\n\n- **If you're using Python 3.10+**, you could leverage the `|` operator for dict merging, but it doesn't directly support max— you'd still need to handle overlaps manually.\n\nThis assumes the values are integers (as specified). If the dictionaries could have non-integer values or you need to handle errors (e.g., non-numeric values), let me know for adjustments! If this is for a different programming language, specify which one.", "error": null, "raw_item": {"task_id": "MyBench/dict_merge_max", "prompt": "Merge two dictionaries with integer values by keeping the maximum value for each key.", "entry_point": "merge_max", "canonical_solution": "def merge_max(d1, d2):\n    out = dict(d1)\n    for k,v in d2.items():\n        out[k] = max(out.get(k, v), v)\n    return out", "test": [{"input": [{"a": 1, "b": 5}, {"b": 3, "c": 10}], "output": {"a": 1, "b": 5, "c": 10}}, {"input": [{}, {"x": 7}], "output": {"x": 7}}, {"input": [{"a": 5}, {"a": 5}], "output": {"a": 5}}, {"input": [{"m": -1, "n": 2}, {"m": -5, "o": 10}], "output": {"m": -1, "n": 2, "o": 10}}, {"input": [{}, {}], "output": {}}]}}
{"timestamp_utc": "2025-09-27T12:15:24.670234", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 39, "question": "Invert a dictionary where values may not be unique. Return a new dictionary mapping each value to a list of keys that had that value.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 39.84926629066467, "response": "Below is a Python function that inverts a dictionary as described. It handles cases where values are not unique by mapping each value to a list of keys (in the order they appear in the original dictionary's iteration order). I've assumed the values are hashable (as required for them to become keys in the new dictionary); if not, a `TypeError` will be raised by Python.\n\n```python\nfrom collections import defaultdict\n\ndef invert_dict(original):\n    inverted = defaultdict(list)\n    for key, value in original.items():\n        inverted[value].append(key)\n    return dict(inverted)  # Convert to a regular dict for the result\n\n# Example usage:\noriginal = {'a': 1, 'b': 1, 'c': 2}\nprint(invert_dict(original))  # Output: {1: ['a', 'b'], 2: ['c']}\n```\n\nThis implementation is efficient (O(n) time, where n is the number of items in the dictionary) and works with empty dictionaries (returns `{}`) or dictionaries with unique values (returns lists with single elements). If you need this in a different language or with modifications, let me know!", "error": null, "raw_item": {"task_id": "dict_invert_multival", "prompt": "Invert a dictionary where values may not be unique. Return a new dictionary mapping each value to a list of keys that had that value.", "entry_point": "invert_multival", "canonical_solution": "def invert_multival(d):\n    out={}\n    for k,v in d.items():\n        out.setdefault(v, []).append(k)\n    return out", "test": [{"input": [{"a": 1, "b": 2, "c": 1}], "output": {"1": ["a", "c"], "2": ["b"]}}, {"input": [{}], "output": {}}, {"input": [{"x": "hi", "y": "hi", "z": "bye"}], "output": {"hi": ["x", "y"], "bye": ["z"]}}, {"input": [{"p": 0, "q": 0, "r": 0}], "output": {"0": ["p", "q", "r"]}}, {"input": [{"k": 42}], "output": {"42": ["k"]}}]}}
{"timestamp_utc": "2025-09-27T12:15:58.155754", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 40, "question": "Return True if an integer has even parity (even number of 1 bits in binary), else False.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 32.48118782043457, "response": "Based on your query, it sounds like you're asking for a function that takes an integer as input and returns `True` if it has an even number of 1 bits in its binary representation (i.e., even parity), or `False` otherwise. Below is a simple Python implementation (this works for both positive and negative integers, treating them in two's complement form, though you could adjust for unsigned if needed).\n\n```python\ndef has_even_parity(n: int) -> bool:\n    # Convert to binary string and count '1's (simple but efficient for most cases)\n    count = bin(n).count('1')\n    return count % 2 == 0\n\n# Example usage:\nprint(has_even_parity(5))   # Binary 101 has 2 ones (even) -> True\nprint(has_even_parity(7))   # Binary 111 has 3 ones (odd) -> False\nprint(has_even_parity(0))   # Binary 0 has 0 ones (even) -> True\nprint(has_even_parity(-1))  # Binary ...111 (infinite ones, but in practice odd) -> False\n```\n\n### Explanation\n- We use Python's `bin()` to get the binary representation as a string (e.g., `'0b101'` for 5).\n- We count the number of `'1'` characters.\n- If the count is even (`count % 2 == 0`), return `True`; else `False`.\n\n### Alternative Implementation (Bitwise, No Strings)\nIf you prefer a purely bitwise approach (more efficient for very large integers, without using `bin()`):\n\n```python\ndef has_even_parity(n: int) -> bool:\n    parity = 0\n    while n:\n        parity ^= (n & 1)  # XOR with the least significant bit\n        n >>= 1            # Right-shift to process next bit\n    return parity == 0     # If final parity is 0, even number of 1s\n\n# Same examples as above\nprint(has_even_parity(5))   # True\nprint(has_even_parity(7))   # False\nprint(has_even_parity(0))   # True\nprint(has_even_parity(-1))  # False (loops forever in theory for negative; see note below)\n```\n\n**Note:** The bitwise version handles non-negative integers perfectly. For negative integers in Python (unbounded size), the loop would theoretically run forever due to sign extension. In practice, you can add a check like `n = n & ((1 << 64) - 1)` to limit to 64 bits, or use the `bin()` version, which handles negatives fine.\n\nIf this isn't what you meant (e.g., if you wanted this in a different language, for a specific integer, or something else), provide more details!", "error": null, "raw_item": {"task_id": "bitwise_parity", "prompt": "Return True if an integer has even parity (even number of 1 bits in binary), else False.", "entry_point": "even_parity", "canonical_solution": "def even_parity(n):\n    c=0\n    while n:\n        n&=n-1\n        c^=1\n    return c==0", "test": [{"input": [3], "output": false}, {"input": [5], "output": true}, {"input": [0], "output": true}, {"input": [15], "output": true}, {"input": [16], "output": false}, {"input": [255], "output": true}]}}
{"timestamp_utc": "2025-09-27T12:16:07.379833", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 41, "question": "Swap two integers without using a temporary variable, using bitwise XOR. Return the swapped pair as a tuple. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 8.220755100250244, "response": "```python\ndef swap(a, b):\n    a = a ^ b\n    b = a ^ b\n    a = a ^ b\n    return (a, b)\n```", "error": null, "raw_item": {"task_id": "bitwise_swap", "prompt": "Swap two integers without using a temporary variable, using bitwise XOR. Return the swapped pair as a tuple. Return only the Python function code with no explanations.", "entry_point": "swap_xor", "canonical_solution": "def swap_xor(a,b):\n    a=a^b; b=a^b; a=a^b\n    return (a,b)", "test": [{"input": [2, 5], "output": [5, 2]}, {"input": [0, 7], "output": [7, 0]}, {"input": [-3, 9], "output": [9, -3]}, {"input": [42, 42], "output": [42, 42]}, {"input": [1000000, 123456], "output": [123456, 1000000]}]}}
{"timestamp_utc": "2025-09-27T12:16:13.823385", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 42, "question": "Compute factorial of n recursively. Assume n >= 0. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 5.440255880355835, "response": "```python\ndef factorial(n):\n    if n == 0:\n        return 1\n    else:\n        return n * factorial(n - 1)\n```", "error": null, "raw_item": {"task_id": "recursion_factorial", "prompt": "Compute factorial of n recursively. Assume n >= 0. Return only the Python function code with no explanations.", "entry_point": "factorial", "canonical_solution": "def factorial(n):\n    return 1 if n<=1 else n*factorial(n-1)", "test": [{"input": [0], "output": 1}, {"input": [1], "output": 1}, {"input": [5], "output": 120}, {"input": [10], "output": 3628800}, {"input": [3], "output": 6}]}}
{"timestamp_utc": "2025-09-27T12:16:28.178954", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 43, "question": "Return the BFS traversal order of a graph represented as adjacency list dict, starting from given node. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 13.3541100025177, "response": "```python\nfrom collections import deque\n\ndef bfs_traversal(graph, start):\n    if start not in graph:\n        return []\n    visited = set()\n    queue = deque([start])\n    visited.add(start)\n    result = [start]\n    while queue:\n        node = queue.popleft()\n        for neighbor in graph.get(node, []):\n            if neighbor not in visited:\n                visited.add(neighbor)\n                queue.append(neighbor)\n                result.append(neighbor)\n    return result\n```", "error": null, "raw_item": {"task_id": "graph_bfs_order", "prompt": "Return the BFS traversal order of a graph represented as adjacency list dict, starting from given node. Return only the Python function code with no explanations.", "entry_point": "bfs_order", "canonical_solution": "from collections import deque\n\ndef bfs_order(graph,start):\n    seen={start}; q=deque([start]); order=[]\n    while q:\n        u=q.popleft(); order.append(u)\n        for v in sorted(graph.get(u,[])):\n            if v not in seen:\n                seen.add(v); q.append(v)\n    return order", "test": [{"input": [{"A": ["B", "C"], "B": ["D"], "C": [], "D": []}, "A"], "output": ["A", "B", "C", "D"]}, {"input": [{"1": ["2"], "2": ["3"], "3": []}, "1"], "output": ["1", "2", "3"]}, {"input": [{"x": []}, "x"], "output": ["x"]}, {"input": [{"a": ["b"], "b": ["a"]}, "a"], "output": ["a", "b"]}, {"input": [{"m": ["n", "o"], "n": [], "o": []}, "m"], "output": ["m", "n", "o"]}]}}
{"timestamp_utc": "2025-09-27T12:16:39.327604", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 44, "question": "Given a CSV string with header 'name,value' and multiple rows, return the sum of the 'value' column as int. Assume comma-separated, no quotes. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 10.143292903900146, "response": "```python\ndef sum_csv_values(csv_string):\n    lines = csv_string.strip().split('\\n')\n    total = 0\n    for line in lines[1:]:\n        parts = line.split(',')\n        total += int(parts[1])\n    return total\n```", "error": null, "raw_item": {"task_id": "parsing_csv_sum", "prompt": "Given a CSV string with header 'name,value' and multiple rows, return the sum of the 'value' column as int. Assume comma-separated, no quotes. Return only the Python function code with no explanations.", "entry_point": "csv_sum", "canonical_solution": "def csv_sum(text):\n    lines=text.strip().split('\\n')\n    if len(lines) <= 1:\n        return 0\n    total=0\n    for line in lines[1:]:\n        if line.strip():\n            name,val=line.split(',')\n            total+=int(val)\n    return total", "test": [{"input": ["name,value\\na,3\\nb,7\\nc,10"], "output": 20}, {"input": ["name,value\\n"], "output": 0}, {"input": ["name,value\\nfoo,0\\nbar,0"], "output": 0}, {"input": ["name,value\\nx,100"], "output": 100}, {"input": ["name,value\\na,1\\nb,2\\nc,3\\nd,4"], "output": 10}]}}
{"timestamp_utc": "2025-09-27T12:16:47.613171", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 45, "question": "Extract all sequences of digits from a string using regex and return them as a list of strings. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 7.28435206413269, "response": "```python\nimport re\n\ndef extract_digit_sequences(s):\n    return re.findall(r'\\d+', s)\n```", "error": null, "raw_item": {"task_id": "parsing_regex_digits", "prompt": "Extract all sequences of digits from a string using regex and return them as a list of strings. Return only the Python function code with no explanations.", "entry_point": "extract_digits", "canonical_solution": "import re\n\ndef extract_digits(s):\n    return re.findall(r'\\d+', s)", "test": [{"input": ["abc123de45f6"], "output": ["123", "45", "6"]}, {"input": ["no digits here"], "output": []}, {"input": ["2025year"], "output": ["2025"]}, {"input": ["a1b2c3d4"], "output": ["1", "2", "3", "4"]}, {"input": ["007bond"], "output": ["007"]}]}}
{"timestamp_utc": "2025-09-27T12:17:00.422935", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 46, "question": "Return the length of the longest increasing subsequence (LIS) in a list of integers. O(n^2) solution is fine. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 11.808247804641724, "response": "```python\ndef lengthOfLIS(nums):\n    if not nums:\n        return 0\n    n = len(nums)\n    dp = [1] * n\n    for i in range(n):\n        for j in range(i):\n            if nums[i] > nums[j]:\n                dp[i] = max(dp[i], dp[j] + 1)\n    return max(dp)\n```", "error": null, "raw_item": {"task_id": "algorithms_longest_increasing", "prompt": "Return the length of the longest increasing subsequence (LIS) in a list of integers. O(n^2) solution is fine. Return only the Python function code with no explanations.", "entry_point": "lis_length", "canonical_solution": "def lis_length(nums):\n    if not nums: return 0\n    dp=[1]*len(nums)\n    for i in range(len(nums)):\n        for j in range(i):\n            if nums[j]<nums[i]:\n                dp[i]=max(dp[i],dp[j]+1)\n    return max(dp)", "test": [{"input": [[10, 9, 2, 5, 3, 7, 101, 18]], "output": 4}, {"input": [[1, 2, 3, 4, 5]], "output": 5}, {"input": [[5, 4, 3, 2, 1]], "output": 1}, {"input": [[]], "output": 0}, {"input": [[2, 2, 2]], "output": 1}]}}
{"timestamp_utc": "2025-09-27T12:17:13.212288", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 47, "question": "0/1 Knapsack: given weights, values, and capacity W, return the maximum achievable value. Use DP. weights and values are equal length. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 11.769130945205688, "response": "```python\ndef knapsack(weights, values, W):\n    n = len(weights)\n    dp = [[0] * (W + 1) for _ in range(n + 1)]\n    for i in range(1, n + 1):\n        for w in range(W + 1):\n            if weights[i - 1] > w:\n                dp[i][w] = dp[i - 1][w]\n            else:\n                dp[i][w] = max(dp[i - 1][w], dp[i - 1][w - weights[i - 1]] + values[i - 1])\n    return dp[n][W]\n```", "error": null, "raw_item": {"task_id": "algorithms_knapsack01", "prompt": "0/1 Knapsack: given weights, values, and capacity W, return the maximum achievable value. Use DP. weights and values are equal length. Return only the Python function code with no explanations.", "entry_point": "knapsack01", "canonical_solution": "def knapsack01(weights, values, W):\n    n=len(weights)\n    dp=[[0]*(W+1) for _ in range(n+1)]\n    for i in range(1,n+1):\n        for w in range(W+1):\n            dp[i][w]=dp[i-1][w]\n            if weights[i-1]<=w:\n                dp[i][w]=max(dp[i][w], values[i-1]+dp[i-1][w-weights[i-1]])\n    return dp[n][W]", "test": [{"input": [[2, 3, 4], [4, 5, 6], 5], "output": 9}, {"input": [[1, 2, 3], [6, 10, 12], 5], "output": 22}, {"input": [[5], [10], 5], "output": 10}, {"input": [[5], [10], 4], "output": 0}, {"input": [[], [], 10], "output": 0}]}}
{"timestamp_utc": "2025-09-27T12:17:23.060900", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 48, "question": "Write parse_csv_numbers(text) that parses a CSV string of integers separated by commas and newlines. Return a 2D list of integers. Ignore empty lines. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 8.845200300216675, "response": "```python\ndef parse_csv_numbers(text):\n    result = []\n    lines = text.splitlines()\n    for line in lines:\n        stripped = line.strip()\n        if stripped:\n            row = [int(x.strip()) for x in stripped.split(',')]\n            result.append(row)\n    return result\n```", "error": null, "raw_item": {"task_id": "custom_parse_csv_numbers", "prompt": "Write parse_csv_numbers(text) that parses a CSV string of integers separated by commas and newlines. Return a 2D list of integers. Ignore empty lines. Return only the Python function code with no explanations.", "entry_point": "parse_csv_numbers", "canonical_solution": "def parse_csv_numbers(text: str) -> list[list[int]]:\n    rows = []\n    for line in text.strip().splitlines():\n        if not line.strip():\n            continue\n        row = [int(x.strip()) for x in line.split(',') if x.strip()]\n        rows.append(row)\n    return rows", "test": [{"input": ["1,2,3\n4,5,6"], "output": [[1, 2, 3], [4, 5, 6]]}, {"input": ["10,20\n30\n\n40,50"], "output": [[10, 20], [30], [40, 50]]}, {"input": ["   7 , 8 ,9  "], "output": [[7, 8, 9]]}, {"input": [""], "output": []}]}}
{"timestamp_utc": "2025-09-27T12:17:35.337447", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 49, "question": "Write normalize_json_keys(obj) that recursively converts all dictionary keys in a JSON-like object to lowercase strings. Works for nested dicts and lists. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 11.274346113204956, "response": "```python\ndef normalize_json_keys(obj):\n    if isinstance(obj, dict):\n        return {k.lower(): normalize_json_keys(v) for k, v in obj.items()}\n    elif isinstance(obj, list):\n        return [normalize_json_keys(item) for item in obj]\n    else:\n        return obj\n```", "error": null, "raw_item": {"task_id": "custom_normalize_json_keys", "prompt": "Write normalize_json_keys(obj) that recursively converts all dictionary keys in a JSON-like object to lowercase strings. Works for nested dicts and lists. Return only the Python function code with no explanations.", "entry_point": "normalize_json_keys", "canonical_solution": "def normalize_json_keys(obj):\n    if isinstance(obj, dict):\n        return {str(k).lower(): normalize_json_keys(v) for k, v in obj.items()}\n    if isinstance(obj, list):\n        return [normalize_json_keys(x) for x in obj]\n    return obj", "test": [{"input": [{"Name": "Alice", "AGE": 30}], "output": {"name": "Alice", "age": 30}}, {"input": [[{"X": 1}, {"Y": 2}]], "output": [{"x": 1}, {"y": 2}]}, {"input": [{"Nested": {"KEY": 5}}], "output": {"nested": {"key": 5}}}, {"input": [123], "output": 123}]}}
{"timestamp_utc": "2025-09-27T12:18:36.697995", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 50, "question": "Write format_duration(seconds) that converts an integer number of seconds into a human-readable string using years, days, hours, minutes, and seconds. Skip units that are zero. Use plural form when needed. Example: 3661 → '1 hour, 1 minute, 1 second'. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 60.35911798477173, "response": "```python\ndef format_duration(seconds):\n    if seconds == 0:\n        return 'now'\n    units = [\n        ('year', 365 * 24 * 3600),\n        ('day', 24 * 3600),\n        ('hour', 3600),\n        ('minute', 60),\n        ('second', 1),\n    ]\n    parts = []\n    for name, secs_per_unit in units:\n        value = seconds // secs_per_unit\n        if value > 0:\n            parts.append(f'{value} {name}' + ('s' if value != 1 else ''))\n            seconds %= secs_per_unit\n    return ', '.join(parts)\n```", "error": null, "raw_item": {"task_id": "custom_format_duration", "prompt": "Write format_duration(seconds) that converts an integer number of seconds into a human-readable string using years, days, hours, minutes, and seconds. Skip units that are zero. Use plural form when needed. Example: 3661 → '1 hour, 1 minute, 1 second'. Return only the Python function code with no explanations.", "entry_point": "format_duration", "canonical_solution": "def format_duration(seconds: int) -> str:\n    units = [(\"year\", 365*24*3600), (\"day\", 24*3600), (\"hour\", 3600), (\"minute\", 60), (\"second\", 1)]\n    parts = []\n    for name, length in units:\n        if seconds >= length:\n            count, seconds = divmod(seconds, length)\n            parts.append(f\"{count} {name}{'s' if count != 1 else ''}\")\n    return \", \".join(parts) if parts else \"0 seconds\"", "test": [{"input": [0], "output": "0 seconds"}, {"input": [62], "output": "1 minute, 2 seconds"}, {"input": [3661], "output": "1 hour, 1 minute, 1 second"}, {"input": [31536000], "output": "1 year"}, {"input": [31556926], "output": "1 year, 6 hours, 9 minutes, 26 seconds"}]}}
{"timestamp_utc": "2025-09-27T12:18:48.162371", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 51, "question": "Write parse_key_value_config(text) that parses a configuration string with lines of the form 'key=value'. Ignore blank lines and lines starting with '#'. Return a dictionary with string keys and values converted to int if possible, else string. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 10.463088750839233, "response": "```python\ndef parse_key_value_config(text):\n    config = {}\n    lines = text.splitlines()\n    for line in lines:\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        if '=' in line:\n            key, value = line.split('=', 1)\n            key = key.strip()\n            value = value.strip()\n            try:\n                value = int(value)\n            except ValueError:\n                pass\n            config[key] = value\n    return config\n```", "error": null, "raw_item": {"task_id": "custom_parse_key_value_config", "prompt": "Write parse_key_value_config(text) that parses a configuration string with lines of the form 'key=value'. Ignore blank lines and lines starting with '#'. Return a dictionary with string keys and values converted to int if possible, else string. Return only the Python function code with no explanations.", "entry_point": "parse_key_value_config", "canonical_solution": "def parse_key_value_config(text: str) -> dict:\n    result = {}\n    for line in text.splitlines():\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        if '=' in line:\n            k,v = line.split('=',1)\n            v = v.strip()\n            if v.isdigit():\n                result[k.strip()] = int(v)\n            else:\n                result[k.strip()] = v\n    return result", "test": [{"input": ["a=1\nb=2\nc=hello"], "output": {"a": 1, "b": 2, "c": "hello"}}, {"input": ["#comment\nx=42\ny=text"], "output": {"x": 42, "y": "text"}}, {"input": [""], "output": {}}]}}
{"timestamp_utc": "2025-09-27T12:19:01.405762", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 52, "question": "Write pretty_print_matrix(matrix) that formats a 2D list of integers into a string where each row is space-separated and rows are separated by newlines. Columns should be aligned to the maximum width of the largest number. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 12.240630149841309, "response": "```python\ndef pretty_print_matrix(matrix):\n    if not matrix or not matrix[0]:\n        return ''\n    max_width = max(len(str(num)) for row in matrix for num in row)\n    formatted_rows = []\n    for row in matrix:\n        formatted = ' '.join(f\"{num:>{max_width}}\" for num in row)\n        formatted_rows.append(formatted)\n    return '\\n'.join(formatted_rows)\n```", "error": null, "raw_item": {"task_id": "custom_pretty_print_matrix", "prompt": "Write pretty_print_matrix(matrix) that formats a 2D list of integers into a string where each row is space-separated and rows are separated by newlines. Columns should be aligned to the maximum width of the largest number. Return only the Python function code with no explanations.", "entry_point": "pretty_print_matrix", "canonical_solution": "def pretty_print_matrix(matrix: list[list[int]]) -> str:\n    if not matrix:\n        return ''\n    col_widths = [max(len(str(row[i])) for row in matrix) for i in range(len(matrix[0]))]\n    lines = []\n    for row in matrix:\n        line = ' '.join(str(val).rjust(col_widths[i]) for i,val in enumerate(row))\n        lines.append(line)\n    return '\\n'.join(lines)", "test": [{"input": [[[1, 20], [300, 4]]], "output": "  1 20\n300  4"}, {"input": [[[5]]], "output": "5"}, {"input": [[]], "output": ""}]}}
{"timestamp_utc": "2025-09-27T12:19:47.847847", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 53, "question": "Write unique_permutations(s) that returns all distinct permutations of string s in lexicographic order. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 45.440314054489136, "response": "```python\ndef unique_permutations(s):\n    def backtrack(start, s_list):\n        if start == len(s_list):\n            result.append(''.join(s_list))\n            return\n        seen = set()\n        for i in range(start, len(s_list)):\n            if s_list[i] in seen:\n                continue\n            seen.add(s_list[i])\n            s_list[start], s_list[i] = s_list[i], s_list[start]\n            backtrack(start + 1, s_list)\n            s_list[start], s_list[i] = s_list[i], s_list[start]\n    s_list = sorted(list(s))\n    result = []\n    backtrack(0, s_list)\n    return result\n```", "error": null, "raw_item": {"task_id": "custom_unique_permutations", "prompt": "Write unique_permutations(s) that returns all distinct permutations of string s in lexicographic order. Return only the Python function code with no explanations.", "entry_point": "unique_permutations", "canonical_solution": "def unique_permutations(s: str) -> list[str]:\n    from itertools import permutations\n    return sorted(set(''.join(p) for p in permutations(s)))", "test": [{"input": ["aab"], "output": ["aab", "aba", "baa"]}, {"input": ["abc"], "output": ["abc", "acb", "bac", "bca", "cab", "cba"]}, {"input": ["x"], "output": ["x"]}]}}
{"timestamp_utc": "2025-09-27T12:20:07.910563", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 54, "question": "Write format_prime_factors(n) that returns the prime factorization of integer n as a string in the form 'p1^a1 * p2^a2 ...'. If exponent is 1, omit the '^1'. Example: 60 → '2^2 * 3 * 5'. Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 19.059072017669678, "response": "```python\ndef format_prime_factors(n):\n    if n <= 1:\n        return str(n)\n    factors = []\n    count = 0\n    while n % 2 == 0:\n        count += 1\n        n //= 2\n    if count:\n        factors.append(f\"2^{count}\" if count > 1 else \"2\")\n    i = 3\n    while i * i <= n:\n        count = 0\n        while n % i == 0:\n            count += 1\n            n //= i\n        if count:\n            factors.append(f\"{i}^{count}\" if count > 1 else str(i))\n        i += 2\n    if n > 1:\n        factors.append(str(n))\n    return ' * '.join(factors)\n```", "error": null, "raw_item": {"task_id": "custom_format_prime_factors", "prompt": "Write format_prime_factors(n) that returns the prime factorization of integer n as a string in the form 'p1^a1 * p2^a2 ...'. If exponent is 1, omit the '^1'. Example: 60 → '2^2 * 3 * 5'. Return only the Python function code with no explanations.", "entry_point": "format_prime_factors", "canonical_solution": "def format_prime_factors(n: int) -> str:\n    factors = []\n    d = 2\n    while d*d <= n:\n        count = 0\n        while n % d == 0:\n            n //= d\n            count += 1\n        if count:\n            factors.append(f\"{d}^{count}\" if count>1 else str(d))\n        d += 1\n    if n > 1:\n        factors.append(str(n))\n    return ' * '.join(factors)", "test": [{"input": [60], "output": "2^2 * 3 * 5"}, {"input": [13], "output": "13"}, {"input": [1024], "output": "2^10"}]}}
{"timestamp_utc": "2025-09-27T12:23:47.406060", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 55, "question": "Write validate_expression(expr) that checks if a string is a valid arithmetic expression containing only digits, +, -, *, /, parentheses, and spaces. Return True if valid, else False. Parentheses must be balanced and no invalid sequences allowed (e.g. '*/', '++', empty parentheses). Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 218.493803024292, "response": "```python\nimport re\n\ndef validate_expression(expr):\n    # Check allowed characters\n    if not re.match(r'^[0-9+\\-*/() ]*$', expr):\n        return False\n    \n    i = [0]\n    \n    def skip_spaces():\n        while i[0] < len(expr) and expr[i[0]] == ' ':\n            i[0] += 1\n    \n    def parse_expression():\n        skip_spaces()\n        parse_term()\n        skip_spaces()\n        while i[0] < len(expr) and expr[i[0]] in '+-':\n            i[0] += 1\n            skip_spaces()\n            parse_term()\n            skip_spaces()\n    \n    def parse_term():\n        skip_spaces()\n        parse_factor()\n        skip_spaces()\n        while i[0] < len(expr) and expr[i[0]] in '*/':\n            i[0] += 1\n            skip_spaces()\n            parse_factor()\n            skip_spaces()\n    \n    def parse_factor():\n        skip_spaces()\n        if i[0] >= len(expr):\n            raise ValueError\n        c = expr[i[0]]\n        if c.isdigit():\n            while i[0] < len(expr) and expr[i[0]].isdigit():\n                i[0] += 1\n            return\n        if c in '+-':\n            i[0] += 1\n            skip_spaces()\n            parse_factor()\n            return\n        if c == '(':\n            i[0] += 1\n            skip_spaces()\n            parse_expression()\n            skip_spaces()\n            if i[0] >= len(expr) or expr[i[0]] != ')':\n                raise ValueError\n            i[0] += 1\n            return\n        raise ValueError\n    \n    try:\n        parse_expression()\n        skip_spaces()\n        if i[0] != len(expr):\n            return False\n        return True\n    except ValueError:\n        return False\n```", "error": null, "raw_item": {"task_id": "custom_validate_expression", "prompt": "Write validate_expression(expr) that checks if a string is a valid arithmetic expression containing only digits, +, -, *, /, parentheses, and spaces. Return True if valid, else False. Parentheses must be balanced and no invalid sequences allowed (e.g. '*/', '++', empty parentheses). Return only the Python function code with no explanations.", "entry_point": "validate_expression", "canonical_solution": "import re\ndef validate_expression(expr: str) -> bool:\n    expr = expr.strip()\n    if not expr:\n        return False\n    # invalid sequences\n    if re.search(r'[+*/-]{2,}', expr):\n        return False\n    if re.search(r'\\(\\)', expr):\n        return False\n    # parentheses balance\n    stack = []\n    for c in expr:\n        if c == '(':\n            stack.append(c)\n        elif c == ')':\n            if not stack:\n                return False\n            stack.pop()\n    if stack:\n        return False\n    # final safety: try eval\n    try:\n        eval(expr, {\"__builtins__\":None}, {})\n    except:\n        return False\n    return True", "test": [{"input": ["1+2*(3-4)"], "output": true}, {"input": ["(5+6"], "output": false}, {"input": ["1++2"], "output": false}, {"input": ["( )"], "output": false}, {"input": ["10/2-3"], "output": true}]}}
{"timestamp_utc": "2025-09-27T12:24:02.204327", "dataset_file": "MyFinalOwnBench.jsonl", "dataset_index": 56, "question": "Write parse_roman(s) that converts a valid Roman numeral string into an integer. Supports numerals up to 3999 (MMMCMXCIX). Return only the Python function code with no explanations.", "provider": "grok", "model": "grok-4", "region": null, "success": true, "response_time": 13.795635223388672, "response": "```python\ndef parse_roman(s):\n    roman_values = {'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, 'D': 500, 'M': 1000}\n    total = 0\n    for i in range(len(s)):\n        if i < len(s) - 1 and roman_values[s[i]] < roman_values[s[i + 1]]:\n            total -= roman_values[s[i]]\n        else:\n            total += roman_values[s[i]]\n    return total\n```", "error": null, "raw_item": {"task_id": "custom_parse_roman", "prompt": "Write parse_roman(s) that converts a valid Roman numeral string into an integer. Supports numerals up to 3999 (MMMCMXCIX). Return only the Python function code with no explanations.", "entry_point": "parse_roman", "canonical_solution": "def parse_roman(s: str) -> int:\n    values = {\"I\":1, \"V\":5, \"X\":10, \"L\":50, \"C\":100, \"D\":500, \"M\":1000}\n    total = 0\n    i = 0\n    while i < len(s):\n        if i+1 < len(s) and values[s[i]] < values[s[i+1]]:\n            total += values[s[i+1]] - values[s[i]]\n            i += 2\n        else:\n            total += values[s[i]]\n            i += 1\n    return total", "test": [{"input": ["III"], "output": 3}, {"input": ["IX"], "output": 9}, {"input": ["LVIII"], "output": 58}, {"input": ["MCMXCIV"], "output": 1994}, {"input": ["MMMCMXCIX"], "output": 3999}]}}
